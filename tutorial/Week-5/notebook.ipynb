{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "352710b7-8462-4e32-9af7-59b20a0edcf5",
   "metadata": {},
   "source": [
    "# OpenAI Multimodal\n",
    "\n",
    "Let me introduce you to something amazing called GPT. Think of GPT as a very smart computer program that can understand both text and images. It can read and write just like a human, and it can also look at pictures and understand what they are. Imagine having a tool that can help you with writing, reading, and even looking at photos to tell you what they show. It's like having a really smart assistant who can do many things at once!\n",
    "\n",
    "讓我向您介紹一個非常了不起的東西，叫做 GPT。想像一下，GPT 就像是一個非常聰明的電腦程式，它能理解文字和圖片。它可以像人一樣閱讀和寫作，還能看圖片並理解它們的內容。想像一下，有一個工具可以幫助您寫作、閱讀，甚至看照片並告訴您照片中的內容。這就像擁有一個非常聰明的助理，可以同時做很多事情！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc181dc-846b-47ba-97e5-3d7526d0702d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Define the HTML to display images side by side\n",
    "html = \"\"\"\n",
    "<div style=\"display: flex; justify-content: space-around;\">\n",
    "    <div>\n",
    "        <img src=\"nDATs9kmQk7sNrx5ELrhZ.png\" height=\"900\" width=\"600\" />\n",
    "    </div>\n",
    "    <div>\n",
    "        <img src=\"yghzBMOFHZRKGvRuw6AM6.png\" height=\"900\" width=\"600\" />\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# Display the HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c438f085-a035-4dc7-b14c-caf726223804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8180ba97-5e95-4e6f-8318-97562c91e9ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from src.initialization import credential_init\n",
    "\n",
    "credential_init()\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-2024-05-13\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe6a598-704b-4666-bd3e-bc1113a6db8a",
   "metadata": {},
   "source": [
    "GPT does not see an image, but something strange called base64 foramt string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284f0d20-8fa9-4c5f-abb1-5ecc17dd084b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "\n",
    "from PIL import Image\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    \n",
    "    # Convert Image to Base64 String\n",
    "    \n",
    "    # Open the Image:\n",
    "    with Image.open(image_path) as image:\n",
    "        \n",
    "        # Save the Image to a Buffer\n",
    "        buffered = io.BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        \n",
    "        # Encode the Image to Base64\n",
    "        image_str = base64.b64encode(buffered.getvalue())\n",
    "    \n",
    "    return image_str.decode('utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd3a825-88de-4355-99ab-4955f5107d5a",
   "metadata": {},
   "source": [
    "### 1. Convert Image Path to Base64 String\n",
    "\n",
    "- The image path is constructed and passed to image_to_base64 to get the Base64 string of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348bce4f-5c4c-4122-bdf6-bd90578b9e32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.io.path_definition import get_project_dir\n",
    "\n",
    "\n",
    "image_str = image_to_base64(os.path.join(get_project_dir(), 'tutorial/Week-5/nDATs9kmQk7sNrx5ELrhZ.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c6d8b3-3d42-4ec0-8091-d2c27486ef0d",
   "metadata": {},
   "source": [
    "### 2. Create a Human Message\n",
    "\n",
    "- A HumanMessage object is created containing two parts:\n",
    "    - A text message asking \"What is in this image?\"\n",
    "    - An image URL containing the Base64 encoded image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918e27e1-5b2b-41c2-bec2-fe0b1e2c7fcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "human_message = HumanMessage(content=[{'type': 'text', \n",
    "                                       'text': 'What is in this image?'},\n",
    "                                      {'type': 'image_url',\n",
    "                                       'image_url': {\n",
    "                                           'url': f\"data:image/jpeg;base64,{image_str}\"}\n",
    "                                      }])\n",
    "\n",
    "# Create a Prompt Template\n",
    "prompt = ChatPromptTemplate.from_messages([human_message])\n",
    "\n",
    "# Generate the Chain\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399b270-924a-4fbe-bf9c-d2f402cf1f51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain.invoke(input={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ea08b2-0f7e-4765-96bc-63937d7e5017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image as Image_IPYTHON\n",
    "\n",
    "Image_IPYTHON(url=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8584e3-ef7a-454a-b4b4-b28e74fb2a16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "human_message = HumanMessage(content=[{'type': 'text', \n",
    "                                       'text': 'What is in this image?'},\n",
    "                                      {'type': 'image_url',\n",
    "                                       'image_url': {\n",
    "                                           'url': \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"}\n",
    "                                      }])\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([human_message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b2db3-00cb-423c-ae4d-0d83571f2fec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = prompt|model\n",
    "\n",
    "chain.invoke(input={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea20aa0e-ffbd-4d24-a77f-d30ed220dbed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([human_message])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1640f6fe-7ee9-469d-931d-f80be9902c66",
   "metadata": {},
   "source": [
    "## 回家作業1: 用LCEL建立一個影像分析函數，輸入為檔案名稱，輸出為content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbbc82b-98a2-44d8-bec3-5f723ef4b00f",
   "metadata": {},
   "source": [
    "## Multiple Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fd108c-16ab-49e4-8488-bc21fda6f194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "human_message = HumanMessage(content=[{'type': 'text', \n",
    "                                       'text': 'What are in these images? Is there any difference between them?'},\n",
    "                                      {'type': 'image_url',\n",
    "                                       'image_url': {\n",
    "                                           'url': \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"}\n",
    "                                      },\n",
    "                                      {'type': 'image_url',\n",
    "                                       'image_url': {\n",
    "                                           'url': \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"}\n",
    "                                      }])\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([human_message])\n",
    "model.invoke(prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37a324e-30cb-43e8-a3d2-5f61a0c2400a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.invoke(prompt.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2163a620-a80e-4800-8e2d-ab6d964eb8e3",
   "metadata": {},
   "source": [
    "# Text Splitting\n",
    "\n",
    "https://www.youtube.com/watch?v=8OJC21T2SL4\n",
    "\n",
    "- Character Split\n",
    "- Recursive Character Split\n",
    "- Document Specific Splitting\n",
    "- Semantic Splitting\n",
    "- Agentic Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aad071-44b8-422e-97df-44b323112ffd",
   "metadata": {},
   "source": [
    "1. Context Limit: Limit on the amount of words/tokens you can pass to the language model\n",
    "2. Signal to Noise: Remove information that isn't helpful to your task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8095c9b4-4c37-4c0f-9ed9-09afb4af019b",
   "metadata": {},
   "source": [
    "## Character Splitting\n",
    "\n",
    "Character splitting is the most basic form of splitting up your text. It is the process of simply dividing your text into N-character sized chunks regardless of their content or form\n",
    "\n",
    "This method isn's recommended for any applications - but it's a great starting point for us to understand the basics.\n",
    "\n",
    "- Pros: Easy & Simple\n",
    "- Cons: Very rigid and doesn't take into account the structure of your text\n",
    "\n",
    "Concepts to know:\n",
    "\n",
    "- Chunk Size - The number of characters you would like in your chunks. 50, 100, 100000, etc.\n",
    "- Chunk Overlap - The amount you would like your sequential chunks to overlap. This is to try to avoid cutting a single piece of context into multiple pieces. This will create duplicate data across chunks.\n",
    "\n",
    "\n",
    "字元分割是將文本分割成最基本形式的方式。它是將文本簡單地分割成N個字元大小的區塊，而不考慮其內容或形式。\n",
    "\n",
    "這種方法不推薦用於任何應用，但它是我們了解基礎知識的絕佳起點。\n",
    "\n",
    "優點：簡單且容易\n",
    "缺點：非常僵硬，不考慮文本結構\n",
    "需要了解的概念：\n",
    "\n",
    "區塊大小：您希望每個區塊包含的字元數量。例如，50，100，100000等。\n",
    "區塊重疊：您希望順序區塊之間重疊的字元數量。這是為了避免將單個上下文切割成多個部分。這將在區塊之間創建重複數據。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c284c380-34dc-4608-8ef0-cc76872ef7b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"This is the text I would like to chunk up. It is the example text for this exercise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e0fd77-62f6-4205-b8eb-9d256d39ea45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=35, chunk_overlap=0, separator='', strip_whitespace=False)\n",
    "text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09c8219-d608-478f-8915-0f0b3d821947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=35, chunk_overlap=4, separator='', strip_whitespace=False)\n",
    "text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0c9cfc-32db-47af-a3f2-6525e4dbd012",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src='https://chunkviz.up.railway.app/', width=800, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7707743-48d5-413f-bcd0-cd91eb9e92b9",
   "metadata": {},
   "source": [
    "- Separators are the character(s) sequences you would like to split on. Say you wanted to chunk your data at `ch`, you can specify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b66788-5329-456d-b66a-ec9ea9d71de9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=4, chunk_overlap=0, separator='ch')\n",
    "text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c6f575-b0dd-4671-a123-9270385ed0de",
   "metadata": {},
   "source": [
    "## Recursive character splitting\n",
    "\n",
    "This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text.\n",
    "\n",
    "這種文本分割器是針對一般文本推薦的。它是由一個字元列表參數化的，按照順序嘗試在這些字元上進行分割，直到區塊足夠小。預設的列表是 [\"\\n\\n\", \"\\n\", \" \", \"\"]. 這樣做的效果是盡可能將所有段落（然後是句子，再然後是單詞）保持在一起，因為這些通常看起來是語義上最相關的文本片段。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afd20fd-6ed5-451a-87d7-3431378a7d10",
   "metadata": {},
   "source": [
    "### CNN (Cable News Network) 數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4264fc48-d24b-4495-ae47-0d1d2d2885da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_news = pd.read_csv(\"tutorial/Week-5/CNN_Articels_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b0d699-2967-4ed9-8da8-e0e483058686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_news.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8934227c-9e2a-4313-b56a-9ce071ec58c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = df_news.iloc[0]['Article text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f73a658-81a3-4ba7-a044-b740c8b8da91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af29441-b7ce-4548-9ed7-821d3f0fe426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=65, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6815b8-fa1d-4e27-a13e-d8faa0948a95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66fe7ac-ec77-4bb4-a832-f71945c53a02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78172450-dc51-45ba-911f-4ea02c42c1d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cce50f6-d7ff-4cc1-a8df-e8cf5a921945",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3391c09-6986-41ac-8fbd-7ed8aa154143",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8185f66-01bc-4257-ac99-497f3774209c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b9a0eb-97fe-42bf-bbbd-db625f4944ac",
   "metadata": {},
   "source": [
    "# **** 預計第一個小時結束 ****\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18358e5-6541-4a6d-92c2-4d4ac24923c1",
   "metadata": {},
   "source": [
    "## Document Specific Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adabbb85-5001-41b7-9994-169b797aec68",
   "metadata": {},
   "source": [
    "### Markdown splitter\n",
    "\n",
    "This code snippet demonstrates how to use LangChain's MarkdownTextSplitter to split a Markdown text document into smaller chunks. The MarkdownTextSplitter class is designed to handle Markdown-specific structure, making it easier to process and retrieve information from Markdown documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3d4354-5d87-4890-8a7b-83a03a8251a4",
   "metadata": {},
   "source": [
    "### 1. Import LangChain Components\n",
    "\n",
    "- Ensure that the necessary components from LangChain are imported. This might include MarkdownTextSplitter.\n",
    "- 確保導入 LangChain 的必要組件。這可能包括 MarkdownTextSplitter。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fab597-e0ae-416d-8951-8aac151abfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2629ee7b-e53a-4c78-9612-4911cf9965ab",
   "metadata": {},
   "source": [
    "### 2. Initialize the Text Splitter\n",
    "\n",
    "- The MarkdownTextSplitter is initialized with a chunk_size of 40 and chunk_overlap of 0. This means each chunk will contain up to 40 characters, and there will be no overlap between chunks.\n",
    "- MarkdownTextSplitter 被初始化為 chunk_size 為 40，chunk_overlap 為 0。這意味著每個塊將包含最多 40 個字符，並且塊之間不會重疊。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b9c0b1-6c02-4060-9e58-93e97de62332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = MarkdownTextSplitter(chunk_size=40, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ea8893-3ebc-481a-8c9d-57fd1d9c36b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_text = \"\"\"\n",
    "# Fun in Califormia\n",
    "\n",
    "## Driving\n",
    "\n",
    "Try driving on the 1 down to San Diego\n",
    "\n",
    "### Food\n",
    "\n",
    "Make sure to eat a burrito while you're there\n",
    "\n",
    "## Hiking\n",
    "\n",
    "Go to Yosemite\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080cc74a-1138-4d78-aa8c-029b7d203e31",
   "metadata": {},
   "source": [
    "### 3. Create Documents from Markdown Text\n",
    "\n",
    "- The create_documents method of MarkdownTextSplitter is used to split the Markdown text into smaller chunks based on the specified chunk size.\n",
    "- 使用 MarkdownTextSplitter 的 create_documents 方法根據指定的塊大小將 Markdown 文本拆分成較小的部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e6e79b-8cca-4541-ae8c-6d8cca989df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter.create_documents([markdown_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b43051b-eccb-4a36-bd69-f89ff0f86b3e",
   "metadata": {},
   "source": [
    "### Python splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1daf779-2204-4c48-b397-3dc7fa956b15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import PythonCodeTextSplitter\n",
    "\n",
    "python_text = \"\"\"\n",
    "class Person:\n",
    "    def __init__(self, name, age):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "\n",
    "p1 = Person(\"John\", 36)\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "\"\"\"\n",
    "\n",
    "python_splitter = PythonCodeTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "python_splitter.create_documents([python_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54945bfe-f512-451c-9dda-d3477837fd77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
    "\n",
    "\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=100, chunk_overlap=0\n",
    ")\n",
    "python_docs = python_splitter.create_documents([python_text])\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4c3479-5616-450f-aacc-bfb4b623f6cc",
   "metadata": {},
   "source": [
    "### split code: https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/code_splitter/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
