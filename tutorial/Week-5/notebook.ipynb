{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "352710b7-8462-4e32-9af7-59b20a0edcf5",
   "metadata": {},
   "source": [
    "# OpenAI Multimodal\n",
    "\n",
    "Let me introduce you to something amazing called GPT. Think of GPT as a very smart computer program that can understand both text and images. It can read and write just like a human, and it can also look at pictures and understand what they are. Imagine having a tool that can help you with writing, reading, and even looking at photos to tell you what they show. It's like having a really smart assistant who can do many things at once!\n",
    "\n",
    "讓我向您介紹一個非常了不起的東西，叫做 GPT。想像一下，GPT 就像是一個非常聰明的電腦程式，它能理解文字和圖片。它可以像人一樣閱讀和寫作，還能看圖片並理解它們的內容。想像一下，有一個工具可以幫助您寫作、閱讀，甚至看照片並告訴您照片中的內容。這就像擁有一個非常聰明的助理，可以同時做很多事情！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc181dc-846b-47ba-97e5-3d7526d0702d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: space-around;\">\n",
       "    <div>\n",
       "        <img src=\"nDATs9kmQk7sNrx5ELrhZ.png\" height=\"900\" width=\"600\" />\n",
       "    </div>\n",
       "    <div>\n",
       "        <img src=\"754703591882697477.png\" height=\"900\" width=\"600\" />\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Define the HTML to display images side by side\n",
    "html = \"\"\"\n",
    "<div style=\"display: flex; justify-content: space-around;\">\n",
    "    <div>\n",
    "        <img src=\"nDATs9kmQk7sNrx5ELrhZ.png\" height=\"900\" width=\"600\" />\n",
    "    </div>\n",
    "    <div>\n",
    "        <img src=\"754703591882697477.png\" height=\"900\" width=\"600\" />\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# Display the HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c438f085-a035-4dc7-b14c-caf726223804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8180ba97-5e95-4e6f-8318-97562c91e9ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MengChieh\\Miniconda3\\envs\\llm_examples\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "from src.initialization import credential_init\n",
    "\n",
    "credential_init()\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-2024-05-13\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe6a598-704b-4666-bd3e-bc1113a6db8a",
   "metadata": {},
   "source": [
    "GPT does not see an image, but something strange called base64 foramt string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "284f0d20-8fa9-4c5f-abb1-5ecc17dd084b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "\n",
    "from PIL import Image\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    \n",
    "    with Image.open(image_path) as image:\n",
    "        \n",
    "        # Save the Image to a Buffer\n",
    "        buffered = io.BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        \n",
    "        # Encode the Image to Base64\n",
    "        image_str = base64.b64encode(buffered.getvalue())\n",
    "    \n",
    "    return image_str.decode('utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd3a825-88de-4355-99ab-4955f5107d5a",
   "metadata": {},
   "source": [
    "### 1. Convert Image Path to Base64 String\n",
    "\n",
    "- The image path is constructed and passed to image_to_base64 to get the Base64 string of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "348bce4f-5c4c-4122-bdf6-bd90578b9e32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.io.path_definition import get_project_dir\n",
    "\n",
    "image_str = image_to_base64(os.path.join(get_project_dir(), 'tutorial/Week-5/754703591882697477.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cdde5ed-0e16-45c5-b3eb-28eb59c9700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c6d8b3-3d42-4ec0-8091-d2c27486ef0d",
   "metadata": {},
   "source": [
    "### 2. Create a Human Message\n",
    "\n",
    "- A HumanMessage object is created containing two parts:\n",
    "    - A text message asking \"What is in this image?\"\n",
    "    - An image URL containing the Base64 encoded image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62783992-178b-449a-beaf-ad5153d0642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python f-string\n",
    "\n",
    "text = f\"今天的天氣是: {天氣}\"\n",
    "天氣 = \"陰天\"\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "918e27e1-5b2b-41c2-bec2-fe0b1e2c7fcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "human_message = HumanMessage(content=[{'type': 'text', \n",
    "                                       'text': 'What is in this image?'},\n",
    "                                      {'type': 'image_url',\n",
    "                                       'image_url': {\n",
    "                                           'url': f\"data:image/jpeg;base64,{image_str}\"}\n",
    "                                      }])\n",
    "\n",
    "# Create a Prompt Template\n",
    "prompt = ChatPromptTemplate.from_messages([human_message])\n",
    "\n",
    "# Generate the Chain\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d399b270-924a-4fbe-bf9c-d2f402cf1f51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = chain.invoke(input={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b926554-0a4a-4ae5-9e6b-1d4c1c0a4482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image features a person dressed in a detailed and elaborate costume, likely inspired by Japanese folklore or anime. The costume includes fox ears and multiple fox tails, suggesting a kitsune (a mythical fox spirit) theme. The person is wearing a traditional-style outfit with a red and blue color scheme, and accessories such as a choker and a hair ornament. The overall look is reminiscent of cosplay, where individuals dress up as characters from various media.\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ec6d71-c535-4be7-a95a-9fc561eb53d2",
   "metadata": {},
   "source": [
    "## Make the input image as a dynamic variable\n",
    "\n",
    "- With PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d7ab65-4d28-4684-927d-b80d44d72b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "\n",
    "HumanMessagePromptTemplate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bce1bb-8ba8-4be1-b8c4-4748fbf9c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(\n",
    "    template=[\n",
    "        {'type': 'text', 'text': 'What is in this image?'},\n",
    "        {'type': 'image_url', 'image_url': {'url': 'data:image/jpeg;base64,{image_str}'}}\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Create a Prompt Template\n",
    "prompt = ChatPromptTemplate.from_messages([human_message_template])\n",
    "\n",
    "# Generate the Chain\n",
    "chain = prompt|model\n",
    "\n",
    "chain.invoke(input={\"image_str\": image_str})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475d85fc-b348-4460-aa72-a282401e78a5",
   "metadata": {},
   "source": [
    "將`問題`和`圖片`都變成輸入變數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1754f003-b076-4979-a87f-e46dcf6ed947",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message_template = HumanMessagePromptTemplate.from_template(\n",
    "    template=[\n",
    "        {'type': 'text', 'text': '{question}'},\n",
    "        {'type': 'image_url', 'image_url': {'url': 'data:image/jpeg;base64,{image_str}'}}\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Create a Prompt Template\n",
    "prompt = ChatPromptTemplate.from_messages([human_message_template])\n",
    "\n",
    "# Generate the Chain\n",
    "chain = prompt|model\n",
    "\n",
    "chain.invoke(input={\"image_str\": image_str, \"question\": \"Are you able to connect this image with any anime character?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcd4818-6017-4844-ad0c-136d457cb388",
   "metadata": {},
   "source": [
    "範圍似乎太廣了，給更多的條件: 來源是Azur Lane(碧藍航線)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dd542e-8ca5-45d0-bba1-1e2749f1788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(input={\"image_str\": image_str, \"question\": \"Are you able to connect this image with any anime character? Hint: Azur Lane.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9e1ad8-f216-481d-b70c-f81bf3ded7ab",
   "metadata": {},
   "source": [
    "將Chain更加一步強化: 圖片路徑作為輸入變數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3f8a2e-f01b-4e18-8b01-e2635854217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "# human_prompt = PromptTemplate(template='existing ingredients:[{existing_ingredients}]; '\n",
    "#                                        'suggested ingredients: [{suggested_ingredients}]\\n; '\n",
    "#                                        'format instruction: {format_instructions}',\n",
    "#                               input_variables=[\"existing_ingredients\", \"suggested_ingredients\"],\n",
    "#                               partial_variables={\"format_instructions\": format_instructions}\n",
    "#                               )\n",
    "\n",
    "# human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "# chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "#                                                 human_message\n",
    "#                                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55daf597-22f3-45ae-a20a-5cb9f357a6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(\n",
    "    template=[\n",
    "        {'type': 'text', 'text': '{question}'},\n",
    "        {'type': 'image_url', 'image_url': {'url': 'data:image/jpeg;base64,{image_str}'}}\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Create a Prompt Template\n",
    "prompt = ChatPromptTemplate.from_messages([human_message_template])\n",
    "\n",
    "# Generate the Chain\n",
    "chain = RunnablePassthrough.assign(image_str=itemgetter('image_path')|RunnableLambda(image_to_base64))|prompt|model|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16643141-1d27-4f61-bb40-4a713390ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = os.path.join(get_project_dir(), 'tutorial/Week-5/nDATs9kmQk7sNrx5ELrhZ.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d5e1db-3475-47fd-8a88-2e615ca6fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = RunnablePassthrough.assign(image_str=itemgetter('image_path')|RunnableLambda(image_to_base64))|prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42ac928-6d76-4251-a1ba-78f5d77e3e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"question\": \"What is in this image?\",\n",
    "              \"image_path\": image_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e82f97-0d3e-4fbd-ae9f-8f6678feca40",
   "metadata": {},
   "source": [
    "直接將圖片URL作為變數輸入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ea08b2-0f7e-4765-96bc-63937d7e5017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image as Image_IPYTHON\n",
    "\n",
    "Image_IPYTHON(url=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8584e3-ef7a-454a-b4b4-b28e74fb2a16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "human_message_template = HumanMessagePromptTemplate.from_template(\n",
    "    template=[\n",
    "        {'type': 'text', 'text': '{question}'},\n",
    "        {'type': 'image_url', 'image_url': {'url': '{image_url}'}}\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Create a Prompt Template\n",
    "prompt = ChatPromptTemplate.from_messages([human_message_template])\n",
    "\n",
    "# Generate the Chain\n",
    "chain = RunnablePassthrough.assign(image_url=itemgetter('url'))|prompt|model|StrOutputParser()\n",
    "\n",
    "url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
    "                                   \n",
    "chain.invoke({\"question\": \"What is in this image?\",\n",
    "              \"url\": url})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1640f6fe-7ee9-469d-931d-f80be9902c66",
   "metadata": {},
   "source": [
    "## 回家作業1: 用LCEL建立一個影像分析函數，輸入為檔案名稱，輸出為content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbbc82b-98a2-44d8-bec3-5f723ef4b00f",
   "metadata": {},
   "source": [
    "## Multiple Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fd108c-16ab-49e4-8488-bc21fda6f194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "human_message_template = HumanMessagePromptTemplate.from_template(\n",
    "    template=[{'type': 'text', \n",
    "               'text': 'What are in these images? Is there any difference between them?'},\n",
    "              {'type': 'image_url',\n",
    "               'image_url': {\n",
    "                   'url': \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"}\n",
    "              },\n",
    "              {'type': 'image_url',\n",
    "               'image_url': {\n",
    "                   'url': \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"}\n",
    "              }],\n",
    ")\n",
    "\n",
    "# Create a Prompt Template\n",
    "prompt = ChatPromptTemplate.from_messages([human_message_template])\n",
    "\n",
    "model.invoke(prompt.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdbf6a0-0c39-4b77-ba13-1a2b1b93d073",
   "metadata": {},
   "source": [
    "有啥點子想試試看的嗎? 現場實操，希望不會翻車"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2163a620-a80e-4800-8e2d-ab6d964eb8e3",
   "metadata": {},
   "source": [
    "# Text Splitting\n",
    "\n",
    "https://www.youtube.com/watch?v=8OJC21T2SL4\n",
    "\n",
    "- Character Split\n",
    "- Recursive Character Split\n",
    "- Document Specific Splitting\n",
    "- Semantic Splitting\n",
    "- Agentic Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aad071-44b8-422e-97df-44b323112ffd",
   "metadata": {},
   "source": [
    "1. Context Limit: Limit on the amount of words/tokens you can pass to the language model\n",
    "2. Signal to Noise: Remove information that isn't helpful to your task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8095c9b4-4c37-4c0f-9ed9-09afb4af019b",
   "metadata": {},
   "source": [
    "## Character Splitting\n",
    "\n",
    "Character splitting is the most basic form of splitting up your text. It is the process of simply dividing your text into N-character sized chunks regardless of their content or form\n",
    "\n",
    "This method isn's recommended for any applications - but it's a great starting point for us to understand the basics.\n",
    "\n",
    "- Pros: Easy & Simple\n",
    "- Cons: Very rigid and doesn't take into account the structure of your text\n",
    "\n",
    "Concepts to know:\n",
    "\n",
    "- Chunk Size - The number of characters you would like in your chunks. 50, 100, 100000, etc.\n",
    "- Chunk Overlap - The amount you would like your sequential chunks to overlap. This is to try to avoid cutting a single piece of context into multiple pieces. This will create duplicate data across chunks.\n",
    "\n",
    "\n",
    "字元分割是將文本分割成最基本形式的方式。它是將文本簡單地分割成N個字元大小的區塊，而不考慮其內容或形式。\n",
    "\n",
    "這種方法不推薦用於任何應用，但它是我們了解基礎知識的絕佳起點。\n",
    "\n",
    "優點：簡單且容易\n",
    "缺點：非常僵硬，不考慮文本結構\n",
    "需要了解的概念：\n",
    "\n",
    "區塊大小：您希望每個區塊包含的字元數量。例如，50，100，100000等。\n",
    "區塊重疊：您希望順序區塊之間重疊的字元數量。這是為了避免將單個上下文切割成多個部分。這將在區塊之間創建重複數據。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c284c380-34dc-4608-8ef0-cc76872ef7b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"This is the text I would like to chunk up. It is the example text for this exercise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e0fd77-62f6-4205-b8eb-9d256d39ea45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=35, chunk_overlap=0, separator='', strip_whitespace=False)\n",
    "text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09c8219-d608-478f-8915-0f0b3d821947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=35, chunk_overlap=4, separator='', strip_whitespace=False)\n",
    "text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0c9cfc-32db-47af-a3f2-6525e4dbd012",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src='https://chunkviz.up.railway.app/', width=800, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7707743-48d5-413f-bcd0-cd91eb9e92b9",
   "metadata": {},
   "source": [
    "- Separators are the character(s) sequences you would like to split on. Say you wanted to chunk your data at `ch`, you can specify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b66788-5329-456d-b66a-ec9ea9d71de9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=4, chunk_overlap=0, separator='ch')\n",
    "text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c6f575-b0dd-4671-a123-9270385ed0de",
   "metadata": {},
   "source": [
    "## Recursive character splitting\n",
    "\n",
    "This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text.\n",
    "\n",
    "這種文本分割器是針對一般文本推薦的。它是由一個字元列表參數化的，按照順序嘗試在這些字元上進行分割，直到區塊足夠小。預設的列表是 [\"\\n\\n\", \"\\n\", \" \", \"\"]. 這樣做的效果是盡可能將所有段落（然後是句子，再然後是單詞）保持在一起，因為這些通常看起來是語義上最相關的文本片段。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afd20fd-6ed5-451a-87d7-3431378a7d10",
   "metadata": {},
   "source": [
    "### CNN (Cable News Network) 數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4264fc48-d24b-4495-ae47-0d1d2d2885da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_news = pd.read_csv(\"tutorial/Week-5/CNN_Articels_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b0d699-2967-4ed9-8da8-e0e483058686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_news.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8934227c-9e2a-4313-b56a-9ce071ec58c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = df_news.iloc[0]['Article text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f73a658-81a3-4ba7-a044-b740c8b8da91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e355ed-4699-41a6-9515-84d91a50da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af29441-b7ce-4548-9ed7-821d3f0fe426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=65, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56beb122-9c77-41ba-881c-6d59f96ac470",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=65, chunk_overlap=0, separators=[\",\", \".\", \"?\", \"!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6815b8-fa1d-4e27-a13e-d8faa0948a95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66fe7ac-ec77-4bb4-a832-f71945c53a02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(documents[0])\n",
    "print(len(documents[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78172450-dc51-45ba-911f-4ea02c42c1d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(documents[1])\n",
    "print(len(documents[1].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e677e9-562a-4386-85a5-2a35f55fe48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents[2])\n",
    "print(len(documents[2].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cce50f6-d7ff-4cc1-a8df-e8cf5a921945",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3391c09-6986-41ac-8fbd-7ed8aa154143",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8185f66-01bc-4257-ac99-497f3774209c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(documents[0])\n",
    "print(len(documents[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d728153f-af82-4450-a403-6d97db56557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Input text\n",
    "text = \", there's a shortage of truck drivers in the US and worldwide.\"\n",
    "\n",
    "# Remove punctuation using regex\n",
    "cleaned_text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b9a0eb-97fe-42bf-bbbd-db625f4944ac",
   "metadata": {},
   "source": [
    "# **** 預計第一個小時結束 ****\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18358e5-6541-4a6d-92c2-4d4ac24923c1",
   "metadata": {},
   "source": [
    "## Document Specific Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adabbb85-5001-41b7-9994-169b797aec68",
   "metadata": {},
   "source": [
    "### Markdown splitter\n",
    "\n",
    "This code snippet demonstrates how to use LangChain's MarkdownTextSplitter to split a Markdown text document into smaller chunks. The MarkdownTextSplitter class is designed to handle Markdown-specific structure, making it easier to process and retrieve information from Markdown documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3d4354-5d87-4890-8a7b-83a03a8251a4",
   "metadata": {},
   "source": [
    "### 1. Import LangChain Components\n",
    "\n",
    "- Ensure that the necessary components from LangChain are imported. This might include MarkdownTextSplitter.\n",
    "- 確保導入 LangChain 的必要組件。這可能包括 MarkdownTextSplitter。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fab597-e0ae-416d-8951-8aac151abfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2629ee7b-e53a-4c78-9612-4911cf9965ab",
   "metadata": {},
   "source": [
    "### 2. Initialize the Text Splitter\n",
    "\n",
    "- The MarkdownTextSplitter is initialized with a chunk_size of 40 and chunk_overlap of 0. This means each chunk will contain up to 40 characters, and there will be no overlap between chunks.\n",
    "- MarkdownTextSplitter 被初始化為 chunk_size 為 40，chunk_overlap 為 0。這意味著每個塊將包含最多 40 個字符，並且塊之間不會重疊。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b9c0b1-6c02-4060-9e58-93e97de62332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = MarkdownTextSplitter(chunk_size=40, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ea8893-3ebc-481a-8c9d-57fd1d9c36b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_text = \"\"\"\n",
    "# Fun in Califormia\n",
    "\n",
    "## Driving\n",
    "\n",
    "Try driving on the 1 down to San Diego\n",
    "\n",
    "### Food\n",
    "\n",
    "Make sure to eat a burrito while you're there\n",
    "\n",
    "## Hiking\n",
    "\n",
    "Go to Yosemite\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080cc74a-1138-4d78-aa8c-029b7d203e31",
   "metadata": {},
   "source": [
    "### 3. Create Documents from Markdown Text\n",
    "\n",
    "- The create_documents method of MarkdownTextSplitter is used to split the Markdown text into smaller chunks based on the specified chunk size.\n",
    "- 使用 MarkdownTextSplitter 的 create_documents 方法根據指定的塊大小將 Markdown 文本拆分成較小的部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e6e79b-8cca-4541-ae8c-6d8cca989df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter.create_documents([markdown_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b43051b-eccb-4a36-bd69-f89ff0f86b3e",
   "metadata": {},
   "source": [
    "### Python splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1daf779-2204-4c48-b397-3dc7fa956b15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import PythonCodeTextSplitter\n",
    "\n",
    "python_text = \"\"\"\n",
    "class Person:\n",
    "    def __init__(self, name, age):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "\n",
    "p1 = Person(\"John\", 36)\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "\"\"\"\n",
    "\n",
    "python_splitter = PythonCodeTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "python_splitter.create_documents([python_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54945bfe-f512-451c-9dda-d3477837fd77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
    "\n",
    "\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=100, chunk_overlap=0\n",
    ")\n",
    "python_docs = python_splitter.create_documents([python_text])\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4c3479-5616-450f-aacc-bfb4b623f6cc",
   "metadata": {},
   "source": [
    "### split code: https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/code_splitter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a205d1-e99a-4460-a20c-c8041c76f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_router.encoders import HuggingFaceEncoder\n",
    "\n",
    "encoder = HuggingFaceEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc49a36-1aa0-4447-9fdb-f48a8994b0ac",
   "metadata": {},
   "source": [
    "## Semantic Splitting\n",
    "\n",
    "- StatisticalChunker (text)\n",
    "- ConsecutiveChunker (text, audio)\n",
    "- CumulativeChunker (text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fcbca0-7380-4055-bf11-77f9fa44ecea",
   "metadata": {},
   "source": [
    "### StatisticalChunker\n",
    "\n",
    "The statistical chunking method our most robust chunking method, it uses a varying similarity threshold to identify more dynamic and local similarity splits. It offers a good balance between accuracy and efficiency but can only be used for text documents (unlike the multi-modal ConsecutiveChunker).\n",
    "\n",
    "The StatisticalChunker can automatically identify a good threshold value to use while chunking our text, so it tends to require less customization than our other chunkers.\n",
    "\n",
    "最強大的分塊方法是統計分塊方法，它使用變化的相似度閾值來識別更多動態和本地相似度的分割。它在準確性和效率之間提供了良好的平衡，但只能用於文本文件（與多模態的連續分塊器不同）。\n",
    "\n",
    "統計分塊器可以自動識別一個好的閾值來用於分塊我們的文本，因此它通常比我們的其他分塊器需要更少的定制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1e7ef7-4d5e-4382-abca-3d1cb393e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_chunkers import StatisticalChunker\n",
    "\n",
    "chunker = StatisticalChunker(encoder=encoder)\n",
    "\n",
    "chunks = chunker(docs=[text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d93e36-9682-49ce-8bb3-a36642421c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[0][0].splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc87a09-b84a-430c-93e8-ce69a1249292",
   "metadata": {},
   "source": [
    "### Consecutive Chunking\n",
    "\n",
    "Consecutive chunking is the simplest version of semantic chunking.\n",
    "\n",
    "連續分塊是語義分塊最簡單的版本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cd5c0c-f4e7-4542-a659-b90014713d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_chunkers import ConsecutiveChunker\n",
    "\n",
    "chunker = ConsecutiveChunker(encoder=encoder, score_threshold=0.3)\n",
    "\n",
    "chunks = chunker(docs=[text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b3fc92-d53a-44b1-9d0f-ef118330b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[0][0].splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39ce94c-e008-436d-a2c3-b9f148eb7f70",
   "metadata": {},
   "source": [
    "## Cumulative Chunking\n",
    "\n",
    "Cumulative chunking is a more compute intensive process, but can often provide more stable results as it is more noise resistant. However, it is very expensive in both time and (if using APIs) money."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb63778c-ca98-41bd-b6f2-5d2f948376b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_chunkers import CumulativeChunker\n",
    "\n",
    "chunker = CumulativeChunker(encoder=encoder, score_threshold=0.3)\n",
    "\n",
    "chunks = chunker(docs=[text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cb2a8b-6f54-4db0-9b0d-a15dc278dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdd683e-b80b-4913-b32f-371e97977092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
