{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "352710b7-8462-4e32-9af7-59b20a0edcf5",
   "metadata": {},
   "source": [
    "# OpenAI Multimodal\n",
    "\n",
    "Let me introduce you to something amazing called GPT. Think of GPT as a very smart computer program that can understand both text and images. It can read and write just like a human, and it can also look at pictures and understand what they are. Imagine having a tool that can help you with writing, reading, and even looking at photos to tell you what they show. It's like having a really smart assistant who can do many things at once!\n",
    "\n",
    "讓我向您介紹一個非常了不起的東西，叫做 GPT。想像一下，GPT 就像是一個非常聰明的電腦程式，它能理解文字和圖片。它可以像人一樣閱讀和寫作，還能看圖片並理解它們的內容。想像一下，有一個工具可以幫助您寫作、閱讀，甚至看照片並告訴您照片中的內容。這就像擁有一個非常聰明的助理，可以同時做很多事情！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc181dc-846b-47ba-97e5-3d7526d0702d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; justify-content: space-around;\">\n",
       "    <div>\n",
       "        <img src=\"nDATs9kmQk7sNrx5ELrhZ.png\" height=\"900\" width=\"600\" />\n",
       "    </div>\n",
       "    <div>\n",
       "        <img src=\"754703591882697477.png\" height=\"900\" width=\"600\" />\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Define the HTML to display images side by side\n",
    "html = \"\"\"\n",
    "<div style=\"display: flex; justify-content: space-around;\">\n",
    "    <div>\n",
    "        <img src=\"nDATs9kmQk7sNrx5ELrhZ.png\" height=\"900\" width=\"600\" />\n",
    "    </div>\n",
    "    <div>\n",
    "        <img src=\"754703591882697477.png\" height=\"900\" width=\"600\" />\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# Display the HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c438f085-a035-4dc7-b14c-caf726223804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8180ba97-5e95-4e6f-8318-97562c91e9ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MengChieh\\Miniconda3\\envs\\llm_examples\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "from src.initialization import credential_init\n",
    "\n",
    "credential_init()\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-2024-05-13\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe6a598-704b-4666-bd3e-bc1113a6db8a",
   "metadata": {},
   "source": [
    "GPT does not see an image, but something strange called base64 foramt string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "284f0d20-8fa9-4c5f-abb1-5ecc17dd084b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "\n",
    "from PIL import Image\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    \n",
    "    with Image.open(image_path) as image:\n",
    "        \n",
    "        # Save the Image to a Buffer\n",
    "        buffered = io.BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        \n",
    "        # Encode the Image to Base64\n",
    "        image_str = base64.b64encode(buffered.getvalue())\n",
    "    \n",
    "    return image_str.decode('utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd3a825-88de-4355-99ab-4955f5107d5a",
   "metadata": {},
   "source": [
    "### 1. Convert Image Path to Base64 String\n",
    "\n",
    "- The image path is constructed and passed to image_to_base64 to get the Base64 string of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "348bce4f-5c4c-4122-bdf6-bd90578b9e32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.io.path_definition import get_project_dir\n",
    "\n",
    "image_str = image_to_base64(os.path.join(get_project_dir(), 'tutorial/Week-5/754703591882697477.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cdde5ed-0e16-45c5-b3eb-28eb59c9700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c6d8b3-3d42-4ec0-8091-d2c27486ef0d",
   "metadata": {},
   "source": [
    "### 2. Create a Human Message\n",
    "\n",
    "- A HumanMessage object is created containing two parts:\n",
    "    - A text message asking \"What is in this image?\"\n",
    "    - An image URL containing the Base64 encoded image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62783992-178b-449a-beaf-ad5153d0642a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今天的天氣是: 陰天\n"
     ]
    }
   ],
   "source": [
    "# python f-string\n",
    "\n",
    "text = f\"今天的天氣是: {天氣}\"\n",
    "天氣 = \"陰天\"\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "918e27e1-5b2b-41c2-bec2-fe0b1e2c7fcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "human_message = HumanMessage(content=[{'type': 'text', \n",
    "                                       'text': 'What is in this image?'},\n",
    "                                      {'type': 'image_url',\n",
    "                                       'image_url': {\n",
    "                                           'url': f\"data:image/jpeg;base64,{image_str}\"}\n",
    "                                      }])\n",
    "\n",
    "# Create a Prompt Template\n",
    "prompt = ChatPromptTemplate.from_messages([human_message])\n",
    "\n",
    "# Generate the Chain\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d399b270-924a-4fbe-bf9c-d2f402cf1f51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = chain.invoke(input={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b926554-0a4a-4ae5-9e6b-1d4c1c0a4482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image depicts a person dressed in a cosplay outfit inspired by a kitsune, a mythical fox spirit from Japanese folklore. The individual is wearing fox ears and has multiple fox tails visible behind them. They are also dressed in traditional Japanese-style clothing, including a kimono with intricate patterns and a decorative hair accessory. The overall look is detailed and carefully crafted to resemble a character from anime, manga, or Japanese mythology.\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ec6d71-c535-4be7-a95a-9fc561eb53d2",
   "metadata": {},
   "source": [
    "## Make the input image as a dynamic variable\n",
    "\n",
    "- With PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15d7ab65-4d28-4684-927d-b80d44d72b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mHumanMessagePromptTemplate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mprompt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlangchain_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprompts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStringPromptTemplate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlangchain_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprompts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStringPromptTemplate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprompts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImagePromptTemplate\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0madditional_kwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m      Human message prompt template. This is a message sent from the user.\n",
       "\u001b[1;31mInit docstring:\u001b[0m\n",
       "Create a new model by parsing and validating input data from keyword arguments.\n",
       "\n",
       "Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\mengchieh\\miniconda3\\envs\\llm_examples\\lib\\site-packages\\langchain_core\\prompts\\chat.py\n",
       "\u001b[1;31mType:\u001b[0m           ModelMetaclass\n",
       "\u001b[1;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "\n",
    "HumanMessagePromptTemplate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06bce1bb-8ba8-4be1-b8c4-4748fbf9c747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The image depicts a person dressed in a cosplay outfit inspired by a kitsune, a mythical fox spirit from Japanese folklore. The individual is wearing fox ears and has multiple fox tails visible behind them. They are also dressed in traditional Japanese-style clothing, including a kimono with intricate patterns and a decorative hair accessory. The overall look is detailed and carefully crafted to resemble a character from anime, manga, or Japanese mythology.', response_metadata={'token_usage': {'completion_tokens': 83, 'prompt_tokens': 1118, 'total_tokens': 1201, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_d0c6e590be', 'finish_reason': 'stop', 'logprobs': None}, id='run-d17695a0-4b04-44e8-bcf8-49dbc143c1f9-0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(\n",
    "    template=[\n",
    "        {'type': 'text', 'text': 'What is in this image?'},\n",
    "        {'type': 'image_url', 'image_url': {'url': 'data:image/jpeg;base64,{image_str}'}}\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Create a Prompt Template\n",
    "prompt = ChatPromptTemplate.from_messages([human_message_template])\n",
    "\n",
    "# Generate the Chain\n",
    "chain = prompt|model\n",
    "\n",
    "chain.invoke(input={\"image_str\": image_str})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475d85fc-b348-4460-aa72-a282401e78a5",
   "metadata": {},
   "source": [
    "將`問題`和`圖片`都變成輸入變數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1754f003-b076-4979-a87f-e46dcf6ed947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The character in the image appears to be a person dressed in a fox-themed costume, which is reminiscent of characters from various anime series. The fox ears and multiple tails suggest a kitsune, a mythical fox spirit from Japanese folklore, which is a common motif in anime. \\n\\nOne well-known anime character that fits this description is Ahri from the game \"League of Legends,\" who is often depicted with fox ears and multiple tails. Another character is Tamamo no Mae from the \"Fate\" series, who also has a similar appearance. However, without more specific details, it\\'s difficult to definitively identify the character.', response_metadata={'token_usage': {'completion_tokens': 124, 'prompt_tokens': 1124, 'total_tokens': 1248, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_d0c6e590be', 'finish_reason': 'stop', 'logprobs': None}, id='run-d20c9c59-298d-4d91-830c-4be9904fb3ee-0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_message_template = HumanMessagePromptTemplate.from_template(\n",
    "    template=[\n",
    "        {'type': 'text', 'text': '{question}'},\n",
    "        {'type': 'image_url', 'image_url': {'url': 'data:image/jpeg;base64,{image_str}'}}\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Create a Prompt Template\n",
    "prompt = ChatPromptTemplate.from_messages([human_message_template])\n",
    "\n",
    "# Generate the Chain\n",
    "chain = prompt|model\n",
    "\n",
    "chain.invoke(input={\"image_str\": image_str, \"question\": \"Are you able to connect this image with any anime character?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcd4818-6017-4844-ad0c-136d457cb388",
   "metadata": {},
   "source": [
    "範圍似乎太廣了，給更多的條件: 來源是Azur Lane(碧藍航線)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5dd542e-8ca5-45d0-bba1-1e2749f1788e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The character in the image appears to be cosplaying as Akagi from the game \"Azur Lane.\" Akagi is known for her fox-like appearance, including fox ears and multiple tails, which are characteristic features depicted in the image.', response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 1130, 'total_tokens': 1176, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_d0c6e590be', 'finish_reason': 'stop', 'logprobs': None}, id='run-ed283c6a-4d5c-489d-b75a-4d1b27783575-0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input={\"image_str\": image_str, \"question\": \"Are you able to connect this image with any anime character? Hint: Azur Lane.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9e1ad8-f216-481d-b70c-f81bf3ded7ab",
   "metadata": {},
   "source": [
    "將Chain更加一步強化: 圖片路徑作為輸入變數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3f8a2e-f01b-4e18-8b01-e2635854217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "# human_prompt = PromptTemplate(template='existing ingredients:[{existing_ingredients}]; '\n",
    "#                                        'suggested ingredients: [{suggested_ingredients}]\\n; '\n",
    "#                                        'format instruction: {format_instructions}',\n",
    "#                               input_variables=[\"existing_ingredients\", \"suggested_ingredients\"],\n",
    "#                               partial_variables={\"format_instructions\": format_instructions}\n",
    "#                               )\n",
    "\n",
    "# human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "# chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "#                                                 human_message\n",
    "#                                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55daf597-22f3-45ae-a20a-5cb9f357a6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(\n",
    "    template=[\n",
    "        {'type': 'text', 'text': '{question}'},\n",
    "        {'type': 'image_url', 'image_url': {'url': 'data:image/jpeg;base64,{image_str}'}}\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Create a Prompt Template\n",
    "prompt = ChatPromptTemplate.from_messages([human_message_template])\n",
    "\n",
    "# Generate the Chain\n",
    "chain = RunnablePassthrough.assign(image_str=itemgetter('image_path')|RunnableLambda(image_to_base64))|prompt|model|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16643141-1d27-4f61-bb40-4a713390ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = os.path.join(get_project_dir(), 'tutorial/Week-5/nDATs9kmQk7sNrx5ELrhZ.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d5e1db-3475-47fd-8a88-2e615ca6fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = RunnablePassthrough.assign(image_str=itemgetter('image_path')|RunnableLambda(image_to_base64))|prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f42ac928-6d76-4251-a1ba-78f5d77e3e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The image appears to be a stylized illustration of a female character in a futuristic, form-fitting combat suit. She is holding a high-tech sniper rifle with a scope. The character has long, flowing hair and is depicted in a dynamic pose, suggesting readiness for action. The background includes some text and logos, with \"NKF\" prominently displayed in the top left corner. The overall aesthetic is reminiscent of sci-fi or cyberpunk themes.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"What is in this image?\",\n",
    "              \"image_path\": image_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e82f97-0d3e-4fbd-ae9f-8f6678feca40",
   "metadata": {},
   "source": [
    "直接將圖片URL作為變數輸入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1ea08b2-0f7e-4765-96bc-63937d7e5017",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image as Image_IPYTHON\n",
    "\n",
    "Image_IPYTHON(url=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e8584e3-ef7a-454a-b4b4-b28e74fb2a16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The image depicts a scenic landscape with a wooden boardwalk path leading through a lush, green field. The sky is clear with a few scattered clouds, and the horizon is lined with trees and bushes. The overall atmosphere is serene and inviting, suggesting a natural, outdoor setting, possibly a park or nature reserve.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_message_template = HumanMessagePromptTemplate.from_template(\n",
    "    template=[\n",
    "        {'type': 'text', 'text': '{question}'},\n",
    "        {'type': 'image_url', 'image_url': {'url': '{image_url}'}}\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Create a Prompt Template\n",
    "prompt = ChatPromptTemplate.from_messages([human_message_template])\n",
    "\n",
    "# Generate the Chain\n",
    "chain = RunnablePassthrough.assign(image_url=itemgetter('url'))|prompt|model|StrOutputParser()\n",
    "\n",
    "url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
    "                                   \n",
    "chain.invoke({\"question\": \"What is in this image?\",\n",
    "              \"url\": url})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1640f6fe-7ee9-469d-931d-f80be9902c66",
   "metadata": {},
   "source": [
    "## 回家作業1: 用LCEL建立一個影像分析函數，輸入為檔案名稱，輸出為content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbbc82b-98a2-44d8-bec3-5f723ef4b00f",
   "metadata": {},
   "source": [
    "## Multiple Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6fd108c-16ab-49e4-8488-bc21fda6f194",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The images you provided are identical. They both depict the same scene: a nature boardwalk in Madison, Wisconsin. The image shows a wooden pathway surrounded by lush greenery, with trees and plants on either side. The sky is clear, and the overall setting appears to be a peaceful, natural environment.\\n\\nSince the images are the same, there is no difference between them.', response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 157, 'total_tokens': 231, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_d0c6e590be', 'finish_reason': 'stop', 'logprobs': None}, id='run-aaba0571-21b7-49bf-b120-2a8a0b9f5b91-0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_message_template = HumanMessagePromptTemplate.from_template(\n",
    "    template=[{'type': 'text', \n",
    "               'text': 'What are in these images? Is there any difference between them?'},\n",
    "              {'type': 'image_url',\n",
    "               'image_url': {\n",
    "                   'url': \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"}\n",
    "              },\n",
    "              {'type': 'image_url',\n",
    "               'image_url': {\n",
    "                   'url': \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"}\n",
    "              }],\n",
    ")\n",
    "\n",
    "# Create a Prompt Template\n",
    "prompt = ChatPromptTemplate.from_messages([human_message_template])\n",
    "\n",
    "model.invoke(prompt.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdbf6a0-0c39-4b77-ba13-1a2b1b93d073",
   "metadata": {},
   "source": [
    "有啥點子想試試看的嗎? 現場實操，希望不會翻車"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2163a620-a80e-4800-8e2d-ab6d964eb8e3",
   "metadata": {},
   "source": [
    "# Text Splitting\n",
    "\n",
    "https://www.youtube.com/watch?v=8OJC21T2SL4\n",
    "\n",
    "- Character Split\n",
    "- Recursive Character Split\n",
    "- Document Specific Splitting\n",
    "- Semantic Splitting\n",
    "- Agentic Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aad071-44b8-422e-97df-44b323112ffd",
   "metadata": {},
   "source": [
    "1. Context Limit: Limit on the amount of words/tokens you can pass to the language model\n",
    "2. Signal to Noise: Remove information that isn't helpful to your task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8095c9b4-4c37-4c0f-9ed9-09afb4af019b",
   "metadata": {},
   "source": [
    "## Character Splitting\n",
    "\n",
    "Character splitting is the most basic form of splitting up your text. It is the process of simply dividing your text into N-character sized chunks regardless of their content or form\n",
    "\n",
    "This method isn's recommended for any applications - but it's a great starting point for us to understand the basics.\n",
    "\n",
    "- Pros: Easy & Simple\n",
    "- Cons: Very rigid and doesn't take into account the structure of your text\n",
    "\n",
    "Concepts to know:\n",
    "\n",
    "- Chunk Size - The number of characters you would like in your chunks. 50, 100, 100000, etc.\n",
    "- Chunk Overlap - The amount you would like your sequential chunks to overlap. This is to try to avoid cutting a single piece of context into multiple pieces. This will create duplicate data across chunks.\n",
    "\n",
    "\n",
    "字元分割是將文本分割成最基本形式的方式。它是將文本簡單地分割成N個字元大小的區塊，而不考慮其內容或形式。\n",
    "\n",
    "這種方法不推薦用於任何應用，但它是我們了解基礎知識的絕佳起點。\n",
    "\n",
    "優點：簡單且容易\n",
    "缺點：非常僵硬，不考慮文本結構\n",
    "需要了解的概念：\n",
    "\n",
    "區塊大小：您希望每個區塊包含的字元數量。例如，50，100，100000等。\n",
    "區塊重疊：您希望順序區塊之間重疊的字元數量。這是為了避免將單個上下文切割成多個部分。這將在區塊之間創建重複數據。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c284c380-34dc-4608-8ef0-cc76872ef7b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"This is the text I would like to chunk up. It is the example text for this exercise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51e0fd77-62f6-4205-b8eb-9d256d39ea45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='This is the text I would like to ch'),\n",
       " Document(page_content='unk up. It is the example text for '),\n",
       " Document(page_content='this exercise')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=35, chunk_overlap=0, separator='', strip_whitespace=False)\n",
    "text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e09c8219-d608-478f-8915-0f0b3d821947",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='This is the text I would like to ch'),\n",
       " Document(page_content='o chunk up. It is the example text '),\n",
       " Document(page_content='ext for this exercise')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=35, chunk_overlap=4, separator='', strip_whitespace=False)\n",
    "text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b0c9cfc-32db-47af-a3f2-6525e4dbd012",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"800\"\n",
       "            src=\"https://chunkviz.up.railway.app/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x19fe9cd0f70>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src='https://chunkviz.up.railway.app/', width=800, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7707743-48d5-413f-bcd0-cd91eb9e92b9",
   "metadata": {},
   "source": [
    "- Separators are the character(s) sequences you would like to split on. Say you wanted to chunk your data at `ch`, you can specify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09b66788-5329-456d-b66a-ec9ea9d71de9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 33, which is longer than the specified 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='This is the text I would like to'),\n",
       " Document(page_content='unk up. It is the example text for this exercise')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=4, chunk_overlap=0, separator='ch')\n",
    "text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c6f575-b0dd-4671-a123-9270385ed0de",
   "metadata": {},
   "source": [
    "## Recursive character splitting\n",
    "\n",
    "This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text.\n",
    "\n",
    "這種文本分割器是針對一般文本推薦的。它是由一個字元列表參數化的，按照順序嘗試在這些字元上進行分割，直到區塊足夠小。預設的列表是 [\"\\n\\n\", \"\\n\", \" \", \"\"]. 這樣做的效果是盡可能將所有段落（然後是句子，再然後是單詞）保持在一起，因為這些通常看起來是語義上最相關的文本片段。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afd20fd-6ed5-451a-87d7-3431378a7d10",
   "metadata": {},
   "source": [
    "### CNN (Cable News Network) 數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4264fc48-d24b-4495-ae47-0d1d2d2885da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_news = pd.read_csv(\"tutorial/Week-5/CNN_Articels_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30b0d699-2967-4ed9-8da8-e0e483058686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date published</th>\n",
       "      <th>Category</th>\n",
       "      <th>Section</th>\n",
       "      <th>Url</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Description</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Second headline</th>\n",
       "      <th>Article text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jacopo Prisco, CNN</td>\n",
       "      <td>2021-07-15 02:46:59</td>\n",
       "      <td>news</td>\n",
       "      <td>world</td>\n",
       "      <td>https://www.cnn.com/2021/07/14/world/tusimple-...</td>\n",
       "      <td>There's a shortage of truckers, but TuSimple t...</td>\n",
       "      <td>The e-commerce boom has exacerbated a global t...</td>\n",
       "      <td>world, There's a shortage of truckers, but TuS...</td>\n",
       "      <td>There's a shortage of truckers, but TuSimple t...</td>\n",
       "      <td>(CNN)Right now, there's a shortage of truck d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Stephanie Bailey, CNN</td>\n",
       "      <td>2021-05-12 07:52:09</td>\n",
       "      <td>news</td>\n",
       "      <td>world</td>\n",
       "      <td>https://www.cnn.com/2021/05/12/world/ironhand-...</td>\n",
       "      <td>Bioservo's robotic 'Ironhand' could protect fa...</td>\n",
       "      <td>Working in a factory can mean doing the same t...</td>\n",
       "      <td>world, Bioservo's robotic 'Ironhand' could pro...</td>\n",
       "      <td>A robotic 'Ironhand' could protect factory wor...</td>\n",
       "      <td>(CNN)Working in a factory or warehouse can me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Words by Stephanie Bailey, video by Zahra Jamshed</td>\n",
       "      <td>2021-06-16 02:51:30</td>\n",
       "      <td>news</td>\n",
       "      <td>asia</td>\n",
       "      <td>https://www.cnn.com/2021/06/15/asia/swarm-robo...</td>\n",
       "      <td>This swarm of robots gets smarter the more it ...</td>\n",
       "      <td>In a Hong Kong warehouse, a swarm of autonomou...</td>\n",
       "      <td>asia, This swarm of robots gets smarter the mo...</td>\n",
       "      <td>This swarm of robots gets smarter the more it ...</td>\n",
       "      <td>(CNN)In a Hong Kong warehouse, a swarm of aut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Paul R. La Monica, CNN Business</td>\n",
       "      <td>2022-03-15 09:57:36</td>\n",
       "      <td>business</td>\n",
       "      <td>investing</td>\n",
       "      <td>https://www.cnn.com/2022/03/15/investing/brics...</td>\n",
       "      <td>Russia is no longer an option for investors. T...</td>\n",
       "      <td>For many years, the world's most popular emerg...</td>\n",
       "      <td>investing, Russia is no longer an option for i...</td>\n",
       "      <td>Russia is no longer an option for investors. T...</td>\n",
       "      <td>New York (CNN Business)For many years, the wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>2022-03-15 11:27:02</td>\n",
       "      <td>business</td>\n",
       "      <td>business</td>\n",
       "      <td>https://www.cnn.com/2022/03/15/business/russia...</td>\n",
       "      <td>Russian energy investment ban part of new EU s...</td>\n",
       "      <td>The European Union formally approved on Tuesda...</td>\n",
       "      <td>business, Russian energy investment ban part o...</td>\n",
       "      <td>EU bans investment in Russian energy in new sa...</td>\n",
       "      <td>The European Union formally approved on Tuesda...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                             Author  \\\n",
       "0      0                                 Jacopo Prisco, CNN   \n",
       "1      2                              Stephanie Bailey, CNN   \n",
       "2      3  Words by Stephanie Bailey, video by Zahra Jamshed   \n",
       "3      4                    Paul R. La Monica, CNN Business   \n",
       "4      7                                            Reuters   \n",
       "\n",
       "        Date published  Category    Section  \\\n",
       "0  2021-07-15 02:46:59      news      world   \n",
       "1  2021-05-12 07:52:09      news      world   \n",
       "2  2021-06-16 02:51:30      news       asia   \n",
       "3  2022-03-15 09:57:36  business  investing   \n",
       "4  2022-03-15 11:27:02  business   business   \n",
       "\n",
       "                                                 Url  \\\n",
       "0  https://www.cnn.com/2021/07/14/world/tusimple-...   \n",
       "1  https://www.cnn.com/2021/05/12/world/ironhand-...   \n",
       "2  https://www.cnn.com/2021/06/15/asia/swarm-robo...   \n",
       "3  https://www.cnn.com/2022/03/15/investing/brics...   \n",
       "4  https://www.cnn.com/2022/03/15/business/russia...   \n",
       "\n",
       "                                            Headline  \\\n",
       "0  There's a shortage of truckers, but TuSimple t...   \n",
       "1  Bioservo's robotic 'Ironhand' could protect fa...   \n",
       "2  This swarm of robots gets smarter the more it ...   \n",
       "3  Russia is no longer an option for investors. T...   \n",
       "4  Russian energy investment ban part of new EU s...   \n",
       "\n",
       "                                         Description  \\\n",
       "0  The e-commerce boom has exacerbated a global t...   \n",
       "1  Working in a factory can mean doing the same t...   \n",
       "2  In a Hong Kong warehouse, a swarm of autonomou...   \n",
       "3  For many years, the world's most popular emerg...   \n",
       "4  The European Union formally approved on Tuesda...   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  world, There's a shortage of truckers, but TuS...   \n",
       "1  world, Bioservo's robotic 'Ironhand' could pro...   \n",
       "2  asia, This swarm of robots gets smarter the mo...   \n",
       "3  investing, Russia is no longer an option for i...   \n",
       "4  business, Russian energy investment ban part o...   \n",
       "\n",
       "                                     Second headline  \\\n",
       "0  There's a shortage of truckers, but TuSimple t...   \n",
       "1  A robotic 'Ironhand' could protect factory wor...   \n",
       "2  This swarm of robots gets smarter the more it ...   \n",
       "3  Russia is no longer an option for investors. T...   \n",
       "4  EU bans investment in Russian energy in new sa...   \n",
       "\n",
       "                                        Article text  \n",
       "0   (CNN)Right now, there's a shortage of truck d...  \n",
       "1   (CNN)Working in a factory or warehouse can me...  \n",
       "2   (CNN)In a Hong Kong warehouse, a swarm of aut...  \n",
       "3  New York (CNN Business)For many years, the wor...  \n",
       "4  The European Union formally approved on Tuesda...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8934227c-9e2a-4313-b56a-9ce071ec58c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = df_news.iloc[0]['Article text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f73a658-81a3-4ba7-a044-b740c8b8da91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12361"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29e355ed-4699-41a6-9515-84d91a50da8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" (CNN)Right now, there's a shortage of truck drivers in the US and worldwide, exacerbated by the e-c\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8af29441-b7ce-4548-9ed7-821d3f0fe426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=65, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56beb122-9c77-41ba-881c-6d59f96ac470",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=65, chunk_overlap=0, separators=[\",\", \".\", \"?\", \"!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c6815b8-fa1d-4e27-a13e-d8faa0948a95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f66fe7ac-ec77-4bb4-a832-f71945c53a02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='(CNN)Right now'\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])\n",
    "print(len(documents[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78172450-dc51-45ba-911f-4ea02c42c1d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=\", there's a shortage of truck drivers in the US and worldwide\"\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "print(documents[1])\n",
    "print(len(documents[1].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50e677e9-562a-4386-85a5-2a35f55fe48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=', exacerbated by the e-commerce boom brought on by the pandemic'\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "print(documents[2])\n",
    "print(len(documents[2].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cce50f6-d7ff-4cc1-a8df-e8cf5a921945",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3391c09-6986-41ac-8fbd-7ed8aa154143",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8185f66-01bc-4257-ac99-497f3774209c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(documents[0])\n",
    "print(len(documents[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d728153f-af82-4450-a403-6d97db56557c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " theres a shortage of truck drivers in the US and worldwide\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Input text\n",
    "text = \", there's a shortage of truck drivers in the US and worldwide.\"\n",
    "\n",
    "# Remove punctuation using regex\n",
    "cleaned_text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b9a0eb-97fe-42bf-bbbd-db625f4944ac",
   "metadata": {},
   "source": [
    "# **** 預計第一個小時結束 ****\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18358e5-6541-4a6d-92c2-4d4ac24923c1",
   "metadata": {},
   "source": [
    "## Document Specific Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adabbb85-5001-41b7-9994-169b797aec68",
   "metadata": {},
   "source": [
    "### Markdown splitter\n",
    "\n",
    "This code snippet demonstrates how to use LangChain's MarkdownTextSplitter to split a Markdown text document into smaller chunks. The MarkdownTextSplitter class is designed to handle Markdown-specific structure, making it easier to process and retrieve information from Markdown documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3d4354-5d87-4890-8a7b-83a03a8251a4",
   "metadata": {},
   "source": [
    "### 1. Import LangChain Components\n",
    "\n",
    "- Ensure that the necessary components from LangChain are imported. This might include MarkdownTextSplitter.\n",
    "- 確保導入 LangChain 的必要組件。這可能包括 MarkdownTextSplitter。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "71fab597-e0ae-416d-8951-8aac151abfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2629ee7b-e53a-4c78-9612-4911cf9965ab",
   "metadata": {},
   "source": [
    "### 2. Initialize the Text Splitter\n",
    "\n",
    "- The MarkdownTextSplitter is initialized with a chunk_size of 40 and chunk_overlap of 0. This means each chunk will contain up to 40 characters, and there will be no overlap between chunks.\n",
    "- MarkdownTextSplitter 被初始化為 chunk_size 為 40，chunk_overlap 為 0。這意味著每個塊將包含最多 40 個字符，並且塊之間不會重疊。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69b9c0b1-6c02-4060-9e58-93e97de62332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = MarkdownTextSplitter(chunk_size=40, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d0ea8893-3ebc-481a-8c9d-57fd1d9c36b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_text = \"\"\"\n",
    "# Fun in Califormia\n",
    "\n",
    "## Driving\n",
    "\n",
    "Try driving on the 1 down to San Diego\n",
    "\n",
    "### Food\n",
    "\n",
    "Make sure to eat a burrito while you're there\n",
    "\n",
    "## Hiking\n",
    "\n",
    "Go to Yosemite\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080cc74a-1138-4d78-aa8c-029b7d203e31",
   "metadata": {},
   "source": [
    "### 3. Create Documents from Markdown Text\n",
    "\n",
    "- The create_documents method of MarkdownTextSplitter is used to split the Markdown text into smaller chunks based on the specified chunk size.\n",
    "- 使用 MarkdownTextSplitter 的 create_documents 方法根據指定的塊大小將 Markdown 文本拆分成較小的部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84e6e79b-8cca-4541-ae8c-6d8cca989df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='# Fun in Califormia\\n\\n## Driving'),\n",
       " Document(page_content='Try driving on the 1 down to San Diego'),\n",
       " Document(page_content='### Food'),\n",
       " Document(page_content=\"Make sure to eat a burrito while you're\"),\n",
       " Document(page_content='there'),\n",
       " Document(page_content='## Hiking\\n\\nGo to Yosemite')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter.create_documents([markdown_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b43051b-eccb-4a36-bd69-f89ff0f86b3e",
   "metadata": {},
   "source": [
    "### Python splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d1daf779-2204-4c48-b397-3dc7fa956b15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='class Person:\\n    def __init__(self, name, age):\\n        self.name = name\\n        self.age = age'),\n",
       " Document(page_content='p1 = Person(\"John\", 36)\\n\\nfor i in range(10):\\n    print(i)')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import PythonCodeTextSplitter\n",
    "\n",
    "python_text = \"\"\"\n",
    "class Person:\n",
    "    def __init__(self, name, age):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "\n",
    "p1 = Person(\"John\", 36)\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "\"\"\"\n",
    "\n",
    "python_splitter = PythonCodeTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "python_splitter.create_documents([python_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54945bfe-f512-451c-9dda-d3477837fd77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='class Person:\\n    def __init__(self, name, age):\\n        self.name = name\\n        self.age = age'),\n",
       " Document(page_content='p1 = Person(\"John\", 36)\\n\\nfor i in range(10):\\n    print(i)')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
    "\n",
    "\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=100, chunk_overlap=0\n",
    ")\n",
    "python_docs = python_splitter.create_documents([python_text])\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4c3479-5616-450f-aacc-bfb4b623f6cc",
   "metadata": {},
   "source": [
    "### split code: https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/code_splitter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04a205d1-e99a-4460-a20c-c8041c76f9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MengChieh\\Miniconda3\\envs\\llm_examples\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from semantic_router.encoders import HuggingFaceEncoder\n",
    "\n",
    "encoder = HuggingFaceEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc49a36-1aa0-4447-9fdb-f48a8994b0ac",
   "metadata": {},
   "source": [
    "## Semantic Splitting\n",
    "\n",
    "- StatisticalChunker (text)\n",
    "- ConsecutiveChunker (text, audio)\n",
    "- CumulativeChunker (text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fcbca0-7380-4055-bf11-77f9fa44ecea",
   "metadata": {},
   "source": [
    "### StatisticalChunker\n",
    "\n",
    "The statistical chunking method our most robust chunking method, it uses a varying similarity threshold to identify more dynamic and local similarity splits. It offers a good balance between accuracy and efficiency but can only be used for text documents (unlike the multi-modal ConsecutiveChunker).\n",
    "\n",
    "The StatisticalChunker can automatically identify a good threshold value to use while chunking our text, so it tends to require less customization than our other chunkers.\n",
    "\n",
    "最強大的分塊方法是統計分塊方法，它使用變化的相似度閾值來識別更多動態和本地相似度的分割。它在準確性和效率之間提供了良好的平衡，但只能用於文本文件（與多模態的連續分塊器不同）。\n",
    "\n",
    "統計分塊器可以自動識別一個好的閾值來用於分塊我們的文本，因此它通常比我們的其他分塊器需要更少的定制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ce1e7ef7-4d5e-4382-abca-3d1cb393e9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]C:\\Users\\MengChieh\\Miniconda3\\envs\\llm_examples\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\MengChieh\\Miniconda3\\envs\\llm_examples\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\MengChieh\\Miniconda3\\envs\\llm_examples\\lib\\site-packages\\numpy\\core\\_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\MengChieh\\Miniconda3\\envs\\llm_examples\\lib\\site-packages\\numpy\\core\\_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "C:\\Users\\MengChieh\\Miniconda3\\envs\\llm_examples\\lib\\site-packages\\numpy\\core\\_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.28it/s]\n"
     ]
    }
   ],
   "source": [
    "from semantic_chunkers import StatisticalChunker\n",
    "\n",
    "chunker = StatisticalChunker(encoder=encoder)\n",
    "\n",
    "chunks = chunker(docs=[text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "01d93e36-9682-49ce-8bb3-a36642421c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\", there's a shortage of truck drivers in the US and worldwide.\"]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0][0].splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc87a09-b84a-430c-93e8-ce69a1249292",
   "metadata": {},
   "source": [
    "### Consecutive Chunking\n",
    "\n",
    "Consecutive chunking is the simplest version of semantic chunking.\n",
    "\n",
    "連續分塊是語義分塊最簡單的版本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "83cd5c0c-f4e7-4542-a659-b90014713d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 112.18it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from semantic_chunkers import ConsecutiveChunker\n",
    "\n",
    "chunker = ConsecutiveChunker(encoder=encoder, score_threshold=0.3)\n",
    "\n",
    "chunks = chunker(docs=[text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a4b3fc92-d53a-44b1-9d0f-ef118330b577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\", there's a shortage of truck drivers in the US and worldwide.\"]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0][0].splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39ce94c-e008-436d-a2c3-b9f148eb7f70",
   "metadata": {},
   "source": [
    "## Cumulative Chunking\n",
    "\n",
    "Cumulative chunking is a more compute intensive process, but can often provide more stable results as it is more noise resistant. However, it is very expensive in both time and (if using APIs) money."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eb63778c-ca98-41bd-b6f2-5d2f948376b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from semantic_chunkers import CumulativeChunker\n",
    "\n",
    "chunker = CumulativeChunker(encoder=encoder, score_threshold=0.3)\n",
    "\n",
    "chunks = chunker(docs=[text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "51cb2a8b-6f54-4db0-9b0d-a15dc278dac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Chunk(splits=[\", there's a shortage of truck drivers in the US and worldwide.\"], is_triggered=False, triggered_score=None, token_count=None, metadata=None)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdd683e-b80b-4913-b32f-371e97977092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
