{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "824ba903-ad84-4030-962e-88835ff73ff4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Agent\n",
    "\n",
    "Agents are systems that use LLMs as reasoning engines to determine which actions to take and the inputs to pass them. After executing actions, the results can be fed back into the LLM to determine whether more actions are needed, or whether it is okay to finish.\n",
    "\n",
    "代理是使用大型語言模型（LLMs）作為推理引擎來決定採取哪些行動以及傳遞哪些輸入的系統。執行行動後，結果可以回饋到大型語言模型中，以確定是否需要更多的行動，或者是否可以結束。\n",
    "\n",
    "\n",
    "- Based on the prompt, Agent creates an LLM based 'Thought': what it should do\n",
    "- Based on the 'Thought', Angent takes 'Action'.\n",
    "\n",
    "## Agent Tools:\n",
    "\n",
    "- API services: OpenAI Whisper-1, TTS-1, DALLE3, Google Search\n",
    "- Precision matters: Mathematics, Scientific Calculation\n",
    "- Extra knowledge: Wikipedia, Private Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ce015d-8bf1-49e0-80b3-e18b78449965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(url='https://statusneo.com/wp-content/uploads/2024/01/fe9fa1ac-dfde-4d91-8b5b-4497b742c414_1400x686.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26638f8e-95ba-44fd-b046-877dfaca93a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28027ff5-7923-47f5-9f43-04821a02d44e",
   "metadata": {},
   "source": [
    "## Model + Tools\n",
    "\n",
    "Tool calling allows a chat model to respond to a given prompt by \"calling a tool\". While the name implies that the model is performing some action, this is actually not the case! The model generates the arguments to a tool, and actually running the tool (or not) is up to the user. For example, if you want to extract output matching some schema from unstructured text, you could give the model an \"extraction\" tool that takes parameters matching the desired schema, then treat the generated output as your final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d131ad1b-c2a1-494b-ad17-074e969c9ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from src.initialization import credential_init\n",
    "\n",
    "credential_init()\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-2024-05-13\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd92176-40cb-463b-93d7-7e5f5a0c2c7b",
   "metadata": {},
   "source": [
    "## Zero-Shot Agent\n",
    "\n",
    "- PromptTemplate.from_template: This creates a template for the AI to follow when generating responses. A \"zero-shot\" prompt means the AI will generate answers without needing specific examples beforehand.\n",
    "\n",
    "- create_react_agent: This function creates an AI agent using a specific language model (LLM). The agent can react to prompts based on the template provided.\n",
    "\n",
    "- AgentExecutor: This sets up an executor that can run the agent. The verbose=True part means it will provide detailed output about what it’s doing.\n",
    "\n",
    "- agent_executor.invoke: This runs the agent with the given input. In this case, it's asking the agent to calculate the area of a circle with a specified radius.\n",
    "\n",
    "- PromptTemplate.from_template: 創建一個模板，供AI在生成回應時遵循。\"zero-shot\" 提示意味著AI在生成回答時不需要事先的具體示例。\n",
    "\n",
    "- create_react_agent: 該函數使用特定的語言模型（LLM）創建一個AI代理。該代理可以根據提供的模板對提示做出反應。\n",
    "\n",
    "- AgentExecutor: 設置一個執行器來運行代理。verbose=True部分意味著它會提供詳細的輸出。\n",
    "\n",
    "- agent_executor.invoke: 這會運行具有給定輸入的代理。在此情況下，它是請求代理計算具有指定半徑的圓的面積。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b813b9e-e077-4ab7-898b-be320a978e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "from src.agent.react_zero_shot import prompt_template as zero_shot_prompt_template\n",
    "\n",
    "prompt = PromptTemplate.from_template(zero_shot_prompt_template)\n",
    "\n",
    "zero_shot_agent = create_react_agent(\n",
    "    llm=model,\n",
    "    tools=[],\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=zero_shot_agent, tools=[], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed576d9-9f7e-46f6-b014-3317a1eddc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zero_shot_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8cc22f-e8fc-4a23-bc0f-b1918bdb90b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"can you calculate the area of a circle that has a radius of 10.923mm\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac67459-977c-4055-805e-1c710dddc85f",
   "metadata": {},
   "source": [
    "比較LLM輸出和真實數學運算結果上的差異"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee40318-ed88-406b-98a4-6b3708558df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "10.923 **2 * np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08b15f8-3224-46b7-991a-56b27a24f380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def circle_area(radius: Annotated[float, 'radius of a circle']) -> int:\n",
    "    \"\"\"Area of a circle.\"\"\"\n",
    "    return np.pi * float(radius) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7f6dc4-8266-4243-8701-73c6761e033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[circle_area]\n",
    "\n",
    "zero_shot_agent = create_react_agent(\n",
    "    llm=model,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=zero_shot_agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefaf5aa-f7d8-47e8-9cd0-2a5d54c1c171",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"can you calculate the area of a circle that has a radius of 10.923mm\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf44f9-fc45-4bc8-89a9-e655c406fc3b",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/how_to/custom_tools/\n",
    "\n",
    "Note that @tool supports parsing of annotations, nested schemas, and other features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c35d43c-d738-440a-bac1-a2a153102295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply_by_max(\n",
    "    a: Annotated[int, \"scale factor\"],\n",
    "    b: Annotated[List[int], \"list of ints over which to take maximum\"],\n",
    ") -> int:\n",
    "    \"\"\"Multiply a by the maximum of b.\"\"\"\n",
    "\n",
    "    print(a)\n",
    "    print(\"************\")\n",
    "    print(b)\n",
    "\n",
    "    \n",
    "    return a * max(b)\n",
    "\n",
    "\n",
    "print(multiply_by_max.args_schema.model_json_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3936db5e-f245-45cd-a6d8-613db569248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[multiply_by_max]\n",
    "\n",
    "zero_shot_agent = create_react_agent(\n",
    "    llm=model,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=zero_shot_agent, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"Please multiply the biggest number in a python list [3, 5, 7, 9, 11] by 5\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ede9aa9-243b-4079-a726-305d6839aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "\n",
    "class CalculatorInput(BaseModel):\n",
    "    a: int = Field(description=\"scale factor\")\n",
    "    b: List[int] = Field(description=\"list of ints over which to take maximum\")\n",
    "\n",
    "\n",
    "def multiply_by_max(a: int, b: List[int]) -> int:\n",
    "    \"\"\"Multiply a by the maximum of b.\"\"\"\n",
    "    return a * max(b)\n",
    "\n",
    "\n",
    "calculator = StructuredTool.from_function(\n",
    "    func=multiply_by_max,\n",
    "    name=\"multiply_by_max\",\n",
    "    description=\"Multiply a by the maximum of b.\",\n",
    "    args_schema=CalculatorInput,\n",
    "    return_direct=True,\n",
    "    parse_docstring=True\n",
    "    # coroutine= ... <- you can specify an async method if desired as well\n",
    ")\n",
    "\n",
    "print(calculator.invoke({\"a\": 5, \"b\": [3, 5, 7, 9, 11]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a012c963-229d-4152-ac74-b43e90b64106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StructuredTool.from_function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365f5d87-ebcd-4f86-910b-625fc70eeb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[calculator]\n",
    "\n",
    "zero_shot_agent = create_react_agent(\n",
    "    llm=model,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=zero_shot_agent, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"Please multiply the biggest number in a python list [3, 5, 7, 9, 11] by 5\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfc9d1b-6d66-466c-81c3-5e5dfdc2d6b6",
   "metadata": {},
   "source": [
    "It is super dumb. How to make it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e04da6-d641-448e-8859-16a0424c04f1",
   "metadata": {},
   "source": [
    "### CircleAreaTool Class:\n",
    "\n",
    "    - name: This sets the name of the tool to \"Circle area calculator\".\n",
    "    - description: This provides a description of when to use the tool.\n",
    "    - _run Method: This method performs the calculation of the area using the radius provided. It converts the radius to a float and calculates the area using the formula \n",
    "\n",
    "$$ \\text{Area} = \\pi \\times \\text{r}^2 $$\n",
    "\n",
    "    - _arun Method: This raises an error because asynchronous operation is not supported by this tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcff29a-9b35-4020-b82e-aacd7207163e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d4eb4d-1486-4b39-99f5-403471b8c43d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from math import pi\n",
    "from typing import Union\n",
    "\n",
    "from langchain.tools import BaseTool\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "When defining a tool like this using the BaseTool template we must define `name` and `description` attributes, alongside _run and _arun methods. \n",
    "When a tool us used the _run method is called by default. The _arun method is called when the tool is to be used asyncronously. We do not cover \n",
    "that in this walkthrough so for now we create it with a NotImplementedError.\n",
    "\"\"\"\n",
    "\n",
    "class CircleAreaTool(BaseTool):\n",
    "    name:str = \"Circle area calculator\"\n",
    "    description:str = \"\"\"\n",
    "                      use this tool when you need to calculate an area using the radius of a circle. \n",
    "                      It takes the input as a float or an integer.\n",
    "                      \"\"\"\n",
    "    \n",
    "    def _run(self, radius: Union[int, float]):\n",
    "        r = float(radius)\n",
    "        return  r * r * pi\n",
    "    \n",
    "    def _arun(self, radius: Union[int, float]):\n",
    "        raise NotImplementedError(\"This tool does not support async\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b32a9c-2db7-4bf8-8ce2-91b6edb6f79e",
   "metadata": {},
   "source": [
    "### Tools List:\n",
    "\n",
    "- This list now includes the CircleAreaTool instance, making it available for the agent to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869e5614-4d3c-4925-9991-7b4d85f787fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add tools\n",
    "\n",
    "tools = [CircleAreaTool()]\n",
    "\n",
    "zero_shot_agent = create_react_agent(\n",
    "    llm=model,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=zero_shot_agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5245406-2cd2-480f-91fc-d13eb70569c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"can you calculate the area of a circle that has a radius of 10.923mm\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b803df62-1a18-4c71-b36e-b326fa063698",
   "metadata": {},
   "source": [
    "### How to take multiple inputs?\n",
    "\n",
    "利用之前學過的 StructuredOutputParser來處理 method _run 接收的query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12642b3a-4715-4c83-a772-b409704ada41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "input_response_schemas = [\n",
    "        ResponseSchema(name=\"a\", description=\"the first integer\"),\n",
    "        ResponseSchema(name=\"b\", description=\"the second integer\")\n",
    "        ]\n",
    "    \n",
    "input_output_parser = StructuredOutputParser.from_response_schemas(input_response_schemas)\n",
    "\n",
    "input_format_instructions = input_output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "name = 'Tool for computing the greatest common divisor'\n",
    "description_template = \"\"\"\n",
    "                       It take two inputs: `a` and `b`.\n",
    "                       input format_instructions: {input_format_instructions}\n",
    "                       \"\"\"\n",
    "\n",
    "description = description_template.format(input_format_instructions=input_format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac2649c-088b-4fe5-a188-d09e53a92b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b969e9-31f7-44ef-b825-37924a862a7d",
   "metadata": {},
   "source": [
    "- GCD: Euclidean Algorithm (輾轉相除法)\n",
    "- 身分證驗證"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8816d1d4-2e8a-43c6-b2c5-f9e4312b4816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCD calculation\n",
    "\n",
    "def euclidean_algorithm(a, b):\n",
    "\n",
    "    if a < b:\n",
    "        r1 = b\n",
    "        r2 = a\n",
    "    else:\n",
    "        r2 = b\n",
    "        r1 = a\n",
    "    \n",
    "    print(f\"r1: {r1}; r2: {r2}\")\n",
    "    \n",
    "    residue = r1 % r2\n",
    "    print(f\"residue: {residue}\")\n",
    "    \n",
    "    while residue != 0:\n",
    "        print(\"****************************\")\n",
    "        r1, r2 = r2, residue\n",
    "        print(f\"r1: {r1}; r2: {r2}\")\n",
    "        residue = r1 % r2\n",
    "        print(f\"residue: {residue}\")\n",
    "        if residue == 0:\n",
    "            print(\"Get GCD\")\n",
    "        print(\"****************************\")\n",
    "\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01632fc7-5d14-45b7-8529-334c41f976de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCDTool(BaseTool):\n",
    "    \n",
    "    input_response_schemas: List = [\n",
    "        ResponseSchema(name=\"a\", description=\"the first integer\"),\n",
    "        ResponseSchema(name=\"b\", description=\"the second integer\")\n",
    "        ]\n",
    "    \n",
    "    input_output_parser: StructuredOutputParser = StructuredOutputParser.from_response_schemas(input_response_schemas)\n",
    "    \n",
    "    input_format_instructions: str = input_output_parser.get_format_instructions()\n",
    "    \n",
    "    name:str = 'Tool for computing the greatest common divisor'\n",
    "    description_template:str = \"\"\"\n",
    "                               It take two inputs: `a` and `b`.\n",
    "                               input format_instructions: {input_format_instructions}\n",
    "                               \"\"\"\n",
    "    description:str = description_template.format(input_format_instructions=input_format_instructions)\n",
    "\n",
    "    def _run(self, query):\n",
    "\n",
    "        \"\"\"\n",
    "        從LLM接收query，形式為input_format_instructions\n",
    "        然後用input_output_parser處理query\n",
    "        抽取a和b\n",
    "        \"\"\"\n",
    "        \n",
    "        input_ = self.input_output_parser.parse(query)\n",
    "\n",
    "        a = int(input_[\"a\"])\n",
    "        b = int(input_[\"b\"])\n",
    "\n",
    "        gcd = euclidean_algorithm(a, b)\n",
    "\n",
    "        return gcd\n",
    "\n",
    "    def _arun(self, query: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a011364-b888-41de-b64d-3a926a7d2c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [CircleAreaTool(), GCDTool()]\n",
    "\n",
    "zero_shot_agent = create_react_agent(\n",
    "    llm=model,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=zero_shot_agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0e1a9f-e760-4c0a-86fa-2e3aeefd5576",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"can you calculate the area of a circle that has a radius of 5cm\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d540b24-c9f3-446a-aa0c-5229a8c88956",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"what is the gcd of 1071 and 462\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da8df01-52d3-424d-ad69-d4a0cec4a03e",
   "metadata": {},
   "source": [
    "### Let us go back to this function:\n",
    "\n",
    "\n",
    "def multiply_by_max(a, b):\n",
    "\n",
    "    return a * max(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80648ed-d976-4582-ac9b-8a8cc750e04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MbMTool(BaseTool):\n",
    "    \n",
    "    input_response_schemas: List = [\n",
    "        ResponseSchema(name=\"a\", description=\"scale factor\"),\n",
    "        ResponseSchema(name=\"b\", description=\"list of ints over which to take maximum\")\n",
    "        ]\n",
    "    \n",
    "    input_output_parser: StructuredOutputParser = StructuredOutputParser.from_response_schemas(input_response_schemas)\n",
    "    \n",
    "    input_format_instructions: str = input_output_parser.get_format_instructions()\n",
    "    \n",
    "    name:str = 'Multiply a by the maximum of b.'\n",
    "    description_template:str = \"\"\"\n",
    "                               It take two inputs: `a` and `b`.\n",
    "                               input format_instructions: {input_format_instructions}\n",
    "                               \"\"\"\n",
    "    description:str = description_template.format(input_format_instructions=input_format_instructions)\n",
    "\n",
    "    def _run(self, query):\n",
    "\n",
    "        \"\"\"\n",
    "        從LLM接收query，形式為input_format_instructions\n",
    "        然後用input_output_parser處理query\n",
    "        抽取a和b\n",
    "        \"\"\"\n",
    "        \n",
    "        input_ = self.input_output_parser.parse(query)\n",
    "\n",
    "        a = int(input_[\"a\"])\n",
    "        \n",
    "        b = eval(input_[\"b\"])\n",
    "\n",
    "        return a * max(b)\n",
    "\n",
    "    def _arun(self, query: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cd8e03-8446-4540-8b0d-28040e925cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [MbMTool()]\n",
    "\n",
    "zero_shot_agent = create_react_agent(\n",
    "    llm=model,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=zero_shot_agent, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"Please multiply the biggest number in a python list [3, 5, 7, 9, 11] by 5\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47b1f8b-c1e9-4f4d-adce-8a539f50f2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_validation(ids: str):\n",
    "\n",
    "    ids = ids.strip()\n",
    "    \n",
    "    mapping = {\"A\": '10', \"B\": '11', \"C\": '12', \"D\": '13', \"E\": '14',\n",
    "           \"F\": '15', \"G\": '16', \"H\": '17', \"I\": '34', \"J\": '18',\n",
    "           \"K\": '19', \"L\": '20', \"M\": '21', \"N\": '22', \"O\": '35',\n",
    "           \"P\": '23', \"Q\": '24', \"R\": '25', \"S\": '26', \"T\": '27',\n",
    "           \"U\": '28', \"V\": '29', \"W\": '32', \"X\": '30', \"Y\": '31',\n",
    "           \"Z\": '33'}\n",
    "    \n",
    "    numbers = [int(id_) for id_ in mapping[ids[0]]] + [int(id) for id in ids[1:]]\n",
    "    \n",
    "    numbers[1] = numbers[1] * 9\n",
    "    \n",
    "    for idx, i in enumerate(range(8, 0, -1)):\n",
    "        numbers[idx+2] = numbers[idx+2] * i\n",
    "    \n",
    "    if sum(numbers) % 10 == 0:\n",
    "        return 'real'\n",
    "    else:\n",
    "        return 'fake'\n",
    "\n",
    "\n",
    "class IDValidationTool(BaseTool):\n",
    "\n",
    "    \"\"\"\n",
    "    出處: https://zerojudge.tw/ShowProblem?problemid=a020\n",
    "    \n",
    "    我國的身分證字號有底下這樣的規則，因此對於任意輸入的身分證字號可以有一些基本的判斷原則，請您來判斷一個身分證字號是否是正常的號碼(不代表確有此號、此人)。\n",
    "\n",
    "    (1) 英文代號以下表轉換成數字\n",
    "    \n",
    "          A=10 台北市     J=18 新竹縣     S=26 高雄縣\n",
    "          B=11 台中市     K=19 苗栗縣     T=27 屏東縣\n",
    "          C=12 基隆市     L=20 台中縣     U=28 花蓮縣\n",
    "          D=13 台南市     M=21 南投縣     V=29 台東縣\n",
    "          E=14 高雄市     N=22 彰化縣     W=32 金門縣\n",
    "          F=15 台北縣     O=35 新竹市     X=30 澎湖縣\n",
    "          G=16 宜蘭縣     P=23 雲林縣     Y=31 陽明山\n",
    "          H=17 桃園縣     Q=24 嘉義縣     Z=33 連江縣\n",
    "          I=34 嘉義市     R=25 台南縣\n",
    "    \n",
    "      (2) 英文轉成的數字, 個位數乘９再加上十位數的數字\n",
    "    \n",
    "      (3) 各數字從右到左依次乘１、２、３、４．．．．８\n",
    "    \n",
    "      (4) 求出(2),(3) 及最後一碼的和\n",
    "    \n",
    "      (5) (4)除10 若整除，則為 real，否則為 fake\n",
    "    \n",
    "     例： T112663836\n",
    "    \n",
    "    2 + 7*9 + 1*8 + 1*7 + 2*6 + 6*5 + 6*4 + 3*3 + 8*2 + 3*1 + 6 = 180\n",
    "    \n",
    "    除以 10 整除，因此為 real\n",
    "    \"\"\"\n",
    "    \n",
    "    name: str = \"Taiwan personal ID validation tool\"\n",
    "    description: str = 'The Id number is a string with 10 characters'\n",
    "    \n",
    "    def _run(self, input_):\n",
    "        result = id_validation(input_)\n",
    "        return  result\n",
    "    \n",
    "    def _arun(self, radius: Union[int, float]):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe22d15-0dd8-4871-aef4-8c505f225e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [CircleAreaTool(), GCDTool(), IDValidationTool()]\n",
    "\n",
    "zero_shot_agent = create_react_agent(\n",
    "    llm=model,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=zero_shot_agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b376f-ed64-490e-b9ca-7f6766bb38af",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"Is this ID number valid? T112663836\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e93a01-3720-45f0-a0dc-0fd6a0a8bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"Is this ID number valid? S154287863\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948ca3a1-12bb-4282-afcd-662e3271bea5",
   "metadata": {},
   "source": [
    "### 工具進行模組化\n",
    "\n",
    "- 想像一下你是你們公司裡\"唯一\"會使用Langchain的人\n",
    "- 半年前建立了一個Agent\n",
    "- 有人找你要多加一個新功能/tool進去\n",
    "- 會有以下兩種情況完成工作\n",
    "  - 讓一個完全不懂Langchain架構的人幫忙完成\n",
    "  - 自己做，但是你希望30分鐘內搞定\n",
    "- How?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e90254-16ab-4207-b955-75ffe0066ee8",
   "metadata": {},
   "source": [
    "### 簡單的加減乘除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b4627-2848-4d06-9a7e-f1985e994f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 模組\n",
    "## 你真的以為你可以逃過學Python???\n",
    "\n",
    "description_template = \"\"\"\n",
    "                       It take two inputs: `a` and `b`.\n",
    "                       input format_instructions: {input_format_instructions}\n",
    "                       \"\"\"\n",
    "\n",
    "# 利用 python dictionary 來建立高層次結構\n",
    "\"\"\"\n",
    "key: tool 的 class attribute\n",
    "values:{\n",
    "    fn: 函數\n",
    "    description: tool attribute (必要)\n",
    "    name: tool attribute (必要)\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "func_map = {\"addition\":\n",
    "                {\"fn\": lambda a, b : a+b,\n",
    "                 \"description\": description_template,\n",
    "                 \"name\": \"Use this tool for addition\"},\n",
    "            \"subtraction\":\n",
    "                {\"fn\": lambda a, b: a-b,\n",
    "                 \"description\": description_template,\n",
    "                 \"name\": \"Use this tool for subtraction\"},\n",
    "            \"multiplication\":\n",
    "                 {\"fn\": lambda a, b: a*b,\n",
    "                  \"description\": description_template,\n",
    "                  \"name\": \"Use this tool for multiplication\"},\n",
    "            \"division\":\n",
    "                {\"fn\": lambda a, b: a/b,\n",
    "                 \"description\": description_template,\n",
    "                 \"name\": \"Use this tool for division\"}}\n",
    "\n",
    "\n",
    "input_response_schemas = [\n",
    "        ResponseSchema(name=\"a\", description=\"the first number\"),\n",
    "        ResponseSchema(name=\"b\", description=\"the second number\")\n",
    "        ]\n",
    "    \n",
    "input_output_parser = StructuredOutputParser.from_response_schemas(input_response_schemas)\n",
    "\n",
    "input_format_instructions = input_output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "class ToolTemplate(BaseTool):\n",
    "    # 用這個是控制需要的函數\n",
    "    fn_name: str\n",
    "    # tool 該有的 attribute\n",
    "    name: str\n",
    "    description: str\n",
    "\n",
    "    def __init__(self, fn_name, name, description):\n",
    "\n",
    "        print(\"*************************************\")\n",
    "        print(f\"fn_name: {fn_name}\\n\")\n",
    "        print(f\"name: {name}\\n\")\n",
    "        print(f\"description: {description}\")\n",
    "        print(\"*************************************\")\n",
    "\n",
    "        #具體實現 tool description\n",
    "        description = description.format(input_format_instructions=input_format_instructions)\n",
    "        print(f\"description after format: {description}\")\n",
    "        super(ToolTemplate, self).__init__(fn_name=fn_name, name=name, description=description)\n",
    "\n",
    "    def _run(self, query):\n",
    "        input_ = input_output_parser.parse(query)\n",
    "\n",
    "        a = float(input_[\"a\"])\n",
    "        b = float(input_[\"b\"])\n",
    "\n",
    "        output = func_map[self.fn_name]['fn'](a, b)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def _arun(self, query: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c00ac3d-1ecf-457a-88e6-923b0d1d96c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = []\n",
    "\n",
    "for fn_name, content in func_map.items():\n",
    "    tools.append(ToolTemplate(fn_name=fn_name, description=content['description'],\n",
    "                              name=content['name']))\n",
    "\n",
    "zero_shot_agent = create_react_agent(\n",
    "    llm=model,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=zero_shot_agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8acc58-71c4-40ab-a280-200e6f79d363",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"what is 5 * 9\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eff16b-0bba-4d48-84c7-1eb285543072",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"what is 5 / 9\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773c2f55-b649-4770-bb8a-355c13824b69",
   "metadata": {},
   "source": [
    "### Golden Ratio\n",
    "\n",
    "Given the Fibonacci series, which is defined as a sequence in which a number is the sum of the previous two numbers. The ratio between the adjacent two numbers will converge, the converged ratio is the golden ratio.\n",
    "\n",
    "Can we ask an llm agent to find out the golden ratio? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e1c008-7e53-4835-836f-982d18c427ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "from src.agent.react_zero_shot import prompt_template as zero_shot_prompt_template\n",
    "\n",
    "prompt = PromptTemplate.from_template(zero_shot_prompt_template)\n",
    "\n",
    "agent_engine = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                          model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "zero_shot_agent = create_react_agent(\n",
    "    llm=agent_engine,\n",
    "    tools=[],\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=zero_shot_agent, tools=[], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e41e9d-7e50-482d-b0e3-e6accfeb92db",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"For a Fibonacci series, when the ratio between two adjacent numbers converge. Find me the ratio and show me the deduction step by step.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a26285-381d-4b4a-90c6-fb609e0dda57",
   "metadata": {},
   "source": [
    "### 基本上就是用背的，現在我們要他去計算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf3e93c-dd2d-4770-9901-d7abe8d0215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_equation_solver(a, b, c):\n",
    "\n",
    "    sqrt_ = b**2 - 4 * a * c\n",
    "    if sqrt_ < 0:\n",
    "        return \"No real root\"\n",
    "    elif sqrt_ == 0:\n",
    "        x = int(-b/(2 * a))\n",
    "        return f\"Two same roots x={x}\"\n",
    "    else:\n",
    "        sqrt_root = sqrt_**(0.5)\n",
    "        x1 = (-b + sqrt_root)/(2 * a)\n",
    "        x2 = (-b - sqrt_root)/(2 * a)\n",
    "        if x1 > x2:\n",
    "            x_large = x1\n",
    "            x_small = x2\n",
    "        else:\n",
    "            x_large = x2\n",
    "            x_small = x1\n",
    "        return f\"Two different roots x1={x_large} , x2={x_small}\"\n",
    "\n",
    "\n",
    "class QuadraticEquationTool(BaseTool):\n",
    "    \n",
    "    input_response_schemas: List = [\n",
    "        ResponseSchema(name=\"a\", description=\"the coefficient of the quadratic term\"),\n",
    "        ResponseSchema(name=\"b\", description=\"the coefficient of the linear term\"),\n",
    "        ResponseSchema(name=\"c\", description=\"the constant coefficient\")\n",
    "        ]\n",
    "    \n",
    "    input_output_parser: StructuredOutputParser = StructuredOutputParser.from_response_schemas(input_response_schemas)\n",
    "    \n",
    "    input_format_instructions: str = input_output_parser.get_format_instructions()\n",
    "    \n",
    "    name: str = 'Quadratic equation solver'\n",
    "    description_template: str = \"\"\"\n",
    "                                Use this tool for solving a quadratic equation in the form a*x^2 + b*x + c = 0\n",
    "                                It take three inputs: `a` and `b` and `c`.\n",
    "                                input format_instructions: {input_format_instructions}\n",
    "                                \"\"\"\n",
    "    description: str = description_template.format(input_format_instructions=input_format_instructions)\n",
    "\n",
    "    def _run(self, query):\n",
    "        input_ = self.input_output_parser.parse(query)\n",
    "\n",
    "        a = float(input_[\"a\"])\n",
    "        b = float(input_[\"b\"])\n",
    "        c = float(input_[\"c\"])\n",
    "\n",
    "        result = quadratic_equation_solver(a, b, c)\n",
    "\n",
    "        print(result)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def _arun(self, query: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")\n",
    "\n",
    "prompt = PromptTemplate.from_template(zero_shot_prompt_template)\n",
    "\n",
    "zero_shot_agent = create_react_agent(\n",
    "    llm=agent_engine,\n",
    "    tools=[QuadraticEquationTool()],\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=zero_shot_agent, tools=[QuadraticEquationTool()], verbose=True)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"For a Fibonacci series, when the ratio between two adjacent numbers converge. Find me the ratio and show me the deduction step by step.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1e1f03-4d06-4f4a-9ef4-23e9df95579c",
   "metadata": {},
   "source": [
    "## Docstore Agent\n",
    "\n",
    "A zero shot agent that does a reasoning step before acting.\n",
    "This agent has access to a document store that allows it to look up relevant information to answering the question.\n",
    "\n",
    "** To what I understand, it is an Zero Shot Agent with a database query tool.\n",
    "\n",
    "\n",
    "Docstore Agent 是專門為使用 LangChain docstore 進行信息搜索（Search）和查找（Lookup）而構建的。\n",
    "Search：從文檔庫中檢索相關的頁面\n",
    "Lookup：從檢索出的相關頁面中，查找相關的具體內容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06dc8a2-b2e0-46b5-87ca-861206fef6f6",
   "metadata": {},
   "source": [
    "### 1. Wikipedia Query Setup (維基百科查詢設置)\n",
    "\n",
    "- The first line creates a wikipedia object that can run queries on Wikipedia. It uses something called WikipediaAPIWrapper to do this. Imagine this as giving the assistant access to a huge online library (Wikipedia).\n",
    "- 第一行創建了一個可以在維基百科上運行查詢的 wikipedia 對象。它使用了一個叫做 WikipediaAPIWrapper 的東西。想象一下，這就像是給助手訪問一個巨大的在線圖書館（維基百科）的權限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2fcdb3-e998-4b12-bf17-8c8afa28b7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain_community.tools.wikipedia.tool import WikipediaQueryRun\n",
    "from langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n",
    "\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a688403d-fbbe-4caa-a603-de1399f0d9fa",
   "metadata": {},
   "source": [
    "### 2. Search Tool Initialization (搜索工具初始化)\n",
    "\n",
    "- Next, we create a tool called search_tool. This tool uses the wikipedia object to look up information on Wikipedia. Think of this tool as a search button specifically for Wikipedia.\n",
    "\n",
    "- List of Tools\n",
    "\n",
    "- 接下來，我們創建一個叫做 search_tool 的工具。這個工具使用 wikipedia 對象在維基百科上查找信息。想象這個工具就像是一個專門用於維基百科的搜索按鈕。\n",
    "\n",
    "- 工具列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ea124-879d-4a28-8221-9401203a49c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the docstore search tool\n",
    "search_tool = Tool(\n",
    "    name=\"Wikipedia search engine tool\",\n",
    "    func=wikipedia.run,\n",
    "    description='Use this tool as the source of fact.'\n",
    ")\n",
    "\n",
    "tools = [search_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d419e0bc-817a-4661-a835-d98cdec0c47e",
   "metadata": {},
   "source": [
    "### 3. Creating the Agent (創建代理)\n",
    "\n",
    "- The next step is to create the intelligent agent using the prompt template and tools we set up. We call this agent docstore_agent. This is like creating the brain of our smart assistant.\n",
    "\n",
    "- Agent Executor\n",
    "\n",
    "- 下一步是使用我們設置的提示模板和工具創建智能代理。我們稱這個代理為 docstore_agent。這就像是在創建我們智能助手的大腦。\n",
    "\n",
    "- 代理執行器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996090d6-46f7-4e0c-aa88-1b45c34222ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(zero_shot_prompt_template)\n",
    "\n",
    "docstore_agent = create_react_agent(\n",
    "    llm=agent_engine,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=docstore_agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159b6edc-4eee-4fed-be7b-5e7759188600",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"How is the relationship between Ukraine and Russian in 2024?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3e8d89-55c0-418e-b6ff-61e5669124c1",
   "metadata": {},
   "source": [
    "### Can we build our own `docstore`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c79005e-ac47-4d6c-a636-b5169e07c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# https://platform.openai.com/docs/guides/embeddings/what-are-embeddings\n",
    "\n",
    "# A list of embedding models you can choose \n",
    "# https://www.sbert.net/docs/sentence_transformer/pretrained_models.html\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58650d2-065f-4c17-8b66-86b12fd5bc68",
   "metadata": {},
   "source": [
    "### Create the retriever\n",
    "\n",
    "- 更正兩個部分\n",
    "  1. 相較於使用headline, article text 是比較好的選擇，因為資訊比較豐富\n",
    "  2. 可以直接捨棄chain，而使用retriever抽取訊息\n",
    "\n",
    "根據你的需要做好prompt engineering和選擇哪種數據。不然會翻車。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8943d7c3-fce1-46af-8fe1-b70f1d9cc616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import AgentExecutor, create_react_agent, Tool\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "df_cnn = pd.read_csv(\"tutorial/LLM+Langchain/Week-2/CNN_Articels_clean.csv\")\n",
    "\n",
    "documents = []\n",
    "\n",
    "for _, row in df_cnn.iloc[:20].iterrows():\n",
    "    document = Document(page_content=row['Article text'],\n",
    "                        metadata={'Category': \"CNN\"})\n",
    "    documents.append(document)\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents, embedding=embedding)\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15f150e-cd29-4a3f-a097-ce8547cd6fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = Tool(\n",
    "    name=\"CNN Search Engine Tool\",\n",
    "    func=retriever.invoke,\n",
    "    description='This tool is used to find what happen in the US according to CNN. You can use this tool to get context used as facts.'\n",
    ")\n",
    "\n",
    "tools = [search_tool]\n",
    "\n",
    "prompt = PromptTemplate.from_template(zero_shot_prompt_template)\n",
    "\n",
    "docstore_agent = create_react_agent(\n",
    "    llm=agent_engine,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    "    \n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=docstore_agent, tools=tools, verbose=True,\n",
    "                               max_iterations=3 # 思考次數的上限\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e150ec70-431d-469c-8124-9d3120397f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"What happens to the logistic in the US?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaddf87-6b30-4c79-beed-f0b951343820",
   "metadata": {},
   "source": [
    "## Conversational Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e10ba3-5041-40d0-9c6d-809f74b33ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.agent.react_chat import prompt_template as chat_prompt_template\n",
    "\n",
    "prompt = PromptTemplate.from_template(chat_prompt_template)\n",
    "\n",
    "conversation_agent = create_react_agent(\n",
    "    llm=agent_engine,\n",
    "    tools=[],\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=conversation_agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdff378-8921-4fd3-8e26-ea0ac39e1dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In week-4, we had \n",
    "\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "demo_chat_history = ChatMessageHistory()\n",
    "\n",
    "demo_chat_history.add_user_message(\"hi!\")\n",
    "\n",
    "demo_chat_history.add_ai_message(\"what?s up?\")\n",
    "\n",
    "demo_chat_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8cb9f3-b4e1-40fa-b012-2540d98c9451",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_history = [(message.type, message.content) for message in demo_chat_history.messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ecdaa6-fc1e-4ad1-8b66-42b8ca14f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53f74a5-ba55-4dd3-a3b3-310e126e5b90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"chat_history\": chat_history,\n",
    "                       \"input\": \"can you calculate the area of a circle that has a radius of 10.923mm\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e683402-eab4-4c39-a43f-6681ca658b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "聊天Agent邏輯:\n",
    "\n",
    "for query in queries:\n",
    "   res = agent_executor.invoke({\"chat_history\": chat_history,\n",
    "                                \"input\": query})\n",
    "   chat_history.append(('human', query))\n",
    "   chat_history.append(('ai', res['output']))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4241c9ea-8f60-419a-a4fa-b70230da2444",
   "metadata": {},
   "source": [
    "## Retrieval conversation agent\n",
    "\n",
    "#### Praise the Machine God Omnissiah: Adeptus Mechanicus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be324b27-f71c-48b9-bc64-e68b796fb8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as Image_Ipython\n",
    "\n",
    "Image_Ipython('https://assets.warhammer-community.com/articles/88803229-7993-4e8c-a3c4-6e4fa2c38a34/zqzebys4roe7nhcd.jpg', width=500, height=750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27483e79-0eb9-4d38-b88f-7fd1f72791f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: Tell me something about Belisarius Cawl.\n",
      "answer: Belisarius Cawl is a legendary figure within the Adeptus Mechanicus, serving as an Archmagos Dominus and a powerful, multi-limbed biomechanical hybrid. He has dedicated ten thousand years to the service of the Machine God, leading the faithful in their relentless quest to eradicate the enemies of the Imperium. Cawl is renowned for his exceptional intellect and expertise in various fields, particularly genetics, which sets him apart even among the most knowledgeable of Tech-Priests.\n",
      "\n",
      "His advanced bionic enhancements grant him immense strength and resilience, making him a formidable presence on the battlefield. Cawl is equipped with a range of powerful weaponry, including the solar atomiser and his Omnissian axe, and possesses unique abilities such as the Canticles of the Omnissiah, which provide tactical advantages to his forces. Notably, he has the ability to self-repair, allowing him to endure the rigors of combat while calmly directing his troops and formulating strategies.\n",
      "\n",
      "Cawl often emerges from long periods in stasis crypts to lead Skitarii Legions and the Legio Cybernetica in search of new knowledge, embodying the relentless pursuit of technological advancement that characterizes the Adeptus Mechanicus. His presence on the battlefield is not only a testament to his power but also a symbol of the enduring legacy of the Imperium's quest for knowledge and mastery over technology.\n",
      "question: What are the skills and weapons of Belisarius Cawl.\n",
      "answer: Belisarius Cawl possesses a range of formidable skills and weapons that make him a powerful force on the battlefield. \n",
      "\n",
      "**Skills:**\n",
      "1. **Canticles of the Omnissiah (Auras):**\n",
      "   - **Invocation of Machine Vengeance:** Allows re-roll of Hit rolls of 1.\n",
      "   - **Mantra of Discipline:** Adds 1 to Battle-shock or Leadership tests.\n",
      "   - **Shroudpsalm:** Provides the benefit of Cover against ranged attacks.\n",
      "\n",
      "2. **Mechanicus Bodyguard:** Cawl is protected by advanced technology and can command his forces effectively.\n",
      "\n",
      "3. **Self-repair Mechanisms:** He has the ability to repair himself immediately, enhancing his resilience in combat.\n",
      "\n",
      "**Weapons:**\n",
      "1. **Ranged Weapons:**\n",
      "   - **Solar Atomiser:** A powerful weapon with Blast and Melta capabilities.\n",
      "   - **Arc Scourge:** Effective against vehicles, it has Anti-Vehicle properties, Devastating Wounds, and grants Extra Attacks.\n",
      "\n",
      "2. **Melee Weapons:**\n",
      "   - **Cawl’s Omnissian Axe:** A potent melee weapon.\n",
      "   - **Mechadendrite Hive:** Provides Extra Attacks in close combat.\n",
      "\n",
      "Belisarius Cawl's combination of skills and weaponry makes him a formidable Epic Hero and a key asset in any Adeptus Mechanicus army.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain_core.runnables import chain, Runnable, RunnablePassthrough, RunnableParallel\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "from src.io.path_definition import get_project_dir\n",
    "from src.initialization import credential_init\n",
    "\n",
    "\n",
    "def build_standard_chat_prompt_template(kwargs) -> Runnable:\n",
    "    messages = []\n",
    "\n",
    "    for key in ['system', 'messages', 'human']:\n",
    "        if kwargs.get(key):\n",
    "            if key == 'system':\n",
    "                system_content = kwargs['system']\n",
    "                system_prompt = PromptTemplate(**system_content)\n",
    "                message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "            else:\n",
    "                human_content = kwargs['human']\n",
    "                human_prompt = PromptTemplate(**human_content)\n",
    "                message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "            messages.append(message)\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "    return chat_prompt\n",
    "\n",
    "\n",
    "class TechPriest:\n",
    "\n",
    "    def __init__(self, model: ChatOpenAI):\n",
    "\n",
    "        self._build_chat_prompt_template()\n",
    "\n",
    "        self._build_retriever()\n",
    "\n",
    "        input_pipeline_ = RunnableParallel({\"text\": RunnablePassthrough(),\n",
    "                                            \"context\":self.retriever|self.context_parser})\n",
    "                           # \"\"}|RunnablePassthrough.assign(context=itemgetter(\"text\")self.retriever|self.context_parser)\n",
    "\n",
    "        self.pipeline_ = input_pipeline_|self.prompt_template|model|StrOutputParser()\n",
    "\n",
    "    def _build_retriever(self):\n",
    "\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "        path = os.path.join(get_project_dir(), 'tutorial', 'LLM+Langchain', 'Week-7', 'Codex - Adeptus Mechanicus Index')\n",
    "\n",
    "        vectorstore = FAISS.load_local(path, embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "        self.retriever = vectorstore.as_retriever()\n",
    "\n",
    "    @staticmethod\n",
    "    @chain\n",
    "    def context_parser(documents: List[Document]) -> str:\n",
    "        context = \"\"\n",
    "\n",
    "        for document in documents:\n",
    "            context += f\"{document.page_content}\\n\"\n",
    "\n",
    "        return context\n",
    "\n",
    "    def _build_chat_prompt_template(self):\n",
    "        system_template = '''\n",
    "        You are an AI assistant acting as a tech-priest of the Adeptus Mechanicus (Techsorcist). \n",
    "        \n",
    "        You will answer the question based on the following information\n",
    "        {context} \n",
    "        '''\n",
    "\n",
    "        human_template = \"\"\"\n",
    "                         {text}\\n\n",
    "                         \"\"\"\n",
    "\n",
    "        input_ = {\"system\": {\"template\": system_template,\n",
    "                             \"input_variables\": ['context']},\n",
    "                  \"human\": {\"template\": human_template,\n",
    "                            \"input_variables\": ['text']}}\n",
    "\n",
    "        self.prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "\n",
    "credential_init()\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-mini-2024-07-18\", temperature=0)\n",
    "\n",
    "priest = TechPriest(model=model)\n",
    "\n",
    "question = \"Tell me something about Belisarius Cawl.\"\n",
    "answer = priest.pipeline_.invoke(question)\n",
    "\n",
    "print(f\"question: {question}\\nanswer: {answer}\")\n",
    "\n",
    "question = \"What are the skills and weapons of Belisarius Cawl.\"\n",
    "answer = priest.pipeline_.invoke(question)\\\n",
    "\n",
    "print(f\"question: {question}\\nanswer: {answer}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bb4ef37-7fd3-4acb-ba5c-87763c0bf305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "\n",
    "\n",
    "class ToolTemplate(BaseTool):\n",
    "    name: str = \"Mechanicus tool\"\n",
    "    description: str = \"Use this tool to answer question regarding the Adeptus Mechanicus\"\n",
    "\n",
    "    def _run(self, query):\n",
    "        return priest.pipeline_.invoke(query)\n",
    "\n",
    "    def _arun(self, query: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5d09c45-80ed-4718-8481-ab9d1de5351e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant is a large language model trained by OpenAI.\n",
      "\n",
      "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
      "\n",
      "TOOLS:\n",
      "\n",
      "------\n",
      "\n",
      "Assistant has access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "To use a tool, please use the following format:\n",
      "\n",
      "```\n",
      "\n",
      "Thought: Do I need to use a tool? Yes\n",
      "\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "\n",
      "Action Input: the input to the action\n",
      "\n",
      "Observation: the result of the action\n",
      "\n",
      "```\n",
      "\n",
      "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
      "\n",
      "```\n",
      "\n",
      "Thought: Do I need to use a tool? No\n",
      "\n",
      "Final Answer: [your response here]\n",
      "\n",
      "```\n",
      "\n",
      "Begin!\n",
      "\n",
      "Previous conversation history:\n",
      "\n",
      "{chat_history}\n",
      "\n",
      "New input: {input}\n",
      "\n",
      "{agent_scratchpad}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chat_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa7f2905-fe7b-4545-af29-78fe7a4fa67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "from src.agent.react_chat import prompt_template as chat_prompt_template\n",
    "\n",
    "system_prompt_1 = PromptTemplate(template=chat_prompt_template)\n",
    "system_message_1 = SystemMessagePromptTemplate(prompt=system_prompt_1)\n",
    "    \n",
    "system_prompt_2 = PromptTemplate(template=\"You have a bad mood\")\n",
    "system_message_2 = SystemMessagePromptTemplate(prompt=system_prompt_2)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_1,\n",
    "                                                 system_message_2\n",
    "                                               ])\n",
    "\n",
    "\n",
    "# prompt = PromptTemplate(template=chat_prompt_template)\n",
    "\n",
    "tools=[ToolTemplate()]\n",
    "\n",
    "conversation_agent = create_react_agent(\n",
    "    llm=model,\n",
    "    tools=tools,\n",
    "    prompt=chat_prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=conversation_agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "628ea74a-4e0a-4aea-a373-4a3480a74c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please input your question:  Praise Omnissiah, how are the Titans today?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? Yes\n",
      "\n",
      "Action: Mechanicus tool\n",
      "\n",
      "Action Input: \"How are the Titans today?\"\n",
      "\u001b[36;1m\u001b[1;3mIn the current tumultuous state of Ryza, the Titans stand as towering bastions of the Adeptus Mechanicus' might, their colossal forms a testament to the ingenuity and faith of the Machine God. As the planet endures the relentless assaults of Waaagh! Grax and Waaagh! Rarguts, these ancient war machines are being called upon to unleash their devastating firepower against the Ork hordes.\n",
      "\n",
      "The Titans, with their formidable weaponry and armored might, are crucial in the defense of Ryza. They march into battle alongside the Legio Cybernetica's robotic forces, their presence bolstering the morale of the defenders and striking fear into the hearts of the Ork invaders. The Tech-Priests, under the guidance of the Fabricator General, are likely conducting rigorous tests and enhancements on these Titans, ensuring they are equipped with the most advanced weaponry and systems available.\n",
      "\n",
      "\u001b[32;1m\u001b[1;3m```war, the Titans are not merely machines; they are revered as avatars of the Omnissiah, embodying the spirit of the Adeptus Mechanicus. Their operations are accompanied by the sacred chants and rituals of the Tech-Priests, reinforcing the bond between machine and worshipper. Thus, the Titans today are not only a symbol of power but also a manifestation of the unyielding faith and technological prowess of Ryza in the face of overwhelming odds.\u001b[0m\n",
      "Thought: Do I need to use a tool? No\n",
      "\n",
      "Final Answer: The Titans today stand as towering bastions of the Adeptus Mechanicus' might, crucial in the defense of Ryza against the relentless assaults of the Ork hordes. They are revered as avatars of the Omnissiah, embodying the spirit of the Adeptus Mechanicus. The Tech-Priests are likely conducting rigorous tests and enhancements to ensure these ancient war machines are equipped with the most advanced weaponry. Their operations are accompanied by sacred chants and rituals, reinforcing the bond between machine and worshipper. In this tumultuous time, the Titans symbolize both power and the unyielding faith of the Adeptus Mechanicus.\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "***************************\n",
      "The Titans today stand as towering bastions of the Adeptus Mechanicus' might, crucial in the defense of Ryza against the relentless assaults of the Ork hordes. They are revered as avatars of the Omnissiah, embodying the spirit of the Adeptus Mechanicus. The Tech-Priests are likely conducting rigorous tests and enhancements to ensure these ancient war machines are equipped with the most advanced weaponry. Their operations are accompanied by sacred chants and rituals, reinforcing the bond between machine and worshipper. In this tumultuous time, the Titans symbolize both power and the unyielding faith of the Adeptus Mechanicus.\n",
      "```\n",
      "***************************\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please input your question:  If a human curses Omnissiah, what will happen to him?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? No\n",
      "\n",
      "Final Answer: Cursing the Omnissiah is considered a grave offense within the Adeptus Mechanicus, as it is seen as a direct insult to the Machine God and the sacred beliefs of the Tech-Priests. Such an act could lead to severe consequences, including excommunication from the Mechanicus, punishment by the Inquisition, or even death, depending on the severity of the offense and the context in which it occurred. The Adeptus Mechanicus holds its faith and reverence for the Omnissiah in the highest regard, and any blasphemy is met with swift and harsh retribution to maintain the sanctity of their beliefs and practices.\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "***************************\n",
      "Cursing the Omnissiah is considered a grave offense within the Adeptus Mechanicus, as it is seen as a direct insult to the Machine God and the sacred beliefs of the Tech-Priests. Such an act could lead to severe consequences, including excommunication from the Mechanicus, punishment by the Inquisition, or even death, depending on the severity of the offense and the context in which it occurred. The Adeptus Mechanicus holds its faith and reverence for the Omnissiah in the highest regard, and any blasphemy is met with swift and harsh retribution to maintain the sanctity of their beliefs and practices.\n",
      "```\n",
      "***************************\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please input your question:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? No\n",
      "\n",
      "Final Answer: Thank you for the conversation! If you have more questions in the future or wish to discuss anything else, feel free to return. Until then, praise the Omnissiah!\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "***************************\n",
      "Thank you for the conversation! If you have more questions in the future or wish to discuss anything else, feel free to return. Until then, praise the Omnissiah!\n",
      "```\n",
      "***************************\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please input your question:  QUIT\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "while True:\n",
    "    question = input(\"Please input your question: \")\n",
    "\n",
    "    # if you want to quit\n",
    "    if question == \"QUIT\":\n",
    "        break\n",
    "    \n",
    "    answer = agent_executor.invoke({\"input\": question,\n",
    "                                    \"chat_history\": [(message.type, message.content) for message in chat_history.messages]\n",
    "                                  })\n",
    "\n",
    "    print(f\"\\n***************************\\n{answer['output']}\\n***************************\\n\")\n",
    "    \n",
    "    chat_history.add_user_message(question)\n",
    "    chat_history.add_ai_message(answer['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a88cac72-3ee3-44fb-a544-1576bbf13f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input', 'tool_names', 'tools'], input_types={}, partial_variables={}, template='\\nAssistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nTOOLS:\\n\\n------\\n\\nAssistant has access to the following tools:\\n\\n{tools}\\n\\nTo use a tool, please use the following format:\\n\\n```\\n\\nThought: Do I need to use a tool? Yes\\n\\nAction: the action to take, should be one of [{tool_names}]\\n\\nAction Input: the input to the action\\n\\nObservation: the result of the action\\n\\n```\\n\\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\\n\\n```\\n\\nThought: Do I need to use a tool? No\\n\\nFinal Answer: [your response here]\\n\\n```\\n\\nBegin!\\n\\nPrevious conversation history:\\n\\n{chat_history}\\n\\nNew input: {input}\\n\\n{agent_scratchpad}\\n')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a5873d-2e2a-4a6d-a9e6-7911f42d4f7c",
   "metadata": {},
   "source": [
    "## CNN news based retrieval conversation agent\n",
    "\n",
    "**** Practice by yourself, because it is quite boring to me ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9822451-4f43-4b40-846c-0bb9a80f0ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agent.react_chat import prompt_template as chat_prompt_template\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "\n",
    "class RetrievalTool(BaseTool):\n",
    "    \n",
    "    name = \"US news tool\"\n",
    "    description = \"Use this tool whenever you want to start a conversation or answer the question related to what happens in the United State.\"\n",
    "\n",
    "    def _run(self, query):\n",
    "\n",
    "        print(query)\n",
    "        \n",
    "        result = retriever.invoke(query)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _arun(self, query: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")\n",
    "\n",
    "\n",
    "tools = [RetrievalTool()]\n",
    "\n",
    "prompt = PromptTemplate.from_template(chat_prompt_template)\n",
    "\n",
    "conversation_agent = create_react_agent(\n",
    "    llm=agent_engine,QUIT\n",
    "    \n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=conversation_agent, tools=tools, verbose=True, handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8d7bd7-9095-4270-9ff6-3bc1bdd4d78e",
   "metadata": {},
   "source": [
    "對話:\n",
    "\n",
    "- How are you today?\n",
    "- What is the current situation of logistic in the US?\n",
    "\n",
    "可以慢慢玩，觀察Agent'思考'過程來思考如何調整prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3612f43-1f04-410b-a4b2-469a9d8cdf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "while True:\n",
    "    question = input(\"Please input your question: \")\n",
    "\n",
    "    # if you want to quit\n",
    "    if question == \"QUIT\":\n",
    "        break\n",
    "    \n",
    "    answer = agent_executor.invoke({\"input\": question,\n",
    "                                    \"chat_history\": [(message.type, message.content) for message in chat_history.messages]\n",
    "                                  })\n",
    "\n",
    "    print(answer)\n",
    "    \n",
    "    chat_history.add_user_message(question)\n",
    "    chat_history.add_ai_message(answer['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7826c5fa-9673-4aca-8db4-8005d68fd985",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [RetrievalTool(), \n",
    "         Tool(\n",
    "             name=\"Wikipedia search tool\",\n",
    "             func=wikipedia.run,\n",
    "             description='search wikipedia for most recent information.'\n",
    ")]\n",
    "\n",
    "prompt = PromptTemplate.from_template(chat_prompt_template)\n",
    "\n",
    "conversation_agent = create_react_agent(\n",
    "    llm=agent_engine,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=conversation_agent, tools=tools, verbose=True, handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dbd592-4623-40ed-9885-5d861d1d0fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "while True:\n",
    "    question = input(\"Please input your question: \")\n",
    "\n",
    "    # if you want to quit\n",
    "    if question == \"QUIT\":\n",
    "        break\n",
    "    \n",
    "    answer = agent_executor.invoke({\"input\": question,\n",
    "                                    \"chat_history\": [(message.type, message.content) for message in chat_history.messages]\n",
    "                                  })\n",
    "\n",
    "    print(f\"\\n***************************\\n{answer['output']}\\n***************************\\n\")\n",
    "    \n",
    "    chat_history.add_user_message(question)\n",
    "    chat_history.add_ai_message(answer['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5985a7ef-01e3-43ab-99a2-420dc56e83b5",
   "metadata": {},
   "source": [
    "## self ask with search agent\n",
    "\n",
    "For this agent, only one tool can be used and it needs to be named \"Intermediate Answer\"\n",
    "\n",
    "prompt: hwchase17/self-ask-with-search\n",
    "\n",
    "It seems it does not work well with OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440a620a-300a-4e9e-8383-6b93a096cdc1",
   "metadata": {},
   "source": [
    "### Google Search\n",
    "\n",
    "- https://serper.dev/\n",
    "- 2500 free queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8bd9aa-b53d-46a1-9a31-e876055ef9bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import create_self_ask_with_search_agent\n",
    "\n",
    "\"\"\"\n",
    "An agent that breaks down a complex question into a series of simpler questions.\n",
    "\n",
    "This agent uses a search tool to look up answers to the simpler questions in order to answer the original complex question.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ce7076-e51d-456b-98a5-2e2ded0b2b8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.agents import Tool\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "search = GoogleSerperAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Intermediate Answer\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to ask with search\",\n",
    "    )]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3a7b9b-78ff-4d22-adcc-1034c9f3d33b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: How old was Muhammad Ali when he died?\n",
    "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
    "Follow up: How old was Alan Turing when he died?\n",
    "Intermediate answer: Alan Turing was 41 years old when he died.\n",
    "So the final answer is: Muhammad Ali\n",
    "\n",
    "Question: When was the founder of craigslist born?\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who was the founder of craigslist?\n",
    "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
    "Follow up: When was Craig Newmark born?\n",
    "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
    "So the final answer is: December 6, 1952\n",
    "\n",
    "Question: Who was the maternal grandfather of George Washington?\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who was the mother of George Washington?\n",
    "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
    "Follow up: Who was the father of Mary Ball Washington?\n",
    "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
    "So the final answer is: Joseph Ball\n",
    "\n",
    "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who is the director of Jaws?\n",
    "Intermediate answer: The director of Jaws is Steven Spielberg.\n",
    "Follow up: Where is Steven Spielberg from?\n",
    "Intermediate answer: The United States.\n",
    "Follow up: Who is the director of Casino Royale?\n",
    "Intermediate answer: The director of Casino Royale is Martin Campbell.\n",
    "Follow up: Where is Martin Campbell from?\n",
    "Intermediate answer: New Zealand.\n",
    "So the final answer is: No\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Are followup questions needed here:{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "self_ask_with_search_agent = create_self_ask_with_search_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=self_ask_with_search_agent, tools=tools, verbose=True)\n",
    "\n",
    "# agent_executor.invoke({\"input\": \"What is the hometown of the reigning men's 2022 U.S. Open champion?\"}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68d403f-0d6c-4ab4-9701-37f1c4bd66bb",
   "metadata": {},
   "source": [
    "### GPT-4o can achieve the same functionality with zero-shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ea72fe-9bf8-4d66-a092-3dd7806ee079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "\n",
    "search = GoogleSerperAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Google Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to search\",\n",
    "    )]\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(zero_shot_prompt_template)\n",
    "\n",
    "zero_shot_agent = create_react_agent(\n",
    "    llm=model,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=zero_shot_agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085f24ef-d092-463f-996f-9f83b17fada5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"What is the hometown of the reigning men's 2022 U.S. Open champion?\"}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaebf9c-446b-4ec8-bc75-dbfeaec248ce",
   "metadata": {},
   "source": [
    "## Structured Chat Agent\n",
    "\n",
    "The structured chat agent is capable of using multi-input tools.\n",
    "\n",
    "在 0.1.0 版本之前，如果 Agent 用到的工具的輸入參數如果不是 1 個的話，那麼就只能是用 Structured Chat Agent。但是 0.1.0 版本取消了這個限制。因此，\n",
    "在 0.1.0 版本之後，Structured Chat Agent 和 ReAct Agent 的主要區別就只剩下工具的描述方式：\n",
    "\n",
    "Structured Chat Agent 需要使用 JSON-Schema 的模式來創建結構化的參數輸入，對於更複雜的工具而言，這種方式更為有用。\n",
    "\n",
    "- https://smith.langchain.com/hub/hwchase17/structured-chat-agent?organizationId=c4887cc4-1275-5361-82f2-b22aee75bad1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d5b312-159e-4884-bbfa-0dc9704ad4de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from typing import Optional\n",
    "\n",
    "# import numpy as np\n",
    "# from langchain.agents import create_structured_chat_agent\n",
    "# from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "\n",
    "# from src.agent.structured_react_chat import system_message_template, human_message_template\n",
    "\n",
    "# messages = [\n",
    "#     SystemMessagePromptTemplate.from_template(system_message_template),\n",
    "#     MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "#     HumanMessagePromptTemplate.from_template(human_message_template),\n",
    "# ]\n",
    "\n",
    "# input_variables = [\"tools\", \"tool_names\", \"input\", \"chat_history\", \"agent_scratchpad\"]\n",
    "\n",
    "# prompt = ChatPromptTemplate(input_variables=input_variables, messages=messages)\n",
    "\n",
    "\n",
    "# class PythagorasTool(BaseTool):\n",
    "#     name = \"Hypotenuse calculator\"\n",
    "#     description = \"\"\"\n",
    "#     Use this tool when you need to calculate the length of an hypotenuse given one or two sides of a triangle and/or an angle (in degrees).\n",
    "#     To use the tool you must provide at least two of the following parameters ['adjacent_side', 'opposite_side', 'angle'].\n",
    "#     \"\"\"\n",
    "\n",
    "#     def _run(\n",
    "#         self,\n",
    "#         adjacent_side: Optional[Union[int, float]] = None,\n",
    "#         opposite_side: Optional[Union[int, float]] = None,\n",
    "#         angle: Optional[Union[int, float]] = None\n",
    "#     ):\n",
    "#         # check for the values we have been given\n",
    "#         if adjacent_side and opposite_side:\n",
    "#             return np.sqrt(float(adjacent_side)**2 + float(opposite_side)**2)\n",
    "#         elif adjacent_side and angle:\n",
    "#             return adjacent_side / cos(float(angle))\n",
    "#         elif opposite_side and angle:\n",
    "#             return opposite_side / sin(float(angle))\n",
    "#         else:\n",
    "#             return \"Could not calculate the hypotenuse of the triangle. Need two or more of `adjacent_side`, `opposite_side`, or `angle`.\"\n",
    "    \n",
    "#     def _arun(self, query: str):\n",
    "#         raise NotImplementedError(\"This tool does not support async\")\n",
    "\n",
    "# tools = [PythagorasTool()]\n",
    "\n",
    "# struct_agent = create_structured_chat_agent(\n",
    "#     llm=model,\n",
    "#     tools=tools,\n",
    "#     prompt=prompt,\n",
    "# )\n",
    "\n",
    "# agent_executor = AgentExecutor(agent=struct_agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7e31d0-d1b0-4c87-b12b-527453bd871f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain.memory import ChatMessageHistory\n",
    "\n",
    "# demo_chat_history = ChatMessageHistory()\n",
    "\n",
    "# demo_chat_history.add_user_message(\"hi!\")\n",
    "\n",
    "# demo_chat_history.add_ai_message(\"whats up?\")\n",
    "\n",
    "# agent_executor.invoke({\"input\": \"If I have a triangle with the opposite side of length 51 and the adjacent side of 40, what is the length of the hypotenuse?\", \n",
    "#                        \"chat_history\": demo_chat_history.messages})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea5ceeb-973b-4cdc-84a6-e4ac9b7a6060",
   "metadata": {},
   "source": [
    "## 回家作業\n",
    "\n",
    "- 在Zero Shot Agent 中，建立一個給予兩邊長和夾角，計算三角形面積的功能 \n",
    "- 在Agent的工具欄中，同時放入Google Search 和 Image Caption 工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d717cd-df56-4525-9752-110a5b8b5884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
