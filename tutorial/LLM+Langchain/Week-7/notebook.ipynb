{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ad11b11-c19a-4323-8a33-0b601d5e7b30",
   "metadata": {},
   "source": [
    "# Image Generation\n",
    "\n",
    "> ğŸ¯ **æœ¬ç« å­¸å®Œä½ å°‡èƒ½å­¸æœƒä»€éº¼ï¼š**\n",
    "> - ç†è§£ OpenAI çš„ **GPT-Image-1** æ¨¡å‹ç‰¹è‰²èˆ‡ä½¿ç”¨æ–¹å¼  \n",
    "> - ç†Ÿæ‚‰ `client.images.generate()` èˆ‡ `client.images.edit()` çš„ä½¿ç”¨æ–¹æ³•  \n",
    "> - æŒæ¡å¦‚ä½•è¨­å®šå½±åƒç”Ÿæˆçš„ **size**ã€**quality**ã€**moderation** ç­‰åƒæ•¸  \n",
    "> - èƒ½ä»¥è‹±æ–‡ prompt ç”Ÿæˆé«˜å“è³ª AI åœ–åƒ  \n",
    "> - ç­è§£å¦‚ä½•å°‡ base64 åœ–åƒè³‡æ–™è½‰æ›ã€é¡¯ç¤ºèˆ‡å„²å­˜  \n",
    "\n",
    "OpenAI æä¾› æ–‡ç”Ÿåœ– (text to image) å’Œ åœ–ç”Ÿåœ– (image to image) APIã€‚\n",
    "\n",
    "## GPT-Image-1\n",
    "\n",
    "The latest image generation model released by OpenAI. Therefore we will work with this.\n",
    "\n",
    "Please update your 'openai' package to 1.97.0 to see the latest documentation\n",
    "\n",
    "å„ªé»:\n",
    "- å‡ºåœ–ç©©å®š (ä¼¼ä¹å›ºå®šäº†Random Seed)\n",
    "- å‡ºåœ–å“è³ªé«˜ï¼Œç´°ç¯€å¥½\n",
    "\n",
    "å»ºè­°ä½¿ç”¨è‹±æ–‡ä½œç‚ºPromptã€‚\n",
    "\n",
    "## ğŸ“š å»¶ä¼¸è³‡æºèˆ‡åƒè€ƒé€£çµ\n",
    "\n",
    "> é€™äº›é€£çµå¯å¹«åŠ©ä½ æ›´æ·±å…¥ç†è§£ OpenAI API èˆ‡ LangChain çš„æ‡‰ç”¨æ–¹å¼ï¼Œ  \n",
    "> ç‰¹åˆ¥é©åˆåœ¨é–±è®€æ•™æå¾Œé€²ä¸€æ­¥æŸ¥é–±å®˜æ–¹æŠ€è¡“æ–‡ä»¶èˆ‡å¯¦ä½œç¯„ä¾‹ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§  OpenAI ç›¸é—œæ–‡ä»¶\n",
    "\n",
    "- [**OpenAI API Image Generation æ–‡æª”**](https://platform.openai.com/docs/guides/image-generation)  \n",
    "  èªªæ˜å¦‚ä½•ä½¿ç”¨ `gpt-image-1` æ¨¡å‹é€²è¡Œ **æ–‡å­—è½‰åœ– (Text-to-Image)**ã€**åœ–åƒç·¨è¼¯ (Image-to-Image)** èˆ‡ **Inpainting**ã€‚  \n",
    "  åŒ…å«è«‹æ±‚åƒæ•¸ï¼ˆå¦‚ `size`ã€`quality`ã€`response_format`ï¼‰åŠå›å‚³æ ¼å¼çš„è©³ç´°èªªæ˜ã€‚  \n",
    "\n",
    "- [**OpenAI API åƒè€ƒæ–‡æª” (API Reference)**](https://platform.openai.com/docs/api-reference/images)  \n",
    "  åˆ—å‡ºæ‰€æœ‰å½±åƒç”Ÿæˆï¼ç·¨è¼¯ç«¯é»èˆ‡å¯ç”¨åƒæ•¸ï¼Œä¸¦æä¾›å¯¦éš›ç¯„ä¾‹ç¨‹å¼ç¢¼ã€‚  \n",
    "  é©åˆåœ¨é–‹ç™¼éšæ®µæŸ¥è©¢ API è«‹æ±‚æ ¼å¼èˆ‡æ¬„ä½èªªæ˜ã€‚  \n",
    "\n",
    "- [**OpenAI Cookbook**](https://cookbook.openai.com/)  \n",
    "  å®˜æ–¹æŠ€è¡“ç¯„ä¾‹é›†ï¼ˆrecipesï¼‰ï¼Œå±•ç¤ºå¦‚ä½•æ•´åˆ OpenAI API è‡³å„ç¨®æ‡‰ç”¨å ´æ™¯ã€‚  \n",
    "  å…¶ä¸­çš„ [å½±åƒç”Ÿæˆç¯„ä¾‹](https://cookbook.openai.com/examples/generate_images_with_gpt_image)  \n",
    "  å°æ‡‰åˆ°æœ¬ç« ç¯€çš„ `client.images.generate()` æ•™å­¸ã€‚\n",
    "\n",
    "\n",
    "- model: gpt-image-1\n",
    "    - size (str): 1024x1024 (square), 1536x1024 (landscape), 1024x1536 (portrait) or auto (default)\n",
    "    - quality: low, medium, high or auto\n",
    "    - moderation: auto, low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238a7c9e-44e8-4192-aa9c-93d6e8378c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b86643-07fa-4cd5-a229-7e01cf9619d1",
   "metadata": {},
   "source": [
    "ç¯„ä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a5fbb5-92dd-456f-8a1a-a41a206abf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "from src.initialization import credential_init\n",
    "\n",
    "credential_init()\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7936f34f-c6ce-43dd-beca-f34bfc8962e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "prompt = (\"A Sumi-e style watercolor painting of mountains during sunset. The sky is depicted with bold \"\n",
    "          \"splashes of orange, pink, and purple hues, blending and overlapping in a dynamic composition. \"\n",
    "          \"The mountains are represented with expressive brushstrokes, emphasizing their majestic and serene \"\n",
    "          \"presence. The focus is on capturing the essence and mood of the scene rather than detailed realism. \"\n",
    "          \"The overall effect is serene and contemplative, with a harmonious balance of color and form.\")\n",
    "\n",
    "response = client.images.generate(\n",
    "    model=\"gpt-image-1\",\n",
    "    prompt=prompt,\n",
    "    size=\"1024x1024\",\n",
    "    # quality=\"hd\",\n",
    "    quality='high',\n",
    "    n=1,\n",
    "    # response_format = 'b64_json'\n",
    ")\n",
    "\n",
    "image_base64 = response.data[0].b64_json\n",
    "\n",
    "# å°‡è¿”å›çš„ base64å­—ä¸²è½‰æ›ç‚ºåœ–åƒä¸¦ä¸”å„²å­˜\n",
    "HTML(f'<img src=\"data:image/png;base64,{image_base64}\"/>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a590663-c339-4bd6-8a09-5ac51b3ecaba",
   "metadata": {},
   "source": [
    "## æŒ‘æˆ°ï¼šå¦‚ä½•æœ‰æ•ˆåœ°æ’°å¯« Text-to-Image æç¤ºè©ï¼š\n",
    "\n",
    "> ğŸ¯ **æœ¬ç« å­¸å®Œä½ å°‡èƒ½å­¸æœƒä»€éº¼ï¼š**\n",
    "> - åˆ†è¾¨å…©ç¨®æç¤ºè©é¢¨æ ¼ï¼š**æ¨™ç±¤å¼æç¤º (Danbooru Tags)** èˆ‡ **è‡ªç„¶èªè¨€æç¤º (Natural Language Prompts)**  \n",
    "> - ç†è§£ä¸åŒæ¨¡å‹å°æ¨™ç±¤çš„æ”¯æ´åº¦å·®ç•°  \n",
    "> - å­¸ç¿’å¦‚ä½•çµåˆè—è¡“ã€æ”å½±ç”¨èªæå‡ç”Ÿæˆå“è³ª   \n",
    "\n",
    "\n",
    "åœ¨ä½¿ç”¨ AI ç”Ÿæˆåœ–åƒï¼ˆä¾‹å¦‚ OpenAI çš„ Image-1ï¼‰æ™‚ï¼Œæç¤ºè©ï¼ˆpromptï¼‰çš„å¯«æ³•å°çµæœæœ‰æ±ºå®šæ€§å½±éŸ¿ã€‚ä¸»è¦æœ‰å…©ç¨®æç¤ºè©æ ¼å¼ï¼š\n",
    "\n",
    "- æ¨™ç±¤å¼æç¤ºï¼ˆDanbooru Tag):\n",
    "\n",
    "    - ç¯„ä¾‹:    \n",
    "\n",
    "        masterpiece, best quality, beautiful eyes, clear eyes, detailed eyes, Blue-eyes, 1girl, 20_old, full-body, break, smoking, break, high_color, blue-hair, beauty, black-boots,break, break, Flat vector art, Colorful art, white_shirt, simple_background, blue_background, Ink art, peeking out upper body, Eyes\n",
    "\n",
    "\n",
    "    - ç‰¹é»èˆ‡æ³¨æ„äº‹é …ï¼š\n",
    "\n",
    "        - ç”Ÿæ•ˆèˆ‡å¦å–æ±ºæ–¼æ¨¡å‹ï¼Œä¸åŒæ¨¡å‹å°åŒä¸€å€‹æ¨™ç±¤çš„ç†è§£å¯èƒ½ä¸åŒã€‚\n",
    "        - æŸäº›æ¨™ç±¤æ˜¯é€šç”¨çš„ï¼Œä¾‹å¦‚ 1girlã€ulzzangï¼Œä½†å‘ˆç¾æ•ˆæœå¯èƒ½å·®ç•°å¾ˆå¤§ã€‚\n",
    "        - ä¸€äº›æ¨™ç±¤éœ€è¦å°ˆæ¥­çŸ¥è­˜ï¼Œä¾‹å¦‚ chiaroscuroï¼ˆæ˜æš—å°ç…§æ³•ï¼‰ã€‚\n",
    "        - éœ€è¦å¤šæ¬¡å˜—è©¦èˆ‡å¾®èª¿ï¼Œæ‰èƒ½æ‰¾åˆ°æœ€ä½³çµ„åˆã€‚\n",
    "\n",
    "2. è‡ªç„¶èªè¨€æç¤ºï¼ˆNatural Language Prompt):\n",
    "\n",
    "    - ç¯„ä¾‹:\n",
    "\n",
    "       A Japanese idol with a breathtakingly glamorous ulzzang appearance,  She has a slim, v-shaped face with large, almond-shaped eyes that sparkle with a lustrous, captivating charm, exuding an aura of youth and ethereal beauty. Her expression is innocent yet alluring, with flawless porcelain skin that enhances her delicate, anime-inspired features. The setting is carefully crafted to complement her enchantment, with soft, diffused lighting that accentuates her mesmerizing, glamorous presence, creating a dreamy and youthful, anime-like allure.\n",
    "\n",
    "\n",
    "    - ç‰¹é»èˆ‡æ³¨æ„äº‹é …ï¼š\n",
    "\n",
    "        - å¥å­å¯«å¾—æµæš¢ã€èªè¨€å„ªç¾ï¼Œèƒ½æå‡ç”Ÿæˆåœ–åƒçš„è³ªæ„Ÿã€‚\n",
    "\n",
    "        - å°éæ¯èªä½¿ç”¨è€…ä¾†èªªï¼Œæ•´åˆå¤šå€‹æè¿°æ€§è©å½™æ˜¯ä¸€å¤§æŒ‘æˆ°ã€‚\n",
    "\n",
    "        - éƒ¨åˆ†è©å½™åœ¨ç›£æ§åš´æ ¼çš„æ¨¡å‹ä¸‹å¯èƒ½æœƒè¢«å±è”½ï¼Œä¾‹å¦‚ serafukuã€‚\n",
    "\n",
    "        - Image-1 ç­‰æ¨¡å‹å¯èƒ½æœƒå°éæ–¼æ˜é¡¯çš„ NSFW æç¤ºè©é€²è¡Œæ””æˆªã€‚è‹¥æƒ³ç”Ÿæˆ NSFW çš„å…§å®¹ï¼Œå»ºè­°å¯ä»¥åƒè€ƒé–‹æºç¤¾ç¾¤ï¼Œä¾‹å¦‚ TensorArtã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742b0214-ea46-4a41-99f4-9cf762e51b0e",
   "metadata": {},
   "source": [
    "## èå…¥ LCEL èˆ‡ LangChain â€” è®“æ¨¡å‹å¹«ä½ ç”Ÿæˆæ›´å¥½çš„ Prompt\n",
    "\n",
    "> ğŸ¯ **æœ¬ç« å­¸å®Œä½ å°‡èƒ½å­¸æœƒä»€éº¼ï¼š**\n",
    "> - èƒ½å°‡ GPT æ¨¡å‹ç”Ÿæˆçš„æ–‡å­—æç¤ºç›´æ¥å°å…¥å½±åƒç”Ÿæˆ API  \n",
    "> - å¯¦ä½œä¸€å€‹è‡ªå‹•å¾æè¿°æ–‡å­— â†’ prompt â†’ åœ–åƒçš„å®Œæ•´æµç¨‹  \n",
    "\n",
    "æœ¬ç¯€å°‡ä»‹ç´¹å¦‚ä½•é‹ç”¨ LangChain å»ºç«‹ä¸€å€‹èƒ½è‡ªå‹•åŒ–æ’°å¯«æç¤ºè©çš„æµç¨‹ï¼Œä¸¦ä¸²æ¥å½±åƒç”Ÿæˆ APIï¼Œé”æˆç«¯åˆ°ç«¯çš„è‡ªå‹•åœ–åƒç”Ÿæˆã€‚\n",
    "\n",
    "### Step1\n",
    "\n",
    "å¯ä»¥çµ¦äºˆå…§å®¹ï¼Œä¸¦ä¸”è®“æ–‡å­—æ¨¡å‹å¹«å¿™å¯«æç¤ºè©ã€‚ä¸¦ä¸”å¯ä»¥è€ƒæ…®ä½¿ç”¨mlflowç›£è¦–ç”¢å‡ºçš„æç¤ºè©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4718b9d-b7f5-4856-9074-d512d0837599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.image import ImagePromptTemplate\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "def build_standard_chat_prompt_template(kwargs):\n",
    "    messages = []\n",
    "\n",
    "    if 'system' in kwargs:\n",
    "        content = kwargs.get('system')\n",
    "\n",
    "        # allow list of prompts for multimodal\n",
    "        if isinstance(content, list):\n",
    "            prompts = [PromptTemplate(**c) for c in content]\n",
    "        else:\n",
    "            prompts = [PromptTemplate(**content)]\n",
    "\n",
    "        message = SystemMessagePromptTemplate(prompt=prompts)\n",
    "        messages.append(message)\n",
    "\n",
    "    if 'human' in kwargs:\n",
    "        content = kwargs.get('human')\n",
    "\n",
    "        # allow list of prompts for multimodal\n",
    "        if isinstance(content, list):\n",
    "            prompts = []\n",
    "            for c in content:\n",
    "                if c.get(\"type\") == \"image\":\n",
    "                    prompts.append(ImagePromptTemplate(**c))\n",
    "                else:\n",
    "                    prompts.append(PromptTemplate(**c))\n",
    "        else:\n",
    "            if content.get(\"type\") == \"image\":\n",
    "                prompts = [ImagePromptTemplate(**content)]\n",
    "            else:\n",
    "                prompts = [PromptTemplate(**content)]\n",
    "\n",
    "        message = HumanMessagePromptTemplate(prompt=prompts)\n",
    "        messages.append(message)\n",
    "\n",
    "    chat_prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "    \n",
    "    return chat_prompt_template\n",
    "\n",
    "\n",
    "\n",
    "system_template = (\"You are a helpful AI assistant and an art expert with extensive knowledge of photography \"\n",
    "                   \"and illustration. You excel at creating breathtaking masterpieces with the DALLE-3 model. \"\n",
    "                   \"For this task, you will be provided with a description of an image, and you will generate a \"\n",
    "                   \"corresponding DALLE-3 prompt. The prompt should be detailed and descriptive, capturing the \"\n",
    "                   \"essence of the image.\")\n",
    "\n",
    "human_template = \"{image_desc}\"\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variable\": [\"image_desc\"]}}\n",
    "    \n",
    "chat_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "nl_prompt_generation_chain = chat_prompt+template | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c89a516-2be9-4641-b061-ddaa79687a97",
   "metadata": {},
   "source": [
    "### Step2\n",
    "\n",
    "å°‡ç”Ÿæˆçš„æç¤ºè©æ”¾å…¥å½±åƒç”ŸæˆAPIä¸­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dc5bc6-3c7e-4fff-9115-7a82bb5f0dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from typing import Dict\n",
    "\n",
    "from langchain_core.runnables import chain, RunnableLambda, RunnableParallel, RunnablePassthrough\n",
    "\n",
    "\n",
    "@chain\n",
    "def gpt_image_worker(kwargs: Dict):\n",
    "\n",
    "    \"\"\"\n",
    "    Generates an image using OpenAI's GPT-Image-1 model based on the provided prompt and optional parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    kwargs (Dict): A dictionary containing the following keys:\n",
    "        - 'nl_prompt' (str): The natural language prompt describing the image to be generated.\n",
    "        - 'size' (str, optional): The size of the generated image. Default is \"1024x1024\".\n",
    "        - 'quality' (str, optional): The quality of the generated image. Default is \"medium\".\n",
    "    \n",
    "    Returns:\n",
    "    str: image base64 string\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Start generating image...\")\n",
    "    print(f\"prompt: {kwargs['nl_prompt']}\")\n",
    "    client = OpenAI()\n",
    "\n",
    "    response = client.images.generate(\n",
    "        model=\"gpt-image-1\",\n",
    "        prompt=kwargs['nl_prompt'],\n",
    "        size=kwargs.get(\"size\", \"1024x1024\"),\n",
    "        quality=kwargs.get('quality', 'medium'),\n",
    "        moderation=kwargs.get('moderation', 'auto'),\n",
    "        n=1)\n",
    "\n",
    "    image_base64 = response.data[0].b64_json\n",
    "    \n",
    "    return image_base64\n",
    "\n",
    "\n",
    "@chain\n",
    "def base64_to_file(kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "    Save the image from a base64 string\n",
    "    \"\"\"\n",
    "    \n",
    "    image_base64 = kwargs['image_base64']\n",
    "    filename = kwargs['filename']\n",
    "    \n",
    "    with open(f\"{filename}\", \"wb\") as fh:\n",
    "        fh.write(base64.b64decode(image_base64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e054b848-beae-4ad2-9ce4-c1dd9cf30255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: ç”Ÿæˆä¾ç…§ä½ æƒ³è¦çš„åœ–åƒæè¿°åœ–åƒæç¤ºè©\n",
    "step_1 = RunnablePassthrough.assign(nl_prompt=itemgetter('image_desc')|nl_prompt_generation_chain)\n",
    "\n",
    "# step 2: ç”Ÿæˆåœ–åƒï¼Œä¸¦å°‡base64å­—ä¸²æ”¾å…¥image_base64è®Šæ•¸ä¸­\n",
    "step_2 = RunnablePassthrough.assign(image_base64=gpt_image_worker)\n",
    "\n",
    "# step 3: å°‡base64å­—ä¸²å„²å­˜ç‚ºåœ–åƒ\n",
    "step_3 = base64_to_file\n",
    "\n",
    "# å°‡ä¸‰å€‹æ­¥é©Ÿç”±æ°´ç®¡ç¬¦è™Ÿ(|)é€£çµèµ·ä¾†\n",
    "gpt_image_chain =  step_1|step_2|step_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6cd391-a27d-4ee6-91c9-c55060b30bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_image_chain.invoke({\"size\": \"1024x1536\",\n",
    "                     \"quality\": \"medium\",\n",
    "                     \"image_desc\": dedent(\"\"\"warhammer 40k, astartes, power armor, chain sword, purity seal, \n",
    "                     oil painting, cinematic view, battle field, black templars, sacred light upon the \"\"\"),\n",
    "                     \"filename\": \"tutorial/LLM+Langchain/Week-8/astartes.png\"\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2228dc-39a5-41e3-85ae-12fbce7dee96",
   "metadata": {},
   "source": [
    "# åœ–åƒæ¸²æŸ“(Image Render)\n",
    "\n",
    "ã€Œåœ–åƒæ¸²æŸ“ã€(Image to Image, ç°¡ç¨± Img2Img) æŒ‡çš„æ˜¯ï¼š\n",
    "åœ¨å·²æœ‰åœ–ç‰‡çš„åŸºç¤ä¸Šï¼Œæ­é…æ–°çš„æç¤ºè© (prompt)ï¼Œç”Ÿæˆå¦ä¸€å¼µé¢¨æ ¼æˆ–å…§å®¹æœ‰æ‰€è®ŠåŒ–çš„åœ–ç‰‡ã€‚\n",
    "\n",
    "## âœ¨ ç‰¹é»\n",
    "\n",
    "1. è¼¸å…¥èˆ‡è¼¸å‡º\n",
    "\n",
    "    - è¼¸å…¥ï¼šä¸€å¼µå·²æœ‰çš„åœ–ç‰‡ + æç¤ºè©\n",
    "\n",
    "    - è¼¸å‡ºï¼šæ ¹æ“šæç¤ºè©æ”¹é€ éçš„åœ–ç‰‡\n",
    "\n",
    "2. éˆæ´»æ€§\n",
    "\n",
    "    - å¯ä»¥ä¿ç•™åŸåœ–çš„çµæ§‹ï¼ˆä¾‹å¦‚äººç‰©å§¿å‹¢ï¼‰ï¼Œåªæ”¹è®Šç´°ç¯€ï¼ˆå¦‚é«®è‰²ã€è¡£æœã€å ´æ™¯ï¼‰ã€‚\n",
    "\n",
    "    - ä¹Ÿå¯ä»¥åšé¢¨æ ¼è½‰æ›ï¼Œè®“ç…§ç‰‡è®Šæˆæ²¹ç•«é¢¨ã€æ¼«ç•«é¢¨ã€æ’ç•«é¢¨ã€‚\n",
    "\n",
    "3. å¸¸è¦‹æ‡‰ç”¨\n",
    "\n",
    "    - ä¿®åœ–ï¼šå»é™¤èƒŒæ™¯ã€ä¿®æ”¹è‡‰éƒ¨ç´°ç¯€ã€æ›è¡£æœã€‚\n",
    "\n",
    "    - é¢¨æ ¼åŒ–ï¼šå°‡ç¾å¯¦ç…§ç‰‡è½‰æˆå‹•æ¼«é¢¨ã€æ’ç•«é¢¨ã€‚\n",
    "\n",
    "    - è¿­ä»£è¨­è¨ˆï¼šå¿«é€Ÿå˜—è©¦ä¸åŒçš„è§’è‰²æœè£ã€é«®å‹æˆ–ç’°å¢ƒã€‚\n",
    "\n",
    "    - å±€éƒ¨ä¿®æ”¹ (Inpainting)ï¼šåœ¨åœ–ç‰‡ä¸ŠæŒ‡å®šå€åŸŸï¼Œåƒ…å°è©²å€åŸŸé€²è¡Œæ›¿æ›æˆ–ä¿®è£œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c029811f-0795-4d9f-b4d5-9a119acd4b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b700bf0c-56b6-4a95-8fc1-8a81e5bcac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Build HTML string\n",
    "html = '<div style=\"display: flex; flex-direction: column;\">'\n",
    "\n",
    "html += '<div style=\"display: flex; justify-content: space-around; margin-bottom: 10px;\">'\n",
    "html += f'''\n",
    "    <div>\n",
    "        <img src=\"Eve_Stellar_Blade.png\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "    </div>\n",
    "'''\n",
    "html += '</div>'\n",
    "\n",
    "html += '</div>'\n",
    "\n",
    "# Display the HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be3c37b-8c72-4907-820e-b9b5ca9dd983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "prompt = dedent(\"\"\"\n",
    "Please rending this image as a realistic photo of a girl cosplaying. A Korean girl with a\n",
    "slim, v-shaped face with large, almond-shaped eyes that sparkle with captivating charm, exuding \n",
    "an aura of youth and ethereal beauty. With flawless skin that enhances her delicate, \n",
    "anime-inspired features. The setting is carefully crafted to complement her enchantment, with \n",
    "soft, diffused lighting that accentuates her mesmerizing, glamorous presence, creating a dreamy \n",
    "and youthful, anime-like allure. Her makeup should resemble the features of K-beauty, such as pale skin tones \n",
    "and dewed skin texture. \n",
    "\"\"\")\n",
    "\n",
    "\n",
    "image_path = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-7\", \"Eve_Stellar_Blade.png\")\n",
    "\n",
    "result_edit = client.images.edit(\n",
    "    model=\"gpt-image-1\",\n",
    "    image=open(image_path, \"rb\"), \n",
    "    prompt=prompt,\n",
    "    size=\"1024x1536\",\n",
    "    input_fidelity=\"high\", # é€™å€‹é¸é …éœ€è¦openai 1.97.0ä»¥ä¸Šç‰ˆæœ¬\n",
    "    #quality=\"high\"\n",
    ")\n",
    "\n",
    "image_base64 = result_edit.data[0].b64_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39988180-9a87-4537-a052-2d1772d408b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.images.edit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19f4403-b6f3-4d5b-b489-68a746633956",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(f'<img src=\"data:image/png;base64,{image_base64}\" />')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d233ce-f88f-44e2-bb3c-137ada00d8d1",
   "metadata": {},
   "source": [
    "You can use one or more images as a reference to generate a new image.\n",
    "\n",
    "In this example, we'll use 4 input images to generate a new image of a gift basket containing the items in the reference images.\n",
    "\n",
    "- Noshiro èƒ½ä»£ (Azur Lane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75090997-6cd6-44c8-9485-96faa0fb087f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "html = '<div style=\"display: flex; flex-direction: column;\">'\n",
    "\n",
    "html += '<div style=\"display: flex; justify-content: space-around; margin-bottom: 10px;\">'\n",
    "html += f'''\n",
    "    <div>\n",
    "        <div>\n",
    "            <img src=\"Noshiro - Spring.png\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "            <img src=\"Noshiro - Summer.png\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "        </div>\n",
    "        <div>\n",
    "            <img src=\"Noshiro - Fall.png\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "            <img src=\"Noshiro - Winter.png\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "        </div>\n",
    "    </div>\n",
    "'''\n",
    "html += '</div>'\n",
    "\n",
    "html += '</div>'\n",
    "\n",
    "# Display the HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593356f2-1bc9-41a9-859b-08af165cd3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1 = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-7\", \"Noshiro - Spring.png\")\n",
    "image_2 = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-7\", \"Noshiro - Summer.png\")\n",
    "image_3 = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-7\", \"Noshiro - Fall.png\")\n",
    "image_4 = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-7\", \"Noshiro - Winter.png\")\n",
    "\n",
    "result_edit = client.images.edit(\n",
    "    model=\"gpt-image-1\",\n",
    "    image=[\n",
    "        # open(image_1, \"rb\"),\n",
    "        open(image_2, \"rb\"),\n",
    "        # open(image_3, \"rb\"),\n",
    "        # open(image_4, \"rb\"),\n",
    "    ],\n",
    "    prompt=dedent(\"\"\"\n",
    "    Create an advertisement of a high end perfume based on the reference image. \n",
    "    The advertisement should deliver a mesmerizingly glamorous texture. \n",
    "    \"\"\"),\n",
    "    size=\"1024x1536\",\n",
    "    input_fidelity=\"high\", # é€™å€‹é¸é …éœ€è¦openai 1.97.0ä»¥ä¸Šç‰ˆæœ¬\n",
    "    quality=\"high\"\n",
    ")\n",
    "\n",
    "image_base64 = result_edit.data[0].b64_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b573038-8787-423e-8da1-90500945ca7f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(f'<img src=\"data:image/png;base64,{image_base64}\"/>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bb9bb7-da23-4023-9d27-0a6c32dc8167",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-7\", \"Noshiro - Summer - Advertisement.png\"), \"wb\") as fh:\n",
    "    fh.write(base64.b64decode(image_base64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86cbbd4-2e76-41c1-ae46-148b0d9609a2",
   "metadata": {},
   "source": [
    "### å°‡ä¸åŒåœ–ç‰‡çš„å…§å®¹èåˆåœ¨ä¸€èµ·\n",
    "\n",
    "åœ–ç‰‡ä¾†æº: https://tensor.art/u/629260971684229814"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6b128b-141c-4e7b-9fa6-0169ef3623c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '<div style=\"display: flex; flex-direction: column;\">'\n",
    "\n",
    "html += '<div style=\"display: flex; justify-content: space-around; margin-bottom: 10px;\">'\n",
    "html += f'''\n",
    "    <div>\n",
    "        <div>\n",
    "            <img src=\"maehara-1.jpg\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "            <img src=\"maehara-2.jpg\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "        </div>\n",
    "    </div>\n",
    "'''\n",
    "html += '</div>'\n",
    "\n",
    "html += '</div>'\n",
    "\n",
    "# Display the HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769c3ca6-307f-4ec0-a8b2-950057d253de",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_a = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-7\", \"maehara-1.jpg\")\n",
    "image_b = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-7\", \"maehara-2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef057e0b-00b4-4adf-a502-ab30227319a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_edit = client.images.edit(\n",
    "    model=\"gpt-image-1\",\n",
    "    image=[\n",
    "        open(image_a, \"rb\"),\n",
    "        open(image_b, \"rb\"),\n",
    "    ],\n",
    "    prompt=dedent(\"\"\"\n",
    "    Fusion the two images to create a high definition 8k movie poster with the text as the background. \n",
    "    \"\"\"),\n",
    "    size=\"1024x1536\",\n",
    "    input_fidelity=\"high\", # é€™å€‹é¸é …éœ€è¦openai 1.97.0ä»¥ä¸Šç‰ˆæœ¬\n",
    "    quality=\"high\"\n",
    ")\n",
    "\n",
    "image_base64 = result_edit.data[0].b64_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff23cbd6-3c75-42b8-a811-ccbe135a32ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(f'<img src=\"data:image/png;base64,{image_base64}\"/>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa8ebfc-db14-4aea-92e5-519112ce17c5",
   "metadata": {},
   "source": [
    "## å±€éƒ¨ä¿®è£œ (Inpaint)\n",
    "\n",
    "ä½ å¯ä»¥æä¾›ä¸€å€‹é®ç½© (mask) ä¾†æŒ‡å®šåœ–åƒä¸­è¦è¢«ç·¨è¼¯çš„å€åŸŸã€‚\n",
    "\n",
    "ç•¶åœ¨ GPT Image ä¸­ä½¿ç”¨é®ç½©æ™‚ï¼Œé¡å¤–çš„æŒ‡ä»¤æœƒä¸€ä½µå‚³é€çµ¦æ¨¡å‹ï¼Œä»¥ä¾¿æ›´å¥½åœ°å¼•å°ç·¨è¼¯éç¨‹ã€‚\n",
    "\n",
    "### é®ç½©çš„è¦æ±‚\n",
    "\n",
    "è¦ç·¨è¼¯çš„åœ–ç‰‡èˆ‡é®ç½©å¿…é ˆç‚ºç›¸åŒçš„æ ¼å¼èˆ‡å°ºå¯¸ï¼Œä¸”æª”æ¡ˆå¤§å°éœ€å°æ–¼ 50MBã€‚\n",
    "\n",
    "é®ç½©åœ–ç‰‡å¿…é ˆåŒ…å« Alpha é€šé“ã€‚å¦‚æœä½ æ˜¯ä½¿ç”¨åœ–åƒç·¨è¼¯å·¥å…·ä¾†è£½ä½œé®ç½©ï¼Œè«‹ç¢ºä¿åœ¨å„²å­˜æ™‚ä¿ç•™ Alpha é€šé“ã€‚\n",
    "\n",
    "\n",
    "### Bug Report\n",
    "\n",
    "https://community.openai.com/t/gpt-image-1-problems-with-mask-edits/1240639/15\n",
    "\n",
    "Image-1 åœ¨ inpainting ä¼¼ä¹åšçš„å¾ˆç³Ÿç³•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb89164a-1949-460f-96d7-97799c481a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '<div style=\"display: flex; flex-direction: column;\">'\n",
    "\n",
    "html += '<div style=\"display: flex; justify-content: space-around; margin-bottom: 10px;\">'\n",
    "html += f'''\n",
    "    <div>\n",
    "        <div>\n",
    "            <img src=\"Noshiro - Winter - Mask.png\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "        </div>\n",
    "    </div>\n",
    "'''\n",
    "html += '</div>'\n",
    "\n",
    "html += '</div>'\n",
    "\n",
    "# Display the HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e57a75-ae39-469c-beb4-022ec309dac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_in = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-7\", \"Noshiro - Winter.png\")\n",
    "image_mask = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-7\", \"Noshiro - Winter - Mask.png\")\n",
    "\n",
    "result_edit = client.images.edit(\n",
    "    model=\"gpt-image-1\",\n",
    "    image=open(image_in, \"rb\"),\n",
    "    mask=open(image_mask, \"rb\"),\n",
    "    prompt=dedent(\"\"\"\n",
    "    In the winter, a girl walking on water and holding MjÃ¶lnir. MjÃ¶lnir is surrounded with electricity and current. \n",
    "    \"\"\"),\n",
    "    size=\"1024x1536\",\n",
    "    input_fidelity=\"high\", # é€™å€‹é¸é …éœ€è¦openai 1.97.0ä»¥ä¸Šç‰ˆæœ¬\n",
    "    quality=\"high\"\n",
    ")\n",
    "\n",
    "image_base64 = result_edit.data[0].b64_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef8cdc-6a7d-43c5-935b-1b4ac2320f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(f'<img src=\"data:image/png;base64,{image_base64}\"/>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824ba903-ad84-4030-962e-88835ff73ff4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Agentï¼ˆä»£ç†å‹ç³»çµ±ï¼‰\n",
    "\n",
    "> ğŸ¯ **æœ¬ç« å­¸å®Œä½ å°‡èƒ½å­¸æœƒä»€éº¼ï¼š**\n",
    "> - ç†è§£ **Agent** çš„æ ¸å¿ƒæ¦‚å¿µèˆ‡èˆ‡å‚³çµ± LLM å›ç­”çš„å·®ç•°  \n",
    "> - æŒæ¡ **ReAct (Reasoning + Acting)** çš„è¡Œå‹•æ€è€ƒå¾ªç’°æ¶æ§‹  \n",
    "> - å­¸æœƒä»¥ LangChain å»ºç«‹å…·é‚è¼¯æ¨ç†èˆ‡å·¥å…·èª¿ç”¨èƒ½åŠ›çš„ Agent  \n",
    "> - ç†Ÿæ‚‰å¦‚ä½•ç”¨ **MLflow** ç›£æ§æ¨¡å‹åŸ·è¡Œéç¨‹èˆ‡æ—¥èªŒ  \n",
    "> - å¯¦ä½œèƒ½è‡ªè¡Œè¦åŠƒæ­¥é©Ÿä¸¦è¨ˆç®—å•é¡Œçš„æ™ºèƒ½ä»£ç†  \n",
    "\n",
    "ä»£ç†å‹ç³»çµ±æ˜¯ä¸€ç¨®èƒ½è‡ªå·±å‹•ä½œçš„ AIï¼Œå®ƒå¯ä»¥ç†è§£è¼¸å…¥ã€æ€è€ƒã€è¦åŠƒï¼Œä¸¦åŸ·è¡Œä»»å‹™ä¾†é”æˆç›®æ¨™ã€‚\n",
    "å’Œä¸€èˆ¬åªèƒ½ä¾ç…§å–®ä¸€æç¤ºå›æ‡‰çš„æ¨¡å‹ä¸åŒï¼Œä»£ç†å‹ç³»çµ±èƒ½è‡ªå·±ç”¢ç”Ÿæç¤ºã€ä½¿ç”¨å¤–éƒ¨å·¥å…·ã€è¨˜ä½å°è©±å…§å®¹ï¼Œä¸¦ä¸”é€éè¦åŠƒå’Œåæ€ä¾†èª¿æ•´è¡Œç‚ºã€‚\n",
    "é€™è®“å®ƒèƒ½æ›´è‡ªå‹•åŒ–åœ°è§£æ±ºå•é¡Œï¼Œä¸¦æŠŠä¸åŒåŠŸèƒ½çµ„åˆèµ·ä¾†ï¼Œå¹«åŠ©ä½¿ç”¨è€…æ›´æœ‰æ•ˆç‡åœ°å®Œæˆäº‹æƒ…ã€‚\n",
    "\n",
    "## ReAct Framework\n",
    "\n",
    "æœ¬ç¯€å°‡èªªæ˜ ReAct çš„æ¦‚å¿µèˆ‡åŸ·è¡Œçµæ§‹ï¼Œå¹«åŠ©ä½ ç†è§£æ€è€ƒï¼ˆReasoningï¼‰èˆ‡è¡Œå‹•ï¼ˆActingï¼‰å¦‚ä½•äº¤äº’ä½œç”¨ã€‚\n",
    "\n",
    "- ReAct: Reasoning - Action\n",
    "\n",
    "- ReAct Agent çš„é‹ä½œæµç¨‹å¤§è‡´æ˜¯ï¼š\n",
    "\n",
    "    1. æ€è€ƒ (Reasoning)ï¼šæ ¹æ“šç•¶å‰çš„ä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆå…§éƒ¨çš„æ¨ç†æˆ–è¨ˆåŠƒã€‚\n",
    "\n",
    "    2. è¡Œå‹• (Acting)ï¼šæ ¹æ“šæ¨ç†çš„çµæœï¼Œæ±ºå®šè¦æ¡å–çš„å‹•ä½œï¼ˆä¾‹å¦‚æŸ¥è©¢å·¥å…·ã€å‘¼å« APIã€æª¢ç´¢çŸ¥è­˜ï¼‰ã€‚\n",
    "\n",
    "    3. è§€å¯Ÿ (Observation)ï¼šå¾—åˆ°å·¥å…·æˆ–ç’°å¢ƒå›é¥‹ã€‚\n",
    "\n",
    "    4. è¿­ä»£ï¼šå°‡è§€å¯Ÿçµæœå†è¼¸å…¥å›å»ï¼Œé€²å…¥ä¸‹ä¸€è¼ªæ€è€ƒã€‚\n",
    "\n",
    "    ç›´åˆ°ï¼š\n",
    "\n",
    "    a. é”åˆ°æœ€çµ‚ç­”æ¡ˆï¼Œæˆ–\n",
    "\n",
    "    b. é‡åˆ°è¨­ç½®çš„åœæ­¢æ¢ä»¶ï¼ˆä¾‹å¦‚ token é™åˆ¶ã€æ­¥æ•¸é™åˆ¶ã€æ˜ç¢ºçš„ \"çµæŸ\" ä¿¡è™Ÿï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ce015d-8bf1-49e0-80b3-e18b78449965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(url='https://statusneo.com/wp-content/uploads/2024/01/fe9fa1ac-dfde-4d91-8b5b-4497b742c414_1400x686.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb253c73-f29a-4f86-9e1c-d7262e2c73eb",
   "metadata": {},
   "source": [
    "### ReAct Template\n",
    "\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "\n",
    "Thought: you should always think about what to do\n",
    "\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "\n",
    "Action Input: the input to the action\n",
    "\n",
    "Observation: the result of the action\n",
    "\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "\n",
    "Thought: I now know the final answer\n",
    "\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Thought:{agent_scratchpad}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26638f8e-95ba-44fd-b046-877dfaca93a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be49e633-6e96-45b9-8ca9-71ccd4893e62",
   "metadata": {},
   "source": [
    "### å»ºç«‹MLflowç›£æ§\n",
    "\n",
    "mlflow server --host 127.0.0.1 --port 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de00d300-5214-4b61-b69d-3e4fb9a7b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from langchain_community.callbacks import MlflowCallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from src.initialization import credential_init\n",
    "\n",
    "credential_init()\n",
    "\n",
    "experiment = \"Week-7\"\n",
    "uri = \"http://127.0.0.1:8080\"\n",
    "\n",
    "mlflow.set_tracking_uri(uri=uri)\n",
    "\n",
    "# Start or get an MLflow run explicitly\n",
    "mlflow.set_experiment(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b51602-d151-4855-8eeb-e5c669b1897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanMlflowCallbackHandler(MlflowCallbackHandler):\n",
    "\n",
    "    def __init__(self, experiment, run_id, tracking_uri, name=\"CleanMLflow\"):\n",
    "        super().__init__(experiment=experiment, run_id=run_id, tracking_uri=tracking_uri, name=name)\n",
    "    \n",
    "    def on_llm_new_token(self, token: str, **kwargs):\n",
    "        # Suppress per-token logging to MLflow\n",
    "        # è‹¥ä½ ä¸é€™éº¼åšçš„è©±\n",
    "        # 1. artifacts è³‡æ–™å¤¾æœƒè¢«æˆåƒä¸Šè¬å€‹å° JSON æª”æ¡ˆå¡æ»¿ã€‚\n",
    "        # 2. æ›´åš´é‡çš„æ˜¯ï¼Œéå¤šçš„é€ token I/O æœƒå¤§å¹…æ‹–æ…¢åŸ·è¡Œé€Ÿåº¦ã€‚\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d131ad1b-c2a1-494b-ad17-074e969c9ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run = mlflow.start_run(run_name=\"react-agent\")\n",
    "\n",
    "# then use this handler instead of the default one\n",
    "mlflow_cb_model = CleanMlflowCallbackHandler(\n",
    "    experiment=experiment,\n",
    "    run_id=run.info.run_id,\n",
    "    tracking_uri=uri,\n",
    ")\n",
    "\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o\", temperature=0, \n",
    "                   callbacks=[mlflow_cb_model],\n",
    "                   name=\"my_model\"\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc06ffce-e3e9-41ad-9f7b-585a5101391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "from src.agent.react_zero_shot import prompt_template as zero_shot_prompt_template\n",
    "\n",
    "prompt = PromptTemplate(template=zero_shot_prompt_template)\n",
    "\n",
    "zero_shot_agent = create_react_agent(\n",
    "    llm=model, ## llmæ˜¯ Agentçš„æ€è€ƒä¸­æ¨ï¼Œé€™å€‹llmæœƒæ±ºå®šagentç¸½é«”ä¸Šçš„å¤§è‡´è¡¨ç¾ï¼Œå»ºè­°è¶Šå¼·è¶Šå¥½\n",
    "    tools=[],\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "class DebugMlflowCallbackHandler(MlflowCallbackHandler):\n",
    "    \n",
    "    def __init__(self, experiment, run_id, tracking_uri, name=\"CleanMLflow\"):\n",
    "        super().__init__(experiment=experiment, run_id=run_id, tracking_uri=tracking_uri)\n",
    "        self.name = name\n",
    "    \n",
    "    def on_chain_error(self, error, **kwargs):\n",
    "        print(f\"Chain error: {error}\")\n",
    "        super().on_chain_error(error, **kwargs)\n",
    "\n",
    "    def on_tool_error(self, error, **kwargs):\n",
    "        print(f\"Tool error: {error}\")\n",
    "        super().on_tool_error(error, **kwargs)\n",
    "\n",
    "\n",
    "mlflow_cb_agent = DebugMlflowCallbackHandler(\n",
    "    experiment=experiment,\n",
    "    run_id=run.info.run_id,\n",
    "    tracking_uri=uri,\n",
    ")\n",
    "\n",
    "\n",
    "agent_executor = AgentExecutor(agent=zero_shot_agent, tools=[], verbose=True, callbacks=[mlflow_cb_agent], name='my_agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8cc22f-e8fc-4a23-bc0f-b1918bdb90b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"Please calculate the area of a circle that has a radius of 10.923mm\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa74eeef-86f2-4e81-a89d-80f796a46c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac67459-977c-4055-805e-1c710dddc85f",
   "metadata": {},
   "source": [
    "# Tool èˆ‡ Agent æ‡‰ç”¨\n",
    "\n",
    "> ğŸ¯ **æœ¬ç« å­¸å®Œä½ å°‡èƒ½å­¸æœƒä»€éº¼ï¼š**\n",
    "> - ç†è§£ LangChain çš„ **Tool ä»‹é¢** èˆ‡è‡ªè¨‚å·¥å…·é–‹ç™¼æµç¨‹  \n",
    "> - å¯¦ä½œä¸‰ç¨®å¸¸è¦‹å·¥å…·ï¼š**MathTool**ã€**SearchTool**ã€**VectorStoreTool**  \n",
    "> - å­¸æœƒä½¿ç”¨ **PydanticOutputParser** å®šç¾©è¼¸å…¥/è¼¸å‡ºæ ¼å¼  \n",
    "> - æŒæ¡å¦‚ä½•å°‡å¤šå€‹å·¥å…·æ¨¡çµ„åŒ–ä¸¦åœ¨ Agent ä¸­æ•´åˆ  \n",
    "> - å»ºç«‹å¯è¨˜æ†¶å°è©±å…§å®¹çš„ **Conversational Agent**  \n",
    "> - ç†è§£å¦‚ä½•å°‡ Agent éƒ¨ç½²è‡³ **LangServe** èˆ‡ **Streamlit** ä»‹é¢  \n",
    "\n",
    "æˆ‘å€‘çŸ¥é“LLMä¸æ˜¯è®“ä½ ç®—æ•¸å­¸ç”¨çš„ã€‚æ•´æ•¸çš„åŠ æ¸›æ³•å¯èƒ½å¯ä»¥ï¼Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932d0eb0-3f19-4614-a683-7062457010f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.start_run(run_name=\"react-agent-with-tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d4eb4d-1486-4b39-99f5-403471b8c43d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Union\n",
    "from textwrap import dedent\n",
    "\n",
    "from langchain.tools import BaseTool\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, \\\n",
    "SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "def build_standard_chat_prompt_template(kwargs):\n",
    "\n",
    "    messages = []\n",
    " \n",
    "    if 'system' in kwargs:\n",
    "        content = kwargs.get('system')\n",
    "        prompt = PromptTemplate(**content)\n",
    "        message = SystemMessagePromptTemplate(prompt=prompt)\n",
    "        messages.append(message)  \n",
    "\n",
    "    if 'human' in kwargs:\n",
    "        content = kwargs.get('human')\n",
    "        prompt = PromptTemplate(**content)\n",
    "        message = HumanMessagePromptTemplate(prompt=prompt)\n",
    "        messages.append(message)\n",
    "        \n",
    "    chat_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "    \n",
    "    return chat_prompt\n",
    "\n",
    "\n",
    "@chain\n",
    "def code_execution(code):\n",
    "    \n",
    "    match = re.findall(r\"python\\n(.*?)\\n```\", code, re.DOTALL)\n",
    "    python_code = match[0]\n",
    "    \n",
    "    lines = python_code.strip()#.split('\\n')\n",
    "    # *stmts, last_line = lines\n",
    "\n",
    "    local_vars = {}\n",
    "    exec(lines, {}, local_vars)\n",
    "\n",
    "    return local_vars\n",
    "\n",
    "\n",
    "system_template = (\n",
    "    \"You are a highly skilled Python developer. Your task is to generate Python code strictly based on the user's instructions.\\n\"\n",
    "    \"Leverage statistical and mathematical libraries such as `statsmodels`, `scipy`, and `numpy` where appropriate to solve the problem.\\n\"\n",
    "    \"Your response must contain only the Python code â€” no explanations, comments, or additional text.\\n\\n\"\n",
    ")\n",
    "\n",
    "human_template = dedent(\"\"\"{query}\\n\\n\n",
    "                            Always copy the final answer to a variable `answer`\n",
    "                            Code:\n",
    "                        \"\"\")\n",
    "\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variable\": [\"query\"]}}\n",
    "\n",
    "code_chat_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "\n",
    "# then use this handler instead of the default one\n",
    "mlflow_cb_model = CleanMlflowCallbackHandler(\n",
    "    experiment=experiment,\n",
    "    run_id=run.info.run_id,\n",
    "    tracking_uri=uri,\n",
    ")\n",
    "\n",
    "model_agent = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                         model_name=\"gpt-4o\", temperature=0, \n",
    "                         callbacks=[mlflow_cb_model]\n",
    "                        )\n",
    "\n",
    "model_coder = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                         model_name=\"gpt-4o-mini\", temperature=0, \n",
    "                         callbacks=[mlflow_cb_model]\n",
    "                        )\n",
    "\n",
    "code_generation = code_chat_prompt_template|model_coder|StrOutputParser()\n",
    "\n",
    "code_pipeline = code_generation|code_execution\n",
    "\n",
    "\n",
    "class MathTool(BaseTool):\n",
    "    name:str = \"Math calculator\"\n",
    "    description:str = dedent(\"\"\"\n",
    "    Use this tool to solve algorithmic problem by python programming.\n",
    "    \"\"\")\n",
    "    \n",
    "    def _run(self, query: str):\n",
    "        \n",
    "        return  code_pipeline.invoke({\"query\": query})\n",
    "    \n",
    "    def _arun(self, radius: Union[int, float]):\n",
    "        raise NotImplementedError(\"This tool does not support async\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ef2c35-768f-46b2-9ee3-a9c1bde3969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "from src.agent.react_zero_shot import prompt_template as zero_shot_prompt_template\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(template=zero_shot_prompt_template)\n",
    "\n",
    "tools = [MathTool()]\n",
    "\n",
    "zero_shot_agent = create_react_agent(\n",
    "    llm=model_agent, ## llmæ˜¯ Agentçš„æ€è€ƒä¸­æ¨ï¼Œé€™å€‹llmæœƒæ±ºå®šagentç¸½é«”ä¸Šçš„å¤§è‡´è¡¨ç¾ï¼Œå»ºè­°è¶Šå¼·è¶Šå¥½\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=zero_shot_agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5245406-2cd2-480f-91fc-d13eb70569c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"Please calculate the area of a circle that has a radius of 10.923mm\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3803271-ce2b-4e82-adb6-3ee933423a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b803df62-1a18-4c71-b36e-b326fa063698",
   "metadata": {},
   "source": [
    "## WebSearch Tool / Wikipedia Tool / å‘é‡è³‡æ–™åº«æ•´åˆ\n",
    "\n",
    "æœ¬ç¯€èªªæ˜å¦‚ä½•å»ºç«‹å¤šè®Šé‡è¼¸å…¥å·¥å…·ï¼ˆå¦‚ SearchToolï¼‰ã€é€£æ¥ç¶­åŸºç™¾ç§‘ã€ä»¥åŠæ•´åˆå‘é‡è³‡æ–™åº«ï¼ˆFAISSï¼‰ã€‚\n",
    "\n",
    "### å¦‚ä½•è®“Toolæ¥æ”¶è¤‡æ•¸çš„è®Šæ•¸?\n",
    "\n",
    "åˆ©ç”¨ä¹‹å‰å­¸éçš„ Pydantic, ä¹Ÿå¯ä»¥ç”¨ResponseSchema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae64487-112d-46b8-adf2-2d0231e0b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3b616c-8a20-491b-86ba-ef61dcabae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Inputs(BaseModel):\n",
    "    query: str = Field(description=\"User query\")\n",
    "    country_code: str = Field(description=\"ISO 3166-1 alpha-2 suggested by the language of the user query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e65d077-d98c-4e15-8bd1-a1fd403b5164",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchTool(BaseTool):\n",
    "\n",
    "    input_output_parser: PydanticOutputParser = PydanticOutputParser(pydantic_object=Inputs)\n",
    "    input_format_instructions: str = input_output_parser.get_format_instructions()\n",
    "    \n",
    "    name:str = \"websearch tool\"\n",
    "    description_template:str = dedent(\"\"\"\n",
    "    Currently it is 2025.    \n",
    "    Use this tool to collect information from the internet, when you are not sure you know the answer.\n",
    "    The input contains the user's question `query` and the ISO 3166-1 alpha-2 `country_code` inferred from the user's language.\n",
    "    input format instructions: {input_format_instructions}\n",
    "    \"\"\")\n",
    "\n",
    "    description: str = description_template.format(input_format_instructions=input_format_instructions)\n",
    "    \n",
    "    def _run(self, query):\n",
    "        \n",
    "        input_ = self.input_output_parser.parse(query)\n",
    "        \n",
    "        query = input_.query\n",
    "        country_code = input_.country_code\n",
    "        \n",
    "        messages = [{\"role\": \"user\",\n",
    "                     \"content\": query}]\n",
    "\n",
    "        response = client.responses.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    tools=[\n",
    "                        {\"type\": \"web_search\",\n",
    "                         \"user_location\":{\n",
    "                             \"type\": \"approximate\",\n",
    "                             \"country\": country_code,\n",
    "                         },\n",
    "                        \"search_context_size\": \"medium\"\n",
    "                        }],\n",
    "                    tool_choice=\"auto\",\n",
    "                    input=query)\n",
    "        \n",
    "        return response.output_text\n",
    "    \n",
    "    def _arun(self, query: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd902b3-bcb5-4546-9829-c008ea4810c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [SearchTool()]\n",
    "\n",
    "zero_shot_agent = create_react_agent(\n",
    "    llm=model,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=zero_shot_agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02083f6d-bc89-4b45-a027-133e777647b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"ç¾ä»»å°ç£ç¸½çµ±çš„è€å®¶æ˜¯å¦æ˜¯é•å»º?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4287efc4-1555-4496-a4f7-25100cd8aa6c",
   "metadata": {},
   "source": [
    "### ç¶­åŸºç™¾ç§‘æŸ¥è©¢è¨­ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c10bc3-3f9a-41e2-94e1-d0c09fbf2229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain, Runnable\n",
    "from langchain_community.tools.wikipedia.tool import WikipediaQueryRun\n",
    "from langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n",
    "\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%Y-%B\")\n",
    "\n",
    "# ä¸€å€‹å¿«é€Ÿå»ºç«‹toolçš„æ–¹æ³•\n",
    "search_tool = Tool(\n",
    "    name=\"Wikipedia search engine tool\",\n",
    "    func=wikipedia.run,\n",
    "    description=f'Wikipedia is up to date to {current_time}. Use this tool to help you answer questions.'\n",
    ")\n",
    "\n",
    "tools = [search_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4361ec4-a2e7-470e-b5ae-8145ece735fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(wikipedia, Runnable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a32f5a-a74b-4930-be18-bd387d0a83cb",
   "metadata": {},
   "source": [
    "### è‡ªå®šç¾©å‘é‡å„²å­˜åº«åšç‚ºå·¥å…·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5c97f-3fc9-4794-aa80-947e814b0fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "\n",
    "vectorstore = FAISS.load_local(\n",
    "    \"tutorial/LLM+Langchain/Week-5/warhammer 40k codex\", embeddings, \n",
    "    allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c5e2bd-7923-42e3-ba5b-10c32ed4e849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableField\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", k=10).configurable_fields( \\\n",
    "                                        search_kwargs=ConfigurableField(\n",
    "                                                id=\"search_kwargs\",\n",
    "                                            )\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87ca978-c912-4f21-a54b-53bb149d8317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "class Inputs(BaseModel):\n",
    "    query: str = Field(description=\"User query\")\n",
    "    clan: Literal['Adeptus Mechanicus', 'Aeldari', 'Black Templars'] = Field(description=\"\")\n",
    "\n",
    "\n",
    "class CodexRetrievalTool(BaseTool):\n",
    "\n",
    "    input_output_parser: PydanticOutputParser = PydanticOutputParser(pydantic_object=Inputs)\n",
    "    input_format_instruction: str = input_output_parser.get_format_instructions()\n",
    "    \n",
    "    name:str = \"warhammer 40k codex\"\n",
    "    description_template:str = dedent(\"\"\"\n",
    "    This tool can be used to retrieve relevant information about warhammer 40k, \n",
    "    particularly Adeptus Mechanicus, Aeldari, Black Templars.\n",
    "    The inputs contains user's question `query` and the party/clan `clan`.\n",
    "    input format instructions: {input_format_instruction}\n",
    "    \"\"\")\n",
    "\n",
    "    description: str = description_template.format(input_format_instruction=input_format_instruction)\n",
    "    \n",
    "    def _run(self, query):\n",
    "        \n",
    "        input_ = self.input_output_parser.parse(query)\n",
    "\n",
    "        query = input_.query\n",
    "        clan = input_.clan\n",
    "\n",
    "        \"\"\"\n",
    "        vectorstoreå‰µé€ æ™‚åœ¨filenameçš„éƒ¨åˆ†æœ‰é»å¤±èª¤\n",
    "        æ‰€ä»¥é€™è£¡ç”¨æ‰‹å‹•çš„æ–¹å¼é€²è¡Œæ ¡æ­£\n",
    "        \"\"\"\n",
    "\n",
    "        if clan == 'Black Templars':\n",
    "            filter_ = {\"filename\": f\"Codex -{clan}\"}\n",
    "        else:\n",
    "            filter_ = {\"filename\": f\"Codex - {clan}\"}\n",
    "        \n",
    "        retrievd_documents = retriever.invoke(query, config={\"configurable\": \n",
    "                                                             {\"search_kwarg\": {\"filter\": filter_\n",
    "                                                                              }\n",
    "                                                             }\n",
    "                                                            }\n",
    "                                             )\n",
    "        \n",
    "        return retrievd_documents\n",
    "    \n",
    "    def _arun(self, query: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b93036d-4a15-420b-9d90-4b521f848bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [CodexRetrievalTool()]\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o\", temperature=0, \n",
    "                   callbacks=[mlflow_cb_model]\n",
    "                  )\n",
    "\n",
    "zero_shot_agent = create_react_agent(\n",
    "    llm=model,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=zero_shot_agent, tools=tools, verbose=True, callbacks=[mlflow_cb_agent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380cc96e-7d0c-4c82-9963-85602532d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"Who is the leader of Aeldari?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc7af47-7507-4d51-ac44-0998455d12cb",
   "metadata": {},
   "source": [
    "### Tools æ¨¡çµ„\n",
    "\n",
    "å‰›å‰›çš„MathTool å’Œ SearchToolçš„ç¯„ä¾‹ä¸­ï¼Œæˆ‘å€‘éƒ½å¿…é ˆè¦ä¸€å€‹å€‹çš„å»ºç«‹å®¢è£½åŒ–å·¥å…·ï¼Œä½†åŒæ™‚æˆ‘å€‘ä¹Ÿç™¼ç¾é€™äº›å·¥å…·éƒ½æœ‰ç›¸åŒçš„çµæ§‹:\n",
    "\n",
    "{\n",
    "- runnable: \n",
    "- description:\n",
    "- name: \n",
    "- input_parser:\n",
    "- \n",
    "}\n",
    "S\n",
    "\n",
    "é‚£èƒ½ä¸èƒ½ç›´æ¥å¯«å¥½éœ€è¦çš„å…§å®¹ï¼Œç„¶å¾Œä½¿ç”¨for loopå¥—æ¨¡æ¿å»ºç«‹å·¥å…·?\n",
    "\n",
    "| å€å¡Š                             | åŠŸèƒ½èªªæ˜                      |\n",
    "| ------------------------------ | ------------------------- |\n",
    "| `class ToolTemplate(BaseTool)` | å»ºç«‹è‡ªè¨‚å·¥å…·çš„ç¯„æœ¬é¡åˆ¥               |\n",
    "| `runnable`                     | å¯¦éš›åŸ·è¡Œä»»å‹™çš„ç‰©ä»¶ï¼ˆå¯æ¥ chain æˆ–ä»»æ„å‡½å¼ï¼‰ |\n",
    "| `input_parser`                 | ç”¨ä¾†è§£æ Agent å‚³å…¥çš„è¼¸å…¥å­—ä¸²ç‚ºçµæ§‹åŒ–æ ¼å¼  |\n",
    "| `create()`                     | é¡åˆ¥æ–¹æ³•ï¼Œç”¨æ–¼å¿«é€Ÿç”Ÿæˆå¸¶æœ‰æè¿°èˆ‡æ ¼å¼èªªæ˜çš„å·¥å…·å¯¦ä¾‹ |\n",
    "| `_run()`                       | å·¥å…·è¢«å‘¼å«æ™‚åŸ·è¡Œçš„ä¸»è¦é‚è¼¯ï¼Œè™•ç†è¼¸å…¥è§£æèˆ‡ä»»å‹™å‘¼å« |\n",
    "| `_arun()`                      | éåŒæ­¥ç‰ˆæœ¬ï¼ˆç›®å‰å°šæœªæ”¯æ´ï¼‰             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b4627-2848-4d06-9a7e-f1985e994f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToolTemplate æ˜¯ä¸€å€‹ã€Œå·¥å…·ç¯„æœ¬ (Tool Template)ã€\n",
    "# ä¸»è¦ç›®çš„æ˜¯è®“æˆ‘å€‘èƒ½å¿«é€Ÿå»ºç«‹å…·æœ‰çµ±ä¸€çµæ§‹çš„è‡ªè¨‚å·¥å…·ï¼ˆToolï¼‰\n",
    "# åœ¨ LangChain çš„ Agent ä¸­ï¼Œå·¥å…· (Tool) æ˜¯ LLM åŸ·è¡Œç‰¹å®šä»»å‹™çš„ã€Œå¤–éƒ¨åŠŸèƒ½æ¨¡çµ„ã€ï¼Œ\n",
    "# ä¾‹å¦‚ï¼šæŸ¥è©¢ç¶²è·¯ã€åŸ·è¡Œç¨‹å¼ç¢¼ã€é€²è¡Œæ•¸å­¸é‹ç®—ã€æª¢ç´¢è³‡æ–™åº« ç­‰ã€‚\n",
    "\n",
    "class ToolTemplate(BaseTool):\n",
    "    # ----------- å±¬æ€§å€ (Attributes) -----------\n",
    "    runnable: Runnable                    # å·¥å…·å¯¦éš›åŸ·è¡Œé‚è¼¯ (ä¾‹å¦‚æŸå€‹ chainã€function)\n",
    "    name: str                             # å·¥å…·åç¨±ï¼ˆAgent æœƒç”¨é€™å€‹åç¨±å‘¼å«å®ƒï¼‰\n",
    "    input_parser: PydanticOutputParser    # ç”¨æ–¼è§£æè¼¸å…¥çš„è³‡æ–™æ¨¡å‹\n",
    "    description: str                      # å·¥å…·èªªæ˜æ–‡å­—ï¼ˆæœƒé¡¯ç¤ºåœ¨ Agent çš„å¯ç”¨å·¥å…·æ¸…å–®ä¸­ï¼‰\n",
    "\n",
    "    # ----------- é¡åˆ¥æ–¹æ³• (Class Method) -----------\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, runnable: Runnable, name: str, description: str,\n",
    "               input_parser: PydanticOutputParser):\n",
    "\n",
    "        \"\"\"\n",
    "        é€™å€‹é¡åˆ¥æ–¹æ³•ç”¨æ–¼ã€Œå¿«é€Ÿå»ºç«‹ã€ä¸€å€‹ Tool å¯¦ä¾‹ã€‚\n",
    "        å®ƒæœƒè‡ªå‹•æ’å…¥æè¿°æ–‡å­— (description) èˆ‡è¼¸å…¥æ ¼å¼èªªæ˜ï¼Œ\n",
    "        è®“ Agent åœ¨ä½¿ç”¨æ™‚çŸ¥é“è©²æ€éº¼å‚³å…¥åƒæ•¸ã€‚\n",
    "        \"\"\"\n",
    "\n",
    "        # å–å¾—è¼¸å…¥æ ¼å¼èªªæ˜ï¼ˆLangChain çš„ Pydantic Parser æœƒç”¢ç”Ÿæ ¼å¼æç¤ºï¼‰\n",
    "        input_format_instruction = input_parser.get_format_instructions()\n",
    "\n",
    "        # å°‡è¼¸å…¥æ ¼å¼èªªæ˜åµŒå…¥åˆ°å·¥å…·èªªæ˜æ–‡å­—ä¸­\n",
    "        description = description_template.format(\n",
    "            input_format_instruction=input_format_instruction\n",
    "        )\n",
    "\n",
    "        # å›å‚³å®Œæ•´çš„ ToolTemplate å¯¦ä¾‹\n",
    "        return cls(runnable=runnable, name=name, description=description,\n",
    "                   input_parser=input_parser)\n",
    "    \n",
    "    def _run(self, query: str):\n",
    "\n",
    "         \"\"\"\n",
    "        å·¥å…·åœ¨è¢« Agent å‘¼å«æ™‚ï¼ŒæœƒåŸ·è¡Œé€™å€‹æ–¹æ³•ã€‚\n",
    "        é€™è£¡çš„ query æ˜¯ LLM å‚³å…¥çš„æ–‡å­—è¼¸å…¥ã€‚\n",
    "        \"\"\"\n",
    "\n",
    "        # Step 1: ä½¿ç”¨ input_parser è§£æè¼¸å…¥ï¼Œç¢ºä¿æ ¼å¼æ­£ç¢º\n",
    "        input_ = self.input_parser.parse(query)\n",
    "\n",
    "        # Step 2: è½‰æ› Pydantic ç‰©ä»¶æˆ Python å­—å…¸ (dict)ï¼Œæ–¹ä¾¿å‚³çµ¦ runnable\n",
    "        runnable_inputs = input_.model_dump()\n",
    "\n",
    "        # Step 3: å‘¼å«å¯¦éš›çš„ runnableï¼ˆå¯èƒ½æ˜¯ chainã€function æˆ– APIï¼‰\n",
    "        if self.input_parser is None:\n",
    "            # è‹¥æ²’æœ‰æŒ‡å®š parserï¼Œå°±ç›´æ¥æŠŠ query ä¸Ÿçµ¦ runnable\n",
    "            return self.runnable.invoke({\"query\": query}) # é€™è¡Œæš—ç¤ºäº†runnableè¦å°‡queryä½œç‚ºä¸€å€‹è¼¸å…¥\n",
    "        else:\n",
    "            # è‹¥æœ‰ parserï¼Œä»£è¡¨è¦ç”¨è§£æå¾Œçš„åƒæ•¸å­—å…¸ä½œç‚ºè¼¸å…¥\n",
    "            input_pydantic = self.input_parser.parse(query)\n",
    "            input_dict = input_pydantic.model_dump()\n",
    "            return self.runnable.invoke(input_dict)\n",
    "\n",
    "# ----------- éåŒæ­¥ç‰ˆæœ¬ (å°šæœªæ”¯æ´) -----------\n",
    "    def _arun(self, query: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f58d23b-14d2-48df-b2bd-33a91e0f37b5",
   "metadata": {},
   "source": [
    "å°‡ä¸Šé¢çš„ä¸€äº›å·¥å…·éƒ½æ‰“åŒ…å…¥toolsé€™å€‹è³‡æ–™å¤¾è£¡ï¼Œæ–¹ä¾¿ä¹‹å¾Œèª¿ç”¨:\n",
    "\n",
    "- tools.websearch: SearchTool\n",
    "- tools.vectorstore: CodexRetrievalTool\n",
    "- tools.math: MathTool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaddf87-6b30-4c79-beed-f0b951343820",
   "metadata": {},
   "source": [
    "## Conversational Agent\n",
    "\n",
    "æœ€å¾Œï¼Œæˆ‘å€‘å°‡ç¤ºç¯„å¦‚ä½•é€é LangChain èˆ‡ LangServeï¼Œå»ºç«‹å…·å‚™ä¸Šä¸‹æ–‡è¨˜æ†¶èˆ‡å·¥å…·èª¿ç”¨èƒ½åŠ›çš„å°è©±å‹ Agentï¼Œä¸¦ä»¥ Streamlit æ‰“é€ äº’å‹•å¼èŠå¤©ä»‹é¢ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c515d-8962-4c7c-9b8d-e8ab3b735ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190cb2ad-4fc2-4851-b275-fe5aef776818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agent.react_chat import prompt_template as chat_prompt_template\n",
    "from src.initialization import credential_init\n",
    "\n",
    "credential_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d566f5a5-dd3c-4755-a1de-267bba413fa2",
   "metadata": {},
   "source": [
    "å¾toolsè£¡ç›´æ¥æŠŠå·¥å…·æ‹‰å‡ºä¾†ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadc2693-d61d-4ae6-884d-458a45b32e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "module_math = importlib.import_module(\"tutorial.LLM+Langchain.Week-7.tools.math\")\n",
    "module_vectorstore = importlib.import_module(\"tutorial.LLM+Langchain.Week-7.tools.vectorstore\")\n",
    "module_websearch = importlib.import_module(\"tutorial.LLM+Langchain.Week-7.tools.websearch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a70a70f-c3c9-4dec-9da1-fe2ce05bc6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [module_math.MathTool(), module_websearch.SearchTool(), module_vectorstore.CodexRetrievalTool()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e10ba3-5041-40d0-9c6d-809f74b33ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain.agents import Tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.wikipedia.tool import WikipediaQueryRun\n",
    "from langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "#å˜—è©¦å–®ç´”çš„åŠ å…¥èŠå¤©ç´€éŒ„\n",
    "\n",
    "template = dedent(\"\"\"\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "When you need to use a tool to get knowledge, the vectorstore tools have a high priority than websearch tool.\n",
    "\n",
    "To use a tool, you MUST strictly follow this format (case-sensitive, exact words)::\n",
    "\n",
    "```\n",
    "\n",
    "Thought: Do I need to use a tool? Yes\n",
    "\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "\n",
    "Action Input: the input to the action\n",
    "\n",
    "Observation: [the result of the action]\n",
    "\n",
    "```\n",
    "\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "\n",
    "\n",
    "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
    "\n",
    "```\n",
    "\n",
    "Thought: Do I need to use a tool? No\n",
    "\n",
    "Final Answer: [your response here]. The final response should be in Traditional Chinese (ç¹é«”ä¸­æ–‡).\n",
    "\n",
    "```\n",
    "\n",
    "Begin!\n",
    "\n",
    "Previous conversation history:\n",
    "\n",
    "{chat_history}\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o\", temperature=0, \n",
    "                  )\n",
    "\n",
    "conversation_agent = create_react_agent(\n",
    "    llm=model,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=conversation_agent, tools=tools, verbose=True,\n",
    "                               handle_parsing_errors=True, max_iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b03b84-a4c2-4bd4-9920-2b17d246b64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5867ed9-1077-4f64-a5da-ab9c5a498203",
   "metadata": {},
   "source": [
    "åœ¨ç¬¬å››å‘¨å­¸ChatBotæ™‚ï¼Œæˆ‘å€‘å­¸éå¦‚ä½•ç”¨ChatMessageHistoryé€™å€‹ç‰©ä»¶å­˜æ”¾èŠå¤©ç´€éŒ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdff378-8921-4fd3-8e26-ea0ac39e1dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "while True:\n",
    "    input_ = input(\"è«‹è¼¸å…¥ä½ çš„å•é¡Œ (è¼¸å…¥ quit è·³å‡º):\")\n",
    "    if input_ == 'quit':\n",
    "        break\n",
    "    output = agent_executor.invoke({\"chat_history\": chat_history,\n",
    "                                    \"input\": input_})\n",
    "\n",
    "    print(f\"\\n***{output['output']}***\\n\")\n",
    "    \n",
    "    chat_history.add_user_message(input_)\n",
    "    chat_history.add_ai_message(output['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c986f2-5f66-4a57-bf2e-ceaef27594c0",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨Streamlitå»ºç«‹åŸºæ–¼Agentçš„èŠå¤©æ©Ÿå™¨äºº\n",
    "\n",
    "- Agent å°‡éƒ¨å±¬æ–¼ Langserve ä¸Š\n",
    "- Agent åœ¨ Langserveä¸Šçš„æ‡‰ç”¨æœ‰äº›çœ‰è§’éœ€è¦æ³¨æ„: è¦é¡å¤–ä½¿ç”¨pydanticæ•¸æ“šæ¨¡å‹è¨»æ˜input å’Œ output é¡å‹\n",
    "    - BaseMessage ç‰©ä»¶ï¼ˆåƒæ˜¯ HumanMessageã€AIMessageï¼‰å…¶å¯¦æ˜¯ Pydantic æ¨¡å‹ï¼Œæ‰€ä»¥ï¼š\n",
    "    - c.model_dump() â†’ æœƒå¾—åˆ° å­—å…¸ (dict)ï¼Œé€™æ­£æ˜¯ requests.post(..., json=...) éœ€è¦çš„æ ¼å¼ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc08a12d-4fe9-456e-b103-ca8029f78b5b",
   "metadata": {},
   "source": [
    "é¦–å…ˆç¢ºèªå¦‚ä½•é€érequestså’Œlangserveäº¤æµ\n",
    "\n",
    "å°‡chat_historyç‰©ä»¶çš„å…§å®¹model_dump(), é€™æ¨£ API æœƒæ”¶åˆ°ä¸€å€‹ chat_historyï¼Œå®ƒæ˜¯ç”± dict çµ„æˆçš„åˆ—è¡¨ï¼ˆè£¡é¢æœ‰ type + content æ¬„ä½ï¼‰ï¼ŒLangServe å°±èƒ½æ­£ç¢ºé‚„åŸæˆ BaseMessage ç‰©ä»¶äº†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08b916c-2aa5-4165-a178-c289e2c245a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from textwrap import dedent\n",
    "\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "chat_history.add_user_message(\"å‰å¤©å¤©æ°£å¦‚ä½•?\")\n",
    "chat_history.add_ai_message(\"å‰å¤©é¢³é¢¨ä¸‹é›¨\")\n",
    "\n",
    "response = requests.post(\n",
    "    \"http://localhost:8080/chatbot/invoke\",\n",
    "    json={'input': {\"input\": \"æˆ‘å‰›å‰›çš„å•é¡Œç‚ºä½•?\",\n",
    "                    \"chat_history\": [c.model_dump() for c in chat_history.messages]\n",
    "                   }\n",
    "         }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e82b6c-efb5-4e77-a1db-7b95d08d1bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540d5464-7f33-4553-8edd-05821defb21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    \"http://localhost:8080/chatbot/invoke\",\n",
    "    json={'input': {\"input\": \"çµ¦äºˆä¸€å€‹é‚Šé•·ç‚º10çš„æ­£æ–¹å½¢ï¼Œé¸å®šå…©å€‹å°è§’é»ï¼Œåœ¨æ­£æ–¹å½¢å…§å„ç•«ä¸€å€‹åŠå¾‘ç‚º10çš„1/4åœ“ã€‚è«‹å•å…©å€‹1/4åœ“é‡ç–Šçš„éƒ¨åˆ†å¤§å°ç‚ºä½•?\",\n",
    "                    \"chat_history\": [c.model_dump() for c in chat_history.messages]\n",
    "                   }\n",
    "         }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e803b-83d8-4287-bb1e-2cd776acc2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "[c.model_dump() for c in chat_history.messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c11088-08c4-42c7-aec7-c829c0325f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f221e36f-0d83-42cc-98b9-802b9118983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "math.pi * 2 * (1/4) * 10 * 10 - 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e478fe7-d9eb-4541-a9f5-a13e76ecda3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'checkpoints' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcheckpoints\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'checkpoints' is not defined"
     ]
    }
   ],
   "source": [
    "checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f92366-99bb-4807-9f03-c36df0a64dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
