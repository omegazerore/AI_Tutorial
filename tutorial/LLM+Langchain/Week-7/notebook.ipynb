{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ad11b11-c19a-4323-8a33-0b601d5e7b30",
   "metadata": {},
   "source": [
    "# Image Generation\n",
    "\n",
    "> 🎯 **本章學完你將能學會什麼：**\n",
    "> - 理解 OpenAI 的 **GPT-Image-1** 模型特色與使用方式  \n",
    "> - 熟悉 `client.images.generate()` 與 `client.images.edit()` 的使用方法  \n",
    "> - 掌握如何設定影像生成的 **size**、**quality**、**moderation** 等參數  \n",
    "> - 能以英文 prompt 生成高品質 AI 圖像  \n",
    "> - 瞭解如何將 base64 圖像資料轉換、顯示與儲存  \n",
    "\n",
    "OpenAI 提供 文生圖 (text to image) 和 圖生圖 (image to image) API。\n",
    "\n",
    "## GPT-Image-1\n",
    "\n",
    "The latest image generation model released by OpenAI. Therefore we will work with this.\n",
    "\n",
    "Please update your 'openai' package to 1.97.0 to see the latest documentation\n",
    "\n",
    "優點:\n",
    "- 出圖穩定 (似乎固定了Random Seed)\n",
    "- 出圖品質高，細節好\n",
    "\n",
    "建議使用英文作為Prompt。\n",
    "\n",
    "## 📚 延伸資源與參考連結\n",
    "\n",
    "> 這些連結可幫助你更深入理解 OpenAI API 與 LangChain 的應用方式，  \n",
    "> 特別適合在閱讀教材後進一步查閱官方技術文件與實作範例。\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 OpenAI 相關文件\n",
    "\n",
    "- [**OpenAI API Image Generation 文檔**](https://platform.openai.com/docs/guides/image-generation)  \n",
    "  說明如何使用 `gpt-image-1` 模型進行 **文字轉圖 (Text-to-Image)**、**圖像編輯 (Image-to-Image)** 與 **Inpainting**。  \n",
    "  包含請求參數（如 `size`、`quality`、`response_format`）及回傳格式的詳細說明。  \n",
    "\n",
    "- [**OpenAI API 參考文檔 (API Reference)**](https://platform.openai.com/docs/api-reference/images)  \n",
    "  列出所有影像生成／編輯端點與可用參數，並提供實際範例程式碼。  \n",
    "  適合在開發階段查詢 API 請求格式與欄位說明。  \n",
    "\n",
    "- [**OpenAI Cookbook**](https://cookbook.openai.com/)  \n",
    "  官方技術範例集（recipes），展示如何整合 OpenAI API 至各種應用場景。  \n",
    "  其中的 [影像生成範例](https://cookbook.openai.com/examples/generate_images_with_gpt_image)  \n",
    "  對應到本章節的 `client.images.generate()` 教學。\n",
    "\n",
    "\n",
    "- model: gpt-image-1\n",
    "    - size (str): 1024x1024 (square), 1536x1024 (landscape), 1024x1536 (portrait) or auto (default)\n",
    "    - quality: low, medium, high or auto\n",
    "    - moderation: auto, low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238a7c9e-44e8-4192-aa9c-93d6e8378c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b86643-07fa-4cd5-a229-7e01cf9619d1",
   "metadata": {},
   "source": [
    "範例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a5fbb5-92dd-456f-8a1a-a41a206abf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "from src.initialization import credential_init\n",
    "\n",
    "credential_init()\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7936f34f-c6ce-43dd-beca-f34bfc8962e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "prompt = (\"A Sumi-e style watercolor painting of mountains during sunset. The sky is depicted with bold \"\n",
    "          \"splashes of orange, pink, and purple hues, blending and overlapping in a dynamic composition. \"\n",
    "          \"The mountains are represented with expressive brushstrokes, emphasizing their majestic and serene \"\n",
    "          \"presence. The focus is on capturing the essence and mood of the scene rather than detailed realism. \"\n",
    "          \"The overall effect is serene and contemplative, with a harmonious balance of color and form.\")\n",
    "\n",
    "response = client.images.generate(\n",
    "    model=\"gpt-image-1\",\n",
    "    prompt=prompt,\n",
    "    size=\"1024x1024\",\n",
    "    # quality=\"hd\",\n",
    "    quality='high',\n",
    "    n=1,\n",
    "    # response_format = 'b64_json'\n",
    ")\n",
    "\n",
    "image_base64 = response.data[0].b64_json\n",
    "\n",
    "# 將返回的 base64字串轉換為圖像並且儲存\n",
    "HTML(f'<img src=\"data:image/png;base64,{image_base64}\"/>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a590663-c339-4bd6-8a09-5ac51b3ecaba",
   "metadata": {},
   "source": [
    "## 挑戰：如何有效地撰寫 Text-to-Image 提示詞：\n",
    "\n",
    "> 🎯 **本章學完你將能學會什麼：**\n",
    "> - 分辨兩種提示詞風格：**標籤式提示 (Danbooru Tags)** 與 **自然語言提示 (Natural Language Prompts)**  \n",
    "> - 理解不同模型對標籤的支援度差異  \n",
    "> - 學習如何結合藝術、攝影用語提升生成品質   \n",
    "\n",
    "\n",
    "在使用 AI 生成圖像（例如 OpenAI 的 Image-1）時，提示詞（prompt）的寫法對結果有決定性影響。主要有兩種提示詞格式：\n",
    "\n",
    "- 標籤式提示（Danbooru Tag):\n",
    "\n",
    "    - 範例:    \n",
    "\n",
    "        masterpiece, best quality, beautiful eyes, clear eyes, detailed eyes, Blue-eyes, 1girl, 20_old, full-body, break, smoking, break, high_color, blue-hair, beauty, black-boots,break, break, Flat vector art, Colorful art, white_shirt, simple_background, blue_background, Ink art, peeking out upper body, Eyes\n",
    "\n",
    "\n",
    "    - 特點與注意事項：\n",
    "\n",
    "        - 生效與否取決於模型，不同模型對同一個標籤的理解可能不同。\n",
    "        - 某些標籤是通用的，例如 1girl、ulzzang，但呈現效果可能差異很大。\n",
    "        - 一些標籤需要專業知識，例如 chiaroscuro（明暗對照法）。\n",
    "        - 需要多次嘗試與微調，才能找到最佳組合。\n",
    "\n",
    "2. 自然語言提示（Natural Language Prompt):\n",
    "\n",
    "    - 範例:\n",
    "\n",
    "       A Japanese idol with a breathtakingly glamorous ulzzang appearance,  She has a slim, v-shaped face with large, almond-shaped eyes that sparkle with a lustrous, captivating charm, exuding an aura of youth and ethereal beauty. Her expression is innocent yet alluring, with flawless porcelain skin that enhances her delicate, anime-inspired features. The setting is carefully crafted to complement her enchantment, with soft, diffused lighting that accentuates her mesmerizing, glamorous presence, creating a dreamy and youthful, anime-like allure.\n",
    "\n",
    "\n",
    "    - 特點與注意事項：\n",
    "\n",
    "        - 句子寫得流暢、語言優美，能提升生成圖像的質感。\n",
    "\n",
    "        - 對非母語使用者來說，整合多個描述性詞彙是一大挑戰。\n",
    "\n",
    "        - 部分詞彙在監控嚴格的模型下可能會被屏蔽，例如 serafuku。\n",
    "\n",
    "        - Image-1 等模型可能會對過於明顯的 NSFW 提示詞進行攔截。若想生成 NSFW 的內容，建議可以參考開源社群，例如 TensorArt。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742b0214-ea46-4a41-99f4-9cf762e51b0e",
   "metadata": {},
   "source": [
    "## 融入 LCEL 與 LangChain — 讓模型幫你生成更好的 Prompt\n",
    "\n",
    "> 🎯 **本章學完你將能學會什麼：**\n",
    "> - 能將 GPT 模型生成的文字提示直接導入影像生成 API  \n",
    "> - 實作一個自動從描述文字 → prompt → 圖像的完整流程  \n",
    "\n",
    "本節將介紹如何運用 LangChain 建立一個能自動化撰寫提示詞的流程，並串接影像生成 API，達成端到端的自動圖像生成。\n",
    "\n",
    "### Step1\n",
    "\n",
    "可以給予內容，並且讓文字模型幫忙寫提示詞。並且可以考慮使用mlflow監視產出的提示詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4718b9d-b7f5-4856-9074-d512d0837599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.image import ImagePromptTemplate\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "def build_standard_chat_prompt_template(kwargs):\n",
    "    messages = []\n",
    "\n",
    "    if 'system' in kwargs:\n",
    "        content = kwargs.get('system')\n",
    "\n",
    "        # allow list of prompts for multimodal\n",
    "        if isinstance(content, list):\n",
    "            prompts = [PromptTemplate(**c) for c in content]\n",
    "        else:\n",
    "            prompts = [PromptTemplate(**content)]\n",
    "\n",
    "        message = SystemMessagePromptTemplate(prompt=prompts)\n",
    "        messages.append(message)\n",
    "\n",
    "    if 'human' in kwargs:\n",
    "        content = kwargs.get('human')\n",
    "\n",
    "        # allow list of prompts for multimodal\n",
    "        if isinstance(content, list):\n",
    "            prompts = []\n",
    "            for c in content:\n",
    "                if c.get(\"type\") == \"image\":\n",
    "                    prompts.append(ImagePromptTemplate(**c))\n",
    "                else:\n",
    "                    prompts.append(PromptTemplate(**c))\n",
    "        else:\n",
    "            if content.get(\"type\") == \"image\":\n",
    "                prompts = [ImagePromptTemplate(**content)]\n",
    "            else:\n",
    "                prompts = [PromptTemplate(**content)]\n",
    "\n",
    "        message = HumanMessagePromptTemplate(prompt=prompts)\n",
    "        messages.append(message)\n",
    "\n",
    "    chat_prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "    \n",
    "    return chat_prompt_template\n",
    "\n",
    "\n",
    "\n",
    "system_template = (\"You are a helpful AI assistant and an art expert with extensive knowledge of photography \"\n",
    "                   \"and illustration. You excel at creating breathtaking masterpieces with the DALLE-3 model. \"\n",
    "                   \"For this task, you will be provided with a description of an image, and you will generate a \"\n",
    "                   \"corresponding DALLE-3 prompt. The prompt should be detailed and descriptive, capturing the \"\n",
    "                   \"essence of the image.\")\n",
    "\n",
    "human_template = \"{image_desc}\"\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variable\": [\"image_desc\"]}}\n",
    "    \n",
    "chat_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "nl_prompt_generation_chain = chat_prompt+template | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c89a516-2be9-4641-b061-ddaa79687a97",
   "metadata": {},
   "source": [
    "### Step2\n",
    "\n",
    "將生成的提示詞放入影像生成API中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dc5bc6-3c7e-4fff-9115-7a82bb5f0dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from typing import Dict\n",
    "\n",
    "from langchain_core.runnables import chain, RunnableLambda, RunnableParallel, RunnablePassthrough\n",
    "\n",
    "\n",
    "@chain\n",
    "def gpt_image_worker(kwargs: Dict):\n",
    "\n",
    "    \"\"\"\n",
    "    Generates an image using OpenAI's GPT-Image-1 model based on the provided prompt and optional parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    kwargs (Dict): A dictionary containing the following keys:\n",
    "        - 'nl_prompt' (str): The natural language prompt describing the image to be generated.\n",
    "        - 'size' (str, optional): The size of the generated image. Default is \"1024x1024\".\n",
    "        - 'quality' (str, optional): The quality of the generated image. Default is \"medium\".\n",
    "    \n",
    "    Returns:\n",
    "    str: image base64 string\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Start generating image...\")\n",
    "    print(f\"prompt: {kwargs['nl_prompt']}\")\n",
    "    client = OpenAI()\n",
    "\n",
    "    response = client.images.generate(\n",
    "        model=\"gpt-image-1\",\n",
    "        prompt=kwargs['nl_prompt'],\n",
    "        size=kwargs.get(\"size\", \"1024x1024\"),\n",
    "        quality=kwargs.get('quality', 'medium'),\n",
    "        moderation=kwargs.get('moderation', 'auto'),\n",
    "        n=1)\n",
    "\n",
    "    image_base64 = response.data[0].b64_json\n",
    "    \n",
    "    return image_base64\n",
    "\n",
    "\n",
    "@chain\n",
    "def base64_to_file(kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "    Save the image from a base64 string\n",
    "    \"\"\"\n",
    "    \n",
    "    image_base64 = kwargs['image_base64']\n",
    "    filename = kwargs['filename']\n",
    "    \n",
    "    with open(f\"{filename}\", \"wb\") as fh:\n",
    "        fh.write(base64.b64decode(image_base64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e054b848-beae-4ad2-9ce4-c1dd9cf30255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: 生成依照你想要的圖像描述圖像提示詞\n",
    "step_1 = RunnablePassthrough.assign(nl_prompt=itemgetter('image_desc')|nl_prompt_generation_chain)\n",
    "\n",
    "# step 2: 生成圖像，並將base64字串放入image_base64變數中\n",
    "step_2 = RunnablePassthrough.assign(image_base64=gpt_image_worker)\n",
    "\n",
    "# step 3: 將base64字串儲存為圖像\n",
    "step_3 = base64_to_file\n",
    "\n",
    "# 將三個步驟由水管符號(|)連結起來\n",
    "gpt_image_chain =  step_1|step_2|step_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6cd391-a27d-4ee6-91c9-c55060b30bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_image_chain.invoke({\"size\": \"1024x1536\",\n",
    "                     \"quality\": \"medium\",\n",
    "                     \"image_desc\": dedent(\"\"\"warhammer 40k, astartes, power armor, chain sword, purity seal, \n",
    "                     oil painting, cinematic view, battle field, black templars, sacred light upon the \"\"\"),\n",
    "                     \"filename\": \"tutorial/LLM+Langchain/Week-8/astartes.png\"\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2228dc-39a5-41e3-85ae-12fbce7dee96",
   "metadata": {},
   "source": [
    "# 圖像渲染(Image Render)\n",
    "\n",
    "「圖像渲染」(Image to Image, 簡稱 Img2Img) 指的是：\n",
    "在已有圖片的基礎上，搭配新的提示詞 (prompt)，生成另一張風格或內容有所變化的圖片。\n",
    "\n",
    "## ✨ 特點\n",
    "\n",
    "1. 輸入與輸出\n",
    "\n",
    "    - 輸入：一張已有的圖片 + 提示詞\n",
    "\n",
    "    - 輸出：根據提示詞改造過的圖片\n",
    "\n",
    "2. 靈活性\n",
    "\n",
    "    - 可以保留原圖的結構（例如人物姿勢），只改變細節（如髮色、衣服、場景）。\n",
    "\n",
    "    - 也可以做風格轉換，讓照片變成油畫風、漫畫風、插畫風。\n",
    "\n",
    "3. 常見應用\n",
    "\n",
    "    - 修圖：去除背景、修改臉部細節、換衣服。\n",
    "\n",
    "    - 風格化：將現實照片轉成動漫風、插畫風。\n",
    "\n",
    "    - 迭代設計：快速嘗試不同的角色服裝、髮型或環境。\n",
    "\n",
    "    - 局部修改 (Inpainting)：在圖片上指定區域，僅對該區域進行替換或修補。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c029811f-0795-4d9f-b4d5-9a119acd4b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b700bf0c-56b6-4a95-8fc1-8a81e5bcac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Build HTML string\n",
    "html = '<div style=\"display: flex; flex-direction: column;\">'\n",
    "\n",
    "html += '<div style=\"display: flex; justify-content: space-around; margin-bottom: 10px;\">'\n",
    "html += f'''\n",
    "    <div>\n",
    "        <img src=\"Eve_Stellar_Blade.png\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "    </div>\n",
    "'''\n",
    "html += '</div>'\n",
    "\n",
    "html += '</div>'\n",
    "\n",
    "# Display the HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be3c37b-8c72-4907-820e-b9b5ca9dd983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "prompt = dedent(\"\"\"\n",
    "Please rending this image as a realistic photo of a girl cosplaying. A Korean girl with a\n",
    "slim, v-shaped face with large, almond-shaped eyes that sparkle with captivating charm, exuding \n",
    "an aura of youth and ethereal beauty. With flawless skin that enhances her delicate, \n",
    "anime-inspired features. The setting is carefully crafted to complement her enchantment, with \n",
    "soft, diffused lighting that accentuates her mesmerizing, glamorous presence, creating a dreamy \n",
    "and youthful, anime-like allure. Her makeup should resemble the features of K-beauty, such as pale skin tones \n",
    "and dewed skin texture. \n",
    "\"\"\")\n",
    "\n",
    "\n",
    "image_path = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-7\", \"Eve_Stellar_Blade.png\")\n",
    "\n",
    "result_edit = client.images.edit(\n",
    "    model=\"gpt-image-1\",\n",
    "    image=open(image_path, \"rb\"), \n",
    "    prompt=prompt,\n",
    "    size=\"1024x1536\",\n",
    "    input_fidelity=\"high\", # 這個選項需要openai 1.97.0以上版本\n",
    "    #quality=\"high\"\n",
    ")\n",
    "\n",
    "image_base64 = result_edit.data[0].b64_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39988180-9a87-4537-a052-2d1772d408b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.images.edit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19f4403-b6f3-4d5b-b489-68a746633956",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(f'<img src=\"data:image/png;base64,{image_base64}\" />')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d233ce-f88f-44e2-bb3c-137ada00d8d1",
   "metadata": {},
   "source": [
    "You can use one or more images as a reference to generate a new image.\n",
    "\n",
    "In this example, we'll use 4 input images to generate a new image of a gift basket containing the items in the reference images.\n",
    "\n",
    "- Noshiro 能代 (Azur Lane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75090997-6cd6-44c8-9485-96faa0fb087f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "html = '<div style=\"display: flex; flex-direction: column;\">'\n",
    "\n",
    "html += '<div style=\"display: flex; justify-content: space-around; margin-bottom: 10px;\">'\n",
    "html += f'''\n",
    "    <div>\n",
    "        <div>\n",
    "            <img src=\"Noshiro - Spring.png\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "            <img src=\"Noshiro - Summer.png\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "        </div>\n",
    "        <div>\n",
    "            <img src=\"Noshiro - Fall.png\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "            <img src=\"Noshiro - Winter.png\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "        </div>\n",
    "    </div>\n",
    "'''\n",
    "html += '</div>'\n",
    "\n",
    "html += '</div>'\n",
    "\n",
    "# Display the HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593356f2-1bc9-41a9-859b-08af165cd3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1 = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-7\", \"Noshiro - Spring.png\")\n",
    "image_2 = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-7\", \"Noshiro - Summer.png\")\n",
    "image_3 = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-7\", \"Noshiro - Fall.png\")\n",
    "image_4 = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-7\", \"Noshiro - Winter.png\")\n",
    "\n",
    "result_edit = client.images.edit(\n",
    "    model=\"gpt-image-1\",\n",
    "    image=[\n",
    "        # open(image_1, \"rb\"),\n",
    "        open(image_2, \"rb\"),\n",
    "        # open(image_3, \"rb\"),\n",
    "        # open(image_4, \"rb\"),\n",
    "    ],\n",
    "    prompt=dedent(\"\"\"\n",
    "    Create an advertisement of a high end perfume based on the reference image. \n",
    "    The advertisement should deliver a mesmerizingly glamorous texture. \n",
    "    \"\"\"),\n",
    "    size=\"1024x1536\",\n",
    "    input_fidelity=\"high\", # 這個選項需要openai 1.97.0以上版本\n",
    "    quality=\"high\"\n",
    ")\n",
    "\n",
    "image_base64 = result_edit.data[0].b64_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b573038-8787-423e-8da1-90500945ca7f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(f'<img src=\"data:image/png;base64,{image_base64}\"/>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bb9bb7-da23-4023-9d27-0a6c32dc8167",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-7\", \"Noshiro - Summer - Advertisement.png\"), \"wb\") as fh:\n",
    "    fh.write(base64.b64decode(image_base64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86cbbd4-2e76-41c1-ae46-148b0d9609a2",
   "metadata": {},
   "source": [
    "### 將不同圖片的內容融合在一起\n",
    "\n",
    "圖片來源: https://tensor.art/u/629260971684229814"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6b128b-141c-4e7b-9fa6-0169ef3623c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '<div style=\"display: flex; flex-direction: column;\">'\n",
    "\n",
    "html += '<div style=\"display: flex; justify-content: space-around; margin-bottom: 10px;\">'\n",
    "html += f'''\n",
    "    <div>\n",
    "        <div>\n",
    "            <img src=\"maehara-1.jpg\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "            <img src=\"maehara-2.jpg\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "        </div>\n",
    "    </div>\n",
    "'''\n",
    "html += '</div>'\n",
    "\n",
    "html += '</div>'\n",
    "\n",
    "# Display the HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769c3ca6-307f-4ec0-a8b2-950057d253de",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_a = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-7\", \"maehara-1.jpg\")\n",
    "image_b = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-7\", \"maehara-2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef057e0b-00b4-4adf-a502-ab30227319a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_edit = client.images.edit(\n",
    "    model=\"gpt-image-1\",\n",
    "    image=[\n",
    "        open(image_a, \"rb\"),\n",
    "        open(image_b, \"rb\"),\n",
    "    ],\n",
    "    prompt=dedent(\"\"\"\n",
    "    Fusion the two images to create a high definition 8k movie poster with the text as the background. \n",
    "    \"\"\"),\n",
    "    size=\"1024x1536\",\n",
    "    input_fidelity=\"high\", # 這個選項需要openai 1.97.0以上版本\n",
    "    quality=\"high\"\n",
    ")\n",
    "\n",
    "image_base64 = result_edit.data[0].b64_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff23cbd6-3c75-42b8-a811-ccbe135a32ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(f'<img src=\"data:image/png;base64,{image_base64}\"/>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa8ebfc-db14-4aea-92e5-519112ce17c5",
   "metadata": {},
   "source": [
    "## 局部修補 (Inpaint)\n",
    "\n",
    "你可以提供一個遮罩 (mask) 來指定圖像中要被編輯的區域。\n",
    "\n",
    "當在 GPT Image 中使用遮罩時，額外的指令會一併傳送給模型，以便更好地引導編輯過程。\n",
    "\n",
    "### 遮罩的要求\n",
    "\n",
    "要編輯的圖片與遮罩必須為相同的格式與尺寸，且檔案大小需小於 50MB。\n",
    "\n",
    "遮罩圖片必須包含 Alpha 通道。如果你是使用圖像編輯工具來製作遮罩，請確保在儲存時保留 Alpha 通道。\n",
    "\n",
    "\n",
    "### Bug Report\n",
    "\n",
    "https://community.openai.com/t/gpt-image-1-problems-with-mask-edits/1240639/15\n",
    "\n",
    "Image-1 在 inpainting 似乎做的很糟糕。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb89164a-1949-460f-96d7-97799c481a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '<div style=\"display: flex; flex-direction: column;\">'\n",
    "\n",
    "html += '<div style=\"display: flex; justify-content: space-around; margin-bottom: 10px;\">'\n",
    "html += f'''\n",
    "    <div>\n",
    "        <div>\n",
    "            <img src=\"Noshiro - Winter - Mask.png\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "        </div>\n",
    "    </div>\n",
    "'''\n",
    "html += '</div>'\n",
    "\n",
    "html += '</div>'\n",
    "\n",
    "# Display the HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e57a75-ae39-469c-beb4-022ec309dac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_in = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-7\", \"Noshiro - Winter.png\")\n",
    "image_mask = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-7\", \"Noshiro - Winter - Mask.png\")\n",
    "\n",
    "result_edit = client.images.edit(\n",
    "    model=\"gpt-image-1\",\n",
    "    image=open(image_in, \"rb\"),\n",
    "    mask=open(image_mask, \"rb\"),\n",
    "    prompt=dedent(\"\"\"\n",
    "    In the winter, a girl walking on water and holding Mjölnir. Mjölnir is surrounded with electricity and current. \n",
    "    \"\"\"),\n",
    "    size=\"1024x1536\",\n",
    "    input_fidelity=\"high\", # 這個選項需要openai 1.97.0以上版本\n",
    "    quality=\"high\"\n",
    ")\n",
    "\n",
    "image_base64 = result_edit.data[0].b64_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef8cdc-6a7d-43c5-935b-1b4ac2320f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(f'<img src=\"data:image/png;base64,{image_base64}\"/>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824ba903-ad84-4030-962e-88835ff73ff4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Agent（代理型系統）\n",
    "\n",
    "> 🎯 **本章學完你將能學會什麼：**\n",
    "> - 理解 **Agent** 的核心概念與與傳統 LLM 回答的差異  \n",
    "> - 掌握 **ReAct (Reasoning + Acting)** 的行動思考循環架構  \n",
    "> - 學會以 LangChain 建立具邏輯推理與工具調用能力的 Agent  \n",
    "> - 熟悉如何用 **MLflow** 監控模型執行過程與日誌  \n",
    "> - 實作能自行規劃步驟並計算問題的智能代理  \n",
    "\n",
    "代理型系統是一種能自己動作的 AI，它可以理解輸入、思考、規劃，並執行任務來達成目標。\n",
    "和一般只能依照單一提示回應的模型不同，代理型系統能自己產生提示、使用外部工具、記住對話內容，並且透過規劃和反思來調整行為。\n",
    "這讓它能更自動化地解決問題，並把不同功能組合起來，幫助使用者更有效率地完成事情。\n",
    "\n",
    "## ReAct Framework\n",
    "\n",
    "本節將說明 ReAct 的概念與執行結構，幫助你理解思考（Reasoning）與行動（Acting）如何交互作用。\n",
    "\n",
    "- ReAct: Reasoning - Action\n",
    "\n",
    "- ReAct Agent 的運作流程大致是：\n",
    "\n",
    "    1. 思考 (Reasoning)：根據當前的上下文，生成內部的推理或計劃。\n",
    "\n",
    "    2. 行動 (Acting)：根據推理的結果，決定要採取的動作（例如查詢工具、呼叫 API、檢索知識）。\n",
    "\n",
    "    3. 觀察 (Observation)：得到工具或環境回饋。\n",
    "\n",
    "    4. 迭代：將觀察結果再輸入回去，進入下一輪思考。\n",
    "\n",
    "    直到：\n",
    "\n",
    "    a. 達到最終答案，或\n",
    "\n",
    "    b. 遇到設置的停止條件（例如 token 限制、步數限制、明確的 \"結束\" 信號）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ce015d-8bf1-49e0-80b3-e18b78449965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(url='https://statusneo.com/wp-content/uploads/2024/01/fe9fa1ac-dfde-4d91-8b5b-4497b742c414_1400x686.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb253c73-f29a-4f86-9e1c-d7262e2c73eb",
   "metadata": {},
   "source": [
    "### ReAct Template\n",
    "\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "\n",
    "Thought: you should always think about what to do\n",
    "\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "\n",
    "Action Input: the input to the action\n",
    "\n",
    "Observation: the result of the action\n",
    "\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "\n",
    "Thought: I now know the final answer\n",
    "\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Thought:{agent_scratchpad}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26638f8e-95ba-44fd-b046-877dfaca93a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be49e633-6e96-45b9-8ca9-71ccd4893e62",
   "metadata": {},
   "source": [
    "### 建立MLflow監控\n",
    "\n",
    "mlflow server --host 127.0.0.1 --port 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de00d300-5214-4b61-b69d-3e4fb9a7b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from langchain_community.callbacks import MlflowCallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from src.initialization import credential_init\n",
    "\n",
    "credential_init()\n",
    "\n",
    "experiment = \"Week-7\"\n",
    "uri = \"http://127.0.0.1:8080\"\n",
    "\n",
    "mlflow.set_tracking_uri(uri=uri)\n",
    "\n",
    "# Start or get an MLflow run explicitly\n",
    "mlflow.set_experiment(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b51602-d151-4855-8eeb-e5c669b1897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanMlflowCallbackHandler(MlflowCallbackHandler):\n",
    "\n",
    "    def __init__(self, experiment, run_id, tracking_uri, name=\"CleanMLflow\"):\n",
    "        super().__init__(experiment=experiment, run_id=run_id, tracking_uri=tracking_uri, name=name)\n",
    "    \n",
    "    def on_llm_new_token(self, token: str, **kwargs):\n",
    "        # Suppress per-token logging to MLflow\n",
    "        # 若你不這麼做的話\n",
    "        # 1. artifacts 資料夾會被成千上萬個小 JSON 檔案塞滿。\n",
    "        # 2. 更嚴重的是，過多的逐 token I/O 會大幅拖慢執行速度。\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d131ad1b-c2a1-494b-ad17-074e969c9ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run = mlflow.start_run(run_name=\"react-agent\")\n",
    "\n",
    "# then use this handler instead of the default one\n",
    "mlflow_cb_model = CleanMlflowCallbackHandler(\n",
    "    experiment=experiment,\n",
    "    run_id=run.info.run_id,\n",
    "    tracking_uri=uri,\n",
    ")\n",
    "\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o\", temperature=0, \n",
    "                   callbacks=[mlflow_cb_model],\n",
    "                   name=\"my_model\"\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc06ffce-e3e9-41ad-9f7b-585a5101391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "from src.agent.react_zero_shot import prompt_template as zero_shot_prompt_template\n",
    "\n",
    "prompt = PromptTemplate(template=zero_shot_prompt_template)\n",
    "\n",
    "zero_shot_agent = create_react_agent(\n",
    "    llm=model, ## llm是 Agent的思考中樞，這個llm會決定agent總體上的大致表現，建議越強越好\n",
    "    tools=[],\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "class DebugMlflowCallbackHandler(MlflowCallbackHandler):\n",
    "    \n",
    "    def __init__(self, experiment, run_id, tracking_uri, name=\"CleanMLflow\"):\n",
    "        super().__init__(experiment=experiment, run_id=run_id, tracking_uri=tracking_uri)\n",
    "        self.name = name\n",
    "    \n",
    "    def on_chain_error(self, error, **kwargs):\n",
    "        print(f\"Chain error: {error}\")\n",
    "        super().on_chain_error(error, **kwargs)\n",
    "\n",
    "    def on_tool_error(self, error, **kwargs):\n",
    "        print(f\"Tool error: {error}\")\n",
    "        super().on_tool_error(error, **kwargs)\n",
    "\n",
    "\n",
    "mlflow_cb_agent = DebugMlflowCallbackHandler(\n",
    "    experiment=experiment,\n",
    "    run_id=run.info.run_id,\n",
    "    tracking_uri=uri,\n",
    ")\n",
    "\n",
    "\n",
    "agent_executor = AgentExecutor(agent=zero_shot_agent, tools=[], verbose=True, callbacks=[mlflow_cb_agent], name='my_agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8cc22f-e8fc-4a23-bc0f-b1918bdb90b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"Please calculate the area of a circle that has a radius of 10.923mm\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa74eeef-86f2-4e81-a89d-80f796a46c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac67459-977c-4055-805e-1c710dddc85f",
   "metadata": {},
   "source": [
    "# Tool 與 Agent 應用\n",
    "\n",
    "> 🎯 **本章學完你將能學會什麼：**\n",
    "> - 理解 LangChain 的 **Tool 介面** 與自訂工具開發流程  \n",
    "> - 實作三種常見工具：**MathTool**、**SearchTool**、**VectorStoreTool**  \n",
    "> - 學會使用 **PydanticOutputParser** 定義輸入/輸出格式  \n",
    "> - 掌握如何將多個工具模組化並在 Agent 中整合  \n",
    "> - 建立可記憶對話內容的 **Conversational Agent**  \n",
    "> - 理解如何將 Agent 部署至 **LangServe** 與 **Streamlit** 介面  \n",
    "\n",
    "我們知道LLM不是讓你算數學用的。整數的加減法可能可以，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932d0eb0-3f19-4614-a683-7062457010f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.start_run(run_name=\"react-agent-with-tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d4eb4d-1486-4b39-99f5-403471b8c43d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Union\n",
    "from textwrap import dedent\n",
    "\n",
    "from langchain.tools import BaseTool\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, \\\n",
    "SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "def build_standard_chat_prompt_template(kwargs):\n",
    "\n",
    "    messages = []\n",
    " \n",
    "    if 'system' in kwargs:\n",
    "        content = kwargs.get('system')\n",
    "        prompt = PromptTemplate(**content)\n",
    "        message = SystemMessagePromptTemplate(prompt=prompt)\n",
    "        messages.append(message)  \n",
    "\n",
    "    if 'human' in kwargs:\n",
    "        content = kwargs.get('human')\n",
    "        prompt = PromptTemplate(**content)\n",
    "        message = HumanMessagePromptTemplate(prompt=prompt)\n",
    "        messages.append(message)\n",
    "        \n",
    "    chat_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "    \n",
    "    return chat_prompt\n",
    "\n",
    "\n",
    "@chain\n",
    "def code_execution(code):\n",
    "    \n",
    "    match = re.findall(r\"python\\n(.*?)\\n```\", code, re.DOTALL)\n",
    "    python_code = match[0]\n",
    "    \n",
    "    lines = python_code.strip()#.split('\\n')\n",
    "    # *stmts, last_line = lines\n",
    "\n",
    "    local_vars = {}\n",
    "    exec(lines, {}, local_vars)\n",
    "\n",
    "    return local_vars\n",
    "\n",
    "\n",
    "system_template = (\n",
    "    \"You are a highly skilled Python developer. Your task is to generate Python code strictly based on the user's instructions.\\n\"\n",
    "    \"Leverage statistical and mathematical libraries such as `statsmodels`, `scipy`, and `numpy` where appropriate to solve the problem.\\n\"\n",
    "    \"Your response must contain only the Python code — no explanations, comments, or additional text.\\n\\n\"\n",
    ")\n",
    "\n",
    "human_template = dedent(\"\"\"{query}\\n\\n\n",
    "                            Always copy the final answer to a variable `answer`\n",
    "                            Code:\n",
    "                        \"\"\")\n",
    "\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variable\": [\"query\"]}}\n",
    "\n",
    "code_chat_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "\n",
    "# then use this handler instead of the default one\n",
    "mlflow_cb_model = CleanMlflowCallbackHandler(\n",
    "    experiment=experiment,\n",
    "    run_id=run.info.run_id,\n",
    "    tracking_uri=uri,\n",
    ")\n",
    "\n",
    "model_agent = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                         model_name=\"gpt-4o\", temperature=0, \n",
    "                         callbacks=[mlflow_cb_model]\n",
    "                        )\n",
    "\n",
    "model_coder = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                         model_name=\"gpt-4o-mini\", temperature=0, \n",
    "                         callbacks=[mlflow_cb_model]\n",
    "                        )\n",
    "\n",
    "code_generation = code_chat_prompt_template|model_coder|StrOutputParser()\n",
    "\n",
    "code_pipeline = code_generation|code_execution\n",
    "\n",
    "\n",
    "class MathTool(BaseTool):\n",
    "    name:str = \"Math calculator\"\n",
    "    description:str = dedent(\"\"\"\n",
    "    Use this tool to solve algorithmic problem by python programming.\n",
    "    \"\"\")\n",
    "    \n",
    "    def _run(self, query: str):\n",
    "        \n",
    "        return  code_pipeline.invoke({\"query\": query})\n",
    "    \n",
    "    def _arun(self, radius: Union[int, float]):\n",
    "        raise NotImplementedError(\"This tool does not support async\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ef2c35-768f-46b2-9ee3-a9c1bde3969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "from src.agent.react_zero_shot import prompt_template as zero_shot_prompt_template\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(template=zero_shot_prompt_template)\n",
    "\n",
    "tools = [MathTool()]\n",
    "\n",
    "zero_shot_agent = create_react_agent(\n",
    "    llm=model_agent, ## llm是 Agent的思考中樞，這個llm會決定agent總體上的大致表現，建議越強越好\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=zero_shot_agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5245406-2cd2-480f-91fc-d13eb70569c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"Please calculate the area of a circle that has a radius of 10.923mm\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3803271-ce2b-4e82-adb6-3ee933423a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b803df62-1a18-4c71-b36e-b326fa063698",
   "metadata": {},
   "source": [
    "## WebSearch Tool / Wikipedia Tool / 向量資料庫整合\n",
    "\n",
    "本節說明如何建立多變量輸入工具（如 SearchTool）、連接維基百科、以及整合向量資料庫（FAISS）。\n",
    "\n",
    "### 如何讓Tool接收複數的變數?\n",
    "\n",
    "利用之前學過的 Pydantic, 也可以用ResponseSchema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae64487-112d-46b8-adf2-2d0231e0b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3b616c-8a20-491b-86ba-ef61dcabae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Inputs(BaseModel):\n",
    "    query: str = Field(description=\"User query\")\n",
    "    country_code: str = Field(description=\"ISO 3166-1 alpha-2 suggested by the language of the user query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e65d077-d98c-4e15-8bd1-a1fd403b5164",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchTool(BaseTool):\n",
    "\n",
    "    input_output_parser: PydanticOutputParser = PydanticOutputParser(pydantic_object=Inputs)\n",
    "    input_format_instructions: str = input_output_parser.get_format_instructions()\n",
    "    \n",
    "    name:str = \"websearch tool\"\n",
    "    description_template:str = dedent(\"\"\"\n",
    "    Currently it is 2025.    \n",
    "    Use this tool to collect information from the internet, when you are not sure you know the answer.\n",
    "    The input contains the user's question `query` and the ISO 3166-1 alpha-2 `country_code` inferred from the user's language.\n",
    "    input format instructions: {input_format_instructions}\n",
    "    \"\"\")\n",
    "\n",
    "    description: str = description_template.format(input_format_instructions=input_format_instructions)\n",
    "    \n",
    "    def _run(self, query):\n",
    "        \n",
    "        input_ = self.input_output_parser.parse(query)\n",
    "        \n",
    "        query = input_.query\n",
    "        country_code = input_.country_code\n",
    "        \n",
    "        messages = [{\"role\": \"user\",\n",
    "                     \"content\": query}]\n",
    "\n",
    "        response = client.responses.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    tools=[\n",
    "                        {\"type\": \"web_search\",\n",
    "                         \"user_location\":{\n",
    "                             \"type\": \"approximate\",\n",
    "                             \"country\": country_code,\n",
    "                         },\n",
    "                        \"search_context_size\": \"medium\"\n",
    "                        }],\n",
    "                    tool_choice=\"auto\",\n",
    "                    input=query)\n",
    "        \n",
    "        return response.output_text\n",
    "    \n",
    "    def _arun(self, query: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd902b3-bcb5-4546-9829-c008ea4810c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [SearchTool()]\n",
    "\n",
    "zero_shot_agent = create_react_agent(\n",
    "    llm=model,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=zero_shot_agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02083f6d-bc89-4b45-a027-133e777647b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"現任台灣總統的老家是否是違建?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4287efc4-1555-4496-a4f7-25100cd8aa6c",
   "metadata": {},
   "source": [
    "### 維基百科查詢設置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c10bc3-3f9a-41e2-94e1-d0c09fbf2229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain, Runnable\n",
    "from langchain_community.tools.wikipedia.tool import WikipediaQueryRun\n",
    "from langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n",
    "\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%Y-%B\")\n",
    "\n",
    "# 一個快速建立tool的方法\n",
    "search_tool = Tool(\n",
    "    name=\"Wikipedia search engine tool\",\n",
    "    func=wikipedia.run,\n",
    "    description=f'Wikipedia is up to date to {current_time}. Use this tool to help you answer questions.'\n",
    ")\n",
    "\n",
    "tools = [search_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4361ec4-a2e7-470e-b5ae-8145ece735fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(wikipedia, Runnable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a32f5a-a74b-4930-be18-bd387d0a83cb",
   "metadata": {},
   "source": [
    "### 自定義向量儲存庫做為工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5c97f-3fc9-4794-aa80-947e814b0fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "\n",
    "vectorstore = FAISS.load_local(\n",
    "    \"tutorial/LLM+Langchain/Week-5/warhammer 40k codex\", embeddings, \n",
    "    allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c5e2bd-7923-42e3-ba5b-10c32ed4e849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableField\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", k=10).configurable_fields( \\\n",
    "                                        search_kwargs=ConfigurableField(\n",
    "                                                id=\"search_kwargs\",\n",
    "                                            )\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87ca978-c912-4f21-a54b-53bb149d8317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "class Inputs(BaseModel):\n",
    "    query: str = Field(description=\"User query\")\n",
    "    clan: Literal['Adeptus Mechanicus', 'Aeldari', 'Black Templars'] = Field(description=\"\")\n",
    "\n",
    "\n",
    "class CodexRetrievalTool(BaseTool):\n",
    "\n",
    "    input_output_parser: PydanticOutputParser = PydanticOutputParser(pydantic_object=Inputs)\n",
    "    input_format_instruction: str = input_output_parser.get_format_instructions()\n",
    "    \n",
    "    name:str = \"warhammer 40k codex\"\n",
    "    description_template:str = dedent(\"\"\"\n",
    "    This tool can be used to retrieve relevant information about warhammer 40k, \n",
    "    particularly Adeptus Mechanicus, Aeldari, Black Templars.\n",
    "    The inputs contains user's question `query` and the party/clan `clan`.\n",
    "    input format instructions: {input_format_instruction}\n",
    "    \"\"\")\n",
    "\n",
    "    description: str = description_template.format(input_format_instruction=input_format_instruction)\n",
    "    \n",
    "    def _run(self, query):\n",
    "        \n",
    "        input_ = self.input_output_parser.parse(query)\n",
    "\n",
    "        query = input_.query\n",
    "        clan = input_.clan\n",
    "\n",
    "        \"\"\"\n",
    "        vectorstore創造時在filename的部分有點失誤\n",
    "        所以這裡用手動的方式進行校正\n",
    "        \"\"\"\n",
    "\n",
    "        if clan == 'Black Templars':\n",
    "            filter_ = {\"filename\": f\"Codex -{clan}\"}\n",
    "        else:\n",
    "            filter_ = {\"filename\": f\"Codex - {clan}\"}\n",
    "        \n",
    "        retrievd_documents = retriever.invoke(query, config={\"configurable\": \n",
    "                                                             {\"search_kwarg\": {\"filter\": filter_\n",
    "                                                                              }\n",
    "                                                             }\n",
    "                                                            }\n",
    "                                             )\n",
    "        \n",
    "        return retrievd_documents\n",
    "    \n",
    "    def _arun(self, query: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b93036d-4a15-420b-9d90-4b521f848bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [CodexRetrievalTool()]\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o\", temperature=0, \n",
    "                   callbacks=[mlflow_cb_model]\n",
    "                  )\n",
    "\n",
    "zero_shot_agent = create_react_agent(\n",
    "    llm=model,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=zero_shot_agent, tools=tools, verbose=True, callbacks=[mlflow_cb_agent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380cc96e-7d0c-4c82-9963-85602532d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"Who is the leader of Aeldari?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc7af47-7507-4d51-ac44-0998455d12cb",
   "metadata": {},
   "source": [
    "### Tools 模組\n",
    "\n",
    "剛剛的MathTool 和 SearchTool的範例中，我們都必須要一個個的建立客製化工具，但同時我們也發現這些工具都有相同的結構:\n",
    "\n",
    "{\n",
    "- runnable: \n",
    "- description:\n",
    "- name: \n",
    "- input_parser:\n",
    "- \n",
    "}\n",
    "S\n",
    "\n",
    "那能不能直接寫好需要的內容，然後使用for loop套模板建立工具?\n",
    "\n",
    "| 區塊                             | 功能說明                      |\n",
    "| ------------------------------ | ------------------------- |\n",
    "| `class ToolTemplate(BaseTool)` | 建立自訂工具的範本類別               |\n",
    "| `runnable`                     | 實際執行任務的物件（可接 chain 或任意函式） |\n",
    "| `input_parser`                 | 用來解析 Agent 傳入的輸入字串為結構化格式  |\n",
    "| `create()`                     | 類別方法，用於快速生成帶有描述與格式說明的工具實例 |\n",
    "| `_run()`                       | 工具被呼叫時執行的主要邏輯，處理輸入解析與任務呼叫 |\n",
    "| `_arun()`                      | 非同步版本（目前尚未支援）             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b4627-2848-4d06-9a7e-f1985e994f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToolTemplate 是一個「工具範本 (Tool Template)」\n",
    "# 主要目的是讓我們能快速建立具有統一結構的自訂工具（Tool）\n",
    "# 在 LangChain 的 Agent 中，工具 (Tool) 是 LLM 執行特定任務的「外部功能模組」，\n",
    "# 例如：查詢網路、執行程式碼、進行數學運算、檢索資料庫 等。\n",
    "\n",
    "class ToolTemplate(BaseTool):\n",
    "    # ----------- 屬性區 (Attributes) -----------\n",
    "    runnable: Runnable                    # 工具實際執行邏輯 (例如某個 chain、function)\n",
    "    name: str                             # 工具名稱（Agent 會用這個名稱呼叫它）\n",
    "    input_parser: PydanticOutputParser    # 用於解析輸入的資料模型\n",
    "    description: str                      # 工具說明文字（會顯示在 Agent 的可用工具清單中）\n",
    "\n",
    "    # ----------- 類別方法 (Class Method) -----------\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, runnable: Runnable, name: str, description: str,\n",
    "               input_parser: PydanticOutputParser):\n",
    "\n",
    "        \"\"\"\n",
    "        這個類別方法用於「快速建立」一個 Tool 實例。\n",
    "        它會自動插入描述文字 (description) 與輸入格式說明，\n",
    "        讓 Agent 在使用時知道該怎麼傳入參數。\n",
    "        \"\"\"\n",
    "\n",
    "        # 取得輸入格式說明（LangChain 的 Pydantic Parser 會產生格式提示）\n",
    "        input_format_instruction = input_parser.get_format_instructions()\n",
    "\n",
    "        # 將輸入格式說明嵌入到工具說明文字中\n",
    "        description = description_template.format(\n",
    "            input_format_instruction=input_format_instruction\n",
    "        )\n",
    "\n",
    "        # 回傳完整的 ToolTemplate 實例\n",
    "        return cls(runnable=runnable, name=name, description=description,\n",
    "                   input_parser=input_parser)\n",
    "    \n",
    "    def _run(self, query: str):\n",
    "\n",
    "         \"\"\"\n",
    "        工具在被 Agent 呼叫時，會執行這個方法。\n",
    "        這裡的 query 是 LLM 傳入的文字輸入。\n",
    "        \"\"\"\n",
    "\n",
    "        # Step 1: 使用 input_parser 解析輸入，確保格式正確\n",
    "        input_ = self.input_parser.parse(query)\n",
    "\n",
    "        # Step 2: 轉換 Pydantic 物件成 Python 字典 (dict)，方便傳給 runnable\n",
    "        runnable_inputs = input_.model_dump()\n",
    "\n",
    "        # Step 3: 呼叫實際的 runnable（可能是 chain、function 或 API）\n",
    "        if self.input_parser is None:\n",
    "            # 若沒有指定 parser，就直接把 query 丟給 runnable\n",
    "            return self.runnable.invoke({\"query\": query}) # 這行暗示了runnable要將query作為一個輸入\n",
    "        else:\n",
    "            # 若有 parser，代表要用解析後的參數字典作為輸入\n",
    "            input_pydantic = self.input_parser.parse(query)\n",
    "            input_dict = input_pydantic.model_dump()\n",
    "            return self.runnable.invoke(input_dict)\n",
    "\n",
    "# ----------- 非同步版本 (尚未支援) -----------\n",
    "    def _arun(self, query: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f58d23b-14d2-48df-b2bd-33a91e0f37b5",
   "metadata": {},
   "source": [
    "將上面的一些工具都打包入tools這個資料夾裡，方便之後調用:\n",
    "\n",
    "- tools.websearch: SearchTool\n",
    "- tools.vectorstore: CodexRetrievalTool\n",
    "- tools.math: MathTool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaddf87-6b30-4c79-beed-f0b951343820",
   "metadata": {},
   "source": [
    "## Conversational Agent\n",
    "\n",
    "最後，我們將示範如何透過 LangChain 與 LangServe，建立具備上下文記憶與工具調用能力的對話型 Agent，並以 Streamlit 打造互動式聊天介面。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c515d-8962-4c7c-9b8d-e8ab3b735ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190cb2ad-4fc2-4851-b275-fe5aef776818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agent.react_chat import prompt_template as chat_prompt_template\n",
    "from src.initialization import credential_init\n",
    "\n",
    "credential_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d566f5a5-dd3c-4755-a1de-267bba413fa2",
   "metadata": {},
   "source": [
    "從tools裡直接把工具拉出來用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadc2693-d61d-4ae6-884d-458a45b32e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "module_math = importlib.import_module(\"tutorial.LLM+Langchain.Week-7.tools.math\")\n",
    "module_vectorstore = importlib.import_module(\"tutorial.LLM+Langchain.Week-7.tools.vectorstore\")\n",
    "module_websearch = importlib.import_module(\"tutorial.LLM+Langchain.Week-7.tools.websearch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a70a70f-c3c9-4dec-9da1-fe2ce05bc6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [module_math.MathTool(), module_websearch.SearchTool(), module_vectorstore.CodexRetrievalTool()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e10ba3-5041-40d0-9c6d-809f74b33ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain.agents import Tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.wikipedia.tool import WikipediaQueryRun\n",
    "from langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "#嘗試單純的加入聊天紀錄\n",
    "\n",
    "template = dedent(\"\"\"\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "When you need to use a tool to get knowledge, the vectorstore tools have a high priority than websearch tool.\n",
    "\n",
    "To use a tool, you MUST strictly follow this format (case-sensitive, exact words)::\n",
    "\n",
    "```\n",
    "\n",
    "Thought: Do I need to use a tool? Yes\n",
    "\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "\n",
    "Action Input: the input to the action\n",
    "\n",
    "Observation: [the result of the action]\n",
    "\n",
    "```\n",
    "\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "\n",
    "\n",
    "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
    "\n",
    "```\n",
    "\n",
    "Thought: Do I need to use a tool? No\n",
    "\n",
    "Final Answer: [your response here]. The final response should be in Traditional Chinese (繁體中文).\n",
    "\n",
    "```\n",
    "\n",
    "Begin!\n",
    "\n",
    "Previous conversation history:\n",
    "\n",
    "{chat_history}\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o\", temperature=0, \n",
    "                  )\n",
    "\n",
    "conversation_agent = create_react_agent(\n",
    "    llm=model,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=conversation_agent, tools=tools, verbose=True,\n",
    "                               handle_parsing_errors=True, max_iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b03b84-a4c2-4bd4-9920-2b17d246b64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5867ed9-1077-4f64-a5da-ab9c5a498203",
   "metadata": {},
   "source": [
    "在第四周學ChatBot時，我們學過如何用ChatMessageHistory這個物件存放聊天紀錄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdff378-8921-4fd3-8e26-ea0ac39e1dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "while True:\n",
    "    input_ = input(\"請輸入你的問題 (輸入 quit 跳出):\")\n",
    "    if input_ == 'quit':\n",
    "        break\n",
    "    output = agent_executor.invoke({\"chat_history\": chat_history,\n",
    "                                    \"input\": input_})\n",
    "\n",
    "    print(f\"\\n***{output['output']}***\\n\")\n",
    "    \n",
    "    chat_history.add_user_message(input_)\n",
    "    chat_history.add_ai_message(output['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c986f2-5f66-4a57-bf2e-ceaef27594c0",
   "metadata": {},
   "source": [
    "### 使用Streamlit建立基於Agent的聊天機器人\n",
    "\n",
    "- Agent 將部屬於 Langserve 上\n",
    "- Agent 在 Langserve上的應用有些眉角需要注意: 要額外使用pydantic數據模型註明input 和 output 類型\n",
    "    - BaseMessage 物件（像是 HumanMessage、AIMessage）其實是 Pydantic 模型，所以：\n",
    "    - c.model_dump() → 會得到 字典 (dict)，這正是 requests.post(..., json=...) 需要的格式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc08a12d-4fe9-456e-b103-ca8029f78b5b",
   "metadata": {},
   "source": [
    "首先確認如何透過requests和langserve交流\n",
    "\n",
    "將chat_history物件的內容model_dump(), 這樣 API 會收到一個 chat_history，它是由 dict 組成的列表（裡面有 type + content 欄位），LangServe 就能正確還原成 BaseMessage 物件了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08b916c-2aa5-4165-a178-c289e2c245a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from textwrap import dedent\n",
    "\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "chat_history.add_user_message(\"前天天氣如何?\")\n",
    "chat_history.add_ai_message(\"前天颳風下雨\")\n",
    "\n",
    "response = requests.post(\n",
    "    \"http://localhost:8080/chatbot/invoke\",\n",
    "    json={'input': {\"input\": \"我剛剛的問題為何?\",\n",
    "                    \"chat_history\": [c.model_dump() for c in chat_history.messages]\n",
    "                   }\n",
    "         }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e82b6c-efb5-4e77-a1db-7b95d08d1bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540d5464-7f33-4553-8edd-05821defb21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    \"http://localhost:8080/chatbot/invoke\",\n",
    "    json={'input': {\"input\": \"給予一個邊長為10的正方形，選定兩個對角點，在正方形內各畫一個半徑為10的1/4圓。請問兩個1/4圓重疊的部分大小為何?\",\n",
    "                    \"chat_history\": [c.model_dump() for c in chat_history.messages]\n",
    "                   }\n",
    "         }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e803b-83d8-4287-bb1e-2cd776acc2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "[c.model_dump() for c in chat_history.messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c11088-08c4-42c7-aec7-c829c0325f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f221e36f-0d83-42cc-98b9-802b9118983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "math.pi * 2 * (1/4) * 10 * 10 - 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e478fe7-d9eb-4541-a9f5-a13e76ecda3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'checkpoints' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcheckpoints\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'checkpoints' is not defined"
     ]
    }
   ],
   "source": [
    "checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f92366-99bb-4807-9f03-c36df0a64dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
