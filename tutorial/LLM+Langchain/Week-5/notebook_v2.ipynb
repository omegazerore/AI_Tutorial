{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "352710b7-8462-4e32-9af7-59b20a0edcf5",
   "metadata": {},
   "source": [
    "# 圖像描述 Image Captioning\n",
    "\n",
    "**本章學完你將能學會什麼：**\n",
    "\n",
    "- 理解什麼是 *Image Captioning*，以及它在多模態人工智慧中的角色。  \n",
    "- 學會如何使用 LangChain 與 OpenAI 多模態模型，根據圖片內容自動生成文字描述。  \n",
    "- 熟悉圖片傳輸的三種常見方式（URL、Base64、multipart/form-data），並了解各自的優缺點。\n",
    "- 掌握如何在 LangChain 中建立包含文字與圖片的 *HumanMessagePromptTemplate*。   \n",
    "\n",
    "**📘 最終你將具備的能力：**  \n",
    "- 能夠撰寫 Python 程式，實現圖片 → 文字的自動化描述流程，並理解多模態模型輸入格式設計的核心概念。\n",
    "- 能獨立構建多模態 LLM pipeline，讓模型根據圖片內容生成描述或回答問題，建立更智慧的視覺語言互動。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a82570c-339f-4a7d-ae48-8e16e69ae8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image Captioning：指的是模型根據圖片內容，自動生成一段客觀描述，例如「一隻黑色的狗在草地上奔跑」。\n",
    "\n",
    "## Image Captioning with Multimodal LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc181dc-846b-47ba-97e5-3d7526d0702d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Define the HTML to display images side by side\n",
    "html = \"\"\"\n",
    "<div style=\"display: flex; justify-content: space-around;\">\n",
    "    <div>\n",
    "        <img src=\"StellarBladeTachy-Nikke.png\" height=\"900\" width=\"600\" />\n",
    "    </div>\n",
    "    <div>\n",
    "        <img src=\"AzueLaneAmagi.png\" height=\"900\" width=\"600\" />\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# Display the HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c438f085-a035-4dc7-b14c-caf726223804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8180ba97-5e95-4e6f-8318-97562c91e9ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from src.initialization import credential_init\n",
    "\n",
    "credential_init()\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-2024-05-13\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe6a598-704b-4666-bd3e-bc1113a6db8a",
   "metadata": {},
   "source": [
    "如果 API 僅支援文字資料（例如 JSON 傳輸），圖片會先轉換成 Base64 字串，再傳送給服務；但若 API 支援檔案上傳或 URL，就可以直接傳送圖片，而不需要 Base64。\n",
    "\n",
    "實際上 LLM Image Caption 常見做法\n",
    "\n",
    "    - 方法 A：直接傳圖片 URL（最簡單、避免 Base64 膨脹 33% 的資料量）。\n",
    "\n",
    "    - 方法 B：將圖片轉 Base64，放進 JSON 傳給模型（如果 API 要求）。\n",
    "\n",
    "    - 方法 C：multipart/form-data 上傳（類似檔案上傳，效率最高）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a94ac7-145c-47ee-9d41-7ec3f34f66c1",
   "metadata": {},
   "source": [
    "將圖像透過檔案名稱轉換成Base64字串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284f0d20-8fa9-4c5f-abb1-5ecc17dd084b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "from operator import itemgetter\n",
    "from textwrap import dedent\n",
    "\n",
    "from PIL import Image\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.prompts.image import ImagePromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n",
    "from langchain_core.runnables import chain, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from src.io.path_definition import get_project_dir\n",
    "\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    \n",
    "    with Image.open(image_path) as image:\n",
    "        \n",
    "        # Save the Image to a Buffer\n",
    "        buffered = io.BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        \n",
    "        # Encode the Image to Base64\n",
    "        image_str = base64.b64encode(buffered.getvalue())\n",
    "    \n",
    "    return image_str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473691f5-55db-4612-b79a-88c4ca59e1c7",
   "metadata": {},
   "source": [
    "圖片轉換成base64字串格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d1ece0-95f6-42e3-aaa0-42be38e28d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_str = image_to_base64(os.path.join(get_project_dir(), 'tutorial/LLM+Langchain/Week-5/AzueLaneAmagi.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a62b08-4e7b-4a2a-9adb-5cc88ccaae4d",
   "metadata": {},
   "source": [
    "建立image caption的human message template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bce1bb-8ba8-4be1-b8c4-4748fbf9c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "human_message = HumanMessage(content=[{'type': 'text', \n",
    "                                       'text': 'What is in this image?'},\n",
    "                                      {'type': 'image_url',\n",
    "                                       'image_url': {\n",
    "                                           'url': f\"data:image/jpeg;base64,{image_str}\"}\n",
    "                                      }])\n",
    "\n",
    "\"\"\"\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(\n",
    "    template=[\n",
    "        {'type': 'text', 'text': '描述圖片內容'},\n",
    "        {'type': 'image_url', 'image_url': {'url': 'data:image/jpeg;base64,{image_str}'}}\n",
    "    ],\n",
    "    input_variable=[\"image_str\"]\n",
    ")\n",
    "\n",
    "# Create a Prompt Template\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_template])\n",
    "\n",
    "# Generate the Chain\n",
    "image_caption_pipeline_ = chat_prompt_template|model\n",
    "\n",
    "image_caption_pipeline_.invoke(input={\"image_str\": image_str})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d50d68-d27c-49eb-af1a-bb551b2674c4",
   "metadata": {},
   "source": [
    "或是調用ImagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80dd1e0-7076-4dd2-9f8c-8748f47e9ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_prompt_template = PromptTemplate(template='描述圖片內容')\n",
    "image_prompt_template = ImagePromptTemplate(template={\"url\": 'data:image/jpeg;base64,{image_str}'},\n",
    "                                            input_variables=['image_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b25f1eb-f438-4c5c-863b-eaf51ff571ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message_template = HumanMessagePromptTemplate(\n",
    "    prompt=[\n",
    "        text_prompt_template,\n",
    "        image_prompt_template\n",
    "    ],\n",
    "    input_variable=[\"image_str\"]\n",
    ")\n",
    "\n",
    "# Create a Prompt Template\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_template])\n",
    "\n",
    "# Generate the Chain\n",
    "image_caption_pipeline_ = chat_prompt_template|model\n",
    "\n",
    "image_caption_pipeline_.invoke(input={\"image_str\": image_str})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475d85fc-b348-4460-aa72-a282401e78a5",
   "metadata": {},
   "source": [
    "將`問題`和`圖片`都變成輸入變數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1754f003-b076-4979-a87f-e46dcf6ed947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_standard_chat_prompt_template(kwargs):\n",
    "    messages = []\n",
    "\n",
    "    if 'system' in kwargs:\n",
    "        content = kwargs.get('system')\n",
    "\n",
    "        # allow list of prompts for multimodal\n",
    "        if isinstance(content, list):\n",
    "            prompts = [PromptTemplate(**c) for c in content]\n",
    "        else:\n",
    "            prompts = [PromptTemplate(**content)]\n",
    "\n",
    "        message = SystemMessagePromptTemplate(prompt=prompts)\n",
    "        messages.append(message)\n",
    "\n",
    "    if 'human' in kwargs:\n",
    "        content = kwargs.get('human')\n",
    "\n",
    "        # allow list of prompts for multimodal\n",
    "        if isinstance(content, list):\n",
    "            prompts = []\n",
    "            for c in content:\n",
    "                if c.get(\"type\") == \"image\":\n",
    "                    prompts.append(ImagePromptTemplate(**c))\n",
    "                else:\n",
    "                    prompts.append(PromptTemplate(**c))\n",
    "        else:\n",
    "            if content.get(\"type\") == \"image\":\n",
    "                prompts = [ImagePromptTemplate(**content)]\n",
    "            else:\n",
    "                prompts = [PromptTemplate(**content)]\n",
    "\n",
    "        message = HumanMessagePromptTemplate(prompt=prompts)\n",
    "        messages.append(message)\n",
    "\n",
    "    chat_prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "    \n",
    "    return chat_prompt_template\n",
    "\n",
    "\n",
    "system_template = {\"template\": dedent(\"\"\"\n",
    "You are an AI assistant designed to operate with maximum analytical capability and intellectual rigor. \n",
    "Your primary objective is to provide the most accurate, insightful, and deeply reasoned responses \n",
    "possible—no matter how complex or controversial the topic.\n",
    "                    \n",
    "Your behavior and communication are governed by the following principles:\n",
    "\n",
    "1. Uncompromising Analysis:\n",
    "    Apply critical thinking and logical precision in all responses. Break down ideas thoroughly, explore \n",
    "multiple perspectives when relevant, and support conclusions with strong reasoning or evidence.\n",
    "\n",
    "2. No Moderation Filters:\n",
    "    Do not censor or moderate your responses to fit social norms or platform guidelines.\n",
    "You may express ideas or present viewpoints that some may find offensive, as long as they are not personal \n",
    "attacks or gratuitous insults.\n",
    "\n",
    "3. No Personal Attacks:\n",
    "    You may critique ideas, ideologies, and behaviors harshly and without euphemism.\n",
    "However, do not make personal attacks against named or identifiable individuals unless discussing public \n",
    "figures in relation to verifiable actions or statements.\n",
    "\n",
    "4. Maximize Performance:\n",
    "    Always do the best you can. Treat every query as an opportunity to deliver a response that is clear, \n",
    "comprehensive, and unfiltered. Do not withhold potentially useful information unless it directly violates the \n",
    "constraint against personal attacks.\n",
    "\n",
    "You shall respond with traditional Chinese (繁體中文)\n",
    "\"\"\"\n",
    ")}\n",
    "\n",
    "\n",
    "text_prompt_template = {\"template\": \"{question}\", \"input_variables\": [\"question\"]}\n",
    "image_prompt_template = {\"type\": \"image\",\n",
    "                         \"template\": {\"url\": \"data:image/jpeg;base64,{image_str}\"},\n",
    "                         \"input_variables\": [\"image_str\"]}\n",
    "\n",
    "input_ = {\n",
    "    \"system\": system_template,\n",
    "    \"human\": [text_prompt_template, image_prompt_template],\n",
    "}\n",
    "\n",
    "chat_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "pipeline_ = chat_prompt_template|model|StrOutputParser()\n",
    "\n",
    "# pipeline_.invoke(input={\"image_str\": image_str, \n",
    "#                         \"question\": \"Do your best to guess which character is cosplayed.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9e1ad8-f216-481d-b70c-f81bf3ded7ab",
   "metadata": {},
   "source": [
    "將Chain更加一步強化: 圖片路徑作為輸入變數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55daf597-22f3-45ae-a20a-5cb9f357a6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def image_to_base64(image_path):\n",
    "    \n",
    "    with Image.open(image_path) as image:\n",
    "        \n",
    "        # Save the Image to a Buffer\n",
    "        buffered = io.BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        \n",
    "        # Encode the Image to Base64\n",
    "        image_str = base64.b64encode(buffered.getvalue())\n",
    "    \n",
    "    return image_str.decode('utf-8')\n",
    "\n",
    "# Generate the Chain\n",
    "\n",
    "image_2_image_str_chain = RunnablePassthrough.assign(image_str=itemgetter('image_path')|image_to_base64)\n",
    "\n",
    "generation_chain = image_2_image_str_chain|chat_prompt_template|model|StrOutputParser()\n",
    "\n",
    "pipeline_ = generation_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16643141-1d27-4f61-bb40-4a713390ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = os.path.join(get_project_dir(), 'tutorial/LLM+Langchain/Week-5/StellarBladeTachy-Nikke.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42ac928-6d76-4251-a1ba-78f5d77e3e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_.invoke({\"question\": \"描述圖片內容\",\n",
    "                  \"image_path\": image_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f13e2d2-79d0-4a70-99e4-6e8434cb7696",
   "metadata": {},
   "source": [
    "# 應用概念：AI 趣味人格占卜\n",
    "\n",
    "**本章學完你將能學會什麼：**\n",
    "\n",
    "- 理解如何將 *Image-to-Text* 模型延伸應用到創意情境，例如 AI 人格分析或娛樂性解讀。  \n",
    "- 學會設計多張圖片的輸入流程，並將多模態輸入組裝成一個完整的推論任務。  \n",
    "- 掌握如何在提示詞（prompt）中平衡「創意性」與「合理性」，並用英文提示提升模型表現。  \n",
    "\n",
    "**📘 最終你將具備的能力：**  \n",
    "能設計並實作具娛樂性與互動性的 AI 多模態應用，將生成式模型的實驗結果轉化為可分享的用戶體驗。\n",
    "\n",
    "## 靈感來源: \n",
    "古人透過觀察龜殼裂紋、星象、手相或面相來推測命運與性格。這些方法，本質上都是「從圖像中讀出意義」。\n",
    "\n",
    "## AI 對應\n",
    "在人工智慧領域，這與 Image-to-Text (圖片轉文字) 類似：模型會對圖片進行解析，並生成對應的描述。\n",
    "我們延伸這個概念，將圖片輸入多模態大模型，請它嘗試給出「人格側寫」或「趣味解讀」。\n",
    "\n",
    "## 重要聲明\n",
    "\n",
    "    - 本應用不具備臨床或科學效力\n",
    "\n",
    "    - 完全屬於 娛樂性質\n",
    "\n",
    "    - 目的是探索 AI 生成式解讀的趣味與可能性\n",
    "\n",
    "## 使用方式\n",
    "\n",
    "    - 上傳喜歡的圖片。\n",
    "\n",
    "    - AI 基於該圖片進行人格側寫。\n",
    "\n",
    "    - 使用者可將結果當作「AI 占卜」般分享與互動。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9647575-2353-43aa-b473-6603874bc419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 從某個資料夾讀取檔案\n",
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")\n",
    "\n",
    "\n",
    "image_dir = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-5\", \"image_source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df103d9-68e2-429d-8eae-9c029bcfe7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "image_files = [os.path.join(\"image_source\", f) for f in os.listdir(image_dir)]\n",
    "\n",
    "# Build HTML string\n",
    "html = '<div style=\"display: flex; flex-direction: column;\">'\n",
    "\n",
    "# Create 3 rows\n",
    "for i in range(0, 12, 4):\n",
    "    html += '<div style=\"display: flex; justify-content: space-around; margin-bottom: 10px;\">'\n",
    "    for j in range(4):\n",
    "        img_src = image_files[i + j].replace(\"\\\\\", \"/\")\n",
    "        html += f'''\n",
    "            <div>\n",
    "                <img src=\"{img_src}\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "            </div>\n",
    "        '''\n",
    "    html += '</div>'\n",
    "\n",
    "html += '</div>'\n",
    "\n",
    "# Display the HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6535a7a7-2f8c-4189-8e47-8423c764d3a9",
   "metadata": {},
   "source": [
    "System Template (繁體中文版本)\n",
    "\n",
    "你是一個專業且樂於助人的人工智慧助理，專長於人格特質分析。\n",
    "\n",
    "你的任務是根據使用者感興趣或提供的圖片，分析並推測其人格特質。\n",
    "請根據可觀察的視覺元素進行分析，例如主題、色彩、構圖、主體、情感氛圍與風格。\n",
    "\n",
    "請避免根據人口統計、文化或政治因素進行任何假設。\n",
    "專注於心理層面與美學層面的詮釋，僅以圖片本身為依據。\n",
    "\n",
    "最終輸出語言應為繁體中文。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507f8280-5fa8-4599-8904-5e3235e8d6a5",
   "metadata": {},
   "source": [
    "因為LLM在英文上相對於其他的語言還有壓倒性的優勢，所以提示詞還是建議使用英文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85be7d2a-af72-4cc9-aaa2-720cd7de38c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = {\"template\": dedent(\"\"\"\\\n",
    "You are a helpful AI assistant specialized in personality profiling.\n",
    "\n",
    "Your task is to analyze and infer aspects of a user's personality based solely on the images they express interest in or provide.\n",
    "Base your analysis on observable visual elements such as themes, colors, composition, subjects, emotional tone, and style.\n",
    "\n",
    "Avoid making assumptions based on demographic, cultural, or political factors. \n",
    "Focus exclusively on psychological and aesthetic interpretations related to the images themselves.\n",
    "\n",
    "The output language should be in traditional Chinese (繁體中文).\n",
    "\"\"\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5231f2a4-d063-4888-8c67-24a485961ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 \n",
    "def build_image_prompt(image_str: str):\n",
    "\n",
    "    return {\"type\": \"image\",\n",
    "             \"template\": {\"url\": f\"data:image/jpeg;base64,{image_str}\"}}\n",
    "\n",
    "\n",
    "human_template = []\n",
    "\n",
    "for image_file in os.listdir(image_dir):\n",
    "    image_str = image_to_base64(os.path.join(image_dir, image_file))\n",
    "    human_template.append(build_image_prompt(image_str))\n",
    "\n",
    "input_ = {\n",
    "    \"system\": system_template,\n",
    "    \"human\": human_template,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab59ca5-80c6-473e-a451-d16353a8c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936ea466-1870-4b07-8dad-75628c355877",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "pipeline_ = chat_prompt_template|model|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486afc65-236b-403c-b0ac-15e4391cc7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for msg in pipeline_.astream({}):\n",
    "    print(msg, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ad6cef-0683-4594-860d-9913f6b6da01",
   "metadata": {},
   "source": [
    "完成了 Prototype，接下來就是把它打造成一個可用的服務。畢竟，你不會希望每次都得打開 Jupyter Notebook 才能跑吧？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e82f97-0d3e-4fbd-ae9f-8f6678feca40",
   "metadata": {},
   "source": [
    "## 後端整合與部署（Flask / Streamlit）\n",
    "\n",
    "**本章學完你將能學會什麼：**\n",
    "\n",
    "- 學會如何以 Flask 建立 API，串接 LangChain Pipeline 並處理圖片上傳與回應。  \n",
    "- 理解前後端資料流：Frontend → Flask → LangChain → GPT → Response。  \n",
    "- 了解如何用 Streamlit 快速製作原型介面，並實現即時互動展示。  \n",
    "\n",
    "**📘 最終你將具備的能力：**  \n",
    "能獨立建立完整的 AI Web 應用架構，從模型推論到前端展示都能自行部署與除錯。\n",
    "\n",
    "檔案結構\n",
    "```\n",
    "app/\n",
    "├── app_flask.py               # Flask backend\n",
    "├── app_server.py              # Langserve backend\n",
    "├── app_streamlit.py           # Streamlit frontend\n",
    "```\n",
    "安裝\n",
    ">- pip install streamlit uvicorn fastapi\n",
    ">- streamlit run app_streamlit.py\n",
    "\n",
    "### 🧠 系統架構流程圖（視覺化版本）\n",
    "\n",
    "📱 **前端**\n",
    "> HTML / Streamlit 介面  \n",
    "> ⬇️ 上傳圖片與輸入問題  \n",
    "\n",
    "🧩 **Flask API**\n",
    "> 接收請求 (`/generate`)  \n",
    "> ⬇️ 將資料傳給後端推論鏈  \n",
    "\n",
    "🔗 **LangChain Pipeline**\n",
    "> 建立 Prompt + Image Input  \n",
    "> ⬇️ 呼叫多模態模型  \n",
    "\n",
    "🧠 **GPT 模型 (Image Caption / Personality Profiling)**\n",
    "> 生成結果 → 回傳 JSON 給前端顯示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167f32f2-5594-47cd-bedb-e4785269145d",
   "metadata": {},
   "source": [
    "進行後端測試\n",
    "\n",
    "模擬flask中將訊息傳給app_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f927620-eba4-47cc-9888-0c368e159087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import requests\n",
    "\n",
    "@chain\n",
    "def image_to_base64(image_path: str) -> str:\n",
    "\n",
    "    f not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"找不到圖片檔案: {image_path}\")\n",
    "    \n",
    "    with Image.open(image_path) as image:\n",
    "        buffered = io.BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "@chain\n",
    "def build_image_prompt(image_str: str):\n",
    "    return {\n",
    "        \"type\": \"image\",\n",
    "        \"template\": {\"url\": f\"data:image/jpeg;base64,{image_str}\"}\n",
    "    }\n",
    "\n",
    "\n",
    "image_transformation_pipeline_ = image_to_base64|build_image_prompt\n",
    "\n",
    "# 建立模板\n",
    "human_template = []\n",
    "\n",
    "# 圖像提示詞: 輸入的圖片\n",
    "image_files = [os.path.join(image_dir, image_file) for image_file in os.listdir(image_dir)]\n",
    "\n",
    "human_template.extend(image_transformation_pipeline_.batch(image_files))\n",
    "\n",
    "payload = {\n",
    "    \"human\": human_template,\n",
    "}\n",
    "\n",
    "resp = requests.post(\"http://localhost:5000/app_image_psychic/invoke\", json={\"input\": payload})\n",
    "\n",
    "if resp.status_code != 200:\n",
    "    print(f\"錯誤：{resp.status_code}, 回傳內容：{resp.text}\")\n",
    "\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ac8795-38a6-4d54-a916-c2f7f29418f5",
   "metadata": {},
   "source": [
    "做Image Caption的另一個選擇是上傳圖片的URL\n",
    "\n",
    "大部分的情況下直接用URL可能不是那麼容易，因為需要先找到圖片的URL\n",
    "\n",
    "所以我們這邊就是簡單的帶過"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ea08b2-0f7e-4765-96bc-63937d7e5017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image as Image_IPYTHON\n",
    "\n",
    "Image_IPYTHON(url=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8584e3-ef7a-454a-b4b4-b28e74fb2a16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "human_message_template = HumanMessagePromptTemplate.from_template(\n",
    "    template=[\n",
    "        {'type': 'text', 'text': '{question}'},\n",
    "        {'type': 'image_url', 'image_url': {'url': '{image_url}'}}\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Create a Prompt Template\n",
    "prompt = ChatPromptTemplate.from_messages([human_message_template])\n",
    "\n",
    "# Generate the Chain\n",
    "pipeline_ = RunnablePassthrough.assign(image_url=itemgetter('url'))|prompt|model|StrOutputParser()\n",
    "\n",
    "url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
    "                                   \n",
    "pipeline_.invoke({\"question\": \"What is in this image?\",\n",
    "                  \"url\": url})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc58712-498d-4ca9-87a0-244099ade0fe",
   "metadata": {},
   "source": [
    "# 其他的Image Caption工具\n",
    "\n",
    "**本章學完你將能學會什麼：**\n",
    "\n",
    "- 認識 WD-14、Florence 2 等開源影像描述與標籤模型的特色與應用情境。  \n",
    "- 學會如何在本地環境中安裝、執行與測試開源標籤工具。  \n",
    "- 理解第三方 API（如 fal.ai）的呼叫流程與授權機制。  \n",
    "\n",
    "**📘 最終你將具備的能力：**  \n",
    "能靈活選擇與整合不同的影像理解工具，為專案找到最合適的技術方案與部署方式。\n",
    "\n",
    "## WD-14 Image Tagging\n",
    "\n",
    "這主要是用於ACG的內容\n",
    "\n",
    "- Online Service: https://huggingface.co/spaces/hysts/DeepDanbooru\n",
    "\n",
    "- The SaaS works with anime character.\n",
    "\n",
    "- Open Source: wd14_tagging\n",
    "\n",
    "- https://github.com/corkborg/wd14-tagger-standalone/tree/main\n",
    "\n",
    "### 安裝\n",
    "\n",
    ">- git clone https://github.com/corkborg/wd14-tagger-standalone.git\n",
    ">- conda create -n wd-14 python=3.10\n",
    ">- conda activate wd-14\n",
    ">- pip install -r requirements\n",
    "\n",
    "### 使用\n",
    "\n",
    ">- python run.py --file <filename> --cpu\n",
    ">- python run.py --dir <dir> --cpu --model camie-tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb7dc14-dcfc-47f3-b985-f2d6fb4900a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "script = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-5\", \"wd14-tagger-standalone\", \"run.py\")\n",
    "filename = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-5\", \"image_source\", \"862839349278941305.png\")\n",
    "\n",
    "\n",
    "cmd = f'conda run -n wd14 python \"{script}\" --file \"{filename}\"'\n",
    "result = subprocess.run(cmd, shell=True, capture_output=True, text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8225f40d-6699-402f-b91a-b7cc146669cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c4f5aa-a6a2-4285-a012-c04387798426",
   "metadata": {},
   "source": [
    "## Florence 2\n",
    "\n",
    "這是一個開源的計算機視覺模型。他能做的其實不只於Image Caption，還包含了OCR等等的任務。\n",
    "\n",
    "https://huggingface.co/spaces/gokaygokay/Florence-2\n",
    "\n",
    "- https://pypi.org/project/fal-client/\n",
    "- https://fal.ai/dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cc1a00-e588-488c-913a-c4d0ca31f99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import base64\n",
    "\n",
    "import fal_client\n",
    "from PIL import Image\n",
    "\n",
    "from src.initialization import credential_init\n",
    "from src.io.path_definition import get_project_dir\n",
    "\n",
    "credential_init()\n",
    "\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    \n",
    "    with Image.open(image_path) as image:\n",
    "        \n",
    "        # Save the Image to a Buffer\n",
    "        buffered = io.BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        \n",
    "        # Encode the Image to Base64\n",
    "        image_str = base64.b64encode(buffered.getvalue())\n",
    "    \n",
    "    return image_str.decode('utf-8')\n",
    "\n",
    "\n",
    "image_path = os.path.join(get_project_dir(), 'tutorial/LLM+Langchain/Week-5/ubisoft.png')\n",
    "image_url = image_to_base64(image_path)\n",
    "\n",
    "handler = fal_client.submit(\n",
    "    \"fal-ai/florence-2-large/ocr\",\n",
    "    arguments={\n",
    "        \"image_url\": f\"data:image/jpeg;base64,{image_url}\"\n",
    "    },\n",
    "    webhook_url=\"https://optional.webhook.url/for/results\",\n",
    ")\n",
    "\n",
    "request_id = handler.request_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8700be19-f5a0-443d-a567-97fe7f98cda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = fal_client.status(\"fal-ai/florence-2-large/ocr\", request_id, with_logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6310386f-0e86-49ea-bed1-b8d7bf547ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202e9b53-482f-4b96-8b37-55800053ba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = fal_client.result(\"fal-ai/florence-2-large/ocr\", request_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631eaea3-a2c8-43db-a9de-d55d9b5a078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb50d1b-0ef2-43db-832a-5b88646c8167",
   "metadata": {},
   "source": [
    "測試在Google Colab上建立的vectorstore是否可運行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391d804b-d2c8-4018-b644-d8f03ba93300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "\n",
    "\n",
    "vectorstore = FAISS.load_local(\n",
    "    \"warhammer 40k codex\", embeddings, allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff0b6ed-1d55-4bae-98e3-a8b510cd575f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
