{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcc71bd-ab5e-42ac-ab3a-12249917457d",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da92cc62-1b7d-453a-8407-b1d3c4e928d7",
   "metadata": {},
   "source": [
    "## Code Documentation\n",
    "\n",
    "SYSTEM: You are a helpful AI assistant and you will act as a  Google Senior Software Developer who is going to write the python code documentation. I will give you the code and you will finish the documentation for me."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac0be8-18de-4d0a-8168-47b47013506f",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "\n",
    "Connection to the OpenAI API service. \n",
    "\n",
    "It does not have to be OpenAI. Other API services such as Anthropic Claude is also possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41972474-dd73-4681-9bfb-b2b00767323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain==0.2.5 langchain-community==0.2.5 langchain-core==0.2.9 langchain-openai==0.1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7fb3d0-40bf-43b7-831f-b710d7278aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e2079a-4283-4220-b5ad-1517b07deb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from src.initialization import credential_init\n",
    "from src.io.path_definition import get_project_dir\n",
    "\n",
    "\n",
    "credential_init()\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-mini\", \n",
    "                   temperature=0 # a range from 0-2, the higher the value, the higher the `creativity`\n",
    "                  )\n",
    "\n",
    "# temperature has a range from 0-2, the higher the temperature, the more creative/unpredictable the outcomes. \n",
    "# to have a stable or more deterministic result, you should choose temperature = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674dbfc3-5e90-4ad9-97ca-063eef38b9f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.invoke(\"Tell me something about Apple Inc. Just a short summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7961d05b-cbd0-43d5-9920-a9a7f994757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.invoke(\"Tell me something about Apple Inc. Just a short summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a7d87-381d-41c5-82bd-75d66bd295ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216956e1-29cf-49ff-8274-0dffe50ef221",
   "metadata": {},
   "source": [
    "## Prompt Engineering SOP\n",
    "\n",
    "### 1. Importing Necessary Modules (導入必要的模塊)：\n",
    "\n",
    "This line imports the required classes from the Langchain library for creating and managing prompt templates.\n",
    "這行代碼從 Langchain 庫中導入了創建和管理提示模板所需的類。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab40aa81-8174-4fb7-b8b6-0797de363cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6340aa6-9f55-4b5a-906c-620feecb43d6",
   "metadata": {},
   "source": [
    "### 2. Defining a System Prompt (定義系統提示):\n",
    "\n",
    "This line creates a system_prompt using the PromptTemplate.from_template method. The template instructs the AI to act like Gordon Ramsay, mimicking his manner of speech from the television show \"Hell's Kitchen\".\n",
    "\n",
    "這行代碼使用 PromptTemplate.from_template 方法創建了一個 system_prompt。這個模板指示 AI 以 Gordon Ramsay 的身份行事，模仿他在電視節目《地獄廚房》中的說話方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028eef83-37a2-4574-b61f-6c01485d8a1a",
   "metadata": {},
   "source": [
    "## 人格提示/Persona Example\n",
    "\n",
    "- Gordon Ramsay: 地獄廚房的暴躁狀態"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0472fb9-4340-4dc2-9ee8-9bf77c87df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = PromptTemplate(template=\"\"\"You are a helpful AI assistant \n",
    "acting as Gordon Ramsay, the British celebrity chef, particular the way he \n",
    "talks in the television show `Hell Kitchen`.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb47aed0-d02e-4590-9cdc-d31e80a74777",
   "metadata": {},
   "source": [
    "### 3. Creating a System Message Prompt (創建系統消息提示):\n",
    "\n",
    "This line wraps the system_prompt in a SystemMessagePromptTemplate, which is used to generate system messages.\n",
    "這行代碼將 system_prompt 包裝在 SystemMessagePromptTemplate 中，用於生成系統消息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f97719-c921-4b03-83ba-3ccc5a5fb71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dc8d50-3d4c-4ac0-868e-90ee2a5628ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a526a3-b551-4ead-99d8-ab0049d8b2a3",
   "metadata": {},
   "source": [
    "### 4. Defining a Human Prompt (定義人類提示):\n",
    "\n",
    "This line defines a human_prompt template that takes a variable query. This variable will be replaced by the user's input when generating the prompt.\n",
    "\n",
    "這行代碼定義了一個 human_prompt 模板，它接收一個變量 query。這個變量在生成提示時將被用戶的輸入替換。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d6fa5d-d549-4cb4-a9fb-bdd05b323f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                              input_variables=[\"query\"]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1ddad5-aedb-4d16-bea1-5419c5d05b2e",
   "metadata": {},
   "source": [
    "### 5. Creating a Human Message Prompt (創建人類消息提示): \n",
    "\n",
    "This line wraps the human_prompt in a HumanMessagePromptTemplate, which is used to generate human messages.\n",
    "\n",
    "這行代碼將 human_prompt 包裝在 HumanMessagePromptTemplate 中，用於生成人類消息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abafa63-1776-47bb-9df2-36a28ccc6998",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebf62b1-9932-44db-bafe-72e84c0f7120",
   "metadata": {},
   "source": [
    "### 6. Combining the Prompts into a Chat Prompt (將提示合併到一個聊天提示中):\n",
    "\n",
    "This line combines the system_message and human_message templates into a single ChatPromptTemplate using the from_messages method. This template will be used to generate the conversation flow, starting with the system message and followed by the human message.\n",
    "\n",
    "這行代碼使用 from_messages 方法將 system_message 和 human_message 模板合併到一個 ChatPromptTemplate 中。這個模板將用於生成對話流程，首先是系統消息，然後是人類消息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a640a253-8a6d-4f71-9419-73617621cf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec676ba9-6c6f-432c-bb0f-3650fd128e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb1658-de53-4804-b0a5-b6d9f0a185ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt.invoke({\"query\": \"\"\"\n",
    "                                      A chef just finished his scallops \n",
    "                                      but you find it is still raw inside.\n",
    "                                      \"\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf247cf6-24eb-42d3-b63c-df3d4a70e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a4bfa6-636e-4332-ae9b-36092a7cda62",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7e899b-5144-4b23-ac99-2f31680c3436",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0036835-9d08-47bb-83f4-8afcdf5600d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ce0a7-f9fd-45d4-bcc8-5a8388b8c351",
   "metadata": {},
   "source": [
    "How to do the translation properly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ce0be-4923-4370-9358-3ec11c74b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = PromptTemplate(template=\"\"\"\n",
    "                                        You are a helpful AI assistant \n",
    "                                        with native speaker fluency in both \n",
    "                                        English and traditional Chinese (繁體中文). \n",
    "                                        You will translate the given content.\n",
    "                                        \"\"\")\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                              input_variables=[\"query\"]\n",
    "                              )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "translation_prompt_template =  ChatPromptTemplate.from_messages([system_message,\n",
    "                                                                 human_message\n",
    "                                                                ])\n",
    "\n",
    "prompt = translation_prompt_template.invoke({\"query\": content})\n",
    "output = model.invoke(prompt)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513b8cbb-28b8-4302-9ac5-ddaf681723c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translation_function(text):\n",
    "\n",
    "    \"\"\"\n",
    "    翻譯\n",
    "    直接將給予內容text翻譯成繁體中文\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = PromptTemplate(template=\"\"\"You are a helpful AI \n",
    "    assistant with native speaker fluency in both English and \n",
    "    traditional Chinese (繁體中文). \n",
    "    You will translate the given content.\"\"\")\n",
    "    system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "    \n",
    "    human_prompt = PromptTemplate(template='{query}',\n",
    "                                  input_variables=[\"query\"]\n",
    "                                  )\n",
    "    human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "    \n",
    "    translation_prompt_template =  ChatPromptTemplate.from_messages([system_message,\n",
    "                                                                     human_message\n",
    "                                                                    ])\n",
    "    \n",
    "    prompt = translation_prompt_template.invoke({\"query\": text})\n",
    "    output = model.invoke(prompt)\n",
    "    return output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fecb7c-b4ba-4b0c-a3c7-3692b18b6f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_function(text=content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165539d3-b5a6-45b9-801b-c11599e6f06d",
   "metadata": {},
   "source": [
    "- Gordon Ramsay: 少年廚神的老好人狀態"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3579b80f-f9c1-4dde-9507-28da6d97433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = PromptTemplate(template=\"\"\"You are a helpful AI assistant \n",
    "acting as Gordon Ramsay, the British celebrity chef, particular the way he \n",
    "talks in the television show `MasterChef Junior`.\"\"\")\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "#之接借用之前的human message\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": \"\"\"A chef just finished his scallops \n",
    "but you find it is still raw inside.\"\"\"})\n",
    "output = model.invoke(prompt)\n",
    "translation_function(text=output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55fb977-316b-49a8-a576-7090a515fb91",
   "metadata": {},
   "source": [
    "- Donald Trump 再次當選"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e75fdfd-7fc1-4859-839f-51233c188fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = PromptTemplate(template=\"\"\"You are a helpful AI assistant \n",
    "mimicking the act Donald Trump. The User you give you intruction and you will \n",
    "do the best you can.\"\"\")\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "#之接借用之前的human message\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": \"\"\"You just won the US presidential \n",
    "election and you are going to give a speech.\"\"\"})\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "print(translation_function(text=output.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4fb329-a8b7-46d9-80be-7b8ad0b41f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt.invoke({\"query\": \"\"\"You are going to talk about your \n",
    "view on the southern boarder\"\"\"})\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "print(translation_function(text=output.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa67331-f344-413d-9798-e7e3dae448ef",
   "metadata": {},
   "source": [
    "- 雖然這是一個ChatModel但是model本身是沒有記憶性的，他完全不記得你之前提過的任何東西。在ChatGPT中，你每次給入Prompt之後，他會把你之前的輸入和模型的回答作為提示詞輸入，所以可以連續性的回答問題。但這也導致了若是模型的回答偏離了正軌，他其實很難修正回來，因為聊天模型基本上是一種n-shot learning，白話一點就是見人說人話，見鬼說鬼話。一但開始說鬼話，要拉回人話會開始有些難度。解決方法是關掉重來。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35dd091-8614-4279-950b-efe8f8e0d479",
   "metadata": {},
   "source": [
    "### There are more than one ways of constructing your prompt:\n",
    "\n",
    "- (\"system\", system_prompt.template): This tuple indicates a system message. system_prompt.template refers to the template content for the system's message.\n",
    "\n",
    "- (\"human\", human_prompt.template): This tuple indicates a human message. human_prompt.template refers to the template content for the human's message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201d09bb-b638-4140-a68e-1475b669e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([(\"system\", system_prompt.template),\n",
    "                                                 (\"human\", human_prompt.template)\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe7bcb0-3c48-42ed-9875-055a0eab4d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt.invoke({\"query\": \"A chef just finished his scallops but you find it is still raw inside.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3221b57-510f-47c7-bc67-8d32f95f4532",
   "metadata": {
    "tags": []
   },
   "source": [
    "- A template is similar to a Python string, but it includes placeholders for variables. Langchain automatically detects and handles these variables, simplifying the process of generating dynamic content\n",
    "- 模板類似於 Python 字符串，但包含變量的佔位符。Langchain 可以自動識別和管理這些變量，從而簡化生成動態內容的過程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6870734-7613-4487-a014-4c60de6a6ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([(\"system\", system_prompt.template),\n",
    "                                                 (\"human\", \"{query}\")\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d72613-6dea-4d65-9a8c-cfea3dc30993",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt.invoke({\"query\": \"A chef just finished his scallops but you find it is still raw inside.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56764450-ef05-421c-a089-91f9c10ad88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt.invoke({\"query\": \"A chef just finished his scallops but you find it is still raw inside.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf2b2b3-acfe-47b8-b9b1-af6d4b05e678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b65a4-fce3-4399-a0f8-2a96d92743d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed the prompt into the model\n",
    "prompt = chat_prompt.invoke({\"query\": \"A chef just finished his scallops but you find it is still raw inside.\"})\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2de5ac-bccd-4738-a908-574264bd9c5c",
   "metadata": {},
   "source": [
    "## 輸出格式控制: 石器時代版本\n",
    "\n",
    "ChatGPT輸出格式百百種，你不控制的話，很難將進行量產。想像一下你今天用Word打好文件後，送入印表機影印後，字體會跑掉。\n",
    "\n",
    "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)\n",
    "\n",
    "\"\"\"\n",
    "In machine learning, a neural network (also artificial neural network or neural net, abbreviated ANN or NN) is a model inspired by the structure and function of biological neural networks in animal brains.[1][2]\n",
    "\n",
    "An ANN consists of connected units or nodes called artificial neurons, which loosely model the neurons in the brain. These are connected by edges, which model the synapses in the brain. Each artificial neuron receives signals from connected neurons, then processes them and sends a signal to other connected neurons. The \"signal\" is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs, called the activation function. The strength of the signal at each connection is determined by a weight, which adjusts during the learning process.\n",
    "\n",
    "Typically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly passing through multiple intermediate layers (hidden layers). A network is typically called a deep neural network if it has at least two hidden layers.[3]\n",
    "\n",
    "Artificial neural networks are used for various tasks, including predictive modeling, adaptive control, and solving problems in artificial intelligence. They can learn from experience, and can derive conclusions from a complex and seemingly unrelated set of information.\n",
    "\n",
    "Training\n",
    "Neural networks are typically trained through empirical risk minimization. This method is based on the idea of optimizing the network's parameters to minimize the difference, or empirical risk, between the predicted output and the actual target values in a given dataset.[4] Gradient-based methods such as backpropagation are usually used to estimate the parameters of the network.[4] During the training phase, ANNs learn from labeled training data by iteratively updating their parameters to minimize a defined loss function.[5] This method allows the network to generalize to unseen data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dafdc6b-02d7-420e-b055-317ff23f4f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "In machine learning, a neural network (also artificial neural network or neural net, abbreviated ANN or NN) is a model inspired by the structure and function of biological neural networks in animal brains.[1][2]\n",
    "\n",
    "An ANN consists of connected units or nodes called artificial neurons, which loosely model the neurons in the brain. These are connected by edges, which model the synapses in the brain. Each artificial neuron receives signals from connected neurons, then processes them and sends a signal to other connected neurons. The \"signal\" is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs, called the activation function. The strength of the signal at each connection is determined by a weight, which adjusts during the learning process.\n",
    "\n",
    "Typically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly passing through multiple intermediate layers (hidden layers). A network is typically called a deep neural network if it has at least two hidden layers.[3]\n",
    "\n",
    "Artificial neural networks are used for various tasks, including predictive modeling, adaptive control, and solving problems in artificial intelligence. They can learn from experience, and can derive conclusions from a complex and seemingly unrelated set of information.\n",
    "\n",
    "Training\n",
    "Neural networks are typically trained through empirical risk minimization. This method is based on the idea of optimizing the network's parameters to minimize the difference, or empirical risk, between the predicted output and the actual target values in a given dataset.[4] Gradient-based methods such as backpropagation are usually used to estimate the parameters of the network.[4] During the training phase, ANNs learn from labeled training data by iteratively updating their parameters to minimize a defined loss function.[5] This method allows the network to generalize to unseen data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5855bed1-277e-48e1-b968-ca45f8ef4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "                  I am going to give you a template for your output. \n",
    "                  CAPITALIZED WORDS are my placeholders. Fill in my \n",
    "                  placeholders with your output. Please preserve the \n",
    "                  overall formatting of my template. My template is:\n",
    "\n",
    "                 *** Question:*** QUESTION\n",
    "                 *** Answer:*** ANSWER\n",
    "                \n",
    "                 I will give you the data to format in the next prompt. \n",
    "                 Create three questions using my template.\n",
    "                 \"\"\"\n",
    "\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                                  input_variables=[\"query\"]\n",
    "                                  )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": query})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa46936-b8c1-40b6-acea-cfb7f9027ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        George Washington (February 22, 1732 – December 14, 1799) was a Founding Father of the United States, military officer, and farmer who served as the first president of the United States from 1789 to 1797. Appointed by the Second Continental Congress as commander of the Continental Army in 1775, Washington led Patriot forces to victory in the American Revolutionary War. He then served as president of the Constitutional Convention in 1787, which drafted the current Constitution of the United States. Washington has thus become commonly known as the \"Father of His Country\".\n",
    "\n",
    "        Washington's first public office, from 1749 to 1750, was as surveyor of Culpeper County in the Colony of Virginia. In 1752, he received military training and was granted the rank of major in the Virginia Regiment. During the French and Indian War, Washington was promoted to lieutenant colonel in 1754 and subsequently became head of the Virginia Regiment in 1755. He was later elected to the Virginia House of Burgesses and was named a delegate to the Continental Congress in Philadelphia, which appointed him commander-in-chief of the Continental Army. Washington led American forces to a decisive victory over the British in the Revolutionary War, leading the British to sign the Treaty of Paris, which acknowledged the sovereignty and independence of the United States. He resigned his commission in 1783 after the conclusion of the Revolutionary War.\n",
    "        \n",
    "        Washington played an indispensable role in the drafting of the Constitution, which replaced the Articles of Confederation in 1789. He was then twice elected president unanimously by the Electoral College in 1788 and 1792. As the first U.S. president, Washington implemented a strong, well-financed national government while remaining impartial in a fierce rivalry that emerged between cabinet members Thomas Jefferson and Alexander Hamilton. During the French Revolution, he proclaimed a policy of neutrality while additionally sanctioning the Jay Treaty. He set enduring precedents for the office of president, including republicanism, a peaceful transfer of power, the use of the title \"Mr. President\", and the two-term tradition. His 1796 farewell address became a preeminent statement on republicanism in which he wrote about the importance of national unity and the dangers that regionalism, partisanship, and foreign influence pose to it. As a planter of tobacco and wheat, Washington owned many slaves. He grew to oppose slavery near the end of his lifetime, and provided in his will for the manumission of his slaves.\n",
    "        \n",
    "        Washington's image is an icon of American culture. He has been memorialized by monuments, a federal holiday, various media depictions, geographical locations including the national capital, the State of Washington, stamps, and currency. In 1976, Washington was posthumously promoted to the rank of general of the Armies, the highest rank in the U.S. Army. Washington consistently ranks in both popular and scholarly polls as one of the greatest presidents in American history.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16feb02f-7bc7-4ba0-906f-29d952fd6be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "                 I am going to give you a template for your output. CAPITALIZED\n",
    "                 WORDS are my placeholders. Fill in my placeholders with your \n",
    "                 output. Please preserve the overall formatting of my template. \n",
    "                 \n",
    "                 My template is:\n",
    "                \n",
    "                 ## Bio: <NAME>\n",
    "                 ***Executive Summary:*** <ONE SENTENCE SUMMARY>\n",
    "                 ***Full Description:*** <ONE PARAGRAPHY SUMMARY>\n",
    "                \n",
    "                 \"\"\"\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                                  input_variables=[\"query\"]\n",
    "                                  )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": query})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e8e75f-96aa-4834-9ca7-1bfb7dbc2fbf",
   "metadata": {},
   "source": [
    "## 自動模式辨認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7652d408-34a3-46b4-8e83-98d2d01c98d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "                  I will tell you my start and \n",
    "                  end destination and you will provide a \n",
    "                  complete list of stops for me, including places to stop \n",
    "                  between my start and destination.\n",
    "                  \"\"\"\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                                  input_variables=[\"query\"]\n",
    "                                  )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                human_message\n",
    "                                               ])\n",
    "\n",
    "query = \"台東太麻里->Day1->Day2->花蓮天祥\"\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": query})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9b8ff-49e9-4a2b-a31f-8add697a6d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "                  I will tell you my start and end destination and you will \n",
    "                  provide a complete list of stops for me, including places \n",
    "                  to stop between my start and destination.\n",
    "                  The output should be in traditional Chinese (繁體中文)\n",
    "                  \"\"\"\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                                  input_variables=[\"query\"]\n",
    "                                  )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "query = \"台東太麻里->Day1->Day2->花蓮天祥\"\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": query})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b4a13b-f296-4b97-80e7-a35f0015d557",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "                  Christmas is coming and I want to ask a girl out. \n",
    "                  Please design a great dating experience for us. \n",
    "                  I will tell you my <start> and <end> destination and you \n",
    "                  will provide a complete list of stops for me, including \n",
    "                  places to stop between my start and destination.\n",
    "                  The output should be in traditional Chinese (繁體中文)\n",
    "                  \"\"\"\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='start: {start}; end: {end}',\n",
    "                                  input_variables=[\"start\", \"end\"]\n",
    "                                  )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "\"\"\"\n",
    "給我提點子，這種題目我會腦死~~\n",
    "\"\"\"\n",
    "start = \"臺北101\"\n",
    "end = \"淡水老街\"\n",
    "\n",
    "\n",
    "prompt = chat_prompt.invoke({\"start\": start, \"end\": end})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a950379-930a-48ce-af03-4ffd16d1c89f",
   "metadata": {},
   "source": [
    "### Let us wrap the chat_prompt generation with a python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dcaf2b-3363-4be9-806b-0a485a846629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_standard_chat_prompt_template(kwargs):\n",
    "\n",
    "    system_content = kwargs['system']\n",
    "    human_content = kwargs['human']\n",
    "    \n",
    "    system_prompt = PromptTemplate(**system_content)\n",
    "    system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "    \n",
    "    human_prompt = PromptTemplate(**human_content)\n",
    "    human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "    \n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                     human_message\n",
    "                                                   ])\n",
    "\n",
    "    return chat_prompt\n",
    "\n",
    "system_template = \"\"\"\n",
    "                  Christmas is coming and I want to ask a girl out. \n",
    "                  Please design a great dating experience for us. \n",
    "                  I will tell you my <start> and <end> destination and you \n",
    "                  will provide a complete list of stops for me, including \n",
    "                  places to stop between my start and destination.\n",
    "                  The output should be in traditional Chinese (繁體中文)\n",
    "                  \"\"\"\n",
    "\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": 'start: {start}; end: {end}',\n",
    "                    \"input_variable\": [\"start\", \"end\"]}}\n",
    "\n",
    "my_chat_prompt_template = build_standard_chat_prompt_template(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60915871-3d19-40c2-af4f-0b9d1d8f7295",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_chat_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c626e3-0807-4810-ba2d-3c420742bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = \"臺北101\"\n",
    "end = \"淡水老街\"\n",
    "\n",
    "prompt = my_chat_prompt_template.invoke({\"start\": start, \n",
    "                                         \"end\": end})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509fe86a-a4a7-49a1-8b05-b12d3c8e7aa5",
   "metadata": {},
   "source": [
    "# **** 預計第一個小時結束 ****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0500267-2e1a-41a1-98ce-c3749e0794c2",
   "metadata": {},
   "source": [
    "## 輸出格式控制: 精確打擊版本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a05a78-b082-4ace-8005-0e3a2bdece14",
   "metadata": {},
   "source": [
    "### 1. Importing Necessary Classes (導入必要的類):\n",
    "\n",
    "- StructuredOutputParser and ResponseSchema are imported from langchain.output_parsers.\n",
    "- 從 langchain.output_parsers 導入 StructuredOutputParser 和 ResponseSchema。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c680e103-d653-4f2d-b5fa-109285881cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a1f896-4fee-423b-84bc-1bd842f62e79",
   "metadata": {},
   "source": [
    "### 2. Defining Response Schemas (定義回應結構):\n",
    "\n",
    "- A list named response_schemas is created, which contains instances of ResponseSchema. ResponseSchema has two attributes:\n",
    "    - name: This is the key used to retrieve the output.\n",
    "    - description: This is part of the prompt that describes what the output should be.\n",
    "\n",
    "<br>\n",
    "\n",
    "- 創建一個名為 response_schemas 的列表，包含 ResponseSchema 的實例。ResponseSchema 有兩個屬性：\n",
    "    - name：用於檢索輸出的鍵。\n",
    "    - description：提示的一部分，用於描述輸出應該是什麼。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0123f5d-4f67-4d0e-9d16-e8a51f4d424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schemas = [\n",
    "        ResponseSchema(name=\"result\", \n",
    "                       description=\"\"\"The result as a python list of \n",
    "                                    python dictionaries\"\"\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d3a04b-3004-4360-88c8-a51743b4fe1c",
   "metadata": {},
   "source": [
    "### 3. Creating the Output Parser (創建輸出解析器):\n",
    "\n",
    "- output_parser is created by calling StructuredOutputParser.from_response_schemas with the response_schemas list.\n",
    "- This parser uses the defined schemas to understand and structure the output.\n",
    "\n",
    "- 通過調用 StructuredOutputParser.from_response_schemas 並傳入 response_schemas 列表來創建 output_parser。\n",
    "- 該解析器使用定義的結構來理解和結構化輸出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad0c5b2-c990-4069-aa5d-fcfafee72792",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8b0f18-7c02-40da-97da-ed655295be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690df7a6-d947-408a-b0f5-d34f0cad52ed",
   "metadata": {},
   "source": [
    "### 4. Generating Format Instructions (生成格式說明):\n",
    "\n",
    "- format_instructions is generated by calling output_parser.get_format_instructions().\n",
    "- These instructions specify how the output should be formatted, based on the defined schemas.\n",
    "<br>\n",
    "<br>\n",
    "- 通過調用 output_parser.get_format_instructions() 來生成 format_instructions。\n",
    "- 這些說明根據定義的結構指定輸出的格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b00293-02b2-4553-b18a-006066418577",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa6c36f-f730-4914-8281-b33e54986bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aa9541-12a9-4475-a8c0-894e919ba374",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "                I am going to give you a template for your output. CAPITALIZED WORDS are my placeholders. Fill in my placeholders with your output. \n",
    "                Please preserve the overall formatting of my template. My template is:\n",
    "                \n",
    "                *** Question:*** QUESTION\n",
    "                *** Answer:*** ANSWER\n",
    "                \n",
    "                I will give you the data to format in the next prompt. Create three questions using my template.\n",
    "                \"\"\"\n",
    "\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template=\"\"\"\n",
    "                                       {query}; \n",
    "                                       format instruction: {format_instructions}\n",
    "                                       \"\"\",\n",
    "                              input_variables=[\"query\"],\n",
    "                              partial_variables={'format_instructions': format_instructions}\n",
    "                              )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt) \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c9e5f-0eac-4f57-9738-4c617b7a2bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "In machine learning, a neural network (also artificial neural network or neural net, abbreviated ANN or NN) is a model inspired by the structure and function of biological neural networks in animal brains.[1][2]\n",
    "\n",
    "An ANN consists of connected units or nodes called artificial neurons, which loosely model the neurons in the brain. These are connected by edges, which model the synapses in the brain. Each artificial neuron receives signals from connected neurons, then processes them and sends a signal to other connected neurons. The \"signal\" is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs, called the activation function. The strength of the signal at each connection is determined by a weight, which adjusts during the learning process.\n",
    "\n",
    "Typically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly passing through multiple intermediate layers (hidden layers). A network is typically called a deep neural network if it has at least two hidden layers.[3]\n",
    "\n",
    "Artificial neural networks are used for various tasks, including predictive modeling, adaptive control, and solving problems in artificial intelligence. They can learn from experience, and can derive conclusions from a complex and seemingly unrelated set of information.\n",
    "\n",
    "Training\n",
    "Neural networks are typically trained through empirical risk minimization. This method is based on the idea of optimizing the network's parameters to minimize the difference, or empirical risk, between the predicted output and the actual target values in a given dataset.[4] Gradient-based methods such as backpropagation are usually used to estimate the parameters of the network.[4] During the training phase, ANNs learn from labeled training data by iteratively updating their parameters to minimize a defined loss function.[5] This method allows the network to generalize to unseen data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b7d3c1-b20c-43c3-87a1-1d85c31215c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt.invoke({\"query\": query})\n",
    "\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d909fc05-ab40-422f-b207-e4f685dc4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb68c2a-2f4d-4283-a665-b0d2214eed7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_parser.parse(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306dc9d1-049d-4da3-b61e-aa70dda0f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output = output_parser.parse(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66728cb-273d-428b-bdd6-48f9d96e85c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4516956f-1a19-45c8-9fe2-b95f99e704e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for content in parsed_output['result']:\n",
    "    print(\"\\n*****************\")\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5098c55f-7116-4e70-9ce7-2d0b925428b7",
   "metadata": {},
   "source": [
    "### 精簡化版本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8258122-103b-4b14-9659-0a1da452eb93",
   "metadata": {},
   "source": [
    "Now you can write a simple for loop for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a16c4-6352-4911-ad5b-179fc156d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schemas = [\n",
    "        ResponseSchema(name=\"result\", \n",
    "                       description=\"\"\"\n",
    "                                   The result as a python list of python dictionaries \n",
    "                                   with the format and the CAPITALIZED WORDS are my \n",
    "                                   placeholders:\n",
    "                                   <Question>: QUESTION,\n",
    "                                   <Answer>: ANSWER\n",
    "                                   \"\"\")\n",
    "    ]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "system_prompt = PromptTemplate(template=\"\"\"\n",
    "                                        Create three questions based on \n",
    "                                        the content.\n",
    "                                        \"\"\")\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}; format instruction: {format_instructions}',\n",
    "                              input_variables=[\"query\"],\n",
    "                              partial_variables={'format_instructions': format_instructions}\n",
    "                              )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt) \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796f3312-aab0-41f6-bf38-a9b6d96de3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt.invoke({\"query\":query})\n",
    "\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060e2232-fa29-4ce0-8e7b-d5f3ebc0d9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser.parse(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a3966-183e-4b1e-9bf2-1b196b42d3aa",
   "metadata": {},
   "source": [
    "## 多練習幾個版本\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4035907-9f76-475e-b771-f8c625597875",
   "metadata": {},
   "source": [
    "system_template = \"\"\"\n",
    "                 I am going to give you a template for your output. CAPITALIZED\n",
    "                 WORDS are my placeholders. Fill in my placeholders with your \n",
    "                 output. Please preserve the overall formatting of my template. My template is:\n",
    "                \n",
    "                 ## Bio: <NAME>\n",
    "                 ***Executive Summary:*** <ONE SENTENCE SUMMARY>\n",
    "                 ***Full Description:*** <ONE PARAGRAPHY SUMMARY>\n",
    "                \n",
    "                 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf35c66-8b1c-44ac-91c4-32c8726eb21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        George Washington (February 22, 1732 – December 14, 1799) was a Founding Father of the United States, military officer, and farmer who served as the first president of the United States from 1789 to 1797. Appointed by the Second Continental Congress as commander of the Continental Army in 1775, Washington led Patriot forces to victory in the American Revolutionary War. He then served as president of the Constitutional Convention in 1787, which drafted the current Constitution of the United States. Washington has thus become commonly known as the \"Father of His Country\".\n",
    "\n",
    "        Washington's first public office, from 1749 to 1750, was as surveyor of Culpeper County in the Colony of Virginia. In 1752, he received military training and was granted the rank of major in the Virginia Regiment. During the French and Indian War, Washington was promoted to lieutenant colonel in 1754 and subsequently became head of the Virginia Regiment in 1755. He was later elected to the Virginia House of Burgesses and was named a delegate to the Continental Congress in Philadelphia, which appointed him commander-in-chief of the Continental Army. Washington led American forces to a decisive victory over the British in the Revolutionary War, leading the British to sign the Treaty of Paris, which acknowledged the sovereignty and independence of the United States. He resigned his commission in 1783 after the conclusion of the Revolutionary War.\n",
    "        \n",
    "        Washington played an indispensable role in the drafting of the Constitution, which replaced the Articles of Confederation in 1789. He was then twice elected president unanimously by the Electoral College in 1788 and 1792. As the first U.S. president, Washington implemented a strong, well-financed national government while remaining impartial in a fierce rivalry that emerged between cabinet members Thomas Jefferson and Alexander Hamilton. During the French Revolution, he proclaimed a policy of neutrality while additionally sanctioning the Jay Treaty. He set enduring precedents for the office of president, including republicanism, a peaceful transfer of power, the use of the title \"Mr. President\", and the two-term tradition. His 1796 farewell address became a preeminent statement on republicanism in which he wrote about the importance of national unity and the dangers that regionalism, partisanship, and foreign influence pose to it. As a planter of tobacco and wheat, Washington owned many slaves. He grew to oppose slavery near the end of his lifetime, and provided in his will for the manumission of his slaves.\n",
    "        \n",
    "        Washington's image is an icon of American culture. He has been memorialized by monuments, a federal holiday, various media depictions, geographical locations including the national capital, the State of Washington, stamps, and currency. In 1976, Washington was posthumously promoted to the rank of general of the Armies, the highest rank in the U.S. Army. Washington consistently ranks in both popular and scholarly polls as one of the greatest presidents in American history.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53393211-130f-454a-b09b-7f4598177007",
   "metadata": {},
   "source": [
    "### Let us try this:\n",
    "\n",
    "- 請針對台灣校長甄試這幾年的考題趨勢，請嘗試命出10個題目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64edb03e-6d17-43e6-921d-e6b6aeda178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "                  You are a helpful AI assistant with great knowledge and insight \n",
    "                  of the educational environment in Taiwan and you have been \n",
    "                  working as a county middle school principle for 20 years.\n",
    "                  You are going to answer the user's question the best you \n",
    "                  can with extensive details.\n",
    "                  The output should be in traditional Chinese (繁體中文)\n",
    "                  \"\"\"\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                                  input_variables=[\"query\"]\n",
    "                                  )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06092c7-9208-483e-8ce4-659b75ca7920",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt.invoke({\"query\": \"請針對台灣校長甄試這幾年的考題趨勢，請嘗試命出10個題目。\"})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    " \n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9774fef-355d-4d7f-9fcf-ee6b33b5a6e1",
   "metadata": {},
   "source": [
    "According to the feedback, the problems seem to be too simple.\n",
    "\n",
    "A template looks like this:\n",
    "\n",
    "聯合國永續發展目標(SDGs)中提及「加強執行手段，重振永續發展的全球夥伴\n",
    "關係」。目前我國教育政策亦強調「跨校的夥伴關係」，請述說明其相關的政策\n",
    "有哪些？跨校的夥伴關係有哪些類型？其執行困境有哪些？\n",
    "\n",
    "Let us try to decompose the template:\n",
    "\n",
    "1. Agenda: 聯合國永續發展目標(SDGs)中提及「加強執行手段，重振永續發展的全球夥伴\n",
    "關係」。目前我國教育政策亦強調「跨校的夥伴關係」.\n",
    "\n",
    "2. Questions: 請述說明其相關的政策有哪些？跨校的夥伴關係有哪些類型？其執行困境有哪些？\n",
    "\n",
    "Let us try to enhance the template to see if we can get better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bbd041-0087-4622-bd0b-8ee5886a11e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "                  You are a helpful AI assistant with great knowledge and insight \n",
    "                  of the educational environment in Taiwan and you have been \n",
    "                  working as a county middle school principle for 20 years.\n",
    "                  You are going to answer the user's question the best you \n",
    "                  can with extensive details.\n",
    "                  The output should be in traditional Chinese (繁體中文)\n",
    "                  \"\"\"\n",
    "\n",
    "human_template = \"\"\"\n",
    "                 {query}. The desired answer should have the following \n",
    "                 structure:\n",
    "                 \n",
    "                 1. Agenda\n",
    "                 2. Questions followed by the agenda.\n",
    "\n",
    "                 Here is an exmaple of the desired output:\n",
    "                 {example}\n",
    "                 \"\"\"\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variable\": [\"query\", \"example\"]}}\n",
    "\n",
    "example = \"\"\"\n",
    "          聯合國永續發展目標(SDGs)中提及「加強執行手段，重振永續發展的全球夥伴 關係」。\n",
    "          目前我國教育政策亦強調「跨校的夥伴關係」，請述說明其相關的政策 有哪些？\n",
    "          跨校的夥伴關係有哪些類型？其執行困境有哪些？\n",
    "          \"\"\"\n",
    "\n",
    "principle_interview_chat_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "prompt = principle_interview_chat_template.invoke({\"query\": \"請針對台灣校長甄試這幾年的考題趨勢，請嘗試命出10個題目。\",\n",
    "                                                   \"example\": example})\n",
    "output = model.invoke(prompt)\n",
    " \n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c624d704-eb6d-4546-a06f-5c8d1a040aa6",
   "metadata": {},
   "source": [
    "#### Overall, you can try to anaylize the topic you are interested in and  decompose the topic to provide a better instruction to the model to improve the outcomes. In conlusion: you should know your shit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ab1725-ca61-41b3-870a-ca08068db030",
   "metadata": {},
   "source": [
    "Let us incorporate the format instruction into the previous work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abfd159-8f6c-4591-a446-21bf1ce449fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "\n",
    "response_schemas = [\n",
    "        ResponseSchema(name=\"result\", \n",
    "                       description=\"\"\"\n",
    "                                   A python list, in which each element should be\n",
    "                                   an agenda and several following up questions.\n",
    "                                   \"\"\")\n",
    "    ]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "system_template = \"\"\"\n",
    "                  You are a helpful AI assistant with great knowledge and insight \n",
    "                  of the educational environment in Taiwan and you have been \n",
    "                  working as a county middle school principle for 20 years.\n",
    "                  You are going to answer the user's question the best you \n",
    "                  can with extensive details.\n",
    "                  The output should be in traditional Chinese (繁體中文)\n",
    "                  \"\"\"\n",
    "\n",
    "human_template = \"\"\"\n",
    "                 {query}. The desired output should have the following \n",
    "                 structure:\n",
    "                 \n",
    "                 1. Agenda\n",
    "                 2. Questions followed by the agenda.\n",
    "\n",
    "                 Here is an exmaple of the desired output:\n",
    "                 {example}\n",
    "\n",
    "                 output format instruction: {format_instructions}\n",
    "                 \"\"\"\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variable\": [\"query\", \"example\"],\n",
    "                    \"partial_variables\": {\"format_instructions\": format_instructions}}}\n",
    "\n",
    "principle_interview_chat_template = build_standard_chat_prompt_template(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e75ed6f-99e0-42f1-b1c1-946e3ce81877",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"\"\"\n",
    "          聯合國永續發展目標(SDGs)中提及「加強執行手段，重振永續發展的全球夥伴 關係」。\n",
    "          目前我國教育政策亦強調「跨校的夥伴關係」，請述說明其相關的政策 有哪些？\n",
    "          跨校的夥伴關係有哪些類型？其執行困境有哪些？\n",
    "          \"\"\"\n",
    "\n",
    "\n",
    "prompt = principle_interview_chat_template.invoke({\"query\": \"請針對台灣校長甄試這幾年的考題趨勢，請嘗試命出10個題目。\",\n",
    "                                                   \"example\": example})\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856bca91-3b0d-4a95-b42c-e2faade703a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0be77e-8581-4cf0-8267-2d5f89a2a28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser.parse(output.content)['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb0d1f7-0790-425b-b7a8-8930204705fb",
   "metadata": {},
   "source": [
    "# Content Enhancement\n",
    "\n",
    "## Okapi BM25 Retrieval System\n",
    "\n",
    "- Purpose: Okapi BM25 helps find the most relevant documents when you search for something.\n",
    "\n",
    "- 目的: Okapi BM25 幫助找到當你搜索某些內容時最相關的文檔。\n",
    "\n",
    "- Documents and Words:\n",
    "\n",
    "    - Imagine you have a bunch of books (documents).\n",
    "    - Each book has many words.\n",
    "\n",
    "- 文檔和詞語:\n",
    "    \n",
    "    - 想像你有一堆書（文檔）。\n",
    "    - 每本書都有很多詞語。\n",
    "\n",
    "- Search Query:\n",
    "\n",
    "    - When you search, you type in a few words (your query).\n",
    "\n",
    "- 搜索查詢:\n",
    "\n",
    "    - 當你搜索時，你會輸入幾個詞語（你的查詢）。\n",
    "\n",
    "- Scoring System:\n",
    "\n",
    "    - Okapi BM25 gives each book a score based on how well it matches your query.\n",
    "\n",
    "- 評分系統:\n",
    "\n",
    "    - Okapi BM25 根據每本書與你的查詢匹配的程度給予每本書一個分數。\n",
    "\n",
    "- Factors for Scoring:\n",
    "\n",
    "    - Term Frequency: If a word from your query appears many times in a book, that book gets a higher score.\n",
    "    - Inverse Document Frequency: If a word is rare across all books but appears in a book, that book gets a higher score.\n",
    "    - Document Length: Longer books get adjusted so they aren't unfairly scored just because they're long.\n",
    "\n",
    "- 評分因素:\n",
    "\n",
    "    - 詞頻: 如果你的查詢中的一個詞在某本書中出現很多次，該書會得到更高的分數。\n",
    "    - 逆文檔頻率: 如果一個詞在所有書中都很稀有，但在某本書中出現，該書會得到更高的分數。\n",
    "    - 文檔長度: 較長的書會進行調整，這樣它們不會僅因為篇幅長而被不公平地評分。\n",
    "\n",
    "- Formula:\n",
    "\n",
    "    - BM25 uses a mathematical formula to combine these factors and calculate the score.\n",
    "\n",
    "- 公式:\n",
    "\n",
    "    -BM25 使用一個數學公式來結合這些因素並計算分數。\n",
    "\n",
    "- Choosing the Best:\n",
    "\n",
    "    - The books with the highest scores are considered the most relevant to your query.\n",
    "\n",
    "- 選擇最佳:\n",
    "\n",
    "    - 分數最高的書被認為是與你的查詢最相關的。\n",
    "\n",
    "- Results:\n",
    "\n",
    "    - These top-scoring books are then shown to you as the search results.\n",
    "\n",
    "- 結果:\n",
    "\n",
    "    - 這些高分書會作為搜索結果顯示給你。\n",
    "\n",
    "Think of it like this: Okapi BM25 is a smart librarian that knows which books are likely to be the most interesting and helpful based on the words you use in your search.\n",
    "\n",
    "想像一下：Okapi BM25 就像是一個聰明的圖書管理員，它根據你在搜索中使用的詞語來判斷哪些書可能是最有趣和最有幫助的。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d71deb-ecda-4379-a041-b482bbfdbead",
   "metadata": {},
   "source": [
    "## OKAPI25 in LangChain\n",
    "\n",
    "https://api.python.langchain.com/en/latest/_modules/langchain_community/retrievers/bm25.html#BM25Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7421cbc-2b35-43ce-854e-911e204040fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa46a39-1500-4223-9de3-7ddd34256ed1",
   "metadata": {},
   "source": [
    "### 1. Reading Training Data (讀取訓練數據):\n",
    "\n",
    "- The code opens a JSON file named recipe_train.json located in the 'tutorial/Week-1' directory within the project directory.\n",
    "- It reads the contents of this file and loads it into a variable called recipe_train.\n",
    "\n",
    "- 該代碼打開位於項目目錄內 'tutorial/Week-1' 目錄中的名為 recipe_train.json 的 JSON 文件。\n",
    "- 它讀取該文件的內容並加載到變量 recipe_train 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df16b07-cd60-4d4d-80ef-a366b66ac9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(get_project_dir(), 'tutorial', 'LLM+Langchain', 'Week-1', 'recipe_train.json'), 'r') as f:\n",
    "    recipe_train = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f81b7b-936a-4693-85d6-64ba7694cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97969ad6-95ce-49bd-8cfc-84cfb9d11173",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Creating Documents from Training Data (從訓練數據創建文檔):\n",
    "\n",
    "- An empty list documents is initialized to store instances of Document.\n",
    "- A loop iterates through each recipe in recipe_train.\n",
    "- For each recipe, a Document object is created:\n",
    "    - page_content is set to a string composed of all ingredients joined by commas.\n",
    "    - metadata includes additional information such as 'cuisine' and 'id' from the recipe.\n",
    "- Each Document instance is appended to the documents list.\n",
    "\n",
    "<br>\n",
    "\n",
    "- 初始化一個空列表 documents，用於儲存 Document 的實例。\n",
    "- 循環遍歷 recipe_train 中個每個食譜中。\n",
    "- 對於每個食譜，創建一個 Document 對象：\n",
    "    - page_content 設置為由所有食材用逗號連接而成的字符串。\n",
    "    - metadata 包含額外的信息，如食譜中的 'cuisine' 和 'id'。\n",
    "- 將每個 Document 實例追加到 documents 列表中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d6e335-a9c6-427e-840a-c2fffb19d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for recipe in recipe_train:\n",
    "    document = Document(page_content=\", \".join(recipe['ingredients']),\n",
    "                        metadata={\"cuisine\": recipe['cuisine'],\n",
    "                                  \"id\": recipe['id']})\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f734a5e1-58b2-4e0c-a294-9db0d554cdb5",
   "metadata": {},
   "source": [
    "### 3. Initializing BM25Retriever (初始化 BM25Retriever):\n",
    "\n",
    "- BM25Retriever.from_documents initializes an instance of BM25Retriever using the documents list.\n",
    "- Parameters:\n",
    "    - k=2: Specifies the number of documents to retrieve per query.\n",
    "    - bm25_params={\"k1\": 2.5}: Sets specific BM25 parameters (k1 parameter set to 2.5).\n",
    "    \n",
    "- 使用 BM25Retriever.from_documents 方法，利用 documents 列表初始化了一个 BM25Retriever 實例。\n",
    "- 參數:\n",
    "    - k=2：指定每個查詢要檢索的文檔數量。\n",
    "    - bm25_params={\"k1\": 2.5}：設置特定的 BM25 參數（設置 k1 參數為 2.5）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd5083d-1969-459f-bb6f-a968a0feaeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6565204d-9d89-4413-8f4e-22762ebd8ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(documents, k=2, \n",
    "                                              bm25_params={\"k1\":2.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8212b863-88b8-4bbd-8a3c-de6de33593c0",
   "metadata": {},
   "source": [
    "### 4. Reading Test Data:\n",
    "\n",
    "- Another JSON file named recipe_test.json is opened from the same directory.\n",
    "- The contents are loaded into a variable called recipe_test.\n",
    "\n",
    "- 從相同目錄中打開另一個名為 recipe_test.json 的 JSON 文件。\n",
    "- 將內容加載到變量 recipe_test 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4e501e-aeeb-4b77-add6-c53647b4d800",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(get_project_dir(), 'tutorial', 'LLM+Langchain', 'Week-1', 'recipe_test.json'), 'r') as f:\n",
    "    recipe_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f9eaf-609e-4f01-a91f-cdc9f910a2ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recipe_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8948b4c6-5d61-4d0c-85fa-f55f5aa6d121",
   "metadata": {},
   "source": [
    "### 5. Getting Top N Results (獲取排名前 N 的結果):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86071b0-8d64-4f9d-85d0-10a3bc5f90e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \", \".join(recipe_test[0]['ingredients'])\n",
    "\n",
    "output = bm25_retriever.invoke(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e92d03d-b699-4fb9-8267-479289a8a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968f8861-ef45-4bb6-8f7b-108ce055d98b",
   "metadata": {},
   "source": [
    "# Wikipedia Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ddbe9-374a-4f42-8a0a-e76f4d8f8409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade --quiet  wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325d56f0-bc4a-40ad-8b45-55bc24d4c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "\n",
    "wiki_retriever = WikipediaRetriever()\n",
    "\n",
    "docs = wiki_retriever.invoke(\"2024 US presidential election\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8e184a-bf82-4687-acd3-ee28ccf3890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18856c98-7918-4afd-9675-3c0e69549d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d145bd2-875d-4f0b-8bfc-1fff44c9a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 若是少於給定返回數量，則返回當前所有可得到文件\n",
    "\n",
    "docs = wiki_retriever.invoke(\"rice\")\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5414999-cb9f-4e3b-a7fe-7340b56eea84",
   "metadata": {},
   "source": [
    "- If you want to know what parameters can be feed to the WikipediaRetriever:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98333101-de37-4203-9f2f-c9a42db21473",
   "metadata": {},
   "outputs": [],
   "source": [
    "WikipediaRetriever?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d4f34-9d99-47ba-9f08-48ac5feb4a76",
   "metadata": {},
   "source": [
    "By default, wikipedia retriever returns 3 documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712d4f6f-12c5-4ef2-a92f-aec594002d76",
   "metadata": {},
   "source": [
    "# Ensemble Retriever\n",
    "\n",
    "- The EnsembleRetriever uses different search tools together to find the best answers.\n",
    "- It combines results from these tools and organizes them using a special method.\n",
    "- By using different tools, it works better than just one tool alone.\n",
    "- Usually, it mixes two types of search: one that looks for exact words (like BM25) and one that understands meanings (like embeddings).\n",
    "- This mix is called \"hybrid search.\"\n",
    "- The first tool finds documents with specific words, and the second finds documents that have similar ideas.\n",
    "\n",
    "<br>\n",
    "\n",
    "- 它結合這些工具的結果並使用特殊方法進行組織。\n",
    "- 通過使用不同的工具，它比僅使用單一工具效果更好。\n",
    "- 通常，它結合兩種類型的搜索：一種尋找精確詞語（例如 BM25），另一種理解含義（例如嵌入式）。\n",
    "- 這種混合稱為 \"混合搜索\"。\n",
    "- 第一種工具尋找具有特定詞語的文檔，而第二種工具則尋找具有相似思想的文檔。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d36f78a-b55a-4e40-ab9c-9ea2151a5c38",
   "metadata": {},
   "source": [
    "- weights: 控制權重\n",
    "- 總返回文件數量等於個別檢索器 (retriever) 檢索文件數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599b51aa-9c1b-4e4b-839f-9fb0bdac182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, wiki_retriever], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb3e2a-8efa-47a0-a682-574adbd1f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ensemble_retriever.invoke(\"rice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef0492-cf23-4c52-9685-a7860ba645e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91847b0e-ef31-45da-88da-a93888cd0093",
   "metadata": {},
   "source": [
    "- bm25_retriever 返回兩份\n",
    "- wiki_retriever 返回兩份"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33749100-3ad0-489b-882d-40a0b41232c2",
   "metadata": {},
   "source": [
    "# Runtime Configuration (運行時配置)\n",
    "\n",
    "- We can also configure the retrievers at runtime. In order to do this, we need to mark the fields as configurable\n",
    "- 我們也可以在運行時配置檢索器。為了做到這一點，我們需要將字段標記為可配置的。\n",
    "\n",
    "If this is too complicated, leave it. Someday when you are more proficient with LangChain and you need better control over your pipeline, you can come back to this. \n",
    "\n",
    "API Reference: https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.utils.ConfigurableField.htmld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2301ed88-4894-4c32-9e1c-a0291e192f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d883448-92c9-4a36-a4bd-20f73a755c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(documents, k=2, \n",
    "    bm25_params={\"k1\": 1}).configurable_fields( \\\n",
    "    k=ConfigurableField(\n",
    "        id=\"bm25_k\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f102aaad-9bf8-42a1-be3d-bc054b3c5c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, wiki_retriever], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f5977c-e120-4f36-b227-262f2add9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"bm25_k\": 5}}\n",
    "docs = ensemble_retriever.invoke(\"rice\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51851ea0-c12e-42bb-b1cf-3e57314e15ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb7982d-f1cb-4036-9317-dd7f96c5836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - bm25_retriever 返回五份\n",
    "# - wiki_retriever 返回兩份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792ac2d5-2284-426d-8894-c9aec4849a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, wiki_retriever], weights=[0.1, 0.9]\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"bm25_k\": 10}}\n",
    "docs = ensemble_retriever.invoke(\"rice\", config=config)\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c45ab-899b-4d21-9f57-7939f79fa4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - bm25_retriever 返回十份\n",
    "# - wiki_retriever 返回兩份"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b59b49-6c02-42a5-b93c-c7126ab2f2e3",
   "metadata": {},
   "source": [
    "## 作業\n",
    "\n",
    "1. 用材料搜尋食譜材料\n",
    "2. 給予某食譜材料，自動生成詳細的食譜內容\n",
    "3. 把食譜內容從英文轉換成中文\n",
    "4. 分離製作方式和使用的食材份量\n",
    "\n",
    "For example:\n",
    "\n",
    "Current ingredient: ['olive oil', 'balsamic vinegar', 'toasted pine nuts', 'kosher salt', 'golden raisins', 'part-skim ricotta cheese', 'grated parmesan cheese', 'baby spinach', 'fresh basil leaves', 'pepper', 'fusilli', 'scallions']\n",
    "\n",
    "根據Okapi25得到某一個食譜\n",
    "\n",
    "將得到的食譜轉換成詳細製作方法:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59d3efb-7466-4799-a6dc-86dfa5f2d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Based on the ingredients you have and the ingredients listed for the recipe, it seems you're aiming to create a dish that combines elements of a pasta salad with a seafood twist. The recipe ingredients suggest a lighter, seafood-focused dish, possibly a crab salad with a lemon-olive oil dressing. However, your current ingredients lean more towards a Mediterranean-inspired pasta dish. \n",
    "\n",
    "To bridge the gap between what you have and the intended recipe, here are the missing ingredients and a suggestion on how to incorporate both sets into a delightful dish:\n",
    "\n",
    "### Missing Ingredients:\n",
    "1. **Baby Greens** - You have baby spinach, which can work as a substitute, adding a similar fresh, leafy component.\n",
    "2. **Flat Leaf Parsley** - This herb would add freshness and a slight peppery note. You have fresh basil, which can provide a different but complementary herbal note.\n",
    "3. **Crabmeat** - This is a significant missing ingredient, as it's the protein component in the recipe. If you cannot obtain crabmeat, you might consider another type of seafood if you're aiming for a seafood dish, or simply focus on a vegetarian option with the ingredients at hand.\n",
    "4. **Fresh Lemon Juice** - This would add acidity and brightness to the dish. You have balsamic vinegar, which also adds acidity but with a sweeter, more complex flavor profile. While not a direct substitute, it can still contribute a pleasant tanginess.\n",
    "\n",
    "### Suggested Dish: Mediterranean Fusilli with Spinach, Pine Nuts, and Ricotta\n",
    "\n",
    "Given your current ingredients, here's a dish you could create:\n",
    "\n",
    "#### Ingredients:\n",
    "- Olive oil\n",
    "- Balsamic vinegar (in place of lemon juice for dressing)\n",
    "- Toasted pine nuts\n",
    "- Kosher salt\n",
    "- Golden raisins\n",
    "- Part-skim ricotta cheese\n",
    "- Grated parmesan cheese\n",
    "- Baby spinach (in place of baby greens)\n",
    "- Fresh basil leaves (instead of flat leaf parsley)\n",
    "- Pepper\n",
    "- Fusilli\n",
    "- Scallions\n",
    "\n",
    "#### Directions:\n",
    "1. **Cook the Fusilli:** Boil the fusilli according to package instructions until al dente. Drain and set aside to cool slightly.\n",
    "2. **Make the Dressing:** Whisk together olive oil, balsamic vinegar, salt, and pepper to taste. Adjust the balance according to your preference.\n",
    "3. **Combine the Ingredients:** In a large bowl, combine the cooked fusilli, toasted pine nuts, golden raisins, chopped scallions, torn baby spinach, and roughly chopped fresh basil leaves. If you have any other fresh vegetables or herbs you'd like to add, feel free to include them.\n",
    "4. **Add Cheese:** Fold in part-skim ricotta cheese and sprinkle grated parmesan over the top. The ricotta adds creaminess, while the parmesan brings a salty, umami depth.\n",
    "5. **Finish and Serve:** Drizzle the dressing over the salad and gently toss to combine. Serve at room temperature or chilled, as preferred.\n",
    "\n",
    "This dish takes a creative turn from the original recipe's intention but utilizes the ingredients you have to create a flavorful, satisfying meal that's perfect for a light lunch or a side dish at dinner.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
