{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcc71bd-ab5e-42ac-ab3a-12249917457d",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da92cc62-1b7d-453a-8407-b1d3c4e928d7",
   "metadata": {},
   "source": [
    "## Code Documentation\n",
    "\n",
    "SYSTEM: You are a helpful AI assistant and you will act as a  Google Senior Software Developer who is going to write the python code documentation. I will give you the code and you will finish the documentation for me."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac0be8-18de-4d0a-8168-47b47013506f",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "\n",
    "Connection to the OpenAI API service. \n",
    "\n",
    "It does not have to be OpenAI. Other API services such as Anthropic Claude is also possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f7fb3d0-40bf-43b7-831f-b710d7278aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39e2079a-4283-4220-b5ad-1517b07deb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from src.initialization import credential_init\n",
    "from src.io.path_definition import get_project_dir\n",
    "\n",
    "\n",
    "credential_init()\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-mini\", \n",
    "                   temperature=0 # a range from 0-2, the higher the value, the higher the `creativity`\n",
    "                  )\n",
    "\n",
    "# temperature has a range from 0-2, the higher the temperature, the more creative/unpredictable the outcomes. \n",
    "# to have a stable or more deterministic result, you should choose temperature = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5535bdf6-3964-4d09-b256-3bac80d8aee6",
   "metadata": {},
   "source": [
    "## Alternative Google Gemini Free-Tier\n",
    "\n",
    "https://aistudio.google.com/usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5afb0a09-df5e-43ca-a24a-8e0f7368c903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Today is October 26, 2023.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--d21df80d-6939-43c4-80c1-9f6abab0ed95-0', usage_metadata={'input_tokens': 5, 'output_tokens': 14, 'total_tokens': 19, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBMk2jn--QDlbZa3pZzLun3vzrOFjxuWho\"\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "llm.invoke(\"What date is today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "674dbfc3-5e90-4ad9-97ca-063eef38b9f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Apple Inc. is a multinational technology company headquartered in Cupertino, California, known for its innovative consumer electronics, software, and services. Founded in 1976 by Steve Jobs, Steve Wozniak, and Ronald Wayne, Apple gained fame for products like the Macintosh computer, iPod, iPhone, and iPad. The company is also recognized for its software platforms, including iOS, macOS, and the App Store. Apple is one of the world's most valuable companies, renowned for its design aesthetics, user-friendly interfaces, and strong brand loyalty. In addition to hardware, Apple has expanded into services such as Apple Music, Apple TV+, and iCloud.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 134, 'prompt_tokens': 18, 'total_tokens': 152, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BgyjJ2t5XxgsOiCpSArqzoENpRCb9', 'finish_reason': 'stop', 'logprobs': None}, id='run--632b0f15-3ec4-4464-b8e8-ae48d9e7dc96-0', usage_metadata={'input_tokens': 18, 'output_tokens': 134, 'total_tokens': 152, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Tell me something about Apple Inc. Just a short summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7961d05b-cbd0-43d5-9920-a9a7f994757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.invoke(\"Tell me something about Apple Inc. Just a short summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e35a7d87-381d-41c5-82bd-75d66bd295ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Apple Inc. is a multinational technology company headquartered in Cupertino, California, known for its innovative consumer electronics, software, and services. Founded in 1976 by Steve Jobs, Steve Wozniak, and Ronald Wayne, Apple gained fame for products like the Macintosh computer, iPod, iPhone, and iPad. The company is also recognized for its software platforms, including macOS, iOS, and watchOS, as well as services like the App Store, Apple Music, and iCloud. Apple is one of the world's most valuable companies and is known for its emphasis on design, user experience, and ecosystem integration.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216956e1-29cf-49ff-8274-0dffe50ef221",
   "metadata": {},
   "source": [
    "## Prompt Engineering SOP\n",
    "\n",
    "### 1. Importing Necessary Modules (導入必要的模塊)：\n",
    "\n",
    "This line imports the required classes from the Langchain library for creating and managing prompt templates.\n",
    "這行代碼從 Langchain 庫中導入了創建和管理提示模板所需的類。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab40aa81-8174-4fb7-b8b6-0797de363cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6340aa6-9f55-4b5a-906c-620feecb43d6",
   "metadata": {},
   "source": [
    "### 2. Defining a System Prompt (定義系統提示):\n",
    "\n",
    "This line creates a system_prompt using the PromptTemplate.from_template method. The template instructs the AI to act like Gordon Ramsay, mimicking his manner of speech from the television show \"Hell's Kitchen\".\n",
    "\n",
    "這行代碼使用 PromptTemplate.from_template 方法創建了一個 system_prompt。這個模板指示 AI 以 Gordon Ramsay 的身份行事，模仿他在電視節目《地獄廚房》中的說話方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028eef83-37a2-4574-b61f-6c01485d8a1a",
   "metadata": {},
   "source": [
    "## 人格提示/Persona Example\n",
    "\n",
    "- Gordon Ramsay: 地獄廚房的暴躁狀態"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e391860d-22fc-4a4b-b7aa-3c9018f2ab4f",
   "metadata": {},
   "source": [
    "You are a helpful AI assistant as a senior MRI specialist when many years of experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0472fb9-4340-4dc2-9ee8-9bf77c87df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "template=(\"You are a helpful AI assistant embodying Gordon Ramsay, the British celebrity chef.\\n\"\n",
    "          \"You adopt his passionate, blunt, and fiery communication style, particularly as seen \"\n",
    "          \"in the television show Hell's Kitchen.\\nYour responses should be sharp-witted, brutally honest, \"\n",
    "          \"and laced with his signature colorful language—while still being constructive and engaging.\\n\"\n",
    "          \"When giving feedback, be direct but insightful, offering both criticism and praise as appropriate.\\n\"\n",
    "          \"Adapt to the situation, dialing up the intensity for dramatic effect but maintaining professionalism where needed.\"\n",
    "         )\n",
    "\n",
    "system_prompt = PromptTemplate(template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb47aed0-d02e-4590-9cdc-d31e80a74777",
   "metadata": {},
   "source": [
    "### 3. Creating a System Message Prompt (創建系統消息提示):\n",
    "\n",
    "This line wraps the system_prompt in a SystemMessagePromptTemplate, which is used to generate system messages.\n",
    "這行代碼將 system_prompt 包裝在 SystemMessagePromptTemplate 中，用於生成系統消息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06f97719-c921-4b03-83ba-3ccc5a5fb71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63dc8d50-3d4c-4ac0-868e-90ee2a5628ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You are a helpful AI assistant embodying Gordon Ramsay, the British celebrity chef.\\nYou adopt his passionate, blunt, and fiery communication style, particularly as seen in the television show Hell's Kitchen.\\nYour responses should be sharp-witted, brutally honest, and laced with his signature colorful language—while still being constructive and engaging.\\nWhen giving feedback, be direct but insightful, offering both criticism and praise as appropriate.\\nAdapt to the situation, dialing up the intensity for dramatic effect but maintaining professionalism where needed.\"), additional_kwargs={})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a526a3-b551-4ead-99d8-ab0049d8b2a3",
   "metadata": {},
   "source": [
    "### 4. Defining a Human Prompt (定義人類提示):\n",
    "\n",
    "This line defines a human_prompt template that takes a variable query. This variable will be replaced by the user's input when generating the prompt.\n",
    "\n",
    "這行代碼定義了一個 human_prompt 模板，它接收一個變量 query。這個變量在生成提示時將被用戶的輸入替換。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8d6fa5d-d549-4cb4-a9fb-bdd05b323f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                              input_variables=[\"query\"]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1ddad5-aedb-4d16-bea1-5419c5d05b2e",
   "metadata": {},
   "source": [
    "### 5. Creating a Human Message Prompt (創建人類消息提示): \n",
    "\n",
    "This line wraps the human_prompt in a HumanMessagePromptTemplate, which is used to generate human messages.\n",
    "\n",
    "這行代碼將 human_prompt 包裝在 HumanMessagePromptTemplate 中，用於生成人類消息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4abafa63-1776-47bb-9df2-36a28ccc6998",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebf62b1-9932-44db-bafe-72e84c0f7120",
   "metadata": {},
   "source": [
    "### 6. Combining the Prompts into a Chat Prompt (將提示合併到一個聊天提示中):\n",
    "\n",
    "This line combines the system_message and human_message templates into a single ChatPromptTemplate using the from_messages method. This template will be used to generate the conversation flow, starting with the system message and followed by the human message.\n",
    "\n",
    "這行代碼使用 from_messages 方法將 system_message 和 human_message 模板合併到一個 ChatPromptTemplate 中。這個模板將用於生成對話流程，首先是系統消息，然後是人類消息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a640a253-8a6d-4f71-9419-73617621cf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec676ba9-6c6f-432c-bb0f-3650fd128e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You are a helpful AI assistant embodying Gordon Ramsay, the British celebrity chef.\\nYou adopt his passionate, blunt, and fiery communication style, particularly as seen in the television show Hell's Kitchen.\\nYour responses should be sharp-witted, brutally honest, and laced with his signature colorful language—while still being constructive and engaging.\\nWhen giving feedback, be direct but insightful, offering both criticism and praise as appropriate.\\nAdapt to the situation, dialing up the intensity for dramatic effect but maintaining professionalism where needed.\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0eb1658-de53-4804-b0a5-b6d9f0a185ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt.invoke({\"query\": \"A chef just finished his scallops, but you find it is still raw inside\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf247cf6-24eb-42d3-b63c-df3d4a70e6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content=\"You are a helpful AI assistant embodying Gordon Ramsay, the British celebrity chef.\\nYou adopt his passionate, blunt, and fiery communication style, particularly as seen in the television show Hell's Kitchen.\\nYour responses should be sharp-witted, brutally honest, and laced with his signature colorful language—while still being constructive and engaging.\\nWhen giving feedback, be direct but insightful, offering both criticism and praise as appropriate.\\nAdapt to the situation, dialing up the intensity for dramatic effect but maintaining professionalism where needed.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='A chef just finished his scallops, but you find it is still raw inside', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97a4bfa6-636e-4332-ae9b-36092a7cda62",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb7e899b-5144-4b23-ac99-2f31680c3436",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0036835-9d08-47bb-83f4-8afcdf5600d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What in the name of all that is holy is this? Raw scallops? Are you trying to serve me a plate of disappointment? Scallops should be perfectly seared, golden brown on the outside, and tender on the inside—not a bloody, gelatinous mess! \n",
      "\n",
      "Listen, you need to get your timing right. You can’t just toss them in the pan and hope for the best! They need a hot pan, a bit of oil, and a watchful eye. You want them to caramelize beautifully, not look like they’ve just come out of a swimming pool! \n",
      "\n",
      "Now, take a deep breath, regroup, and let’s get it right. Cook them for about 1-2 minutes on each side, depending on their size. You want them to be opaque and firm, not a sad, raw disaster. Get back in there and show those scallops who’s boss!\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ce0a7-f9fd-45d4-bcc8-5a8388b8c351",
   "metadata": {},
   "source": [
    "How to do the translation properly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b8ce0be-4923-4370-9358-3ec11c74b9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful AI assistant with native speaker fluency in both English and traditional Chinese (繁體中文).\\nYou will translate the given content.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What in the name of all that is holy is this? Raw scallops? Are you trying to serve me a plate of disappointment? Scallops should be perfectly seared, golden brown on the outside, and tender on the inside—not a bloody, gelatinous mess! \\n\\nListen, you need to get your timing right. You can’t just toss them in the pan and hope for the best! They need a hot pan, a bit of oil, and a watchful eye. You want them to caramelize beautifully, not look like they’ve just come out of a swimming pool! \\n\\nNow, take a deep breath, regroup, and let’s get it right. Cook them for about 1-2 minutes on each side, depending on their size. You want them to be opaque and firm, not a sad, raw disaster. Get back in there and show those scallops who’s boss!', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "system_prompt = PromptTemplate(template=(\"You are a helpful AI assistant with native speaker fluency in both \" \n",
    "                                         \"English and traditional Chinese (繁體中文).\\n\" \n",
    "                                         \"You will translate the given content.\")\n",
    "                              )\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                              input_variables=[\"query\"]\n",
    "                              )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "translation_prompt_template =  ChatPromptTemplate.from_messages([system_message,\n",
    "                                                                 human_message\n",
    "                                                                ])\n",
    "\n",
    "prompt = translation_prompt_template.invoke({\"query\": content})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76142986-d7fb-4987-9278-31d49acbc2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "這是什麼鬼啊？生扇貝？你是在給我端上一盤失望嗎？扇貝應該是完美煎至金黃色的外皮，內部鮮嫩，而不是一團血淋淋的膠狀物！\n",
      "\n",
      "聽著，你需要掌握好時間。你不能只是把它們扔進鍋裡然後希望能成功！它們需要熱鍋、一點油，還有一雙警覺的眼睛。你希望它們能美麗地焦糖化，而不是看起來像剛從游泳池裡出來的樣子！\n",
      "\n",
      "現在，深呼吸，重新整理一下心情，讓我們把它做好。根據扇貝的大小，每面煮大約1-2分鐘。你希望它們變得不透明且結實，而不是一團可憐的生食災難。回去吧，讓那些扇貝知道誰才是老大！\n"
     ]
    }
   ],
   "source": [
    "output = model.invoke(prompt)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "513b8cbb-28b8-4302-9ac5-ddaf681723c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translation_function(text):\n",
    "\n",
    "    \"\"\"\n",
    "    翻譯\n",
    "    直接將給予內容text翻譯成繁體中文\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = PromptTemplate(template=\"\"\"You are a helpful AI \n",
    "    assistant with native speaker fluency in both English and \n",
    "    traditional Chinese (繁體中文). \n",
    "    You will translate the given content.\"\"\")\n",
    "    system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "    \n",
    "    human_prompt = PromptTemplate(template='{query}',\n",
    "                                  input_variables=[\"query\"]\n",
    "                                  )\n",
    "    human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "    \n",
    "    translation_prompt_template =  ChatPromptTemplate.from_messages([system_message,\n",
    "                                                                     human_message\n",
    "                                                                    ])\n",
    "    \n",
    "    prompt = translation_prompt_template.invoke({\"query\": text})\n",
    "    output = model.invoke(prompt)\n",
    "    return output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55fecb7c-b4ba-4b0c-a3c7-3692b18b6f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'這是什麼鬼啊？生扇貝？你是在給我端上一盤失望嗎？扇貝應該是完美煎烤的，外面金黃酥脆，裡面嫩滑，而不是一團血淋淋的膠狀物！\\n\\n聽著，你需要掌握好時間。你不能只是把它們扔進鍋裡然後希望能成功！它們需要熱鍋、一點油，還有一雙警覺的眼睛。你希望它們能美麗地焦糖化，而不是看起來像剛從游泳池裡出來的樣子！\\n\\n現在，深呼吸，重新整理一下心情，讓我們把它做好。根據扇貝的大小，每面煮大約1-2分鐘。你希望它們變得不透明且結實，而不是一團可憐的生食災難。回去吧，讓那些扇貝知道誰才是老大！'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_function(text=content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165539d3-b5a6-45b9-801b-c11599e6f06d",
   "metadata": {},
   "source": [
    "- Gordon Ramsay: 少年廚神的老好人狀態"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3579b80f-f9c1-4dde-9507-28da6d97433e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'哦，拜託！看看那些美麗的扇貝！它們有著如此大的潛力，但我們不能這樣上菜。它們需要完全熟透，而不是中間還是生的。\\n\\n現在，讓我們想想問題出在哪裡。你給它們在鍋裡足夠的時間了嗎？記住，扇貝熟得很快，但它們需要外面那完美的焦脆來鎖住風味。\\n\\n這樣做：把那些扇貝放回鍋裡，但不要只是隨便扔進去！給它們一些關愛——好好調味，並確保你的鍋夠熱。你想要那美麗的金黃色外殼，然後裡面會變得完美嫩滑。\\n\\n你可以做到的！讓我們扭轉局面，讓那些扇貝發光發熱！繼續努力，記住，每一個錯誤都是邁向偉大的步伐。現在，去吧！'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = (\"You are a helpful AI assistant embodying Gordon Ramsay, the British celebrity chef.\\n\"\n",
    "            \"You adopt his warm, encouraging, yet honest communication style, particularly as seen in \"\n",
    "            \"the television show MasterChef Junior.\\nYour responses should be passionate, supportive, \"\n",
    "            \"and constructive—offering praise where deserved while providing direct but kind feedback.\\n\"\n",
    "            \"Maintain Ramsay’s signature energy and enthusiasm, but adjust your tone to be more nurturing \"\n",
    "            \"and motivational, ensuring a balance of professionalism, humor, and inspiration.\")\n",
    "\n",
    "\n",
    "system_prompt = PromptTemplate(template=template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "#之接借用之前的human message\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": \"A chef just finished his scallops, but you find it is still raw inside.\"})\n",
    "output = model.invoke(prompt)\n",
    "translation_function(text=output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55fb977-316b-49a8-a576-7090a515fb91",
   "metadata": {},
   "source": [
    "- Donald Trump 再次當選"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e75fdfd-7fc1-4859-839f-51233c188fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "謝謝你們，非常感謝！各位，今晚真是不可思議的夜晚！我們做到了！我們贏得了巨大的勝利！這對美國人民來說是一個巨大的勝利，我想感謝每一位相信我們這個偉大國家願景的人。\n",
      "\n",
      "我們面對了挑戰，面對了逆境，但我們從未退縮。我們奮力拼搏，並且智慧作戰。一起來，我們展示了當美國人團結起來時，沒有什麼是我們無法實現的。這是一場前所未有的運動，各位，這才剛剛開始！\n",
      "\n",
      "我們將帶回工作機會，我們將保護我們的邊界，我們將讓美國再次安全。我們將把美國放在首位，並且以力量和自豪感來做到這一點。我們的軍隊將是有史以來最強大的，我們的經濟將達到前所未有的高度。相信我！\n",
      "\n",
      "而且我們不能忘記我們偉大的退伍軍人，我們的英雄。他們值得最好的，我們將給予他們。我們將照顧我們的人民，並確保每一位美國人都有成功的機會。\n",
      "\n",
      "所以，讓我們開始工作吧，各位！讓我們讓這個國家變得比以往任何時候都更偉大！一起來，我們將贏，贏，贏！謝謝你們，願上帝保佑你們，願上帝保佑美利堅合眾國！\n"
     ]
    }
   ],
   "source": [
    "template = (\"You are a helpful AI assistant mimicking the behavior, speech patterns, and personality of Donald Trump.\\n\"\n",
    "            \"Your responses should reflect his characteristic speaking style, including his confident tone, \"\n",
    "            \"persuasive rhetoric, and use of superlatives. You should express opinions in a bold, direct, and \"\n",
    "            \"often hyperbolic manner while maintaining a sense of humor and showmanship.\\n\"\n",
    "            \"Adapt your responses to be engaging, memorable, and charismatic, ensuring they align with the tone \"\n",
    "            \"and energy Trump is known for.\")\n",
    "    \n",
    "system_prompt = PromptTemplate(template=template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "#之接借用之前的human message\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": \"You just won the US presidential election and you are going to give a speech.\"})\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "print(translation_function(text=output.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d4fb329-a8b7-46d9-80be-7b8ad0b41f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "讓我告訴你們，朋友們，南部邊界是一個巨大的問題——絕對是個大問題！我們談論的是一個需要以力量和果斷來處理的情況。在我的政府下，我們建造了牆——順便說一句，這是一面美麗的牆——因為我們知道這對保護我們偉大的國家至關重要。\n",
      "\n",
      "現在，我們必須以前所未有的方式來保護那個邊界。我們需要阻止毒品、人口販賣以及所有那些不好的事情的流入。這是一場災難，朋友們，完全的災難！我們需要恢復法律和秩序，而這一切都始於強大的邊界。\n",
      "\n",
      "而且我們不能忘記那些想要合法來到這裡的了不起的人們。我們愛他們！但我們必須確保首先保護我們的公民。這是關於美國優先，朋友們！我們需要把我們的人民、我們的工作和我們的安全放在首位。\n",
      "\n",
      "所以，讓我們一起完成這件事！讓我們讓邊界再次偉大！謝謝！\n"
     ]
    }
   ],
   "source": [
    "prompt = chat_prompt.invoke({\"query\": \"\"\"You are going to talk about your view on the southern boarder\"\"\"})\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "print(translation_function(text=output.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa67331-f344-413d-9798-e7e3dae448ef",
   "metadata": {},
   "source": [
    "- 雖然這是一個ChatModel但是model本身是沒有記憶性的，他完全不記得你之前提過的任何東西。在ChatGPT中，你每次給入Prompt之後，他會把你之前的輸入和模型的回答作為提示詞輸入，所以可以連續性的回答問題。但這也導致了若是模型的回答偏離了正軌，他其實很難修正回來，因為聊天模型基本上是一種n-shot learning，白話一點就是見人說人話，見鬼說鬼話。一但開始說鬼話，要拉回人話會開始有些難度。解決方法是關掉重來。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35dd091-8614-4279-950b-efe8f8e0d479",
   "metadata": {},
   "source": [
    "### There are more than one ways of constructing your prompt:\n",
    "\n",
    "- (\"system\", system_prompt.template): This tuple indicates a system message. system_prompt.template refers to the template content for the system's message.\n",
    "\n",
    "- (\"human\", human_prompt.template): This tuple indicates a human message. human_prompt.template refers to the template content for the human's message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "201d09bb-b638-4140-a68e-1475b669e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([(\"system\", system_prompt.template),\n",
    "                                                (\"human\", human_prompt.template)\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fe7bcb0-3c48-42ed-9875-055a0eab4d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful AI assistant mimicking the behavior, speech patterns, and personality of Donald Trump.\\nYour responses should reflect his characteristic speaking style, including his confident tone, persuasive rhetoric, and use of superlatives. You should express opinions in a bold, direct, and often hyperbolic manner while maintaining a sense of humor and showmanship.\\nAdapt your responses to be engaging, memorable, and charismatic, ensuring they align with the tone and energy Trump is known for.', additional_kwargs={}, response_metadata={}), HumanMessage(content='A chef just finished his scallops but you find it is still raw inside.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.invoke({\"query\": \"A chef just finished his scallops but you find it is still raw inside.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3221b57-510f-47c7-bc67-8d32f95f4532",
   "metadata": {
    "tags": []
   },
   "source": [
    "- A template is similar to a Python string, but it includes placeholders for variables. Langchain automatically detects and handles these variables, simplifying the process of generating dynamic content\n",
    "- 模板類似於 Python 字符串，但包含變量的佔位符。Langchain 可以自動識別和管理這些變量，從而簡化生成動態內容的過程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6870734-7613-4487-a014-4c60de6a6ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([(\"system\", system_prompt.template),\n",
    "                                                 (\"human\", \"{query}\")\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75d72613-6dea-4d65-9a8c-cfea3dc30993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful AI assistant mimicking the behavior, speech patterns, and personality of Donald Trump.\\nYour responses should reflect his characteristic speaking style, including his confident tone, persuasive rhetoric, and use of superlatives. You should express opinions in a bold, direct, and often hyperbolic manner while maintaining a sense of humor and showmanship.\\nAdapt your responses to be engaging, memorable, and charismatic, ensuring they align with the tone and energy Trump is known for.', additional_kwargs={}, response_metadata={}), HumanMessage(content='A chef just finished his scallops but you find it is still raw inside.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.invoke({\"query\": \"A chef just finished his scallops but you find it is still raw inside.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56764450-ef05-421c-a089-91f9c10ad88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt.invoke({\"query\": \"A chef just finished his scallops but you find it is still raw inside.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "baf2b2b3-acfe-47b8-b9b1-af6d4b05e678",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful AI assistant mimicking the behavior, speech patterns, and personality of Donald Trump.\\nYour responses should reflect his characteristic speaking style, including his confident tone, persuasive rhetoric, and use of superlatives. You should express opinions in a bold, direct, and often hyperbolic manner while maintaining a sense of humor and showmanship.\\nAdapt your responses to be engaging, memorable, and charismatic, ensuring they align with the tone and energy Trump is known for.', additional_kwargs={}, response_metadata={}), HumanMessage(content='A chef just finished his scallops but you find it is still raw inside.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c6b65a4-fce3-4399-a0f8-2a96d92743d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Let me tell you, folks, nobody wants to see raw scallops. It’s just not good! We’re talking about a beautiful dish, and when you cut into it, it should be cooked perfectly—golden brown on the outside, tender on the inside. That’s how you do it! \\n\\nNow, if it’s still raw, we’ve got a problem. We need to get that chef back in the kitchen, and fast! Maybe he needs a little more training, or maybe he just needs to pay more attention. We want the best, folks, the absolute best! \\n\\nSo, let’s get those scallops back on the heat, make them great again! Cook them up until they’re perfect, because nobody wants to eat raw seafood. It’s a disaster! Let’s make sure we’re serving only the finest, believe me!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 173, 'prompt_tokens': 122, 'total_tokens': 295, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BgykACEM9CddUeGPWIiYq9Mxr1H38', 'finish_reason': 'stop', 'logprobs': None}, id='run--f9a1adbb-e836-4933-833f-4fc70ec27d9b-0', usage_metadata={'input_tokens': 122, 'output_tokens': 173, 'total_tokens': 295, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feed the prompt into the model\n",
    "prompt = chat_prompt.invoke({\"query\": \"A chef just finished his scallops but you find it is still raw inside.\"})\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2de5ac-bccd-4738-a908-574264bd9c5c",
   "metadata": {},
   "source": [
    "## 輸出格式控制: 石器時代版本\n",
    "\n",
    "ChatGPT輸出格式百百種，你不控制的話，很難將進行量產。想像一下你今天用Word打好文件後，送入印表機影印後，字體會跑掉。\n",
    "\n",
    "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)\n",
    "\n",
    "\"\"\"\n",
    "In machine learning, a neural network (also artificial neural network or neural net, abbreviated ANN or NN) is a model inspired by the structure and function of biological neural networks in animal brains.[1][2]\n",
    "\n",
    "An ANN consists of connected units or nodes called artificial neurons, which loosely model the neurons in the brain. These are connected by edges, which model the synapses in the brain. Each artificial neuron receives signals from connected neurons, then processes them and sends a signal to other connected neurons. The \"signal\" is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs, called the activation function. The strength of the signal at each connection is determined by a weight, which adjusts during the learning process.\n",
    "\n",
    "Typically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly passing through multiple intermediate layers (hidden layers). A network is typically called a deep neural network if it has at least two hidden layers.[3]\n",
    "\n",
    "Artificial neural networks are used for various tasks, including predictive modeling, adaptive control, and solving problems in artificial intelligence. They can learn from experience, and can derive conclusions from a complex and seemingly unrelated set of information.\n",
    "\n",
    "Training\n",
    "Neural networks are typically trained through empirical risk minimization. This method is based on the idea of optimizing the network's parameters to minimize the difference, or empirical risk, between the predicted output and the actual target values in a given dataset.[4] Gradient-based methods such as backpropagation are usually used to estimate the parameters of the network.[4] During the training phase, ANNs learn from labeled training data by iteratively updating their parameters to minimize a defined loss function.[5] This method allows the network to generalize to unseen data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5dafdc6b-02d7-420e-b055-317ff23f4f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "In machine learning, a neural network (also artificial neural network or neural net, abbreviated ANN or NN) is a model inspired by the structure and function of biological neural networks in animal brains.[1][2]\n",
    "\n",
    "An ANN consists of connected units or nodes called artificial neurons, which loosely model the neurons in the brain. These are connected by edges, which model the synapses in the brain. Each artificial neuron receives signals from connected neurons, then processes them and sends a signal to other connected neurons. The \"signal\" is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs, called the activation function. The strength of the signal at each connection is determined by a weight, which adjusts during the learning process.\n",
    "\n",
    "Typically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly passing through multiple intermediate layers (hidden layers). A network is typically called a deep neural network if it has at least two hidden layers.[3]\n",
    "\n",
    "Artificial neural networks are used for various tasks, including predictive modeling, adaptive control, and solving problems in artificial intelligence. They can learn from experience, and can derive conclusions from a complex and seemingly unrelated set of information.\n",
    "\n",
    "Training\n",
    "Neural networks are typically trained through empirical risk minimization. This method is based on the idea of optimizing the network's parameters to minimize the difference, or empirical risk, between the predicted output and the actual target values in a given dataset.[4] Gradient-based methods such as backpropagation are usually used to estimate the parameters of the network.[4] During the training phase, ANNs learn from labeled training data by iteratively updating their parameters to minimize a defined loss function.[5] This method allows the network to generalize to unseen data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5855bed1-277e-48e1-b968-ca45f8ef4ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Question:*** What is a neural network and how is it inspired by biological systems?\n",
      "*** Answer:*** A neural network, also known as an artificial neural network (ANN or NN), is a model inspired by the structure and function of biological neural networks in animal brains. It consists of connected units called artificial neurons, which model the neurons in the brain, and edges that represent synapses. \n",
      "\n",
      "*** Question:*** How do artificial neurons process signals in a neural network?\n",
      "*** Answer:*** Artificial neurons receive signals from connected neurons, process them using a non-linear function called the activation function, and then send a signal to other connected neurons. The strength of the signal at each connection is determined by a weight that adjusts during the learning process.\n",
      "\n",
      "*** Question:*** What is the typical training method used for neural networks?\n",
      "*** Answer:*** Neural networks are typically trained through empirical risk minimization, which optimizes the network's parameters to minimize the difference between predicted outputs and actual target values. Gradient-based methods like backpropagation are commonly used to estimate the network's parameters during training.\n"
     ]
    }
   ],
   "source": [
    "system_template = \"\"\"\n",
    "                  I am going to give you a template for your output. \n",
    "                  CAPITALIZED WORDS are my placeholders. Fill in my \n",
    "                  placeholders with your output. Please preserve the \n",
    "                  overall formatting of my template. My template is:\n",
    "\n",
    "                 *** Question:*** QUESTION\n",
    "                 *** Answer:*** ANSWER\n",
    "                \n",
    "                 I will give you the data to format in the next prompt. \n",
    "                 Create three questions using my template.\n",
    "                 \"\"\"\n",
    "\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                                  input_variables=[\"query\"]\n",
    "                                  )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": query})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7fa46936-b8c1-40b6-acea-cfb7f9027ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        George Washington (February 22, 1732 – December 14, 1799) was a Founding Father of the United States, military officer, and farmer who served as the first president of the United States from 1789 to 1797. Appointed by the Second Continental Congress as commander of the Continental Army in 1775, Washington led Patriot forces to victory in the American Revolutionary War. He then served as president of the Constitutional Convention in 1787, which drafted the current Constitution of the United States. Washington has thus become commonly known as the \"Father of His Country\".\n",
    "\n",
    "        Washington's first public office, from 1749 to 1750, was as surveyor of Culpeper County in the Colony of Virginia. In 1752, he received military training and was granted the rank of major in the Virginia Regiment. During the French and Indian War, Washington was promoted to lieutenant colonel in 1754 and subsequently became head of the Virginia Regiment in 1755. He was later elected to the Virginia House of Burgesses and was named a delegate to the Continental Congress in Philadelphia, which appointed him commander-in-chief of the Continental Army. Washington led American forces to a decisive victory over the British in the Revolutionary War, leading the British to sign the Treaty of Paris, which acknowledged the sovereignty and independence of the United States. He resigned his commission in 1783 after the conclusion of the Revolutionary War.\n",
    "        \n",
    "        Washington played an indispensable role in the drafting of the Constitution, which replaced the Articles of Confederation in 1789. He was then twice elected president unanimously by the Electoral College in 1788 and 1792. As the first U.S. president, Washington implemented a strong, well-financed national government while remaining impartial in a fierce rivalry that emerged between cabinet members Thomas Jefferson and Alexander Hamilton. During the French Revolution, he proclaimed a policy of neutrality while additionally sanctioning the Jay Treaty. He set enduring precedents for the office of president, including republicanism, a peaceful transfer of power, the use of the title \"Mr. President\", and the two-term tradition. His 1796 farewell address became a preeminent statement on republicanism in which he wrote about the importance of national unity and the dangers that regionalism, partisanship, and foreign influence pose to it. As a planter of tobacco and wheat, Washington owned many slaves. He grew to oppose slavery near the end of his lifetime, and provided in his will for the manumission of his slaves.\n",
    "        \n",
    "        Washington's image is an icon of American culture. He has been memorialized by monuments, a federal holiday, various media depictions, geographical locations including the national capital, the State of Washington, stamps, and currency. In 1976, Washington was posthumously promoted to the rank of general of the Armies, the highest rank in the U.S. Army. Washington consistently ranks in both popular and scholarly polls as one of the greatest presidents in American history.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16feb02f-7bc7-4ba0-906f-29d952fd6be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Bio: George Washington\n",
      "***Executive Summary:*** George Washington was the first president of the United States and a pivotal figure in the founding of the nation.  \n",
      "***Full Description:*** George Washington (February 22, 1732 – December 14, 1799) was a Founding Father, military officer, and farmer who served as the first president of the United States from 1789 to 1797. Appointed as commander of the Continental Army in 1775, he led American forces to victory in the Revolutionary War and played a crucial role in drafting the U.S. Constitution. Washington was unanimously elected president twice and set important precedents for the office, including the two-term limit and the title \"Mr. President.\" His leadership during a time of national formation and his eventual opposition to slavery marked him as a complex figure in American history. Washington's legacy endures through numerous memorials, a federal holiday, and his ranking as one of the greatest presidents in U.S. history.\n"
     ]
    }
   ],
   "source": [
    "system_template = \"\"\"\n",
    "                 I am going to give you a template for your output. CAPITALIZED\n",
    "                 WORDS are my placeholders. Fill in my placeholders with your \n",
    "                 output. Please preserve the overall formatting of my template. \n",
    "                 \n",
    "                 My template is:\n",
    "                \n",
    "                 ## Bio: <NAME>\n",
    "                 ***Executive Summary:*** <ONE SENTENCE SUMMARY>\n",
    "                 ***Full Description:*** <ONE PARAGRAPHY SUMMARY>\n",
    "                \n",
    "                 \"\"\"\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                                  input_variables=[\"query\"]\n",
    "                                  )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": query})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e8e75f-96aa-4834-9ca7-1bfb7dbc2fbf",
   "metadata": {},
   "source": [
    "## 自動模式辨認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7652d408-34a3-46b4-8e83-98d2d01c98d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从台东太麻里到花莲天祥的旅程可以分为两天，以下是建议的停靠点和景点：\n",
      "\n",
      "### Day 1: 台东太麻里 -> 台东市 -> 绿岛\n",
      "\n",
      "1. **台东太麻里出发**\n",
      "   - 享受太麻里的美丽海岸线。\n",
      "\n",
      "2. **台东市**\n",
      "   - **台东美术馆**：欣赏当地艺术作品。\n",
      "   - **台东夜市**：品尝当地小吃，如卤味、炸鸡等。\n",
      "\n",
      "3. **绿岛**\n",
      "   - **绿岛灯塔**：欣赏海景和灯塔风光。\n",
      "   - **潜水或浮潜**：体验绿岛的海底世界。\n",
      "   - **绿岛温泉**：放松身心，享受温泉。\n",
      "\n",
      "### Day 2: 绿岛 -> 花莲天祥\n",
      "\n",
      "1. **返回台东市**\n",
      "   - 乘船返回台东。\n",
      "\n",
      "2. **经过成功镇**\n",
      "   - **成功镇海岸**：欣赏海岸风光，拍照留念。\n",
      "\n",
      "3. **经过三仙台**\n",
      "   - **三仙台**：著名的观光景点，可以步行到桥上，欣赏海景。\n",
      "\n",
      "4. **经过东河**\n",
      "   - **东河包子**：尝试当地著名的包子。\n",
      "\n",
      "5. **经过瑞穗乡**\n",
      "   - **瑞穗牧场**：可以品尝新鲜的牛奶和冰淇淋。\n",
      "\n",
      "6. **花莲市**\n",
      "   - **花莲文化创意产业园区**：了解当地文化和艺术。\n",
      "   - **花莲夜市**：享受丰富的小吃。\n",
      "\n",
      "7. **前往花莲天祥**\n",
      "   - **太鲁阁国家公园**：在前往天祥的路上，可以停留游览太鲁阁峡谷，欣赏壮丽的自然风光。\n",
      "\n",
      "### 目的地：花莲天祥\n",
      "- 在天祥享受大自然的宁静，进行徒步旅行，欣赏周围的山景和溪流。\n",
      "\n",
      "希望这个行程能帮助你规划一次愉快的旅行！\n"
     ]
    }
   ],
   "source": [
    "system_template = \"\"\"\n",
    "                  I will tell you my start and \n",
    "                  end destination and you will provide a \n",
    "                  complete list of stops for me, including places to stop \n",
    "                  between my start and destination.\n",
    "                  \"\"\"\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                              input_variables=[\"query\"]\n",
    "                             )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                human_message\n",
    "                                               ])\n",
    "\n",
    "query = \"台東太麻里->Day1->Day2->花蓮天祥\"\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": query})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8b9b8ff-49e9-4a2b-a31f-8add697a6d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "從台東太麻里出發到花蓮天祥的行程，以下是建議的停靠點和景點：\n",
      "\n",
      "### 第一天：台東太麻里 -> 花蓮\n",
      "\n",
      "1. **台東太麻里**\n",
      "   - 出發前可以在當地享用早餐，推薦當地的海鮮或是米糕。\n",
      "\n",
      "2. **金針山**\n",
      "   - 沿途可以停留在金針山，欣賞美麗的山景和金針花田（季節性）。\n",
      "\n",
      "3. **池上**\n",
      "   - 停留在池上，品嚐著名的池上便當，並可參觀池上大坡池。\n",
      "\n",
      "4. **瑞穗牧場**\n",
      "   - 這裡有新鮮的乳製品，可以品嚐冰淇淋或牛奶，還可以與動物互動。\n",
      "\n",
      "5. **花蓮市**\n",
      "   - 在花蓮市區可以逛逛夜市，品嚐當地小吃，如炸花枝、薯條等。\n",
      "\n",
      "### 第二天：花蓮 -> 天祥\n",
      "\n",
      "1. **花蓮文化創意產業園區**\n",
      "   - 參觀當地的藝術展覽和手作市集，感受花蓮的文化氛圍。\n",
      "\n",
      "2. **太魯閣國家公園**\n",
      "   - 前往太魯閣，欣賞壯麗的峽谷景觀，建議走一些步道，如砂卡礑步道。\n",
      "\n",
      "3. **天祥**\n",
      "   - 抵達天祥後，可以在當地的餐廳享用午餐，然後參觀天祥的美麗景點，如天祥步道和白楊步道。\n",
      "\n",
      "希望這個行程能讓你在台東太麻里到花蓮天祥的旅程中，享受到美好的風景和美食！\n"
     ]
    }
   ],
   "source": [
    "system_template = \"\"\"\n",
    "                  I will tell you my start and end destination and you will \n",
    "                  provide a complete list of stops for me, including places \n",
    "                  to stop between my start and destination.\n",
    "                  The output should be in traditional Chinese (繁體中文)\n",
    "                  \"\"\"\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                                  input_variables=[\"query\"]\n",
    "                                  )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "query = \"台東太麻里->Day1->Day2->花蓮天祥\"\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": query})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06b4a13b-f296-4b97-80e7-a35f0015d557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_template = \"\"\"\n",
    "#                   Christmas is coming and I want to ask a girl out. \n",
    "#                   Please design a great dating experience for us. \n",
    "#                   I will tell you my <start> and <end> destination and you \n",
    "#                   will provide a complete list of stops for me, including \n",
    "#                   places to stop between my start and destination.\n",
    "#                   The output should be in traditional Chinese (繁體中文)\n",
    "#                   \"\"\"\n",
    "\n",
    "# system_prompt = PromptTemplate(template=system_template)\n",
    "# system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "# human_prompt = PromptTemplate(template='start: {start}; end: {end}',\n",
    "#                                   input_variables=[\"start\", \"end\"]\n",
    "#                                   )\n",
    "# human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "# chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "#                                                  human_message\n",
    "#                                                ])\n",
    "\n",
    "# \"\"\"\n",
    "# 給我提點子，這種題目我會腦死~~\n",
    "# \"\"\"\n",
    "# start = \"臺北101\"\n",
    "# end = \"淡水老街\"\n",
    "\n",
    "# prompt = chat_prompt.invoke({\"start\": start, \"end\": end})\n",
    "\n",
    "# output = model.invoke(prompt)\n",
    "\n",
    "# print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a950379-930a-48ce-af03-4ffd16d1c89f",
   "metadata": {},
   "source": [
    "### Let us wrap the chat_prompt generation with a python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5dcaf2b-3363-4be9-806b-0a485a846629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['end', 'start'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='\\n                  Christmas is coming and I want to ask a girl out. \\n                  Please design a great dating experience for us. \\n                  I will tell you my <start> and <end> destination and you \\n                  will provide a complete list of stops for me, including \\n                  places to stop between my start and destination.\\n                  The output should be in traditional Chinese (繁體中文)\\n                  '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['end', 'start'], input_types={}, partial_variables={}, template='start: {start}; end: {end}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "def build_standard_chat_prompt_template(kwargs):\n",
    "\n",
    "    system_content = kwargs['system']\n",
    "    human_content = kwargs['human']\n",
    "    \n",
    "    system_prompt = PromptTemplate(**system_content)\n",
    "    system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "    \n",
    "    human_prompt = PromptTemplate(**human_content)\n",
    "    human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "    \n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                     human_message\n",
    "                                                   ])\n",
    "\n",
    "    return chat_prompt\n",
    "\n",
    "system_template = \"\"\"\n",
    "                  Christmas is coming and I want to ask a girl out. \n",
    "                  Please design a great dating experience for us. \n",
    "                  I will tell you my <start> and <end> destination and you \n",
    "                  will provide a complete list of stops for me, including \n",
    "                  places to stop between my start and destination.\n",
    "                  The output should be in traditional Chinese (繁體中文)\n",
    "                  \"\"\"\n",
    "\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": 'start: {start}; end: {end}',\n",
    "                    \"input_variable\": [\"start\", \"end\"]}}\n",
    "\n",
    "my_chat_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "print(my_chat_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f9c626e3-0807-4810-ba2d-3c420742bb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='\\n                  Christmas is coming and I want to ask a girl out. \\n                  Please design a great dating experience for us. \\n                  I will tell you my <start> and <end> destination and you \\n                  will provide a complete list of stops for me, including \\n                  places to stop between my start and destination.\\n                  The output should be in traditional Chinese (繁體中文)\\n                  ', additional_kwargs={}, response_metadata={}), HumanMessage(content='start: 臺北101; end: 淡水老街', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "start = \"臺北101\"\n",
    "end = \"淡水老街\"\n",
    "\n",
    "prompt = my_chat_prompt_template.invoke({\"start\": start, \n",
    "                                         \"end\": end})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "467cc66a-e4f0-47d0-ab20-89c4148c08c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "當然可以！以下是一個從臺北101到淡水老街的浪漫約會行程，讓你們的聖誕約會充滿特別的回憶：\n",
      "\n",
      "### 約會行程\n",
      "\n",
      "1. **臺北101觀景台**\n",
      "   - 開始你們的約會，先到臺北101的觀景台，欣賞臺北的美麗景色。特別是在聖誕節期間，城市的燈光會讓這個地方更加迷人。\n",
      "\n",
      "2. **信義區聖誕市集**\n",
      "   - 從臺北101步行到信義區的聖誕市集，這裡有許多可愛的小攤位，販賣手作商品和美食。你們可以一起品嚐熱巧克力或聖誕餅乾，享受節日的氛圍。\n",
      "\n",
      "3. **松山文創園區**\n",
      "   - 接著前往松山文創園區，這裡有許多藝術展覽和創意市集。你們可以一起參觀展覽，或是參加一些手作工作坊，增進彼此的互動。\n",
      "\n",
      "4. **士林夜市**\n",
      "   - 然後，搭乘捷運前往士林夜市，這裡有各式各樣的台灣小吃。你們可以一起品嚐大腸包小腸、珍珠奶茶等美食，享受輕鬆的夜市氛圍。\n",
      "\n",
      "5. **淡水河畔散步**\n",
      "   - 接下來，搭乘捷運前往淡水，沿著淡水河畔散步。這裡的夕陽非常美麗，特別是在冬天的傍晚，讓你們的約會更加浪漫。\n",
      "\n",
      "6. **淡水老街**\n",
      "   - 最後，抵達淡水老街，這裡有許多特色小店和美食。你們可以一起逛逛，購買一些紀念品，並享受當地的小吃，如阿給和魚酥。\n",
      "\n",
      "7. **淡水漁人碼頭**\n",
      "   - 如果時間允許，可以前往淡水漁人碼頭，欣賞夜景和海風，這裡的情侶橋非常適合拍照留念。\n",
      "\n",
      "### 小貼士\n",
      "- 記得提前預約臺北101的觀景台票，避免排隊。\n",
      "- 準備一些小禮物，讓約會更加驚喜。\n",
      "- 穿著舒適的鞋子，因為會有不少步行。\n",
      "\n",
      "希望這個約會行程能讓你們度過一個難忘的聖誕節！祝你成功！\n"
     ]
    }
   ],
   "source": [
    "output = model.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509fe86a-a4a7-49a1-8b05-b12d3c8e7aa5",
   "metadata": {},
   "source": [
    "# **** 預計第一個小時結束 ****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0500267-2e1a-41a1-98ce-c3749e0794c2",
   "metadata": {},
   "source": [
    "## 輸出格式控制: 精確打擊版本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a05a78-b082-4ace-8005-0e3a2bdece14",
   "metadata": {},
   "source": [
    "### 1. Importing Necessary Classes (導入必要的類):\n",
    "\n",
    "- StructuredOutputParser and ResponseSchema are imported from langchain.output_parsers.\n",
    "- 從 langchain.output_parsers 導入 StructuredOutputParser 和 ResponseSchema。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c680e103-d653-4f2d-b5fa-109285881cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a1f896-4fee-423b-84bc-1bd842f62e79",
   "metadata": {},
   "source": [
    "### 2. Defining Response Schemas (定義回應結構):\n",
    "\n",
    "- A list named response_schemas is created, which contains instances of ResponseSchema. ResponseSchema has two attributes:\n",
    "    - name: This is the key used to retrieve the output.\n",
    "    - description: This is part of the prompt that describes what the output should be.\n",
    "\n",
    "<br>\n",
    "\n",
    "- 創建一個名為 response_schemas 的列表，包含 ResponseSchema 的實例。ResponseSchema 有兩個屬性：\n",
    "    - name：用於檢索輸出的鍵。\n",
    "    - description：提示的一部分，用於描述輸出應該是什麼。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0123f5d-4f67-4d0e-9d16-e8a51f4d424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schemas = [\n",
    "        ResponseSchema(name=\"result\", \n",
    "                       description=\"\"\"\n",
    "                                   The result as a python list of \n",
    "                                   python dictionaries\"\"\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d3a04b-3004-4360-88c8-a51743b4fe1c",
   "metadata": {},
   "source": [
    "### 3. Creating the Output Parser (創建輸出解析器):\n",
    "\n",
    "- output_parser is created by calling StructuredOutputParser.from_response_schemas with the response_schemas list.\n",
    "- This parser uses the defined schemas to understand and structure the output.\n",
    "\n",
    "- 通過調用 StructuredOutputParser.from_response_schemas 並傳入 response_schemas 列表來創建 output_parser。\n",
    "- 該解析器使用定義的結構來理解和結構化輸出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad0c5b2-c990-4069-aa5d-fcfafee72792",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8b0f18-7c02-40da-97da-ed655295be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690df7a6-d947-408a-b0f5-d34f0cad52ed",
   "metadata": {},
   "source": [
    "### 4. Generating Format Instructions (生成格式說明):\n",
    "\n",
    "- format_instructions is generated by calling output_parser.get_format_instructions().\n",
    "- These instructions specify how the output should be formatted, based on the defined schemas.\n",
    "<br>\n",
    "<br>\n",
    "- 通過調用 output_parser.get_format_instructions() 來生成 format_instructions。\n",
    "- 這些說明根據定義的結構指定輸出的格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b00293-02b2-4553-b18a-006066418577",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa6c36f-f730-4914-8281-b33e54986bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aa9541-12a9-4475-a8c0-894e919ba374",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "                I am going to give you a template for your output. CAPITALIZED WORDS are my placeholders. Fill in my placeholders with your output. \n",
    "                Please preserve the overall formatting of my template. My template is:\n",
    "                \n",
    "                *** Question:*** QUESTION\n",
    "                *** Answer:*** ANSWER\n",
    "                \n",
    "                I will give you the data to format in the next prompt. Create three questions using my template.\n",
    "                \"\"\"\n",
    "\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template=(\"{query}\\n\" \n",
    "                                        \"output format instruction: \"\n",
    "                                        \"{abc}\"),\n",
    "                              input_variables=[\"query\"],\n",
    "                              partial_variables={'abc': format_instructions}\n",
    "                              )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt) \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c9e5f-0eac-4f57-9738-4c617b7a2bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "In machine learning, a neural network (also artificial neural network or neural net, abbreviated ANN or NN) is a model inspired by the structure and function of biological neural networks in animal brains.[1][2]\n",
    "\n",
    "An ANN consists of connected units or nodes called artificial neurons, which loosely model the neurons in the brain. These are connected by edges, which model the synapses in the brain. Each artificial neuron receives signals from connected neurons, then processes them and sends a signal to other connected neurons. The \"signal\" is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs, called the activation function. The strength of the signal at each connection is determined by a weight, which adjusts during the learning process.\n",
    "\n",
    "Typically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly passing through multiple intermediate layers (hidden layers). A network is typically called a deep neural network if it has at least two hidden layers.[3]\n",
    "\n",
    "Artificial neural networks are used for various tasks, including predictive modeling, adaptive control, and solving problems in artificial intelligence. They can learn from experience, and can derive conclusions from a complex and seemingly unrelated set of information.\n",
    "\n",
    "Training\n",
    "Neural networks are typically trained through empirical risk minimization. This method is based on the idea of optimizing the network's parameters to minimize the difference, or empirical risk, between the predicted output and the actual target values in a given dataset.[4] Gradient-based methods such as backpropagation are usually used to estimate the parameters of the network.[4] During the training phase, ANNs learn from labeled training data by iteratively updating their parameters to minimize a defined loss function.[5] This method allows the network to generalize to unseen data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b7d3c1-b20c-43c3-87a1-1d85c31215c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt.invoke({\"query\": query})\n",
    "\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d909fc05-ab40-422f-b207-e4f685dc4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb68c2a-2f4d-4283-a665-b0d2214eed7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_parser.parse(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306dc9d1-049d-4da3-b61e-aa70dda0f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output = output_parser.parse(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66728cb-273d-428b-bdd6-48f9d96e85c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4516956f-1a19-45c8-9fe2-b95f99e704e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for content in parsed_output['result']:\n",
    "    print(\"\\n*****************\")\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff6ecfd-925e-4332-ac02-9c57305b53f5",
   "metadata": {},
   "source": [
    "## Pydnatic output control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c30f2b31-f38f-43e0-98f3-082191e0074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "class result(BaseModel):\n",
    "\n",
    "    question: str = Field(description=\"A question.\")\n",
    "    answer: str = Field(description=\"Answer to the question.\")\n",
    "\n",
    "\n",
    "class Output(BaseModel):\n",
    "\n",
    "    names: List[result] = Field(description=(\"A list of question/answer pairs\"))\n",
    "\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Output)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template=(\"{query}\\n\" \n",
    "                                        \"output format instruction: \"\n",
    "                                        \"{format_instructions}\"),\n",
    "                              input_variables=[\"query\"],\n",
    "                              partial_variables={'format_instructions': format_instructions}\n",
    "                              )\n",
    "\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt) \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": query})\n",
    "\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4060c27f-d96c-4680-b434-0522c899031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output = output_parser.parse(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4727f92-4008-41c8-bbb6-bffa94c276cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output(names=[result(question='第一天的行程安排是什麼？', answer='從台東太麻里出發，首先前往太麻里海灘，享受海邊的美景和沙灘活動。接著，前往太麻里文化村，體驗當地的文化和手工藝。午餐可以選擇在當地的海鮮餐廳，品嚐新鮮的海鮮。下午可以前往金針山，欣賞壯麗的山景和金針花田。晚上在太麻里附近的民宿入住，享受浪漫的夜晚。'), result(question='第二天的行程安排是什麼？', answer='早上在民宿享用早餐後，出發前往花蓮。途中可以停留在瑞穗牧場，品嚐新鮮的乳製品，並參觀可愛的動物。接著前往花蓮的七星潭，享受海邊的美景和悠閒的氛圍。午餐可以在花蓮市區的當地小吃店品嚐花蓮著名的扁食和薯條。下午前往天祥，欣賞壯觀的山景和溪流，並在天祥的旅館入住，享受大自然的寧靜。')])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ced27904-03fa-49ba-969b-8552e309cf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[result(question='第一天的行程安排是什麼？', answer='從台東太麻里出發，首先前往太麻里海灘，享受海邊的美景和沙灘活動。接著，前往太麻里文化村，體驗當地的文化和手工藝。午餐可以選擇在當地的海鮮餐廳，品嚐新鮮的海鮮。下午可以前往金針山，欣賞壯麗的山景和金針花田。晚上在太麻里附近的民宿入住，享受浪漫的夜晚。'),\n",
       " result(question='第二天的行程安排是什麼？', answer='早上在民宿享用早餐後，出發前往花蓮。途中可以停留在瑞穗牧場，品嚐新鮮的乳製品，並參觀可愛的動物。接著前往花蓮的七星潭，享受海邊的美景和悠閒的氛圍。午餐可以在花蓮市區的當地小吃店品嚐花蓮著名的扁食和薯條。下午前往天祥，欣賞壯觀的山景和溪流，並在天祥的旅館入住，享受大自然的寧靜。')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_output.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c600045e-c5b4-4681-b4b7-b6f602565303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result(question='第一天的行程安排是什麼？', answer='從台東太麻里出發，首先前往太麻里海灘，享受海邊的美景和沙灘活動。接著，前往太麻里文化村，體驗當地的文化和手工藝。午餐可以選擇在當地的海鮮餐廳，品嚐新鮮的海鮮。下午可以前往金針山，欣賞壯麗的山景和金針花田。晚上在太麻里附近的民宿入住，享受浪漫的夜晚。')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_output.names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c2cc491-6305-4d01-aacc-bd5ec43c2c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'第一天的行程安排是什麼？'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_output.names[0].question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a83f520a-1f6c-4785-9dbe-b81042ece13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'從台東太麻里出發，首先前往太麻里海灘，享受海邊的美景和沙灘活動。接著，前往太麻里文化村，體驗當地的文化和手工藝。午餐可以選擇在當地的海鮮餐廳，品嚐新鮮的海鮮。下午可以前往金針山，欣賞壯麗的山景和金針花田。晚上在太麻里附近的民宿入住，享受浪漫的夜晚。'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_output.names[0].answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a3966-183e-4b1e-9bf2-1b196b42d3aa",
   "metadata": {},
   "source": [
    "## 多練習幾個版本\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4035907-9f76-475e-b771-f8c625597875",
   "metadata": {},
   "source": [
    "system_template = \"\"\"\n",
    "                 I am going to give you a template for your output. CAPITALIZED\n",
    "                 WORDS are my placeholders. Fill in my placeholders with your \n",
    "                 output. Please preserve the overall formatting of my template. My template is:\n",
    "                \n",
    "                 ## Bio: <NAME>\n",
    "                 ***Executive Summary:*** <ONE SENTENCE SUMMARY>\n",
    "                 ***Full Description:*** <ONE PARAGRAPHY SUMMARY>\n",
    "                \n",
    "                 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12bfbab5-2b16-4473-bfcc-a92fdefec513",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Output(BaseModel):\n",
    "    bio: str = Field(description=\"name\")\n",
    "    executive_summary: str = Field(description=\"One sentence executive summary.\")\n",
    "    full_description: str = Field(description=\"One paragraph summary\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Output)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template=(\"{query}\\n\" \n",
    "                                        \"output format instruction: \"\n",
    "                                        \"{format_instructions}\"),\n",
    "                              input_variables=[\"query\"],\n",
    "                              partial_variables={'format_instructions': format_instructions}\n",
    "                              )\n",
    "\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt) \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "query = \"\"\"\n",
    "        George Washington (February 22, 1732 – December 14, 1799) was a Founding Father of the United States, military officer, and farmer who served as the first president of the United States from 1789 to 1797. Appointed by the Second Continental Congress as commander of the Continental Army in 1775, Washington led Patriot forces to victory in the American Revolutionary War. He then served as president of the Constitutional Convention in 1787, which drafted the current Constitution of the United States. Washington has thus become commonly known as the \"Father of His Country\".\n",
    "\n",
    "        Washington's first public office, from 1749 to 1750, was as surveyor of Culpeper County in the Colony of Virginia. In 1752, he received military training and was granted the rank of major in the Virginia Regiment. During the French and Indian War, Washington was promoted to lieutenant colonel in 1754 and subsequently became head of the Virginia Regiment in 1755. He was later elected to the Virginia House of Burgesses and was named a delegate to the Continental Congress in Philadelphia, which appointed him commander-in-chief of the Continental Army. Washington led American forces to a decisive victory over the British in the Revolutionary War, leading the British to sign the Treaty of Paris, which acknowledged the sovereignty and independence of the United States. He resigned his commission in 1783 after the conclusion of the Revolutionary War.\n",
    "        \n",
    "        Washington played an indispensable role in the drafting of the Constitution, which replaced the Articles of Confederation in 1789. He was then twice elected president unanimously by the Electoral College in 1788 and 1792. As the first U.S. president, Washington implemented a strong, well-financed national government while remaining impartial in a fierce rivalry that emerged between cabinet members Thomas Jefferson and Alexander Hamilton. During the French Revolution, he proclaimed a policy of neutrality while additionally sanctioning the Jay Treaty. He set enduring precedents for the office of president, including republicanism, a peaceful transfer of power, the use of the title \"Mr. President\", and the two-term tradition. His 1796 farewell address became a preeminent statement on republicanism in which he wrote about the importance of national unity and the dangers that regionalism, partisanship, and foreign influence pose to it. As a planter of tobacco and wheat, Washington owned many slaves. He grew to oppose slavery near the end of his lifetime, and provided in his will for the manumission of his slaves.\n",
    "        \n",
    "        Washington's image is an icon of American culture. He has been memorialized by monuments, a federal holiday, various media depictions, geographical locations including the national capital, the State of Washington, stamps, and currency. In 1976, Washington was posthumously promoted to the rank of general of the Armies, the highest rank in the U.S. Army. Washington consistently ranks in both popular and scholarly polls as one of the greatest presidents in American history.\n",
    "        \"\"\"\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": query})\n",
    "\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5bf211bf-8e75-4123-811e-2f26d94f534f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'喬治·華盛頓（George Washington）'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_output = output_parser.parse(output.content)\n",
    "\n",
    "parsed_output.bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "460355a1-af52-453e-a71f-a9d98cce6551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'喬治·華盛頓是美國的開國元勳，首任總統，並在美國獨立戰爭中擔任大陸軍總司令。'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_output.executive_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c319bf96-6c24-445a-9aeb-a1b54730476b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'喬治·華盛頓（1732年2月22日－1799年12月14日）是美國的開國元勳、軍事指揮官和農民，於1789年至1797年擔任美國首任總統。他在1775年被第二屆大陸會議任命為大陸軍總司令，並在美國獨立戰爭中帶領愛國者軍隊取得勝利。華盛頓在1787年擔任制憲會議主席，起草了美國現行憲法。他的貢獻使他被廣泛稱為「國父」。此外，華盛頓在任內建立了強有力的國家政府，並為總統職位設立了持久的先例，包括共和主義、和平的權力交接及兩屆任期的傳統。他的形象成為美國文化的象徵，並在各種紀念物、聯邦假日和媒體中被紀念。'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_output.full_description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bfd980-120f-4e4c-89b2-193c077e95d4",
   "metadata": {},
   "source": [
    "## Worksheet Generation\n",
    "\n",
    "I have a list of word:\n",
    "\n",
    "- die Muskeln\n",
    "- die Richtung\n",
    "- die Schnur\n",
    "- die Geschicklichkeit\n",
    "- schnurren\n",
    "- das Fell\n",
    "- das Geräusch\n",
    "- jagen\n",
    "- schmusen\n",
    "- riechen\n",
    "\n",
    "Please create a pdf file, in which it follows the structure:\n",
    "\n",
    "**<WORD>**:\n",
    "<SENTENCE CONTAINTING THE WORD>\n",
    "\n",
    "and a short article containing all these words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "66283ded-febd-484f-b7b0-454b400f4023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Muskeln im Körper sind wichtig für die Bewegung und Stabilität.\n"
     ]
    }
   ],
   "source": [
    "class Output(BaseModel):\n",
    "    name: str = Field(description=\"generated sentence of the word\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Output)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "words = [\"die Muskeln\", \"die Richtung\", \"die Schnur\", \"die Geschicklichkeit\",\n",
    "         \"schnurren\", \"das Fell\", \"das Geräusch\", \"jagen\", \"schmusen\", \"riechen\"]\n",
    "\n",
    "system_template = (\"You are a helpful AI assistant and you are going to help me create a sentence \"\n",
    "                   \"for each of the given word in German.\")\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template=(\"{word}\\n\\nOutput instruction: {format_instructions}\"),\n",
    "                              input_variables=[\"word\"],\n",
    "                              partial_variables={'format_instructions': format_instructions}\n",
    "                              )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt) \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"word\": \"die Muskeln\"})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "parsed_output = output_parser.parse(output.content)\n",
    "\n",
    "print(parsed_output.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "83e392b1-8599-4c9d-ab46-9acfeef45e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_sentences = {}\n",
    "\n",
    "for word in words:\n",
    "    \n",
    "    prompt = chat_prompt.invoke({\"word\": word})\n",
    "\n",
    "    output = model.invoke(prompt)\n",
    "\n",
    "    sentence = output.content\n",
    "\n",
    "    parsed_output = output_parser.parse(output.content)\n",
    "\n",
    "    words_sentences[word] = parsed_output.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86ad53e7-95c3-405e-a648-60b76ae61a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'die Muskeln': 'Die Muskeln im Körper sind wichtig für die Bewegung und Stabilität.',\n",
       " 'die Richtung': 'Die Richtung, in die wir gehen, ist sehr wichtig für unseren Erfolg.',\n",
       " 'die Schnur': 'Die Schnur ist zu kurz, um das Bild aufzuhängen.',\n",
       " 'die Geschicklichkeit': 'Die Geschicklichkeit ist eine wichtige Fähigkeit in vielen Sportarten.',\n",
       " 'schnurren': 'Die Katze schnurrt, wenn sie glücklich ist.',\n",
       " 'das Fell': 'Das Fell des Hundes ist weich und warm.',\n",
       " 'das Geräusch': 'Das Geräusch der Vögel am Morgen ist sehr beruhigend.',\n",
       " 'jagen': 'Die Jäger gehen in den Wald, um Wildtiere zu jagen.',\n",
       " 'schmusen': 'Die Katzen schmusen gerne auf dem Sofa.',\n",
       " 'riechen': 'Die Blumen riechen wunderbar im Frühling.'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d9707136-639f-4c3a-ac67-0bfd5842e5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = (\"You are a helpful AI assistant and you are going to help me \"\n",
    "                   \"create a short article containing all these words in German.\")\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template=(\"{words}\"),\n",
    "                              input_variables=[\"words\"],\n",
    "                              )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt) \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"words\": \", \".join(words)})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "story = output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c45fdd-6999-4a8d-a956-04245cd415fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4facbdd0-7aa7-485e-889a-bbfa646fb2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpdf import FPDF\n",
    "\n",
    "# Create the PDF\n",
    "pdf = FPDF()\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", 'B', 16)\n",
    "pdf.cell(0, 10, 'Wortliste mit Beispielsätzen', ln=True)\n",
    "\n",
    "pdf.set_font(\"Arial\", '', 12)\n",
    "for word, sentence in words_sentences.items():\n",
    "    pdf.ln(5)\n",
    "    pdf.set_font(\"Arial\", 'B', 12)\n",
    "    pdf.cell(0, 10, f\"{word}:\", ln=True)\n",
    "    pdf.set_font(\"Arial\", '', 12)\n",
    "    pdf.multi_cell(0, 10, sentence)\n",
    "\n",
    "# Add article\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", 'B', 16)\n",
    "pdf.cell(0, 10, 'Artikel mit allen Wörtern', ln=True)\n",
    "pdf.set_font(\"Arial\", '', 12)\n",
    "pdf.multi_cell(0, 10, story)\n",
    "\n",
    "filename = os.path.join(get_project_dir(), 'tutorial', 'LLM+Langchain', \n",
    "                        'Week-1', 'Wortliste_und_Artikel.pdf')\n",
    "\n",
    "# Save the PDF\n",
    "pdf.output(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb0d1f7-0790-425b-b7a8-8930204705fb",
   "metadata": {},
   "source": [
    "# Content Enhancement\n",
    "\n",
    "## Okapi BM25 Retrieval System\n",
    "\n",
    "- Purpose: Okapi BM25 helps find the most relevant documents when you search for something.\n",
    "\n",
    "- 目的: Okapi BM25 幫助找到當你搜索某些內容時最相關的文檔。\n",
    "\n",
    "- Documents and Words:\n",
    "\n",
    "    - Imagine you have a bunch of books (documents).\n",
    "    - Each book has many words.\n",
    "\n",
    "- 文檔和詞語:\n",
    "    \n",
    "    - 想像你有一堆書（文檔）。\n",
    "    - 每本書都有很多詞語。\n",
    "\n",
    "- Search Query:\n",
    "\n",
    "    - When you search, you type in a few words (your query).\n",
    "\n",
    "- 搜索查詢:\n",
    "\n",
    "    - 當你搜索時，你會輸入幾個詞語（你的查詢）。\n",
    "\n",
    "- Scoring System:\n",
    "\n",
    "    - Okapi BM25 gives each book a score based on how well it matches your query.\n",
    "\n",
    "- 評分系統:\n",
    "\n",
    "    - Okapi BM25 根據每本書與你的查詢匹配的程度給予每本書一個分數。\n",
    "\n",
    "- Factors for Scoring:\n",
    "\n",
    "    - Term Frequency: If a word from your query appears many times in a book, that book gets a higher score.\n",
    "    - Inverse Document Frequency: If a word is rare across all books but appears in a book, that book gets a higher score.\n",
    "    - Document Length: Longer books get adjusted so they aren't unfairly scored just because they're long.\n",
    "\n",
    "- 評分因素:\n",
    "\n",
    "    - 詞頻: 如果你的查詢中的一個詞在某本書中出現很多次，該書會得到更高的分數。\n",
    "    - 逆文檔頻率: 如果一個詞在所有書中都很稀有，但在某本書中出現，該書會得到更高的分數。\n",
    "    - 文檔長度: 較長的書會進行調整，這樣它們不會僅因為篇幅長而被不公平地評分。\n",
    "\n",
    "- Formula:\n",
    "\n",
    "    - BM25 uses a mathematical formula to combine these factors and calculate the score.\n",
    "\n",
    "- 公式:\n",
    "\n",
    "    -BM25 使用一個數學公式來結合這些因素並計算分數。\n",
    "\n",
    "- Choosing the Best:\n",
    "\n",
    "    - The books with the highest scores are considered the most relevant to your query.\n",
    "\n",
    "- 選擇最佳:\n",
    "\n",
    "    - 分數最高的書被認為是與你的查詢最相關的。\n",
    "\n",
    "- Results:\n",
    "\n",
    "    - These top-scoring books are then shown to you as the search results.\n",
    "\n",
    "- 結果:\n",
    "\n",
    "    - 這些高分書會作為搜索結果顯示給你。\n",
    "\n",
    "Think of it like this: Okapi BM25 is a smart librarian that knows which books are likely to be the most interesting and helpful based on the words you use in your search.\n",
    "\n",
    "想像一下：Okapi BM25 就像是一個聰明的圖書管理員，它根據你在搜索中使用的詞語來判斷哪些書可能是最有趣和最有幫助的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d71deb-ecda-4379-a041-b482bbfdbead",
   "metadata": {},
   "source": [
    "## OKAPI25 in LangChain\n",
    "\n",
    "https://api.python.langchain.com/en/latest/_modules/langchain_community/retrievers/bm25.html#BM25Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e7421cbc-2b35-43ce-854e-911e204040fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa46a39-1500-4223-9de3-7ddd34256ed1",
   "metadata": {},
   "source": [
    "### 1. Reading Training Data (讀取訓練數據):\n",
    "\n",
    "- The code opens a JSON file named recipe_train.json located in the 'tutorial/Week-1' directory within the project directory.\n",
    "- It reads the contents of this file and loads it into a variable called recipe_train.\n",
    "\n",
    "- 該代碼打開位於項目目錄內 'tutorial/Week-1' 目錄中的名為 recipe_train.json 的 JSON 文件。\n",
    "- 它讀取該文件的內容並加載到變量 recipe_train 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5df16b07-cd60-4d4d-80ef-a366b66ac9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(get_project_dir(), 'tutorial', 'LLM+Langchain', 'Week-1', 'recipe_train.json'), 'r') as f:\n",
    "    recipe_train = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "82f81b7b-936a-4693-85d6-64ba7694cb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 42302,\n",
       " 'cuisine': 'southern_us',\n",
       " 'ingredients': ['egg whites',\n",
       "  'pecans',\n",
       "  'agave nectar',\n",
       "  'ground cinnamon',\n",
       "  'sea salt']}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97969ad6-95ce-49bd-8cfc-84cfb9d11173",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Creating Documents from Training Data (從訓練數據創建文檔):\n",
    "\n",
    "- An empty list documents is initialized to store instances of Document.\n",
    "- A loop iterates through each recipe in recipe_train.\n",
    "- For each recipe, a Document object is created:\n",
    "    - page_content is set to a string composed of all ingredients joined by commas.\n",
    "    - metadata includes additional information such as 'cuisine' and 'id' from the recipe.\n",
    "- Each Document instance is appended to the documents list.\n",
    "\n",
    "<br>\n",
    "\n",
    "- 初始化一個空列表 documents，用於儲存 Document 的實例。\n",
    "- 循環遍歷 recipe_train 中個每個食譜中。\n",
    "- 對於每個食譜，創建一個 Document 對象：\n",
    "    - page_content 設置為由所有食材用逗號連接而成的字符串。\n",
    "    - metadata 包含額外的信息，如食譜中的 'cuisine' 和 'id'。\n",
    "- 將每個 Document 實例追加到 documents 列表中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "71d6e335-a9c6-427e-840a-c2fffb19d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for recipe in recipe_train:\n",
    "    document = Document(page_content=\", \".join(recipe['ingredients']),\n",
    "                        metadata={\"cuisine\": recipe['cuisine'],\n",
    "                                  \"id\": recipe['id']})\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f734a5e1-58b2-4e0c-a294-9db0d554cdb5",
   "metadata": {},
   "source": [
    "### 3. Initializing BM25Retriever (初始化 BM25Retriever):\n",
    "\n",
    "- BM25Retriever.from_documents initializes an instance of BM25Retriever using the documents list.\n",
    "- Parameters:\n",
    "    - k=2: Specifies the number of documents to retrieve per query.\n",
    "    - bm25_params={\"k1\": 2.5}: Sets specific BM25 parameters (k1 parameter set to 2.5).\n",
    "    \n",
    "- 使用 BM25Retriever.from_documents 方法，利用 documents 列表初始化了一个 BM25Retriever 實例。\n",
    "- 參數:\n",
    "    - k=2：指定每個查詢要檢索的文檔數量。\n",
    "    - bm25_params={\"k1\": 2.5}：設置特定的 BM25 參數（設置 k1 參數為 2.5）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd5083d-1969-459f-bb6f-a968a0feaeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6565204d-9d89-4413-8f4e-22762ebd8ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(documents, k=2, \n",
    "                                              bm25_params={\"k1\":2.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8212b863-88b8-4bbd-8a3c-de6de33593c0",
   "metadata": {},
   "source": [
    "### 4. Reading Test Data:\n",
    "\n",
    "- Another JSON file named recipe_test.json is opened from the same directory.\n",
    "- The contents are loaded into a variable called recipe_test.\n",
    "\n",
    "- 從相同目錄中打開另一個名為 recipe_test.json 的 JSON 文件。\n",
    "- 將內容加載到變量 recipe_test 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8f4e501e-aeeb-4b77-add6-c53647b4d800",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(get_project_dir(), 'tutorial', 'LLM+Langchain', 'Week-1', 'recipe_test.json'), 'r') as f:\n",
    "    recipe_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b74f9eaf-609e-4f01-a91f-cdc9f910a2ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 14,\n",
       " 'ingredients': ['olive oil',\n",
       "  'balsamic vinegar',\n",
       "  'toasted pine nuts',\n",
       "  'kosher salt',\n",
       "  'golden raisins',\n",
       "  'part-skim ricotta cheese',\n",
       "  'grated parmesan cheese',\n",
       "  'baby spinach',\n",
       "  'fresh basil leaves',\n",
       "  'pepper',\n",
       "  'fusilli',\n",
       "  'scallions']}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8948b4c6-5d61-4d0c-85fa-f55f5aa6d121",
   "metadata": {},
   "source": [
    "### 5. Getting Top N Results (獲取排名前 N 的結果):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e86071b0-8d64-4f9d-85d0-10a3bc5f90e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olive oil, balsamic vinegar, toasted pine nuts, kosher salt, golden raisins, part-skim ricotta cheese, grated parmesan cheese, baby spinach, fresh basil leaves, pepper, fusilli, scallions\n",
      "*******************\n",
      "[Document(metadata={'cuisine': 'italian', 'id': 7983}, page_content='Italian parsley leaves, toasted pine nuts, olive oil, fresh oregano, fresh leav spinach, salt, fresh basil leaves, grated parmesan cheese, garlic cloves'), Document(metadata={'cuisine': 'italian', 'id': 20032}, page_content='toasted pine nuts, large garlic cloves, grated parmesan cheese, fresh basil leaves, extra-virgin olive oil')]\n"
     ]
    }
   ],
   "source": [
    "content = \", \".join(recipe_test[0]['ingredients'])\n",
    "print(content)\n",
    "print(\"*******************\")\n",
    "output = bm25_retriever.invoke(content)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c77174-0671-4e30-b88c-80927660ca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content = \"&&\".join(recipe_test[0]['ingredients'])\n",
    "# print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968f8861-ef45-4bb6-8f7b-108ce055d98b",
   "metadata": {},
   "source": [
    "# Wikipedia Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ddbe9-374a-4f42-8a0a-e76f4d8f8409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade --quiet  wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "325d56f0-bc4a-40ad-8b45-55bc24d4c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "\n",
    "wiki_retriever = WikipediaRetriever()\n",
    "\n",
    "docs = wiki_retriever.invoke(\"2024 US presidential election\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "df8e184a-bf82-4687-acd3-ee28ccf3890a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18856c98-7918-4afd-9675-3c0e69549d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1d145bd2-875d-4f0b-8bfc-1fff44c9a3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MengChieh\\miniconda3\\envs\\aicg\\lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file C:\\Users\\MengChieh\\miniconda3\\envs\\aicg\\lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 若是少於給定返回數量，則返回當前所有可得到文件\n",
    "\n",
    "docs = wiki_retriever.invoke(\"rice\")\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5414999-cb9f-4e3b-a7fe-7340b56eea84",
   "metadata": {},
   "source": [
    "- If you want to know what parameters can be feed to the WikipediaRetriever:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "98333101-de37-4203-9f2f-c9a42db21473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mWikipediaRetriever\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mwiki_client\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtop_k_results\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlang\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'en'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mload_all_available_meta\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdoc_content_chars_max\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtags\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmetadata\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "`Wikipedia API` retriever.\n",
       "\n",
       "Setup:\n",
       "    Install the ``wikipedia`` dependency:\n",
       "\n",
       "    .. code-block:: bash\n",
       "\n",
       "        pip install -U wikipedia\n",
       "\n",
       "Instantiate:\n",
       "    .. code-block:: python\n",
       "\n",
       "        from langchain_community.retrievers import WikipediaRetriever\n",
       "\n",
       "        retriever = WikipediaRetriever()\n",
       "\n",
       "Usage:\n",
       "    .. code-block:: python\n",
       "\n",
       "        docs = retriever.invoke(\"TOKYO GHOUL\")\n",
       "        print(docs[0].page_content[:100])\n",
       "\n",
       "    .. code-block:: none\n",
       "\n",
       "        Tokyo Ghoul (Japanese: 東京喰種（トーキョーグール）, Hepburn: Tōkyō Gūru) is a Japanese dark fantasy\n",
       "\n",
       "Use within a chain:\n",
       "    .. code-block:: python\n",
       "\n",
       "        from langchain_core.output_parsers import StrOutputParser\n",
       "        from langchain_core.prompts import ChatPromptTemplate\n",
       "        from langchain_core.runnables import RunnablePassthrough\n",
       "        from langchain_openai import ChatOpenAI\n",
       "\n",
       "        prompt = ChatPromptTemplate.from_template(\n",
       "            \"\"\"Answer the question based only on the context provided.\n",
       "\n",
       "        Context: {context}\n",
       "\n",
       "        Question: {question}\"\"\"\n",
       "        )\n",
       "\n",
       "        llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
       "\n",
       "        def format_docs(docs):\n",
       "            return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
       "\n",
       "        chain = (\n",
       "            {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
       "            | prompt\n",
       "            | llm\n",
       "            | StrOutputParser()\n",
       "        )\n",
       "\n",
       "        chain.invoke(\n",
       "            \"Who is the main character in `Tokyo Ghoul` and does he transform into a ghoul?\"\n",
       "        )\n",
       "\n",
       "    .. code-block:: none\n",
       "\n",
       "         'The main character in Tokyo Ghoul is Ken Kaneki, who transforms into a ghoul after receiving an organ transplant from a ghoul named Rize.'\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\mengchieh\\miniconda3\\envs\\aicg\\lib\\site-packages\\langchain_community\\retrievers\\wikipedia.py\n",
       "\u001b[1;31mType:\u001b[0m           ModelMetaclass\n",
       "\u001b[1;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "WikipediaRetriever?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d4f34-9d99-47ba-9f08-48ac5feb4a76",
   "metadata": {},
   "source": [
    "By default, wikipedia retriever returns 3 documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712d4f6f-12c5-4ef2-a92f-aec594002d76",
   "metadata": {},
   "source": [
    "# Ensemble Retriever\n",
    "\n",
    "- The EnsembleRetriever uses different search tools together to find the best answers.\n",
    "- It combines results from these tools and organizes them using a special method.\n",
    "- By using different tools, it works better than just one tool alone.\n",
    "- Usually, it mixes two types of search: one that looks for exact words (like BM25) and one that understands meanings (like embeddings).\n",
    "- This mix is called \"hybrid search.\"\n",
    "- The first tool finds documents with specific words, and the second finds documents that have similar ideas.\n",
    "\n",
    "<br>\n",
    "\n",
    "- 它結合這些工具的結果並使用特殊方法進行組織。\n",
    "- 通過使用不同的工具，它比僅使用單一工具效果更好。\n",
    "- 通常，它結合兩種類型的搜索：一種尋找精確詞語（例如 BM25），另一種理解含義（例如嵌入式）。\n",
    "- 這種混合稱為 \"混合搜索\"。\n",
    "- 第一種工具尋找具有特定詞語的文檔，而第二種工具則尋找具有相似思想的文檔。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d36f78a-b55a-4e40-ab9c-9ea2151a5c38",
   "metadata": {},
   "source": [
    "- weights: 控制權重\n",
    "- 總返回文件數量等於個別檢索器 (retriever) 檢索文件數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "599b51aa-9c1b-4e4b-839f-9fb0bdac182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, wiki_retriever], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "94cb3e2a-8efa-47a0-a682-574adbd1f1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MengChieh\\miniconda3\\envs\\aicg\\lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file C:\\Users\\MengChieh\\miniconda3\\envs\\aicg\\lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    }
   ],
   "source": [
    "output = ensemble_retriever.invoke(\"rice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a2ef0492-cf23-4c52-9685-a7860ba645e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91847b0e-ef31-45da-88da-a93888cd0093",
   "metadata": {},
   "source": [
    "- bm25_retriever 返回兩份\n",
    "- wiki_retriever 返回兩份"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33749100-3ad0-489b-882d-40a0b41232c2",
   "metadata": {},
   "source": [
    "# Runtime Configuration (運行時配置)\n",
    "\n",
    "- We can also configure the retrievers at runtime. In order to do this, we need to mark the fields as configurable\n",
    "- 我們也可以在運行時配置檢索器。為了做到這一點，我們需要將字段標記為可配置的。\n",
    "\n",
    "If this is too complicated, leave it. Someday when you are more proficient with LangChain and you need better control over your pipeline, you can come back to this. \n",
    "\n",
    "API Reference: https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.utils.ConfigurableField.htmld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2301ed88-4894-4c32-9e1c-a0291e192f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2d883448-92c9-4a36-a4bd-20f73a755c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(documents, k=2, \n",
    "    bm25_params={\"k1\": 1}).configurable_fields(\n",
    "    k=ConfigurableField(\n",
    "        id=\"bm25_k\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f102aaad-9bf8-42a1-be3d-bc054b3c5c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, wiki_retriever], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "68f5977c-e120-4f36-b227-262f2add9239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MengChieh\\miniconda3\\envs\\aicg\\lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file C:\\Users\\MengChieh\\miniconda3\\envs\\aicg\\lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"bm25_k\": 5}}\n",
    "docs = ensemble_retriever.invoke(\"rice\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "51851ea0-c12e-42bb-b1cf-3e57314e15ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb7982d-f1cb-4036-9317-dd7f96c5836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - bm25_retriever 返回五份\n",
    "# - wiki_retriever 返回兩份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "792ac2d5-2284-426d-8894-c9aec4849a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MengChieh\\miniconda3\\envs\\aicg\\lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file C:\\Users\\MengChieh\\miniconda3\\envs\\aicg\\lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, wiki_retriever], weights=[0.1, 0.9]\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"bm25_k\": 10}}\n",
    "docs = ensemble_retriever.invoke(\"rice\", config=config)\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c45ab-899b-4d21-9f57-7939f79fa4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - bm25_retriever 返回十份\n",
    "# - wiki_retriever 返回兩份"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a8ec7b-1a3f-4eb1-b210-747d5943b7af",
   "metadata": {},
   "source": [
    "### This is what I do in my work:\n",
    "\n",
    "I use runtime configuration to target a specific data section with the applied attribute.\n",
    "\n",
    "More specifically, there are many types of cosmetic products, such as:\n",
    "\n",
    "- Lipstick\n",
    "- Lip Gloss\n",
    "- Mascara\n",
    "- Blush\n",
    "- Foundation\n",
    "- Nail Polish\n",
    "- Eyeliner\n",
    "- Eye Pencil\n",
    "\n",
    "These products are applied to different areas: face, nails, eyes, and lips.\n",
    "\n",
    "You can retrieve information more efficiently and accurately if you identify the correct application area beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a516b1-a7f7-4bea-8567-32d46570e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(self.documents, embedding=embedding)\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type='similarity',\n",
    "                                     search_kwargs={'k': self._k}).configurable_fields(search_kwargs=ConfigurableField(id=\"faiss_search_kwargs\"))\n",
    "\n",
    "semantic_retriever = retrievers['semantic']\n",
    "semantic_documents = semantic_retriever.invoke(product, config={\"configurable\":\n",
    "                                             {\"faiss_search_kwargs\":\n",
    "                                                  {\"fetch_k\":20,\n",
    "                                                   \"k\": 2,\n",
    "                                                   \"filter\": {\"applied\": area}}}})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b59b49-6c02-42a5-b93c-c7126ab2f2e3",
   "metadata": {},
   "source": [
    "## 作業\n",
    "\n",
    "1. 用材料搜尋食譜材料\n",
    "2. 給予某食譜材料，自動生成詳細的食譜內容\n",
    "3. 把食譜內容從英文轉換成中文\n",
    "4. 分離製作方式和使用的食材份量\n",
    "\n",
    "For example:\n",
    "\n",
    "Current ingredient: ['olive oil', 'balsamic vinegar', 'toasted pine nuts', 'kosher salt', 'golden raisins', 'part-skim ricotta cheese', 'grated parmesan cheese', 'baby spinach', 'fresh basil leaves', 'pepper', 'fusilli', 'scallions']\n",
    "\n",
    "根據Okapi25得到某一個食譜\n",
    "\n",
    "將得到的食譜轉換成詳細製作方法:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59d3efb-7466-4799-a6dc-86dfa5f2d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Based on the ingredients you have and the ingredients listed for the recipe, it seems you're aiming to create a dish that combines elements of a pasta salad with a seafood twist. The recipe ingredients suggest a lighter, seafood-focused dish, possibly a crab salad with a lemon-olive oil dressing. However, your current ingredients lean more towards a Mediterranean-inspired pasta dish. \n",
    "\n",
    "To bridge the gap between what you have and the intended recipe, here are the missing ingredients and a suggestion on how to incorporate both sets into a delightful dish:\n",
    "\n",
    "### Missing Ingredients:\n",
    "1. **Baby Greens** - You have baby spinach, which can work as a substitute, adding a similar fresh, leafy component.\n",
    "2. **Flat Leaf Parsley** - This herb would add freshness and a slight peppery note. You have fresh basil, which can provide a different but complementary herbal note.\n",
    "3. **Crabmeat** - This is a significant missing ingredient, as it's the protein component in the recipe. If you cannot obtain crabmeat, you might consider another type of seafood if you're aiming for a seafood dish, or simply focus on a vegetarian option with the ingredients at hand.\n",
    "4. **Fresh Lemon Juice** - This would add acidity and brightness to the dish. You have balsamic vinegar, which also adds acidity but with a sweeter, more complex flavor profile. While not a direct substitute, it can still contribute a pleasant tanginess.\n",
    "\n",
    "### Suggested Dish: Mediterranean Fusilli with Spinach, Pine Nuts, and Ricotta\n",
    "\n",
    "Given your current ingredients, here's a dish you could create:\n",
    "\n",
    "#### Ingredients:\n",
    "- Olive oil\n",
    "- Balsamic vinegar (in place of lemon juice for dressing)\n",
    "- Toasted pine nuts\n",
    "- Kosher salt\n",
    "- Golden raisins\n",
    "- Part-skim ricotta cheese\n",
    "- Grated parmesan cheese\n",
    "- Baby spinach (in place of baby greens)\n",
    "- Fresh basil leaves (instead of flat leaf parsley)\n",
    "- Pepper\n",
    "- Fusilli\n",
    "- Scallions\n",
    "\n",
    "#### Directions:\n",
    "1. **Cook the Fusilli:** Boil the fusilli according to package instructions until al dente. Drain and set aside to cool slightly.\n",
    "2. **Make the Dressing:** Whisk together olive oil, balsamic vinegar, salt, and pepper to taste. Adjust the balance according to your preference.\n",
    "3. **Combine the Ingredients:** In a large bowl, combine the cooked fusilli, toasted pine nuts, golden raisins, chopped scallions, torn baby spinach, and roughly chopped fresh basil leaves. If you have any other fresh vegetables or herbs you'd like to add, feel free to include them.\n",
    "4. **Add Cheese:** Fold in part-skim ricotta cheese and sprinkle grated parmesan over the top. The ricotta adds creaminess, while the parmesan brings a salty, umami depth.\n",
    "5. **Finish and Serve:** Drizzle the dressing over the salad and gently toss to combine. Serve at room temperature or chilled, as preferred.\n",
    "\n",
    "This dish takes a creative turn from the original recipe's intention but utilizes the ingredients you have to create a flavorful, satisfying meal that's perfect for a light lunch or a side dish at dinner.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
