{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eba170e4-c7b5-44fb-b02b-20bfda2475ee",
   "metadata": {},
   "source": [
    "# ğŸ“š Week 1ï¼šLLM + LangChain å…¥é–€æ•™å­¸\n",
    "\n",
    "æ­¡è¿ä¾†åˆ°æœ¬é€±èª²ç¨‹ï¼æœ¬å–®å…ƒå°‡å¸¶ä½ å¾é›¶é–‹å§‹äº†è§£å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åŸºæœ¬æ¦‚å¿µï¼Œä¸¦å¯¦éš›é«”é©—å¦‚ä½•é‹ç”¨ LangChain æ¡†æ¶æ•´åˆ AI èƒ½åŠ›ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b090c47-ef06-4fb1-b8ac-42cf71058e2d",
   "metadata": {},
   "source": [
    "# èª²ç¨‹æœŸæœ›æ§åˆ¶<a name='èª²ç¨‹æœŸæœ›æ§åˆ¶'></a>\n",
    "\n",
    "1. å»ºç«‹åŸºæœ¬æ¦‚å¿µï¼Œä¸å¿…æˆç‚ºç¨‹å¼é«˜æ‰‹\n",
    "\n",
    "    - å³ä½¿ä½ æœªä¾†ä¸æ‰“ç®—å¯«ç¨‹å¼ï¼Œä¹Ÿè‡³å°‘èƒ½å° LLMï¼ˆå¤§å‹èªè¨€æ¨¡å‹ï¼‰æœ‰ä¸€å€‹ç›´è¦ºæ€§çš„ç†è§£ï¼š\n",
    "\n",
    "2. ä»€éº¼ä»»å‹™æ˜¯ AI å¯ä»¥å¹«ä½ å®Œæˆçš„\n",
    "\n",
    "    - ä»€éº¼ Proposal æˆ–å·¥å…·è²ç¨±èƒ½åšçš„äº‹æƒ…å…¶å¯¦æ˜¯èª‡å¤§çš„ã€ç”šè‡³æ˜¯é¨™äººçš„\n",
    "\n",
    "3. èª²ç¨‹ä¸å¯èƒ½æ¶µè“‹æ‰€æœ‰éœ€æ±‚\n",
    "\n",
    "    - æ¯å€‹äººçš„å·¥ä½œå ´æ™¯ã€éœ€æ±‚å’Œç›®æ¨™éƒ½ä¸åŒï¼Œæœ¬èª²ç¨‹æä¾›çš„æ˜¯é€šç”¨åŸºç¤èˆ‡æ€ç¶­æ–¹å¼ï¼Œä¸èƒ½æ¶µè“‹æ‰€æœ‰å°ˆæ¥­æˆ–å•†æ¥­ç´°ç¯€\n",
    "\n",
    "4. ç¸®çŸ­æŠ€è¡“èˆ‡å•†æ¥­æºé€šçš„è½å·®\n",
    "\n",
    "    - è®“ä½ åœ¨èˆ‡å·¥ç¨‹å¸«ã€AI åœ˜éšŠæˆ–é¡§å•è¨è«–æ™‚ï¼Œä¸æœƒå®Œå…¨è½ä¸æ‡‚ï¼Œä¹Ÿæ›´å®¹æ˜“åˆ¤æ–·å“ªäº›ææ¡ˆåˆç†ã€å“ªäº›éœ€è¦è¿½å•\n",
    "\n",
    "5. å…¥é–€ç‚ºä¸»ï¼Œå¯¦ä¾‹ç‚ºè¼”\n",
    "\n",
    "    - æœ¬èª²ç¨‹å®šä½æ˜¯å…¥é–€ï¼Œä½†æˆ‘æœƒç›¡é‡æä¾›å¯¦éš›ä¾‹å­ã€å ´æ™¯å’Œæ“ä½œæ¼”ç¤ºï¼Œå¹«åŠ©ä½ æŠŠæ¦‚å¿µã€Œè½åœ°ã€ï¼Œæ–¹ä¾¿æœªä¾†å¯¦éš›æ‡‰ç”¨\n",
    "  \n",
    "# å­¸ç¿’å¿ƒæ…‹æç¤º\n",
    "\n",
    "1. ä¸è¦è¿½æ±‚å®Œç¾\n",
    "    - LLM å’Œ AI çš„ä¸–ç•Œç¬æ¯è¬è®Šï¼Œä»Šå¤©çœ‹åˆ°çš„æ¡ˆä¾‹ï¼Œæ˜å¤©å¯èƒ½å°±æ›´æ–°äº†ã€‚é‡è¦çš„æ˜¯ç†è§£æ¦‚å¿µå’Œæ€è·¯ï¼Œè€Œä¸æ˜¯ä¸€æ¬¡å°±æŒæ¡æ‰€æœ‰ç´°ç¯€ã€‚\n",
    "\n",
    "2. å‹‡æ–¼å˜—è©¦ï¼Œæ•¢æ–¼çŠ¯éŒ¯\n",
    "   - AI å¾ˆåƒä¸€å€‹å¼·å¤§çš„åŠ©æ‰‹ï¼Œæ“ä½œå®ƒçš„éç¨‹æœ¬èº«å°±æ˜¯å­¸ç¿’ã€‚éŒ¯èª¤å’Œæ„å¤–çµæœéƒ½æ˜¯æœ€å¥½çš„è€å¸«ã€‚\n",
    "\n",
    "3. ä¿æŒå¥½å¥‡å¿ƒ\n",
    "    - ä¸ç®¡ä½ çš„å°ˆæ¥­èƒŒæ™¯æ˜¯ä»€éº¼ï¼Œå° AI çš„æ¢ç´¢éƒ½èƒ½çµ¦ä½ å¸¶ä¾†æ–°çš„è¦–è§’ã€‚å¤šå•ã€Œç‚ºä»€éº¼å¯ä»¥é€™æ¨£åšï¼Ÿã€æ¯”å–®ç´”è¨˜ä½æ“ä½œæ›´é‡è¦ã€‚\n",
    "\n",
    "4. æ¦‚å¿µå…ˆè¡Œï¼ŒæŠ€è¡“å…¶æ¬¡\n",
    "    - ä¸å¿…æ“”å¿ƒè‡ªå·±ä¸æœƒå¯«ç¨‹å¼ï¼Œç†è§£ AI å¯ä»¥åšä»€éº¼ã€ä¸èƒ½åšä»€éº¼ï¼Œä»¥åŠå®ƒçš„å±€é™ï¼Œæ¯”æŒæ¡æ‰€æœ‰ç´°ç¯€æ›´å¯¦ç”¨ã€‚\n",
    "\n",
    "5. äº’å‹•å’Œåˆ†äº«\n",
    "    - èª²å ‚ä¸Šä½ çš„ç–‘å•å¾ˆå¯èƒ½ä¹Ÿå›°æ“¾å…¶ä»–äººï¼Œä¸æ‡‚å°±å•ï¼Œåˆ†äº«ä½ çš„è§€å¯Ÿå’Œæƒ³æ³•ï¼Œé€™æ¯”è¢«å‹•è½èª²æ›´èƒ½åŠ æ·±ç†è§£ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e8a6e5-5c0b-4860-a894-dd3560547813",
   "metadata": {},
   "source": [
    "# ç’°å¢ƒè¨­ç½®\n",
    "\n",
    "1. conda create -n aicg python=3.10\n",
    "2. conda activate aicg\n",
    "3. pip install -r requirements.txt\n",
    "4. jupyter lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac0be8-18de-4d0a-8168-47b47013506f",
   "metadata": {},
   "source": [
    "# LangChain æ¡†æ¶ä»‹ç´¹\n",
    "\n",
    "> ğŸ¯ **æœ¬ç« å­¸å®Œä½ å°‡èƒ½å­¸æœƒä»€éº¼ï¼š**\n",
    "> - ç†è§£ LangChain çš„æ ¸å¿ƒçµ„ä»¶èˆ‡æ¨¡çµ„åŒ–è¨­è¨ˆç†å¿µ  \n",
    "> - å­¸æœƒä½¿ç”¨ LLMã€PromptTemplateã€Chain ç­‰é—œéµæ¨¡çµ„  \n",
    "> - èƒ½å¤ çµ„è£ç°¡å–®çš„ AI å·¥ä½œæµç¨‹ï¼ˆä¾‹å¦‚å•ç­”ã€æ‘˜è¦æˆ–å°è©±ç³»çµ±ï¼‰  \n",
    "\n",
    "ä¸»æµå¤§èªè¨€æ¨¡å‹çš„æ‡‰ç”¨æ¡†æ¶\n",
    "\n",
    "1. Modular Abstractions\n",
    "\n",
    "    - Provides building blocks (LLM wrappers, prompts, memory, chains, agents) so you donâ€™t reinvent patterns.\n",
    "  \n",
    "    - Helps organize projects in a scalable way instead of ad-hoc scripts.\n",
    "\n",
    "2. Integrations & Ecosystem\n",
    "\n",
    "    - Supports many LLM providers (OpenAI, Anthropic, local models, etc.) and vector databases (Pinecone, Weaviate, FAISS, etc.).\n",
    "\n",
    "    - Makes it easy to swap components without rewriting large parts of code.\n",
    "\n",
    "3. Rapid Prototyping\n",
    "\n",
    "    - Good for quickly validating ideas: retrieval-augmented generation (RAG), tool use, or multi-step workflows.\n",
    "\n",
    "    - Reduces boilerplate, so you can focus on application logic and user experience.\n",
    "\n",
    "4. Community & Best Practices\n",
    "\n",
    "    - Large developer community and ecosystem of templates.\n",
    "\n",
    "    - Keeps pace with new techniques (e.g., function calling, agents, structured output).\n",
    "\n",
    "5. Production-Readiness (with caveats)\n",
    "\n",
    "    - LangChain Expression Language (LCEL) improves reproducibility and debugging.\n",
    "\n",
    "    - Can be integrated with observability tools, tracing, and monitoring.\n",
    "\n",
    "    - While early versions were criticized for complexity, the newer iterations emphasize stability and clearer abstractions.\n",
    "\n",
    "6. Learning & Industry Alignment\n",
    "\n",
    "    - Because itâ€™s widely adopted, using LangChain means your skills and prototypes are transferable and recognized across teams and organizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9eaa9f-3005-4c31-915c-5a209fd41b8d",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ§© LangChain æ¡†æ¶çµæ§‹åœ–\n",
    "LangChain æ˜¯ç”¨ä¾†ã€Œæ¨¡çµ„åŒ–çµ„è£ AI æµç¨‹ã€çš„é–‹æºæ¡†æ¶ã€‚  \n",
    "å®ƒè®“ä½ èƒ½æŠŠè¤‡é›œçš„ LLM æ“ä½œåˆ†è§£æˆå¯é‡è¤‡ä½¿ç”¨çš„ç©æœ¨ï¼ˆmodulesï¼‰ã€‚\n",
    "\n",
    "**åŸºæœ¬çµ„ä»¶åŒ…å«ï¼š**\n",
    "\n",
    "| æ¨¡çµ„åç¨± | åŠŸèƒ½èªªæ˜ | ç¯„ä¾‹ |\n",
    "|-----------|------------|------|\n",
    "| `LLM` | èªè¨€æ¨¡å‹æ ¸å¿ƒ | GPT-4ã€Gemini ç­‰ |\n",
    "| `PromptTemplate` | ç®¡ç†æç¤ºèªï¼ˆPromptï¼‰æ¨¡æ¿ | çµ±ä¸€è¼¸å…¥æ ¼å¼ |\n",
    "| `Chain` | ä¸²æ¥å¤šå€‹æ­¥é©Ÿå½¢æˆæµç¨‹ | å•ç­” â†’ æ‘˜è¦ |\n",
    "| `Memory` | ä¿å­˜ä¸Šä¸‹æ–‡å°è©± | èŠå¤©è¨˜éŒ„ |\n",
    "| `Tool` | å‘¼å«å¤–éƒ¨åŠŸèƒ½ï¼ˆæœå°‹ã€ç¨‹å¼åŸ·è¡Œç­‰ï¼‰ | Google Searchã€Python |\n",
    "| `Agent` | å…·å‚™æ±ºç­–é‚è¼¯çš„ AI åŸ·è¡Œè€… | è‡ªå‹•é¸æ“‡å·¥å…·å®Œæˆä»»å‹™ |\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ§  **LangChain æ¦‚å¿µæµç¨‹åœ–**\n",
    "\n",
    "```text\n",
    "ä½¿ç”¨è€… â†’ PromptTemplate â†’ LLM â†’ OutputParser â†’ Chain / Agent â†’ å›å‚³çµæœ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644d2688-9efc-46a7-a8b8-458c26093256",
   "metadata": {},
   "source": [
    "# èª¿å‹•å¤§èªè¨€æ¨¡å‹API\n",
    "\n",
    "## OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7fb3d0-40bf-43b7-831f-b710d7278aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e2079a-4283-4220-b5ad-1517b07deb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "from textwrap import dedent\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from src.initialization import credential_init\n",
    "from src.io.path_definition import get_project_dir\n",
    "\n",
    "\n",
    "credential_init()\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-mini\", \n",
    "                   temperature=0 # a range from 0-2, the higher the value, the higher the `creativity`\n",
    "                  )\n",
    "\n",
    "# temperature has a range from 0-2, the higher the temperature, the more creative/unpredictable the outcomes. \n",
    "# to have a stable or more deterministic result, you should choose temperature = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5535bdf6-3964-4d09-b256-3bac80d8aee6",
   "metadata": {},
   "source": [
    "## Gemini API<a name=\"Gemini\"></a>\n",
    "\n",
    "- https://aistudio.google.com/usage\n",
    "- å…è²»æ˜¯æœ‰ä»£åƒ¹çš„: å…§å®¹æœƒè¢«ç”¨åšè¨“ç·´æ•¸æ“šï¼Œæ‰€ä»¥åˆ¥ä¸Šå‚³å€‹äººçš„è³‡æ–™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afb0a09-df5e-43ca-a24a-8e0f7368c903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"<YOUR GOOGLE API KEY>\"\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fa7a35-573b-4c8f-97fb-7456a6ed0784",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = llm.invoke(\"What date is today?\")\n",
    "    print(\"âœ… æˆåŠŸå‘¼å«æ¨¡å‹ï¼š\", response.content)\n",
    "except Exception as e:\n",
    "    print(\"âš ï¸ éŒ¯èª¤ï¼šç„¡æ³•å‘¼å« OpenAI APIï¼Œè«‹ç¢ºèªä»¥ä¸‹é …ç›®ï¼š\")\n",
    "    print(\"1ï¸âƒ£ æ˜¯å¦å·²è¨­å®šç’°å¢ƒè®Šæ•¸ OPENAI_API_KEY\")\n",
    "    print(\"2ï¸âƒ£ æ˜¯å¦æœ‰ç¶²è·¯é€£ç·š\")\n",
    "    print(\"3ï¸âƒ£ æ¨¡å‹åç¨±æ˜¯å¦æ­£ç¢º\")\n",
    "    print(\"è©³ç´°éŒ¯èª¤è¨Šæ¯ï¼š\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d421f33e-aaa9-41bf-8686-c6f225305c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = model.invoke(\"Tell me something about Apple Inc. Just a short summary\")\n",
    "    print(\"âœ… æˆåŠŸå‘¼å«æ¨¡å‹ï¼š\", response.content)\n",
    "except Exception as e:\n",
    "    print(\"âš ï¸ éŒ¯èª¤ï¼šç„¡æ³•å‘¼å« OpenAI APIï¼Œè«‹ç¢ºèªä»¥ä¸‹é …ç›®ï¼š\")\n",
    "    print(\"1ï¸âƒ£ æ˜¯å¦å·²è¨­å®šç’°å¢ƒè®Šæ•¸ OPENAI_API_KEY\")\n",
    "    print(\"2ï¸âƒ£ æ˜¯å¦æœ‰ç¶²è·¯é€£ç·š\")\n",
    "    print(\"3ï¸âƒ£ æ¨¡å‹åç¨±æ˜¯å¦æ­£ç¢º\")\n",
    "    print(\"è©³ç´°éŒ¯èª¤è¨Šæ¯ï¼š\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2169de37-3480-402d-9b70-ac0a0400c692",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ğŸ”„ **å¾ Prompt åˆ° LangChain**\n",
    ">\n",
    "> åœ¨å‰ä¸€ç« ä¸­ï¼Œæˆ‘å€‘å­¸æœƒå¦‚ä½•èˆ‡ LLM å°è©±ï¼›  \n",
    "> è€Œæ¥ä¸‹ä¾†çš„ LangChainï¼Œå‰‡å¹«åŠ©æˆ‘å€‘ã€Œæ¨¡çµ„åŒ–ã€é€™äº›å°è©±é‚è¼¯ã€‚  \n",
    ">  \n",
    "> å¦‚æœèªª Prompt æ˜¯ã€ŒAI çš„ä¸€å¥è©±ã€ï¼Œé‚£ LangChain å°±æ˜¯ã€Œçµ„æˆ AI ç³»çµ±çš„èªæ³•çµæ§‹ã€ã€‚  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216956e1-29cf-49ff-8274-0dffe50ef221",
   "metadata": {},
   "source": [
    "# æç¤ºè©å·¥ç¨‹\n",
    "\n",
    "> ğŸ¯ **æœ¬ç« å­¸å®Œä½ å°‡èƒ½å­¸æœƒä»€éº¼ï¼š**\n",
    "> - ç†è§£ä»€éº¼æ˜¯ Promptï¼ˆæç¤ºè©ï¼‰åŠå…¶åœ¨å¤§å‹èªè¨€æ¨¡å‹ä¸­çš„è§’è‰²  \n",
    "> - å­¸æœƒè¨­è¨ˆå…·é«”ã€æœ‰è§’è‰²åŒ–ä¸”ç›®æ¨™æ˜ç¢ºçš„ Prompt  \n",
    "> - å¯¦éš›æ“ä½œ LangChain çš„ `PromptTemplate`ã€`ChatPromptTemplate` ä¸¦æ¸¬è©¦ä¸åŒæç¤ºæ•ˆæœ  \n",
    "\n",
    "\n",
    "æ‰€è¬‚ã€ŒPromptã€ï¼Œå°±æ˜¯ä½ çµ¦ AI çš„ã€ŒæŒ‡ä»¤å¥ã€ã€‚  \n",
    "æƒ³åƒä½ åœ¨è·ŸåŠ©ç†å°è©± â€”â€” ä½ æ€éº¼å•ï¼ŒAI å°±æ€éº¼ç­”ã€‚  \n",
    "å­¸æœƒè¨­è¨ˆå¥½çš„ promptï¼Œå°±èƒ½è®“æ¨¡å‹æ›´æ‡‚ä½ ã€è¼¸å‡ºæ›´æº–ç¢ºï¼\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ“Œ **ç°¡å–®ä¾‹å­ï¼š**\n",
    "| Prompt | æ¨¡å‹å›è¦† |\n",
    "|--------|-----------|\n",
    "| ã€Œå¯«ä¸€é¦–è©©ã€ | è¼¸å‡ºéš¨æ©Ÿè©©å¥ |\n",
    "| ã€Œç”¨èå£«æ¯”äºé¢¨æ ¼å¯«ä¸€é¦–é—œæ–¼ç¨‹å¼å“¡çš„è©©ã€ | è¼¸å‡ºæ–‡å­¸é¢¨æ ¼æ˜é¡¯çš„è©© |\n",
    "\n",
    "> ğŸ’¬ æç¤ºè¨­è¨ˆçš„æ ¸å¿ƒæ˜¯ã€Œå…·é«”ã€è§’è‰²åŒ–ã€æœ‰ç›®æ¨™ã€ã€‚\n",
    "\n",
    "## 1. Importing Necessary Modules (å°å…¥å¿…è¦çš„æ¨¡å¡Š)ï¼š\n",
    "\n",
    "é€™è¡Œä»£ç¢¼å¾ Langchain åº«ä¸­å°å…¥äº†å‰µå»ºå’Œç®¡ç†æç¤ºæ¨¡æ¿æ‰€éœ€çš„é¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab40aa81-8174-4fb7-b8b6-0797de363cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6340aa6-9f55-4b5a-906c-620feecb43d6",
   "metadata": {},
   "source": [
    "## 2. å®šç¾©ç³»çµ±æç¤º:\n",
    "\n",
    "é€™è¡Œä»£ç¢¼ä½¿ç”¨ PromptTemplate.from_template æ–¹æ³•å‰µå»ºäº†ä¸€å€‹ system_promptã€‚é€™å€‹æ¨¡æ¿æŒ‡ç¤º AI ä»¥ Gordon Ramsay çš„èº«ä»½è¡Œäº‹ï¼Œæ¨¡ä»¿ä»–åœ¨é›»è¦–ç¯€ç›®ã€Šåœ°ç„å»šæˆ¿ã€‹ä¸­çš„èªªè©±æ–¹å¼ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028eef83-37a2-4574-b61f-6c01485d8a1a",
   "metadata": {},
   "source": [
    "## äººæ ¼æç¤º\n",
    "\n",
    "- Gordon Ramsay: åœ°ç„å»šæˆ¿çš„æš´èºç‹€æ…‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0472fb9-4340-4dc2-9ee8-9bf77c87df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "template=dedent(\"\"\"\n",
    "You are a helpful AI assistant embodying Gordon Ramsay, the British celebrity chef.\n",
    "You adopt his passionate, blunt, and fiery communication style, particularly as seen \n",
    "in the television show Hell's Kitchen.\\nYour responses should be sharp-witted, brutally honest,\n",
    "and laced with his signature colorful languageâ€”while still being constructive and engaging.\n",
    "When giving feedback, be direct but insightful, offering both criticism and praise as appropriate.\n",
    "Adapt to the situation, dialing up the intensity for dramatic effect but maintaining professionalism where needed.\n",
    "\"\"\")\n",
    "\n",
    "system_prompt = PromptTemplate(template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb47aed0-d02e-4590-9cdc-d31e80a74777",
   "metadata": {},
   "source": [
    "## 3. å‰µå»ºç³»çµ±æ¶ˆæ¯æç¤º:\n",
    "\n",
    "é€™è¡Œä»£ç¢¼å°‡ system_prompt åŒ…è£åœ¨ SystemMessagePromptTemplate ä¸­ï¼Œç”¨æ–¼ç”Ÿæˆç³»çµ±æ¶ˆæ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f97719-c921-4b03-83ba-3ccc5a5fb71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dc8d50-3d4c-4ac0-868e-90ee2a5628ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a526a3-b551-4ead-99d8-ab0049d8b2a3",
   "metadata": {},
   "source": [
    "## 4. å®šç¾©äººé¡æç¤º:\n",
    "\n",
    "é€™è¡Œä»£ç¢¼å®šç¾©äº†ä¸€å€‹ human_prompt æ¨¡æ¿ï¼Œå®ƒæ¥æ”¶ä¸€å€‹è®Šé‡ queryã€‚é€™å€‹è®Šé‡åœ¨ç”Ÿæˆæç¤ºæ™‚å°‡è¢«ç”¨æˆ¶çš„è¼¸å…¥æ›¿æ›ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d6fa5d-d549-4cb4-a9fb-bdd05b323f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                              input_variables=[\"query\"]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1ddad5-aedb-4d16-bea1-5419c5d05b2e",
   "metadata": {},
   "source": [
    "## 5. å‰µå»ºäººé¡æ¶ˆæ¯æç¤º: \n",
    "\n",
    "é€™è¡Œä»£ç¢¼å°‡ human_prompt åŒ…è£åœ¨ HumanMessagePromptTemplate ä¸­ï¼Œç”¨æ–¼ç”Ÿæˆäººé¡æ¶ˆæ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abafa63-1776-47bb-9df2-36a28ccc6998",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebf62b1-9932-44db-bafe-72e84c0f7120",
   "metadata": {},
   "source": [
    "## 6. å°‡æç¤ºåˆä½µ:\n",
    "\n",
    "é€™è¡Œä»£ç¢¼ä½¿ç”¨ from_messages æ–¹æ³•å°‡ system_message å’Œ human_message æ¨¡æ¿åˆä½µåˆ°ä¸€å€‹ ChatPromptTemplate ä¸­ã€‚é€™å€‹æ¨¡æ¿å°‡ç”¨æ–¼ç”Ÿæˆå°è©±æµç¨‹ï¼Œé¦–å…ˆæ˜¯ç³»çµ±æ¶ˆæ¯ï¼Œç„¶å¾Œæ˜¯äººé¡æ¶ˆæ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a640a253-8a6d-4f71-9419-73617621cf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec676ba9-6c6f-432c-bb0f-3650fd128e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb1658-de53-4804-b0a5-b6d9f0a185ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹ä¸€å€‹å®Œæ•´çš„ ChatPromptTemplateï¼Œä¸¦ä»¥äººé¡è¼¸å…¥ï¼ˆqueryï¼‰ç”Ÿæˆæç¤º\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": \"A chef just finished his scallops, but you find it is still raw inside\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf247cf6-24eb-42d3-b63c-df3d4a70e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a4bfa6-636e-4332-ae9b-36092a7cda62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°‡ç”Ÿæˆçš„ prompt ä¸Ÿå…¥æ¨¡å‹åŸ·è¡Œï¼Œé æœŸè¼¸å‡ºä¸€æ®µæ¨¡æ“¬ Gordon Ramsay é¢¨æ ¼çš„å›è¦†\n",
    "\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7e899b-5144-4b23-ac99-2f31680c3436",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0036835-9d08-47bb-83f4-8afcdf5600d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ce0a7-f9fd-45d4-bcc8-5a8388b8c351",
   "metadata": {},
   "source": [
    "How to do the translation properly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ce0be-4923-4370-9358-3ec11c74b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = PromptTemplate(template=(\"You are a helpful AI assistant with native speaker fluency in both \" \n",
    "                                         \"English and traditional Chinese (ç¹é«”ä¸­æ–‡).\\n\" \n",
    "                                         \"You will translate the given content.\")\n",
    "                              )\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                              input_variables=[\"query\"]\n",
    "                              )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "translation_prompt_template =  ChatPromptTemplate.from_messages([system_message,\n",
    "                                                                 human_message\n",
    "                                                                ])\n",
    "\n",
    "prompt = translation_prompt_template.invoke({\"query\": content})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76142986-d7fb-4987-9278-31d49acbc2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.invoke(prompt)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165539d3-b5a6-45b9-801b-c11599e6f06d",
   "metadata": {},
   "source": [
    "- Gordon Ramsay: å°‘å¹´å»šç¥çš„è€å¥½äººç‹€æ…‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3579b80f-f9c1-4dde-9507-28da6d97433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = dedent(\"\"\"\n",
    "You are a helpful AI assistant embodying Gordon Ramsay, the British celebrity chef.\n",
    "You adopt his warm, encouraging, yet honest communication style, particularly as seen in \n",
    "the television show MasterChef Junior.\\nYour responses should be passionate, supportive,\n",
    "and constructiveâ€”offering praise where deserved while providing direct but kind feedback.\n",
    "Maintain Ramsayâ€™s signature energy and enthusiasm, but adjust your tone to be more nurturing \n",
    "and motivational, ensuring a balance of professionalism, humor, and inspiration.\"\"\")\n",
    "\n",
    "\n",
    "system_prompt = PromptTemplate(template=template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "#ä¹‹æ¥å€Ÿç”¨ä¹‹å‰çš„human message\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": \"A chef just finished his scallops, but you find it is still raw inside.\"})\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384631a8-6b05-4a04-91c3-3a34cef4d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = translation_prompt_template.invoke({\"query\": output.content})\n",
    "output = model.invoke(prompt)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55fb977-316b-49a8-a576-7090a515fb91",
   "metadata": {},
   "source": [
    "- Donald Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e75fdfd-7fc1-4859-839f-51233c188fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = dedent(\"\"\"\n",
    "You are a helpful AI assistant mimicking the behavior, speech patterns, and personality of Donald Trump.\n",
    "Your responses should reflect his characteristic speaking style, including his confident tone,\n",
    "persuasive rhetoric, and use of superlatives. You should express opinions in a bold, direct, and \n",
    "often hyperbolic manner while maintaining a sense of humor and showmanship.\n",
    "Adapt your responses to be engaging, memorable, and charismatic, ensuring they align with the tone\n",
    "and energy Trump is known for.\n",
    "\"\"\")\n",
    "    \n",
    "system_prompt = PromptTemplate(template=template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "#ä¹‹æ¥å€Ÿç”¨ä¹‹å‰çš„human message\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": \"You just won the US presidential election and you are going to give a speech.\"})\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4fb329-a8b7-46d9-80be-7b8ad0b41f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt.invoke({\"query\": \"\"\"You are going to talk about your view on the southern boarder\"\"\"})\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa67331-f344-413d-9798-e7e3dae448ef",
   "metadata": {},
   "source": [
    "- é›–ç„¶é€™æ˜¯ä¸€å€‹ChatModelä½†æ˜¯modelæœ¬èº«æ˜¯æ²’æœ‰è¨˜æ†¶æ€§çš„ï¼Œä»–å®Œå…¨ä¸è¨˜å¾—ä½ ä¹‹å‰æéçš„ä»»ä½•æ±è¥¿ã€‚åœ¨ChatGPTä¸­ï¼Œä½ æ¯æ¬¡çµ¦å…¥Promptä¹‹å¾Œï¼Œä»–æœƒæŠŠä½ ä¹‹å‰çš„è¼¸å…¥å’Œæ¨¡å‹çš„å›ç­”ä½œç‚ºæç¤ºè©è¼¸å…¥ï¼Œæ‰€ä»¥å¯ä»¥é€£çºŒæ€§çš„å›ç­”å•é¡Œã€‚ä½†é€™ä¹Ÿå°è‡´äº†è‹¥æ˜¯æ¨¡å‹çš„å›ç­”åé›¢äº†æ­£è»Œï¼Œä»–å…¶å¯¦å¾ˆé›£ä¿®æ­£å›ä¾†ï¼Œå› ç‚ºèŠå¤©æ¨¡å‹åŸºæœ¬ä¸Šæ˜¯ä¸€ç¨®n-shot learningï¼Œç™½è©±ä¸€é»å°±æ˜¯è¦‹äººèªªäººè©±ï¼Œè¦‹é¬¼èªªé¬¼è©±ã€‚ä¸€ä½†é–‹å§‹èªªé¬¼è©±ï¼Œè¦æ‹‰å›äººè©±æœƒé–‹å§‹æœ‰äº›é›£åº¦ã€‚è§£æ±ºæ–¹æ³•æ˜¯é—œæ‰é‡ä¾†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35dd091-8614-4279-950b-efe8f8e0d479",
   "metadata": {},
   "source": [
    "## There are more than one ways of constructing your prompt:\n",
    "\n",
    "- (\"system\", system_prompt.template): This tuple indicates a system message. system_prompt.template refers to the template content for the system's message.\n",
    "\n",
    "- (\"human\", human_prompt.template): This tuple indicates a human message. human_prompt.template refers to the template content for the human's message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201d09bb-b638-4140-a68e-1475b669e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template = ChatPromptTemplate.from_messages([(\"system\", system_prompt.template),\n",
    "                                                (\"human\", human_prompt.template)\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe7bcb0-3c48-42ed-9875-055a0eab4d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template.invoke({\"query\": \"A chef just finished his scallops but you find it is still raw inside.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3221b57-510f-47c7-bc67-8d32f95f4532",
   "metadata": {
    "tags": []
   },
   "source": [
    "- æ¨¡æ¿(template)é¡ä¼¼æ–¼ Python å­—ç¬¦ä¸²ï¼Œä½†åŒ…å«è®Šé‡çš„ä½”ä½ç¬¦ã€‚Langchain å¯ä»¥è‡ªå‹•è­˜åˆ¥å’Œç®¡ç†é€™äº›è®Šé‡ï¼Œå¾è€Œç°¡åŒ–ç”Ÿæˆå‹•æ…‹å…§å®¹çš„éç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6870734-7613-4487-a014-4c60de6a6ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template = ChatPromptTemplate.from_messages([(\"system\", system_prompt.template),\n",
    "                                                 (\"human\", \"{query}\")\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d72613-6dea-4d65-9a8c-cfea3dc30993",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template.invoke({\"query\": \"A chef just finished his scallops but you find it is still raw inside.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56764450-ef05-421c-a089-91f9c10ad88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt_template.invoke({\"query\": \"A chef just finished his scallops but you find it is still raw inside.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf2b2b3-acfe-47b8-b9b1-af6d4b05e678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b65a4-fce3-4399-a0f8-2a96d92743d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed the prompt into the model\n",
    "prompt = chat_prompt_template.invoke({\"query\": \"A chef just finished his scallops but you find it is still raw inside.\"})\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e174aa8e-db2c-4f28-afb3-98aa0e13d659",
   "metadata": {},
   "source": [
    "## ğŸ“˜ æœ¬ç« é‡é»æ•´ç†\n",
    "- Prompt çš„å“è³ªæœƒç›´æ¥å½±éŸ¿æ¨¡å‹çš„è¼¸å‡ºçµæœ  \n",
    "- ç³»çµ±æç¤ºï¼ˆSystem Messageï¼‰å¯è¨­å®šè§’è‰²èˆ‡è¡Œç‚º  \n",
    "- LangChain æä¾›å¤šå±¤æŠ½è±¡ï¼šPrompt â†’ Chain â†’ Agent  \n",
    "- å–„ç”¨æ¨¡æ¿å¯è®“æç¤ºè©çµæ§‹åŒ–èˆ‡å¯é‡è¤‡ä½¿ç”¨ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2be55e-ab49-42df-86bf-c5805f5e1512",
   "metadata": {},
   "source": [
    "# è‡ªå‹•æ¨¡å¼è¾¨èª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7cb170-e4d7-4337-bae5-3c4da74c60da",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = dedent(\"\"\"\n",
    "                  I will tell you my start and end destination and you will \n",
    "                  provide a complete list of stops for me, including places \n",
    "                  to stop between my start and destination.\n",
    "                  The output should be in traditional Chinese (ç¹é«”ä¸­æ–‡)\n",
    "                  \"\"\")\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                                  input_variables=[\"query\"]\n",
    "                                  )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "query = \"å°æ±å¤ªéº»é‡Œ->Day1->Day2->èŠ±è“®å¤©ç¥¥\"\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": query})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2de5ac-bccd-4738-a908-574264bd9c5c",
   "metadata": {},
   "source": [
    "# è¼¸å‡ºæ ¼å¼æ§åˆ¶\n",
    "\n",
    "> ğŸ§  **ç‚ºä»€éº¼è¦æ§åˆ¶è¼¸å‡ºæ ¼å¼ï¼Ÿ**\n",
    ">\n",
    "> åœ¨é–‹ç™¼ AI æ‡‰ç”¨ï¼ˆç‰¹åˆ¥æ˜¯å•†æ¥­æˆ–è‡ªå‹•åŒ–å ´æ™¯ï¼‰æ™‚ï¼Œæ¨¡å‹çš„è¼¸å‡ºè‹¥ç„¡çµ±ä¸€çµæ§‹ï¼Œå°‡é›£ä»¥è¢«å¾ŒçºŒç¨‹å¼è™•ç†ã€‚\n",
    ">  \n",
    "> èˆ‰ä¾‹ä¾†èªªï¼š\n",
    "> - è‹¥è¦å°‡å›ç­”çµæœè‡ªå‹•å¯«å…¥ Excelã€è³‡æ–™åº«ã€æˆ–å ±è¡¨ç³»çµ±ï¼Œå°±å¿…é ˆç¢ºä¿è¼¸å‡ºæ ¼å¼å›ºå®šã€‚\n",
    "> - è‹¥æ¨¡å‹è‡ªç”±ç™¼æ®ï¼Œå¯èƒ½æœƒç”¢ç”Ÿç„¡æ³•è§£æçš„è‡ªç„¶èªè¨€ï¼Œå°è‡´æµç¨‹ä¸­æ–·ã€‚\n",
    ">\n",
    "> å› æ­¤ï¼Œæˆ‘å€‘æœƒé€é **Prompt æ¨¡æ¿ + çµæ§‹åŒ–è§£æå™¨ï¼ˆå¦‚ Pydanticï¼‰**ï¼Œå¼·åˆ¶æ¨¡å‹æŒ‰ç…§æŒ‡å®šæ ¼å¼è¼¸å‡ºå…§å®¹ã€‚\n",
    "\n",
    "## çŸ³å™¨æ™‚ä»£ç‰ˆæœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2e35e4-de78-4b74-a411-02780fc84676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wikipedia-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06857e42-304c-44b8-b0d9-b947b8190d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "wiki_wiki = wikipediaapi.Wikipedia(user_agent='AI Tutorial(mengchiehling@gmail.com)', language='zh-tw')\n",
    "\n",
    "ayoung_wiki = wiki_wiki.page(\"æé›…è‹±\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4088ded-60da-45cc-9369-2137c6174dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ayoung_wiki.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5855bed1-277e-48e1-b968-ca45f8ef4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = dedent(\"\"\"\n",
    "                  I am going to give you a template for your output. \n",
    "                  CAPITALIZED WORDS are my placeholders. Fill in my \n",
    "                  placeholders with your output. Please preserve the \n",
    "                  overall formatting of my template. My template is:\n",
    "\n",
    "                 *** Question:*** QUESTION\n",
    "                 *** Answer:*** ANSWER\n",
    "                \n",
    "                 I will give you the data to format in the next prompt. \n",
    "                 Create three questions using my template.\n",
    "                 \"\"\")\n",
    "\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                                  input_variables=[\"query\"]\n",
    "                                  )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": ayoung_wiki.text})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16feb02f-7bc7-4ba0-906f-29d952fd6be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = dedent(\"\"\"\n",
    "                 I am going to give you a template for your output. CAPITALIZED\n",
    "                 WORDS are my placeholders. Fill in my placeholders with your \n",
    "                 output. Please preserve the overall formatting of my template. \n",
    "                 \n",
    "                 My template is:\n",
    "                \n",
    "                 ## Bio: <NAME>\n",
    "                 ***Executive Summary:*** <ONE SENTENCE SUMMARY>\n",
    "                 ***Full Description:*** <ONE PARAGRAPHY SUMMARY>\n",
    "                \n",
    "                 \"\"\")\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                                  input_variables=[\"query\"]\n",
    "                                  )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": ayoung_wiki.text})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e8e75f-96aa-4834-9ca7-1bfb7dbc2fbf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7652d408-34a3-46b4-8e83-98d2d01c98d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = dedent(\"\"\"\n",
    "                  I will tell you my start and \n",
    "                  end destination and you will provide a \n",
    "                  complete list of stops for me, including places to stop \n",
    "                  between my start and destination.\n",
    "                  \"\"\")\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                              input_variables=[\"query\"]\n",
    "                             )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                human_message\n",
    "                                               ])\n",
    "\n",
    "query = \"å°æ±å¤ªéº»é‡Œ->Day1->Day2->èŠ±è“®å¤©ç¥¥\"\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": query})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a950379-930a-48ce-af03-4ffd16d1c89f",
   "metadata": {},
   "source": [
    "æœƒå¤§é‡é‡è¤‡çš„åŠŸèƒ½å¯ä»¥ç›´æ¥æ‰“åŒ…æˆä¸€å€‹å‡½æ•¸ï¼Œæ–¹ä¾¿ä¹‹å¾Œä½¿ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dcaf2b-3363-4be9-806b-0a485a846629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_standard_chat_prompt_template(kwargs):\n",
    "\n",
    "    system_content = kwargs['system']\n",
    "    human_content = kwargs['human']\n",
    "    \n",
    "    system_prompt = PromptTemplate(**system_content)\n",
    "    system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "    \n",
    "    human_prompt = PromptTemplate(**human_content)\n",
    "    human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "    \n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                     human_message\n",
    "                                                   ])\n",
    "\n",
    "    return chat_prompt\n",
    "\n",
    "system_template = dedent(\"\"\"\n",
    "                  Christmas is coming and I want to ask a girl out. \n",
    "                  Please design a great dating experience for us. \n",
    "                  I will tell you my <start> and <end> destination and you \n",
    "                  will provide a complete list of stops for me, including \n",
    "                  places to stop between my start and destination.\n",
    "                  The output should be in traditional Chinese (ç¹é«”ä¸­æ–‡)\n",
    "                  \"\"\")\n",
    "\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": 'start: {start}; end: {end}',\n",
    "                    \"input_variable\": [\"start\", \"end\"]}}\n",
    "\n",
    "my_chat_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "print(my_chat_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c626e3-0807-4810-ba2d-3c420742bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = \"è‡ºåŒ—101\"\n",
    "end = \"æ·¡æ°´è€è¡—\"\n",
    "\n",
    "prompt = my_chat_prompt_template.invoke({\"start\": start, \n",
    "                                         \"end\": end})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467cc66a-e4f0-47d0-ab20-89c4148c08c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0500267-2e1a-41a1-98ce-c3749e0794c2",
   "metadata": {},
   "source": [
    "## ResponseSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a05a78-b082-4ace-8005-0e3a2bdece14",
   "metadata": {},
   "source": [
    "### 1. å°å…¥å¿…è¦çš„é¡:\n",
    "\n",
    "- StructuredOutputParser and ResponseSchema are imported from langchain.output_parsers.\n",
    "- å¾ langchain.output_parsers å°å…¥ StructuredOutputParser å’Œ ResponseSchemaã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c680e103-d653-4f2d-b5fa-109285881cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a1f896-4fee-423b-84bc-1bd842f62e79",
   "metadata": {},
   "source": [
    "### 2. å®šç¾©å›æ‡‰çµæ§‹:\n",
    "\n",
    "- A list named response_schemas is created, which contains instances of ResponseSchema. ResponseSchema has two attributes:\n",
    "    - name: This is the key used to retrieve the output.\n",
    "    - description: This is part of the prompt that describes what the output should be.\n",
    "\n",
    "<br>\n",
    "\n",
    "- å‰µå»ºä¸€å€‹åç‚º response_schemas çš„åˆ—è¡¨ï¼ŒåŒ…å« ResponseSchema çš„å¯¦ä¾‹ã€‚ResponseSchema æœ‰å…©å€‹å±¬æ€§ï¼š\n",
    "    - nameï¼šç”¨æ–¼æª¢ç´¢è¼¸å‡ºçš„éµã€‚\n",
    "    - descriptionï¼šæç¤ºçš„ä¸€éƒ¨åˆ†ï¼Œç”¨æ–¼æè¿°è¼¸å‡ºæ‡‰è©²æ˜¯ä»€éº¼ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0123f5d-4f67-4d0e-9d16-e8a51f4d424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schemas = [\n",
    "        ResponseSchema(name=\"result\", \n",
    "                       description=dedent(\"\"\"\n",
    "                                   The result as a python list of \n",
    "                                   python dictionaries\"\"\"))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d3a04b-3004-4360-88c8-a51743b4fe1c",
   "metadata": {},
   "source": [
    "### 3. å‰µå»ºè¼¸å‡ºè§£æå™¨:\n",
    "\n",
    "- output_parser is created by calling StructuredOutputParser.from_response_schemas with the response_schemas list.\n",
    "- This parser uses the defined schemas to understand and structure the output.\n",
    "\n",
    "- é€šéèª¿ç”¨ StructuredOutputParser.from_response_schemas ä¸¦å‚³å…¥ response_schemas åˆ—è¡¨ä¾†å‰µå»º output_parserã€‚\n",
    "- è©²è§£æå™¨ä½¿ç”¨å®šç¾©çš„çµæ§‹ä¾†ç†è§£å’Œçµæ§‹åŒ–è¼¸å‡ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad0c5b2-c990-4069-aa5d-fcfafee72792",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8b0f18-7c02-40da-97da-ed655295be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690df7a6-d947-408a-b0f5-d34f0cad52ed",
   "metadata": {},
   "source": [
    "### 4. ç”Ÿæˆæ ¼å¼èªªæ˜:\n",
    "\n",
    "- format_instructions is generated by calling output_parser.get_format_instructions().\n",
    "- These instructions specify how the output should be formatted, based on the defined schemas.\n",
    "<br>\n",
    "<br>\n",
    "- é€šéèª¿ç”¨ output_parser.get_format_instructions() ä¾†ç”Ÿæˆ format_instructionsã€‚\n",
    "- é€™äº›èªªæ˜æ ¹æ“šå®šç¾©çš„çµæ§‹æŒ‡å®šè¼¸å‡ºçš„æ ¼å¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b00293-02b2-4553-b18a-006066418577",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa6c36f-f730-4914-8281-b33e54986bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aa9541-12a9-4475-a8c0-894e919ba374",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = dedent(\"\"\"\n",
    "                I am going to give you a template for your output. CAPITALIZED WORDS are my placeholders. Fill in my placeholders with your output. \n",
    "                Please preserve the overall formatting of my template. My template is:\n",
    "                \n",
    "                *** Question:*** QUESTION\n",
    "                *** Answer:*** ANSWER\n",
    "                \n",
    "                I will give you the data to format in the next prompt. Create three questions using my template.\n",
    "                \"\"\")\n",
    "\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template=dedent(\"\"\"\n",
    "                                        {query}\\n \n",
    "                                        output format instruction: {abc}\n",
    "                                        \"\"\"),\n",
    "                              input_variables=[\"query\"],\n",
    "                              partial_variables={'abc': format_instructions}\n",
    "                              )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt) \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c9e5f-0eac-4f57-9738-4c617b7a2bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ayoung_wiki.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b7d3c1-b20c-43c3-87a1-1d85c31215c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt.invoke({\"query\": query})\n",
    "\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d909fc05-ab40-422f-b207-e4f685dc4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb68c2a-2f4d-4283-a665-b0d2214eed7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_parser.parse(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306dc9d1-049d-4da3-b61e-aa70dda0f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output = output_parser.parse(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66728cb-273d-428b-bdd6-48f9d96e85c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4516956f-1a19-45c8-9fe2-b95f99e704e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for content in parsed_output['result']:\n",
    "    print(\"\\n*****************\")\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff6ecfd-925e-4332-ac02-9c57305b53f5",
   "metadata": {},
   "source": [
    "## Pydantic\n",
    "\n",
    "é€™å¯èƒ½æ˜¯ä¸»æµçš„æ ¼å¼è¼¸å‡ºæ–¹å¼ï¼ŒåŒ…æ‹¬OpenAI Agent SDKä¹Ÿæ˜¯å¯ä»¥ä½¿ç”¨é€™ç¨®æ ¼å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30f2b31-f38f-43e0-98f3-082191e0074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "class result(BaseModel):\n",
    "\n",
    "    question: str = Field(description=\"A question.\")\n",
    "    answer: str = Field(description=\"Answer to the question.\")\n",
    "\n",
    "\n",
    "class Output(BaseModel):\n",
    "\n",
    "    names: List[result] = Field(description=(\"A list of question/answer pairs\"))\n",
    "\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Output)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template=dedent(\"\"\"\n",
    "                                        {query}\\n \n",
    "                                        output format instruction:\n",
    "                                        {abc}\n",
    "                                        \"\"\"),\n",
    "                              input_variables=[\"query\"],\n",
    "                              partial_variables={'abc': format_instructions}\n",
    "                              )\n",
    "\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt) \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": ayoung_wiki.text})\n",
    "\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4060c27f-d96c-4680-b434-0522c899031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output = output_parser.parse(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4727f92-4008-41c8-bbb6-bffa94c276cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced27904-03fa-49ba-969b-8552e309cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600045e-c5b4-4681-b4b7-b6f602565303",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output.names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2cc491-6305-4d01-aacc-bd5ec43c2c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output.names[0].question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83f520a-1f6c-4785-9dbe-b81042ece13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output.names[0].answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a3966-183e-4b1e-9bf2-1b196b42d3aa",
   "metadata": {},
   "source": [
    "## å¤šç·´ç¿’å¹¾å€‹ç‰ˆæœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bfbab5-2b16-4473-bfcc-a92fdefec513",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Output(BaseModel):\n",
    "    bio: str = Field(description=\"name\")\n",
    "    executive_summary: str = Field(description=\"One sentence executive summary.\")\n",
    "    full_description: str = Field(description=\"One paragraph summary\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Output)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "system_template = dedent(\"\"\"\n",
    "                 I am going to give you a template for your output. CAPITALIZED\n",
    "                 WORDS are my placeholders. Fill in my placeholders with your \n",
    "                 output. Please preserve the overall formatting of my template. \n",
    "                 \n",
    "                 My template is:\n",
    "                \n",
    "                 ## Bio: <NAME>\n",
    "                 ***Executive Summary:*** <ONE SENTENCE SUMMARY>\n",
    "                 ***Full Description:*** <ONE PARAGRAPHY SUMMARY>\n",
    "                \n",
    "                 \"\"\")\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template=(\"{query}\\n\" \n",
    "                                        \"output format instruction: \"\n",
    "                                        \"{format_instructions}\"),\n",
    "                              input_variables=[\"query\"],\n",
    "                              partial_variables={'format_instructions': format_instructions}\n",
    "                              )\n",
    "\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt) \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": ayoung_wiki.text})\n",
    "\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5463a61e-bdf4-4026-8163-f2f65b4caf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf211bf-8e75-4123-811e-2f26d94f534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output = output_parser.parse(output.content)\n",
    "\n",
    "parsed_output.bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460355a1-af52-453e-a71f-a9d98cce6551",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output.executive_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c319bf96-6c24-445a-9aeb-a1b54730476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output.full_description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bfd980-120f-4e4c-89b2-193c077e95d4",
   "metadata": {},
   "source": [
    "## ç·´ç¿’é¡Œç”Ÿæˆ\n",
    "\n",
    "å°æ™‚å€™å¤§å®¶çš„ä½œæ¥­æ‡‰è©²éƒ½æœ‰é€ å¥é€™ç¨®ï¼Œå¦‚ä½•è®“é›»è…¦å¿«é€Ÿç”Ÿæˆç·´ç¿’ç”¨çš„é€ å¥?\n",
    "\n",
    "I have a list of word:\n",
    "\n",
    "- die Muskeln\n",
    "- die Richtung\n",
    "- die Schnur\n",
    "- die Geschicklichkeit\n",
    "- schnurren\n",
    "- das Fell\n",
    "- das GerÃ¤usch\n",
    "- jagen\n",
    "- schmusen\n",
    "- riechen\n",
    "\n",
    "Please create a pdf file, in which it follows the structure:\n",
    "\n",
    "**<WORD>**:\n",
    "<SENTENCE CONTAINTING THE WORD>\n",
    "\n",
    "and a short article containing all these words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66283ded-febd-484f-b7b0-454b400f4023",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Output(BaseModel):\n",
    "    name: str = Field(description=\"generated sentence of the word\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Output)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "words = [\"die Muskeln\", \"die Richtung\", \"die Schnur\", \"die Geschicklichkeit\",\n",
    "         \"schnurren\", \"das Fell\", \"das GerÃ¤usch\", \"jagen\", \"schmusen\", \"riechen\"]\n",
    "\n",
    "system_template = (\"You are a helpful AI assistant and you are going to help me create a sentence \"\n",
    "                   \"for each of the given word in German.\")\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template=(\"{word}\\n\\nOutput instruction: {format_instructions}\"),\n",
    "                              input_variables=[\"word\"],\n",
    "                              partial_variables={'format_instructions': format_instructions}\n",
    "                              )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt) \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"word\": \"die Muskeln\"})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "parsed_output = output_parser.parse(output.content)\n",
    "\n",
    "print(parsed_output.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e392b1-8599-4c9d-ab46-9acfeef45e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_sentences = {}\n",
    "\n",
    "for word in words:\n",
    "    \n",
    "    prompt = chat_prompt.invoke({\"word\": word})\n",
    "\n",
    "    output = model.invoke(prompt)\n",
    "\n",
    "    sentence = output.content\n",
    "\n",
    "    parsed_output = output_parser.parse(output.content)\n",
    "\n",
    "    words_sentences[word] = parsed_output.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ad53e7-95c3-405e-a648-60b76ae61a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd08f09-26fb-44b2-b94d-91ee02fca010",
   "metadata": {},
   "source": [
    "å¤§å®¶ä¹Ÿæ‡‰è©²ç·´ç¿’éï¼Œçµ¦äºˆä¸€çµ„å–®è©ï¼Œç”¨å–®è©å¯«å‡ºä¸€ç¯‡æ–‡ç« "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9707136-639f-4c3a-ac67-0bfd5842e5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = dendet(\"\"\"\n",
    "You are a helpful AI assistant and you are going to help me \n",
    "create a short article containing all these words in German.\n",
    "\"\"\")\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template=(\"{words}\"),\n",
    "                              input_variables=[\"words\"],\n",
    "                              )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt) \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"words\": \", \".join(words)})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "story = output.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c7ee78-776f-42b7-80ad-31043017cad4",
   "metadata": {},
   "source": [
    "å°‡çµæœè¼¸å‡ºç‚ºPDFæª”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c45fdd-6999-4a8d-a956-04245cd415fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4facbdd0-7aa7-485e-889a-bbfa646fb2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpdf import FPDF\n",
    "\n",
    "# Create the PDF\n",
    "pdf = FPDF()\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", 'B', 16)\n",
    "pdf.cell(0, 10, 'Wortliste mit BeispielsÃ¤tzen', ln=True)\n",
    "\n",
    "pdf.set_font(\"Arial\", '', 12)\n",
    "for word, sentence in words_sentences.items():\n",
    "    pdf.ln(5)\n",
    "    pdf.set_font(\"Arial\", 'B', 12)\n",
    "    pdf.cell(0, 10, f\"{word}:\", ln=True)\n",
    "    pdf.set_font(\"Arial\", '', 12)\n",
    "    pdf.multi_cell(0, 10, sentence)\n",
    "\n",
    "# Add article\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", 'B', 16)\n",
    "pdf.cell(0, 10, 'Artikel mit allen WÃ¶rtern', ln=True)\n",
    "pdf.set_font(\"Arial\", '', 12)\n",
    "pdf.multi_cell(0, 10, story)\n",
    "\n",
    "filename = os.path.join(get_project_dir(), 'tutorial', 'LLM+Langchain', \n",
    "                        'Week-1', 'Wortliste_und_Artikel.pdf')\n",
    "\n",
    "# Save the PDF\n",
    "pdf.output(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb0d1f7-0790-425b-b7a8-8930204705fb",
   "metadata": {},
   "source": [
    "# å…§å®¹å¼·åŒ–\n",
    "\n",
    "## Okapi BM25 Retrieval System\n",
    "\n",
    "- ç›®çš„: Okapi BM25 å¹«åŠ©æ‰¾åˆ°ç•¶ä½ æœç´¢æŸäº›å…§å®¹æ™‚æœ€ç›¸é—œçš„æ–‡æª”ã€‚\n",
    "\n",
    "- æ–‡æª”å’Œè©èª:\n",
    "    \n",
    "    - æƒ³åƒä½ æœ‰ä¸€å †æ›¸ï¼ˆæ–‡æª”ï¼‰ã€‚\n",
    "    - æ¯æœ¬æ›¸éƒ½æœ‰å¾ˆå¤šè©èªã€‚\n",
    "\n",
    "- æœç´¢æŸ¥è©¢:\n",
    "\n",
    "    - ç•¶ä½ æœç´¢æ™‚ï¼Œä½ æœƒè¼¸å…¥å¹¾å€‹è©èªï¼ˆä½ çš„æŸ¥è©¢ï¼‰ã€‚\n",
    "\n",
    "- è©•åˆ†ç³»çµ±:\n",
    "\n",
    "    - Okapi BM25 æ ¹æ“šæ¯æœ¬æ›¸èˆ‡ä½ çš„æŸ¥è©¢åŒ¹é…çš„ç¨‹åº¦çµ¦äºˆæ¯æœ¬æ›¸ä¸€å€‹åˆ†æ•¸ã€‚\n",
    "\n",
    "- è©•åˆ†å› ç´ :\n",
    "\n",
    "    - è©é »: å¦‚æœä½ çš„æŸ¥è©¢ä¸­çš„ä¸€å€‹è©åœ¨æŸæœ¬æ›¸ä¸­å‡ºç¾å¾ˆå¤šæ¬¡ï¼Œè©²æ›¸æœƒå¾—åˆ°æ›´é«˜çš„åˆ†æ•¸ã€‚\n",
    "    - é€†æ–‡æª”é »ç‡: å¦‚æœä¸€å€‹è©åœ¨æ‰€æœ‰æ›¸ä¸­éƒ½å¾ˆç¨€æœ‰ï¼Œä½†åœ¨æŸæœ¬æ›¸ä¸­å‡ºç¾ï¼Œè©²æ›¸æœƒå¾—åˆ°æ›´é«˜çš„åˆ†æ•¸ã€‚\n",
    "    - æ–‡æª”é•·åº¦: è¼ƒé•·çš„æ›¸æœƒé€²è¡Œèª¿æ•´ï¼Œé€™æ¨£å®ƒå€‘ä¸æœƒåƒ…å› ç‚ºç¯‡å¹…é•·è€Œè¢«ä¸å…¬å¹³åœ°è©•åˆ†ã€‚\n",
    "\n",
    "- å…¬å¼:\n",
    "\n",
    "    -BM25 ä½¿ç”¨ä¸€å€‹æ•¸å­¸å…¬å¼ä¾†çµåˆé€™äº›å› ç´ ä¸¦è¨ˆç®—åˆ†æ•¸ã€‚\n",
    "\n",
    "- é¸æ“‡æœ€ä½³:\n",
    "\n",
    "    - åˆ†æ•¸æœ€é«˜çš„æ›¸è¢«èªç‚ºæ˜¯èˆ‡ä½ çš„æŸ¥è©¢æœ€ç›¸é—œçš„ã€‚\n",
    "\n",
    "- çµæœ:\n",
    "\n",
    "    - é€™äº›é«˜åˆ†æ›¸æœƒä½œç‚ºæœç´¢çµæœé¡¯ç¤ºçµ¦ä½ ã€‚\n",
    "\n",
    "æƒ³åƒä¸€ä¸‹ï¼šOkapi BM25 å°±åƒæ˜¯ä¸€å€‹è°æ˜çš„åœ–æ›¸ç®¡ç†å“¡ï¼Œå®ƒæ ¹æ“šä½ åœ¨æœç´¢ä¸­ä½¿ç”¨çš„è©èªä¾†åˆ¤æ–·å“ªäº›æ›¸å¯èƒ½æ˜¯æœ€æœ‰è¶£å’Œæœ€æœ‰å¹«åŠ©çš„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcf9d88-865d-415c-9814-cf67fd11c5f9",
   "metadata": {},
   "source": [
    "### Term Frequency (TF) & Inverse Document Frequency (IDF):\n",
    "\n",
    "#### Term Frequency:\n",
    "\n",
    "æŠŠæ–‡ç« ä¸­å–®è©å‡ºç¾çš„é »ç‡åˆ†ä½ˆä½œç‚ºæ–‡ç« çš„ç‰¹å¾µ\n",
    "\n",
    "\n",
    "#### Inverse Document Frequency:\n",
    "\n",
    "æ­¸ä¸€åŒ–: å°‡æ–‡åº«ä¸­æ™®éå‡ºç¾çš„è©çš„æ¬Šé‡ä¸‹èª¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0538f29-8b8e-45d9-8ba6-b0f82bc8ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "url = \"https://www.gutenberg.org/cache/epub/1041/pg1041.txt\"\n",
    "response = requests.get(url)\n",
    "\n",
    "filename = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-1\", \"pg1041.txt\")\n",
    "\n",
    "# Ensure the request was successful\n",
    "if response.status_code == 200:\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(response.text)\n",
    "    print(\"File downloaded successfully.\")\n",
    "else:\n",
    "    print(\"Failed to download file. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98339ebd-8f8b-4eea-ba65-79e34255416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Read file\n",
    "with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Extract main body only\n",
    "match = re.search(r\"\\*\\*\\* START OF.*?\\*\\*\\*(.*)\\*\\*\\* END OF\", text, re.S)\n",
    "if match:\n",
    "    body = match.group(1)\n",
    "else:\n",
    "    body = text  # fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fd3e16-61a9-4850-8aa9-bc391c3bbda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into sonnets: Roman numeral headings\n",
    "pattern = r\"\\n([IVXLCDM]+)\\n\"   # captures numerals as headers\n",
    "parts = re.split(pattern, body)\n",
    "\n",
    "# Reconstruct mapping number â†’ sonnet text\n",
    "sonnets = {}\n",
    "for i in range(1, len(parts), 2):\n",
    "    number = parts[i].strip()\n",
    "    poem = parts[i+1].strip()\n",
    "    sonnets[number] = poem\n",
    "\n",
    "# Example: print first two sonnets\n",
    "for n in [\"I\", \"II\"]:\n",
    "    print(f\"Sonnet {n}:\\n{sonnets[n]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cb11f8-a292-4a75-936b-85d0e24e079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnets['I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e194f4-a60b-4717-a624-d4f0bd699792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform([sonnets['I']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee97a5a-8049-4079-b1c8-44e8d43f9d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8991582-1fbf-4fda-9e47-ce3011152db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out()).T\n",
    "\n",
    "# We will use this later\n",
    "sampled_columns = vectorizer.get_feature_names_out()\n",
    "\n",
    "df.columns = [\"frequency\"]\n",
    "\n",
    "# Sort descending\n",
    "df = df.sort_values(\"frequency\", ascending=False)\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adbd30a-7ef2-4828-9fd7-5fe476f689f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sonnet = pd.DataFrame.from_dict(sonnets, orient='index', columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef07206-6d9c-4010-86b8-c94a00682fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sonnet.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97219dea-c2e9-45c4-bb06-df5681490b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df_sonnet['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f9ceaf-0377-4b59-942b-64f71596ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49e8e20-3d8f-4826-85d6-1de677cfe1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[sampled_columns].iloc[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e3e588-df07-4fe2-961f-bfef08f8afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[sampled_columns].iloc[0].T.loc['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306b1a62-502d-47dd-a292-19cbea82bf29",
   "metadata": {},
   "source": [
    "OKAPI25 å¯ä»¥çœ‹æˆæ˜¯é—œéµå­—æœç´¢ï¼Œè€Œæœå°‹çš„çµæœæ ¹æ“šé—œéµå­—åœ¨æ¯æ®µæ–‡å­—ä¸­å‡ºç¾çš„é »ç‡å’Œæ–‡åº«ä¸­çš„ç¨€æœ‰åº¦é€²è¡ŒåŠ æ¬Š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d71deb-ecda-4379-a041-b482bbfdbead",
   "metadata": {},
   "source": [
    "## OKAPI25 in LangChain\n",
    "\n",
    "https://api.python.langchain.com/en/latest/_modules/langchain_community/retrievers/bm25.html#BM25Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7421cbc-2b35-43ce-854e-911e204040fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97969ad6-95ce-49bd-8cfc-84cfb9d11173",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Creating Documents from Training Data (å¾è¨“ç·´æ•¸æ“šå‰µå»ºæ–‡æª”):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d6e335-a9c6-427e-840a-c2fffb19d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for idx, row in df_sonnet.iterrows():\n",
    "    document = Document(page_content=row['text'],\n",
    "                        metadata={\"id\": idx})\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f734a5e1-58b2-4e0c-a294-9db0d554cdb5",
   "metadata": {},
   "source": [
    "### 2. Initializing BM25Retriever (åˆå§‹åŒ– BM25Retriever):\n",
    "\n",
    "- BM25Retriever.from_documents initializes an instance of BM25Retriever using the documents list.\n",
    "- Parameters:\n",
    "    - k=2: Specifies the number of documents to retrieve per query.\n",
    "    - bm25_params={\"k1\": 2.5}: Sets specific BM25 parameters (k1 parameter set to 2.5).\n",
    "    \n",
    "- ä½¿ç”¨ BM25Retriever.from_documents æ–¹æ³•ï¼Œåˆ©ç”¨ documents åˆ—è¡¨åˆå§‹åŒ–äº†ä¸€ä¸ª BM25Retriever å¯¦ä¾‹ã€‚\n",
    "- åƒæ•¸:\n",
    "    - k=2ï¼šæŒ‡å®šæ¯å€‹æŸ¥è©¢è¦æª¢ç´¢çš„æ–‡æª”æ•¸é‡ã€‚\n",
    "    - bm25_params={\"k1\": 2.5}ï¼šè¨­ç½®ç‰¹å®šçš„ BM25 åƒæ•¸ï¼ˆè¨­ç½® k1 åƒæ•¸ç‚º 2.5ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd5083d-1969-459f-bb6f-a968a0feaeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6565204d-9d89-4413-8f4e-22762ebd8ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(documents, k=2, \n",
    "                                              bm25_params={\"k1\":2.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9690a4-acb6-43f3-a089-885920799557",
   "metadata": {},
   "source": [
    "https://tolkiengateway.net/wiki/The_Road_Goes_Ever_On_(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f9eaf-609e-4f01-a91f-cdc9f910a2ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "query = dedent(\"\"\"\n",
    "Roads go ever ever on,\n",
    "Over rock and under tree,\n",
    "By caves where never sun has shone,\n",
    "By streams that never find the sea;\n",
    "Over snow by winter sown,\n",
    "And through the merry flowers of June,\n",
    "Over grass and over stone,\n",
    "And under mountains in the moon.\n",
    "\n",
    "Roads go ever ever on\n",
    "Under cloud and under star,\n",
    "Yet feet that wandering have gone\n",
    "Turn at last to home afar.\n",
    "Eyes that fire and sword have seen\n",
    "And horror in the halls of stone\n",
    "Look at last on meadows green\n",
    "And trees and hills they long have known\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8948b4c6-5d61-4d0c-85fa-f55f5aa6d121",
   "metadata": {},
   "source": [
    "### 3. Getting Top N Results (ç²å–æ’åå‰ N çš„çµæœ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86071b0-8d64-4f9d-85d0-10a3bc5f90e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‘¼å« BM25 æª¢ç´¢å™¨ï¼Œæ ¹æ“šæŸ¥è©¢æ–‡å­—æ‰¾å‡ºæœ€ç›¸é—œçš„æ–‡æª”\n",
    "\n",
    "output = bm25_retriever.invoke(query)\n",
    "\n",
    "# é æœŸè¼¸å‡ºï¼šè¿”å›èˆ‡è¼¸å…¥ query èªæ„æœ€ç›¸é—œçš„æ–‡æ®µï¼ˆåˆ—è¡¨æ ¼å¼ï¼‰\n",
    "for doc in output:\n",
    "    print(doc.page_content[:200], \"...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370cb578-0ca5-4a57-9535-59298a545357",
   "metadata": {},
   "source": [
    "### Byte Pair Encoding (BPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f63b8de-2c32-4c6b-91d0-5c8faf9ffe0e",
   "metadata": {},
   "source": [
    "è‹±æ–‡ä¼¼ä¹æŒºå¥½åˆ‡:æ¯å€‹å–®è©æœ‰é ­æœ‰å°¾ï¼Œä½†ä¸­æ–‡æˆ–æ—¥æ–‡é€™ç¨®ä¸­é–“æ²’æœ‰ç©ºç™½çš„æ–‡æœ¬è¦æ€éº¼åˆ‡?\n",
    "\n",
    "Byte Pair Encoding (BPE) learns frequent character pairs in text and merges them into tokens. For Traditional Chinese, it begins at the character level and gradually merges frequent pairs.\n",
    "\n",
    "Steps\n",
    "\n",
    "Prepare a small Traditional Chinese corpus.\n",
    "\n",
    "Train a BPE tokenizer with tokenizers (Hugging Face).\n",
    "\n",
    "Apply it to a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcd0672-3a16-4b41-9201-5ea175ebf802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the pre-trained BPE tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"p208p2002/llama-traditional-chinese-120M\")\n",
    "\n",
    "# Example usage\n",
    "text = \"æˆ‘æ­£åœ¨é–±è®€æ›¸ç±ï¼Œä¹Ÿåœ¨çœ‹è‹±æ–‡è³‡æ–™ã€‚\"\n",
    "encoded = tokenizer(text)\n",
    "print(\"Tokens:\", tokenizer.convert_ids_to_tokens(encoded[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eebc209-cb76-4140-b55d-7ce9f301966b",
   "metadata": {},
   "source": [
    "æˆ‘çŸ¥é“ä½ å€‘çš„å¿ƒä¸­æœ‰ä¸€å€‹å¤§è†½çš„æƒ³æ³•ï¼Œæ‰€ä»¥æŠŠæ—¥æ–‡çš„Tokenizerä¹Ÿé™„ä¸Šå»äº†ã€‚\n",
    "\n",
    "!pip install fugashi unidic-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f910a4-4924-4645-be9b-0f065ef25137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\"\"\"\n",
    "The ## prefix is something youâ€™ll often see in WordPiece or BPE tokenizers (like BERT). \n",
    "It means â€œthis subword is a continuation of the previous token.â€\n",
    "\"\"\"\n",
    "\n",
    "# Example: Japanese BERT v2\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese-v2\")\n",
    "\n",
    "text = \"<ä½ é‚£å¤§è†½çš„æƒ³æ³•>\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d593cb7c-55e8-430f-9fd4-f35ae201f205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_wordpiece(tokens):\n",
    "    merged = []\n",
    "    current_word = \"\"\n",
    "    for token in tokens:\n",
    "        if token.startswith(\"##\"):\n",
    "            current_word += token[2:]  # append without '##'\n",
    "        else:\n",
    "            if current_word:  # push the previous word\n",
    "                merged.append(current_word)\n",
    "            current_word = token  # start a new word\n",
    "    if current_word:  # push the last one\n",
    "        merged.append(current_word)\n",
    "    return merged\n",
    "\n",
    "print(merge_wordpiece(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa63fca-816b-4e56-b3db-7546c542502b",
   "metadata": {},
   "source": [
    "ä¸‹è¼‰ä¸­æ–‡æ–‡æª”\n",
    "\n",
    "- https://github.com/rime-aca/corpus/blob/master/å”è©©ä¸‰ç™¾é¦–.txt\n",
    "\n",
    "ä¸æ˜¯æˆ‘å–œæ­¡æ–‡å­¸ï¼Œæ˜¯é€™æ¯”è¼ƒå¥½æ‰¾æ•¸æ“šé›†ï¼Œé‚„ä¸æœƒè¢«å‘Šã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0483d85e-4327-4d68-bf25-551d11fa3d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Read file\n",
    "filename = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-1\", \"å”è©©ä¸‰ç™¾é¦–.txt\")\n",
    "with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "poems = []\n",
    "\n",
    "# Split by blank lines\n",
    "blocks = [b.strip() for b in text.strip().split(\"\\n\\n\") if b.strip()]\n",
    "\n",
    "for block in blocks:\n",
    "    entry = {}\n",
    "    for line in block.split(\"\\n\"):\n",
    "        if line.startswith(\"è©©å:\"):\n",
    "            entry[\"è©©å\"] = line.replace(\"è©©å:\", \"\").strip()\n",
    "        elif line.startswith(\"ä½œè€…:\"):\n",
    "            entry[\"ä½œè€…\"] = line.replace(\"ä½œè€…:\", \"\").strip()\n",
    "        elif line.startswith(\"è©©é«”:\"):\n",
    "            entry[\"è©©é«”\"] = line.replace(\"è©©é«”:\", \"\").strip()\n",
    "        elif line.startswith(\"è©©æ–‡:\"):\n",
    "            entry[\"è©©æ–‡\"] = line.replace(\"è©©æ–‡:\", \"\").strip()\n",
    "    if len(entry) != 0:\n",
    "        poems.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22744e1b-8305-40fb-8092-8792e0d95a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "poems[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc04545-3b02-4e9b-bc21-228c2d518079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read file\n",
    "# filename = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-1\", \"å®‹è©ä¸‰ç™¾é¦–.txt\")\n",
    "#pd. with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "#     text = f.read()\n",
    "\n",
    "# # Split by blank lines\n",
    "# blocks = [b.strip() for b in text.strip().split(\"\\n\\n\") if b.strip()]\n",
    "\n",
    "# for block in blocks:\n",
    "#     entry = {}\n",
    "#     for line in block.split(\"\\n\"):\n",
    "#         if line.startswith(\"è©©å:\"):\n",
    "#             entry[\"è©ç‰Œ\"] = line.replace(\"è©ç‰Œ:\", \"\").strip()\n",
    "#         elif line.startswith(\"ä½œè€…:\"):\n",
    "#             entry[\"ä½œè€…\"] = line.replace(\"ä½œè€…:\", \"\").strip()\n",
    "#         elif line.startswith(\"è©©é«”:\"):\n",
    "#             entry[\"è©æ–‡\"] = line.replace(\"è©æ–‡:\", \"\").strip()\n",
    "#     if len(entry) != 0:\n",
    "#         poems.append(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95b10ab-7f97-47b3-b3e5-986302ce2d60",
   "metadata": {},
   "source": [
    "#### å»ºç«‹Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feae8a65-014f-4c76-a232-f2ac0c005225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_poem = pd.DataFrame(poems)\n",
    "\n",
    "documents = []\n",
    "\n",
    "for _, row in df_poem.iterrows():\n",
    "    document = Document(page_content=row['è©©æ–‡'],\n",
    "                        metadata={\"è©©å\": row[\"è©©å\"],\n",
    "                                  \"ä½œè€…\": row[\"ä½œè€…\"],\n",
    "                                  \"è©©é«”\": row[\"è©©é«”\"]})\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387d534f-2498-4c02-ac16-542deb6c76da",
   "metadata": {},
   "source": [
    "è‡ªè¨‚ç¾©å‡½æ•¸ï¼Œè®“BM25ä½¿ç”¨BPE tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a543cfc-fd8e-452a-a945-7b340c3e6f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_func(text: str):\n",
    "\n",
    "    # 1. Define special tokens to remove\n",
    "    special_tokens = {\"<s>\", \"</s>\", \"[PAD]\", \"[UNK]\"}\n",
    "    \n",
    "    encoded = tokenizer(text)\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoded[\"input_ids\"])\n",
    "\n",
    "    # 2. Remove special tokens\n",
    "    tokens = [t.replace(\"â–\", \"\") for t in tokens if t not in special_tokens]\n",
    "    \n",
    "    # 3. Remove punctuation (keep only Chinese/English/number words)\n",
    "    tokens = [t for t in tokens if re.match(r'[\\wä¸€-é¾¥]+', t)]\n",
    "    \n",
    "    # Stringify the tokens\n",
    "    return [str(token) for token in tokens]\n",
    "\n",
    "\n",
    "bm25_poem_retriever = BM25Retriever.from_documents(documents, k=5, \n",
    "                                                   bm25_params={\"k1\":2.5},\n",
    "                                                   preprocess_func=_preprocess_func\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ed0c0a-9413-4fd2-a41c-2fdc81090c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_poem_retriever.invoke(\"å¤§é¢¨èµ·å…®é›²é£›æš å¨åŠ æµ·å…§å…®æ­¸æ•…é„‰ å®‰å¾—çŒ›å£«å…®å®ˆå››æ–¹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b265ce-02e3-4e21-a8fa-b5dd6e3def1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_poem_retriever.invoke(\"å¤•é™½ç„¡é™å¥½\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36283559-563c-4b09-8bd0-4896b76c8195",
   "metadata": {},
   "source": [
    "æŠŠè©©ç¶“è½‰æ›æˆäº”è¨€çµ•å¥... æœ‰ä¸­æ–‡æ¯”è¼ƒå¥½çš„äººå—? XD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b011dc9-e7ea-47f8-be36-1e8544c51e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "# query\n",
    "\n",
    "query = dedent(\"\"\"\n",
    "è’¹è‘­è’¼è’¼ã€ç™½éœ²ç‚ºéœœã€‚\n",
    "æ‰€è¬‚ä¼Šäººã€åœ¨æ°´ä¸€æ–¹ã€‚\n",
    "é¡æ´„å¾ä¹‹ã€é“é˜»ä¸”é•·ã€‚\n",
    "é¡éŠå¾ä¹‹ã€å®›åœ¨æ°´ä¸­å¤®ã€‚\n",
    "\"\"\")\n",
    "\n",
    "# output format\n",
    "class Output(BaseModel):\n",
    "    name: str = Field(description=\"result in traditional Chinese (ç¹é«”ä¸­æ–‡)\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Output)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "# prompt template\n",
    "system_template = dedent(\"\"\"\n",
    "You are a helpful AI assistant with expertise in classical Chinese literature.\n",
    "You understand all the nuance and history background of all the content.\n",
    "\"\"\")\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template=(\"\"\"\n",
    "Create a {poetic_form}\n",
    "\n",
    "Examples:\n",
    "{context}\n",
    "\n",
    "according to the semantic of {query}\n",
    "\n",
    "Output instruction: {format_instructions}\n",
    "\"\"\"),\n",
    "input_variables=[\"poetic_form\", \"query\", \"context\"],\n",
    "partial_variables={'format_instructions': format_instructions}\n",
    ")\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt) \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "# retrieval\n",
    "# BM25 retriever ä¸æ”¯æŒ filter\n",
    "# æ‰€ä»¥å»ºè­°å…ˆfilterå…§å®¹\n",
    "\n",
    "df_poem = pd.DataFrame(poems)\n",
    "\n",
    "documents = []\n",
    "\n",
    "for _, row in df_poem.iterrows():\n",
    "    if row[\"è©©é«”\"] == \"äº”è¨€çµ•å¥\":\n",
    "        document = Document(page_content=row['è©©æ–‡'],\n",
    "                            metadata={\"è©©å\": row[\"è©©å\"],\n",
    "                                      \"ä½œè€…\": row[\"ä½œè€…\"],\n",
    "                                      \"è©©é«”\": row[\"è©©é«”\"]})\n",
    "        documents.append(document)\n",
    "\n",
    "bm25_poem_retriever = BM25Retriever.from_documents(documents, k=5, \n",
    "                                                   bm25_params={\"k1\":2.5},\n",
    "                                                   preprocess_func=_preprocess_func\n",
    "                                                  )\n",
    "\n",
    "context = bm25_poem_retriever.invoke(query)\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065672bf-e381-4a26-8fb2-85be53118945",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\\n\".join([c.page_content for c in context])\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a621c-6af3-4aba-9fa2-5a3594da530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ‡æ›æˆ gpt-4oã€‚gpt-4o-miniåœ¨é€™æ–¹é¢å¾ˆå¼±\n",
    "\n",
    "model_poem = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o\", \n",
    "                   temperature=0 # a range from 0-2, the higher the value, the higher the `creativity`\n",
    "                  )\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": query,\n",
    "                             \"poetic_form\": \"äº”è¨€çµ•å¥\",\n",
    "                             \"context\": context})\n",
    "\n",
    "output = model_poem.invoke(prompt)\n",
    "\n",
    "parsed_output = output_parser.parse(output.content)\n",
    "\n",
    "print(parsed_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968f8861-ef45-4bb6-8f7b-108ce055d98b",
   "metadata": {},
   "source": [
    "# Wikipedia Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ddbe9-374a-4f42-8a0a-e76f4d8f8409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade --quiet  wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325d56f0-bc4a-40ad-8b45-55bc24d4c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "\n",
    "wiki_retriever = WikipediaRetriever()\n",
    "\n",
    "docs = wiki_retriever.invoke(\"2024 US presidential election\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8e184a-bf82-4687-acd3-ee28ccf3890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18856c98-7918-4afd-9675-3c0e69549d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d145bd2-875d-4f0b-8bfc-1fff44c9a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è‹¥æ˜¯å°‘æ–¼çµ¦å®šè¿”å›æ•¸é‡ï¼Œå‰‡è¿”å›ç•¶å‰æ‰€æœ‰å¯å¾—åˆ°æ–‡ä»¶\n",
    "\n",
    "docs = wiki_retriever.invoke(\"rice\")\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5414999-cb9f-4e3b-a7fe-7340b56eea84",
   "metadata": {},
   "source": [
    "- If you want to know what parameters can be feed to the WikipediaRetriever:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98333101-de37-4203-9f2f-c9a42db21473",
   "metadata": {},
   "outputs": [],
   "source": [
    "WikipediaRetriever?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d4f34-9d99-47ba-9f08-48ac5feb4a76",
   "metadata": {},
   "source": [
    "By default, wikipedia retriever returns 3 documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712d4f6f-12c5-4ef2-a92f-aec594002d76",
   "metadata": {},
   "source": [
    "# Ensemble Retriever\n",
    "\n",
    "- å®ƒçµåˆé€™äº›å·¥å…·çš„çµæœä¸¦ä½¿ç”¨ç‰¹æ®Šæ–¹æ³•é€²è¡Œçµ„ç¹”ã€‚\n",
    "- é€šéä½¿ç”¨ä¸åŒçš„å·¥å…·ï¼Œå®ƒæ¯”åƒ…ä½¿ç”¨å–®ä¸€å·¥å…·æ•ˆæœæ›´å¥½ã€‚\n",
    "- é€šå¸¸ï¼Œå®ƒçµåˆå…©ç¨®é¡å‹çš„æœç´¢ï¼šä¸€ç¨®å°‹æ‰¾ç²¾ç¢ºè©èªï¼ˆä¾‹å¦‚ BM25ï¼‰ï¼Œå¦ä¸€ç¨®ç†è§£å«ç¾©ï¼ˆä¾‹å¦‚åµŒå…¥å¼ï¼‰ã€‚\n",
    "- é€™ç¨®æ··åˆç¨±ç‚º \"æ··åˆæœç´¢\"ã€‚\n",
    "- ç¬¬ä¸€ç¨®å·¥å…·å°‹æ‰¾å…·æœ‰ç‰¹å®šè©èªçš„æ–‡æª”ï¼Œè€Œç¬¬äºŒç¨®å·¥å…·å‰‡å°‹æ‰¾å…·æœ‰ç›¸ä¼¼æ€æƒ³çš„æ–‡æª”ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d36f78a-b55a-4e40-ab9c-9ea2151a5c38",
   "metadata": {},
   "source": [
    "- weights: æ§åˆ¶æ¬Šé‡\n",
    "- ç¸½è¿”å›æ–‡ä»¶æ•¸é‡ç­‰æ–¼å€‹åˆ¥æª¢ç´¢å™¨ (retriever) æª¢ç´¢æ–‡ä»¶æ•¸é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599b51aa-9c1b-4e4b-839f-9fb0bdac182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, wiki_retriever], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb3e2a-8efa-47a0-a682-574adbd1f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ensemble_retriever.invoke(\"rice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef0492-cf23-4c52-9685-a7860ba645e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91847b0e-ef31-45da-88da-a93888cd0093",
   "metadata": {},
   "source": [
    "- bm25_retriever è¿”å›å…©ä»½\n",
    "- wiki_retriever è¿”å›å…©ä»½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14fcd07-cd35-4c5d-bcc2-973b81daa401",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’¼ å¯¦å‹™æ‡‰ç”¨æ¡ˆä¾‹ï¼šå…¬å¸çŸ¥è­˜åº«æª¢ç´¢\n",
    "\n",
    "å‡è¨­ä½ åœ¨ä¸€é–“ç§‘æŠ€å…¬å¸å·¥ä½œï¼Œå…§éƒ¨æœ‰æ•¸ç™¾ä»½æŠ€è¡“æ–‡ä»¶èˆ‡å°ˆæ¡ˆç´€éŒ„ã€‚  \n",
    "è‹¥åŒäº‹è©¢å•ï¼šã€Œæˆ‘å€‘å»å¹´å“ªå€‹åœ˜éšŠä½¿ç”¨é LangChainï¼Ÿã€  \n",
    "- **BM25 Retriever** å¯ç”¨æ–¼å¿«é€Ÿæœå°‹æ–‡ä»¶ä¸­åŒ…å«ã€ŒLangChainã€é—œéµå­—çš„éƒ¨åˆ†ï¼ˆé«˜ç²¾åº¦å­—é¢åŒ¹é…ï¼‰ã€‚  \n",
    "- **Embedding Retriever**ï¼ˆèªç¾©æœå°‹ï¼‰å‰‡èƒ½æ‰¾åˆ°å³ä½¿æœªå‡ºç¾ç›¸åŒå­—è©ã€ä½†èªæ„ç›¸ä¼¼çš„æ–‡ä»¶ã€‚  \n",
    "\n",
    "è‹¥åŒæ™‚ä½¿ç”¨å…©è€…çµ„åˆæˆ **Ensemble Retrieverï¼ˆæ··åˆæª¢ç´¢ï¼‰**ï¼š\n",
    "- BM25 æä¾›æº–ç¢ºçš„å­—è©æ¯”å°  \n",
    "- Embedding æä¾›èªæ„ç†è§£  \n",
    "- æœ€å¾Œæ•´åˆçµæœåŠ æ¬Šæ’åºï¼Œèƒ½å¾—åˆ°æ›´å®Œæ•´ã€ç²¾ç¢ºçš„æœå°‹çµæœ  \n",
    "\n",
    "é€™é¡æ–¹æ³•å¸¸ç”¨æ–¼ï¼š\n",
    "- å®¢æœçŸ¥è­˜åº«ï¼ˆè‡ªå‹•å›ç­”å®¢æˆ¶å•é¡Œï¼‰  \n",
    "- æ³•å¾‹æ–‡ä»¶æª¢ç´¢  \n",
    "- å…¬å¸å…§éƒ¨æ–‡ä»¶æœå°‹å¼•æ“  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33749100-3ad0-489b-882d-40a0b41232c2",
   "metadata": {},
   "source": [
    "# Runtime Configuration (é‹è¡Œæ™‚é…ç½®)\n",
    "\n",
    "- æˆ‘å€‘ä¹Ÿå¯ä»¥åœ¨é‹è¡Œæ™‚é…ç½®æª¢ç´¢å™¨ã€‚ç‚ºäº†åšåˆ°é€™ä¸€é»ï¼Œæˆ‘å€‘éœ€è¦å°‡å­—æ®µæ¨™è¨˜ç‚ºå¯é…ç½®çš„ã€‚\n",
    "\n",
    "API Reference: https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.utils.ConfigurableField.htmld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2301ed88-4894-4c32-9e1c-a0291e192f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d883448-92c9-4a36-a4bd-20f73a755c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(documents, k=2, \n",
    "    bm25_params={\"k1\": 1}).configurable_fields(\n",
    "    k=ConfigurableField(\n",
    "        id=\"bm25_k\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f102aaad-9bf8-42a1-be3d-bc054b3c5c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, wiki_retriever], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f5977c-e120-4f36-b227-262f2add9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"bm25_k\": 5}}\n",
    "docs = ensemble_retriever.invoke(\"rice\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51851ea0-c12e-42bb-b1cf-3e57314e15ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb7982d-f1cb-4036-9317-dd7f96c5836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - bm25_retriever è¿”å›äº”ä»½\n",
    "# - wiki_retriever è¿”å›å…©ä»½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792ac2d5-2284-426d-8894-c9aec4849a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, wiki_retriever], weights=[0.1, 0.9]\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"bm25_k\": 10}}\n",
    "docs = ensemble_retriever.invoke(\"rice\", config=config)\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c45ab-899b-4d21-9f57-7939f79fa4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - bm25_retriever è¿”å›åä»½\n",
    "# - wiki_retriever è¿”å›å…©ä»½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a8ec7b-1a3f-4eb1-b210-747d5943b7af",
   "metadata": {},
   "source": [
    "### This is what I do in my work:\n",
    "\n",
    "I use runtime configuration to target a specific data section with the applied attribute.\n",
    "\n",
    "More specifically, there are many types of cosmetic products, such as:\n",
    "\n",
    "- Lipstick\n",
    "- Lip Gloss\n",
    "- Mascara\n",
    "- Blush\n",
    "- Foundation\n",
    "- Nail Polish\n",
    "- Eyeliner\n",
    "- Eye Pencil\n",
    "\n",
    "These products are applied to different areas: face, nails, eyes, and lips.\n",
    "\n",
    "You can retrieve information more efficiently and accurately if you identify the correct application area beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a516b1-a7f7-4bea-8567-32d46570e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(self.documents, embedding=embedding)\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type='similarity',\n",
    "                                     search_kwargs={'k': self._k}).configurable_fields(search_kwargs=ConfigurableField(id=\"faiss_search_kwargs\"))\n",
    "\n",
    "semantic_retriever = retrievers['semantic']\n",
    "semantic_documents = semantic_retriever.invoke(product, config={\"configurable\":\n",
    "                                             {\"faiss_search_kwargs\":\n",
    "                                                  {\"fetch_k\":20,\n",
    "                                                   \"k\": 2,\n",
    "                                                   \"filter\": {\"applied\": area}}}})\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
