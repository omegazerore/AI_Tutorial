{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebfbfab-219f-4ea9-b24a-f7f414cf25ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b9ca05-18e4-4ecb-83c2-4bb1efcdf588",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b691104-7300-4274-baa7-11ef5def708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from textwrap import dedent\n",
    "\n",
    "from src.initialization import credential_init\n",
    "from src.io.path_definition import get_project_dir\n",
    "\n",
    "\n",
    "def build_standard_chat_prompt_template(kwargs):\n",
    "\n",
    "    messages = []\n",
    " \n",
    "    if 'system' in kwargs:\n",
    "        content = kwargs.get('system')\n",
    "        prompt = PromptTemplate(**content)\n",
    "        message = SystemMessagePromptTemplate(prompt=prompt)\n",
    "        messages.append(message)  \n",
    "\n",
    "    if 'human' in kwargs:\n",
    "        content = kwargs.get('human')\n",
    "        prompt = PromptTemplate(**content)\n",
    "        message = HumanMessagePromptTemplate(prompt=prompt)\n",
    "        messages.append(message)\n",
    "        \n",
    "    chat_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "    \n",
    "    return chat_prompt\n",
    "\n",
    "\n",
    "\n",
    "credential_init()\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Read file\n",
    "filename = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-1\", \"唐詩三百首.txt\")\n",
    "with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "poems = []\n",
    "\n",
    "# Split by blank lines\n",
    "blocks = [b.strip() for b in text.strip().split(\"\\n\\n\") if b.strip()]\n",
    "\n",
    "for block in blocks:\n",
    "    entry = {}\n",
    "    for line in block.split(\"\\n\"):\n",
    "        if line.startswith(\"詩名:\"):\n",
    "            entry[\"詩名\"] = line.replace(\"詩名:\", \"\").strip()\n",
    "        elif line.startswith(\"作者:\"):\n",
    "            entry[\"作者\"] = line.replace(\"作者:\", \"\").strip()\n",
    "        elif line.startswith(\"詩體:\"):\n",
    "            entry[\"詩體\"] = line.replace(\"詩體:\", \"\").strip()\n",
    "        elif line.startswith(\"詩文:\"):\n",
    "            entry[\"詩文\"] = line.replace(\"詩文:\", \"\").strip()\n",
    "    if len(entry) != 0:\n",
    "        poems.append(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ed7ca1-3a1f-4915-a35c-2f239fa0325a",
   "metadata": {},
   "source": [
    "# 語意檢索系統\n",
    "\n",
    "> 🎯 **本章學完你將能學會什麼：**\n",
    "> - 理解「語意檢索」的核心概念與傳統單詞比對的限制  \n",
    "> - 了解 **Word2Vec**、**GloVe** 的詞向量原理與語義空間表示方式  \n",
    "> - 認識 **上下文詞向量（Contextual Embeddings）** 與 **Transformer 架構**  \n",
    "> - 比較 Encoder-only（BERT）、Decoder-only（GPT）、Encoder-Decoder（T5）的差異  \n",
    "> - 掌握如何在 Python 中使用 **Gensim**、**LangChain** 與 **FAISS** 進行語意檢索  \n",
    "> - 能將文字資料轉換為向量嵌入，並建立可檢索的語意資料庫  \n",
    "> - 應用語意搜尋於詩文檢索、文本對比與自動化問答等任務  \n",
    "\n",
    "\n",
    "\n",
    "使用單詞比對搜尋的問題:\n",
    "\n",
    "猛男 != 兄貴\n",
    "\n",
    "我們知道這在意思上非常的相近，但是單詞比對不一樣就是不一樣，差一點點都不行\n",
    "\n",
    "## 解決方法:\n",
    "\n",
    "Word2Vec\n",
    "\n",
    "- Word2Vec 可透過 Skip-gram 或 CBOW 架構，將單詞映射到實數向量空間。\n",
    "- 在這個空間中，單詞的分佈式表示能捕捉語義與上下文關係。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c805a3-928a-439a-95e3-84c0ae28f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(filename= \"tutorial/LLM+Langchain/Week-2/Word2Vec.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9636700-d1f6-4ebb-b053-c7b23157e956",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550a5af0-45b6-4bd0-9652-3df4fe72bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Download and load the model (first-run will download ~128 MB)\n",
    "model = api.load('glove-wiki-gigaword-100')\n",
    "\n",
    "# Usage examples:\n",
    "# king + woman - man\n",
    "print(model.most_similar(positive=['king', 'woman'], negative=['man'], topn=1))\n",
    "# → [('queen', similarity_score)]\n",
    "\n",
    "# print(model['computer'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128596c0-8053-4b48-be9e-78087ff5843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model['queen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6886e8-7589-4267-aeda-c68dc1aede59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage examples:\n",
    "print(model.most_similar(positive=['warrior', 'woman'], negative=['man'], topn=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469c61bd-06e4-4f84-ae4a-43ce9a2660d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage examples:\n",
    "print(model.most_similar(positive=['priest', 'woman'], negative=['man'], topn=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d12bba-c165-4924-8175-2a4de2779db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 這個模型1.5G大小\n",
    "\n",
    "# from gensim.models import KeyedVectors\n",
    "\n",
    "# model = KeyedVectors.load_word2vec_format(\n",
    "#     'GoogleNews-vectors-negative300.bin', binary=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c048273-24a5-468b-884e-760302e66e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Similarity 高中數學沒忘光吧\n",
    "word1 = \"king\"\n",
    "word2 = \"queen\"\n",
    "\n",
    "similarity_score = model.similarity(word1, word2)\n",
    "print(f\"Cosine similarity between '{word1}' and '{word2}': {similarity_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca47d88-dd0c-4400-9d93-b037c44117f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most similar words\n",
    "\n",
    "model.most_similar('king', topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c426ed1d-4e71-4d59-af09-25be99541002",
   "metadata": {},
   "source": [
    "Word2Vec 雖然能捕捉詞彙的語義相似性，但它有一個限制：無法處理一字多義(polysemy)的情況。因為 Word2Vec 是全域向量(global vector)模型，每個單詞只有一個固定的向量表示，與上下文無關。例如：\n",
    "- 菜市場的「蘋果」和 San Jose 的「Apple」的向量是一樣的\n",
    "- 河岸的「bank」和銀行的「bank」向量也是一樣的\n",
    "\n",
    "解決方法是使用上下文詞向量（Contextual Embeddings），如 BERT 或 ELMo，它們能根據上下文生成不同的詞向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb4dbff-b985-4f28-884e-db5ca55e1c6f",
   "metadata": {},
   "source": [
    "### Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a971ce1-6df3-4284-af43-ca72cd603325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)#/media/File:Transformer,_full_architecture.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87a892b-b263-4cac-bb33-102b2c743684",
   "metadata": {},
   "source": [
    "Transformer的Attention layer可以讓單詞去注意他該去\"看\"句子的哪個地方，來達到捕捉上下文涵意\n",
    "\n",
    "#### Attention 的作用\n",
    "\n",
    "Transformer 的 Attention 層可以讓每個單詞在編碼時「注意」句子中其他單詞的重要性，從而捕捉上下文語意。\n",
    "\n",
    "#### Transformer 架構\n",
    "\n",
    "- Encoder-Decoder (T5)：Encoder 負責理解輸入句子，Decoder 負責生成文字。\n",
    "\n",
    "- Encoder-only（如 BERT）：只做理解，產生 Contextual Embeddings。\n",
    "\n",
    "- Decoder-only（如 GPT）：只做生成，但也能捕捉上下文語意。\n",
    "\n",
    "Contextual Embeddings\n",
    "\n",
    "每個單詞的向量表示(vector presentation)會根據上下文不同而改變。\n",
    "\n",
    "這些表示可以由 Encoder 或 Decoder 生成，取決於模型架構。\n",
    "\n",
    "Embedding 的獲得方式\n",
    "\n",
    "通常由 Transformer 在訓練過程中學得（例如 Masked Language Modeling、Causal LM 等）。\n",
    "\n",
    "也可以用特殊任務或對比學習方法訓練句子/單詞嵌入，但這不是唯一方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6d51ec-213c-4af4-8627-c4054a5f96c8",
   "metadata": {},
   "source": [
    "### Contrastive Learning\n",
    "\n",
    "\n",
    "1. 目標\n",
    "\n",
    "在嵌入（Embedding）學習中，我們希望把輸入資料（如文字、圖片、音訊）映射到一個向量空間中，使得：\n",
    "\n",
    "相似的樣本在向量空間中距離接近\n",
    "\n",
    "不相似的樣本在向量空間中距離遠\n",
    "\n",
    "對比學習正是用這個原理來訓練模型生成高品質的 Embedding。\n",
    "\n",
    "2. 做法\n",
    "\n",
    "選取正負樣本對\n",
    "\n",
    "正樣本對（positive pair）：同一個語義或內容的兩個樣本。\n",
    "\n",
    "文字：同義句、翻譯句\n",
    "\n",
    "圖片：同一張圖片經過不同增強（裁切、旋轉、顏色變化）\n",
    "\n",
    "負樣本對（negative pair）：語義不同或來源不同的樣本\n",
    "\n",
    "映射到向量空間\n",
    "\n",
    "用模型（如 Transformer、CNN）將每個樣本映射成向量表示（Embedding）\n",
    "\n",
    "計算正負樣本對的相似度（通常用餘弦相似度）\n",
    "\n",
    "訓練目標\n",
    "\n",
    "拉近正樣本對的距離\n",
    "\n",
    "推遠負樣本對的距離\n",
    "\n",
    "損失函數常用 Contrastive Loss 或 InfoNCE Loss\n",
    "\n",
    "3. 效果\n",
    "\n",
    "訓練完成後，Embedding 空間會自動形成 語義結構：\n",
    "\n",
    "相似意思的文字或圖片會聚在一起\n",
    "\n",
    "不相似的樣本會遠離\n",
    "\n",
    "這種 Embedding 可以直接用於：\n",
    "\n",
    "檢索（Retrieval）：找最相似的句子或圖片\n",
    "\n",
    "分類（Classification）：用 Embedding 做下游任務\n",
    "\n",
    "聚類（Clustering）：將相似樣本聚在一起\n",
    "\n",
    "4. 實際例子\n",
    "\n",
    "文字嵌入：Sentence-BERT 用對比學習將語義相近的句子映射到相近向量，方便語義搜索或問答系統。\n",
    "\n",
    "圖像嵌入：SimCLR 用對比學習生成圖片特徵向量，無需標籤也能捕捉圖像語義。\n",
    "\n",
    "多模態嵌入：CLIP 將圖片和對應描述映射到同一向量空間，方便圖像檢索或生成。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510885f1-6f5e-40fc-a1ba-4bbae638e7a8",
   "metadata": {},
   "source": [
    "理論講完了，上手實操。理論建議看一下，也許面試時會問。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3a7a88-0bd5-4ed1-a619-b7c537813bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# https://platform.openai.com/docs/guides/embeddings/what-are-embeddings\n",
    "\n",
    "# A list of embedding models you can choose \n",
    "# https://www.sbert.net/docs/sentence_transformer/pretrained_models.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d359c46-df1c-4449-8a78-297c41b43088",
   "metadata": {},
   "source": [
    "### 1. 創建嵌入:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47235efc-d786-4a04-9ec1-89c3a4203e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aece8f30-980a-4f5c-8fe2-d574eb14a301",
   "metadata": {},
   "source": [
    "### 2. 載入向量資料庫:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d74fce-c711-4dbb-8b81-0f6cae45ccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "df_poem = pd.DataFrame(poems)\n",
    "\n",
    "documents = []\n",
    "\n",
    "for _, row in df_poem.iterrows():\n",
    "    document = Document(page_content=row['詩文'],\n",
    "                        metadata={\"詩名\": row[\"詩名\"],\n",
    "                                  \"作者\": row[\"作者\"],\n",
    "                                  \"詩體\": row[\"詩體\"]})\n",
    "    documents.append(document)\n",
    "\n",
    "filename = os.path.join(get_project_dir(), \"tutorial\", \"LLM+Langchain\", \"Week-2\", \"poem_faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab208791-70cf-4a93-a23b-b27b4613e253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 挑選一個有包含中文的Embedding 模型\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "\n",
    "# 我的這台電腦要跑一個小時左右，所以留給你們，反正不用錢\n",
    "# 我直接使用已經轉換完成的 vectorstore\n",
    "# vectorstore = FAISS.from_documents(documents, embedding=embeddings)\n",
    "\n",
    "# it seems that you cannot use Chinese character in the filename\n",
    "# vectorstore.save_local(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc76a677-9833-4844-a700-71108179fd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.load_local(\n",
    "    filename, embeddings, allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 5})\n",
    "\n",
    "retriever.invoke(\"夕陽無限好\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fcc1c6-026e-4afc-8f87-fb57b8733f7e",
   "metadata": {},
   "source": [
    "## 🧠 理解 FAISS 中的 IVF-PQ\n",
    "\n",
    "> 🎯 **本章學完你將能學會什麼：**\n",
    "> - 理解 **FAISS（Facebook AI Similarity Search）** 的基本架構與用途  \n",
    "> - 分辨不同索引類型：**IndexFlatL2、IVF、PQ、IVF+PQ**  \n",
    "> - 了解倒排索引（IVF）與產品量化（PQ）的運作機制  \n",
    "> - 掌握 **IVF+PQ** 結合後的優勢：高速檢索與記憶體壓縮  \n",
    "> - 能在程式中建立、訓練與儲存 FAISS 索引  \n",
    "> - 學會如何使用 LangChain 的 **FAISS VectorStore** 封裝檢索流程  \n",
    "> - 理解三種檢索策略（similarity、score threshold、MMR）與實際應用差異  \n",
    "> - 具備分析向量空間結構與相似度分佈的能力  \n",
    "\n",
    "本筆記說明 **FAISS**（Facebook AI Similarity Search）的索引與搜尋策略，特別聚焦在 **IVF**、**PQ** 及其組合 **IVF+PQ**。\n",
    "\n",
    "---\n",
    "\n",
    "### 🧩 IndexFlatL2\n",
    "\n",
    "**機制：**  \n",
    "最簡單的暴力搜尋索引 — 查詢時，會計算查詢向量與 **資料庫中所有向量** 的 **L2 距離**，然後排序結果。\n",
    "\n",
    "**優點：**\n",
    "- 提供 **精確最近鄰**。\n",
    "- 不需要訓練（可即插即用）。\n",
    "\n",
    "**缺點：**\n",
    "- 對於大規模資料集（百萬或數十億向量）非常 **慢**，且 **耗記憶體**。\n",
    "\n",
    "---\n",
    "\n",
    "### ⚙️ IVF（Inverted File Index 倒排索引）\n",
    "\n",
    "**概念：**  \n",
    "將向量空間分成 `nlist` 個 cluster（通常使用 **k-means** 聚類）。  \n",
    "每個 cluster 有一個 **倒排列表**（inverted list），儲存分配到該 cluster 的向量。\n",
    "\n",
    "**查詢流程：**\n",
    "1. 使用 **coarse quantizer**（通常是 `IndexFlatL2`）找出與查詢向量最接近的 `nprobe` 個 cluster。  \n",
    "2. 僅在這些 cluster 中進行細部搜尋，而非整個資料庫。\n",
    "\n",
    "**優點：**\n",
    "- 透過忽略大部分資料庫，大幅 **加快搜尋速度**。\n",
    "- 適合 **大規模資料集**。\n",
    "\n",
    "**缺點：**\n",
    "- 精準度略下降（取決於 `nlist` 與 `nprobe` 的設定）。\n",
    "- 需要訓練（k-means）。\n",
    "\n",
    "---\n",
    "\n",
    "### 📦 PQ（Product Quantization 產品量化）\n",
    "\n",
    "**概念：**  \n",
    "將向量壓縮成緊湊表示，以便更快地進行近似距離計算。\n",
    "\n",
    "**步驟：**\n",
    "1. 將向量（維度 `d`）分成 `m` 個 **子向量**，每個長度為 `d/m`。\n",
    "2. 為每組子向量訓練一個 **codebook**（centroids 集合），通常大小為 `2^bits`。\n",
    "3. 將每個子向量替換為最接近 centroid 的 **索引值**。\n",
    "\n",
    "如此一來，一個浮點向量就可以轉換為一串小整數編碼，大幅減少記憶體使用量。\n",
    "\n",
    "**查詢時：**\n",
    "- 不直接計算向量距離，而是使用查詢向量各子向量與 codebook 的 **查表距離**。\n",
    "- 將每個子向量的距離加總作為近似距離。\n",
    "\n",
    "**優點：**\n",
    "- **大幅壓縮記憶體**（可縮小 10–100 倍）。\n",
    "- **加速距離計算**。\n",
    "\n",
    "**缺點：**\n",
    "- 會產生量化誤差，降低精確度。\n",
    "\n",
    "---\n",
    "\n",
    "### 🔗 IVF + PQ（混合索引）\n",
    "\n",
    "**概念：**\n",
    "- **IVF**：縮小搜尋範圍（只看部分 cluster）。\n",
    "- **PQ**：壓縮 cluster 內向量，加快運算。\n",
    "\n",
    "**結果：**\n",
    "- **搜尋速度快**、**記憶體效率高**。\n",
    "- 精確度略有下降，但通常可接受。\n",
    "\n",
    "**典型應用：**  \n",
    "大規模 **語意搜尋**、**embedding 檢索** 或 **影像相似度搜尋**，需要高效率搜尋大量向量。\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 總結\n",
    "\n",
    "| 索引類型       | 描述                                   | 精準度 | 速度 | 記憶體 | 是否需要訓練 |\n",
    "|----------------|----------------------------------------|---------|------|--------|----------------|\n",
    "| **IndexFlatL2** | 精確暴力搜尋                           | ✅ 高    | ❌ 慢 | ❌ 大   | 否             |\n",
    "| **IVF**         | 基於 cluster 的倒排搜尋                 | ⚖️ 中   | ✅ 快 | ✅ 較小 | 是             |\n",
    "| **PQ**          | 向量量化與壓縮                          | ⚖️ 中   | ✅ 快 | ✅ 最小 | 是             |\n",
    "| **IVF + PQ**    | Cluster + Quantization（混合）          | ⚖️ 中   | ✅✅ 非常快 | ✅✅ 緊湊 | 是             |\n",
    "\n",
    "---\n",
    "\n",
    "> 🧭 **簡而言之：**  \n",
    "> - `IndexFlatL2` → 精確但慢。  \n",
    "> - `IVF` → 篩選搜尋範圍。  \n",
    "> - `PQ` → 壓縮向量與加速計算。  \n",
    "> - `IVF + PQ` → 結合兩者，實現**快速、節省記憶體**的近似最近鄰搜尋。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded4662-2ab5-4b4c-bab7-678f6f02f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "# The raw FAISS index\n",
    "faiss_index = vectorstore.index  \n",
    "\n",
    "# Extract all vectors from the FAISS index\n",
    "# (returns numpy array of shape [n_vectors, dim])\n",
    "vectors = faiss_index.reconstruct_n(0, faiss_index.ntotal)\n",
    "\n",
    "dimension = vectors.shape[1]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. 建立 IVF + PQ FAISS 索引\n",
    "# -----------------------------\n",
    "nlist = 1  # 聚類中心數量\n",
    "m = 1      # PQ 分段數\n",
    "bits = 8\n",
    "quantizer = faiss.IndexFlatL2(dimension)  # 基礎量化器\n",
    "\n",
    "# IndexIVFPQ：IVF + PQ 索引\n",
    "index = faiss.IndexIVFPQ(quantizer, dimension, nlist, m, bits)\n",
    "index.train(vectors)\n",
    "index.add(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800edd89-8c4e-4965-a7e6-c44b542d48fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore import InMemoryDocstore\n",
    "\n",
    "# -----------------------------\n",
    "# 4. 封裝到 LangChain FAISS\n",
    "# -----------------------------\n",
    "# 這裡我們直接把 faiss 索引和文本對應起來\n",
    "faiss_db = FAISS(\n",
    "    embedding_function=embeddings.embed_query,  # 嵌入函數\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(\n",
    "        {i: doc for i, doc in enumerate(documents)}\n",
    "    ),\n",
    "    index_to_docstore_id={i: i for i in range(len(documents))}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda19b68-aa3c-4bc6-bee6-31e9cae66170",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_ann = faiss_db.as_retriever(search_kwargs={'k': 5})\n",
    "retriever_ann.invoke(\"夕陽無限好\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821359f8-fde9-44dc-8cfb-bb5acbe3a47f",
   "metadata": {},
   "source": [
    "## Runtime Configuration\n",
    "\n",
    "複習上星期學到的東西: 透過Runtime Configuration動態的調整搜索器的參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58945a-674e-4501-be3b-22ac739cb9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableField\n",
    "\n",
    "query = \"夕陽無限好\"\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\").configurable_fields( \\\n",
    "                                        search_kwargs=ConfigurableField(\n",
    "                                                id=\"hello_search\",\n",
    "                                            )\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e72f2c-dfd1-4de9-b065-ec77f2a0c75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(query, config={\"configurable\": {\"hello_search\": {\"k\": 7}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198a2242-afae-4197-a671-36ed1819f007",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(query, config={\"configurable\": {\"hello_search\": {\"k\": 3}}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81ce668-c24a-44c8-adfb-209b1118faa5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Three search types:\n",
    "\n",
    "### 1. similarity (default)\n",
    "\n",
    "- 這種搜索類型找到與你的查詢最相似的文檔。它會看你使用詞語的意思，並匹配具有相似意思的文檔。可以把它想像成找到與你感興趣的主題密切相關的文章或文檔。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b11f7d-93ab-438a-ad4f-28a621becdb3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### 2. similarity_score_threshold (相似性分數閾值):\n",
    "\n",
    "- 這種搜索類型設置一個最小相似性分數，只有達到這個分數的文檔才會被認為是相關的。只有那些在意思上與你的查詢非常接近的文檔才會被包含進來。它確保結果高度相關，並過濾掉不太相關的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e436f-96ab-4977-8300-78100b9a90a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cosine similarity\n",
    "\n",
    "https://api.python.langchain.com/en/latest/_modules/langchain_core/vectorstores.html\n",
    "\n",
    "elif search_type == \"similarity_score_threshold\":\n",
    "    docs_and_similarities = self.similarity_search_with_relevance_scores(\n",
    "        query, **kwargs\n",
    "    )\n",
    "    return [doc for doc, _ in docs_and_similarities]\n",
    "\n",
    "in subclass.\n",
    "Return docs and relevance scores in the range [0, 1].\n",
    "\n",
    "0 is dissimilar, 1 is most similar.\n",
    "\"\"\"\n",
    "\n",
    "query = \"傍晚心情鬱悶，登高望景。眼前的夕陽極為壯麗，但它即將沉沒，這就像人生或理想，美好卻轉瞬即逝\"\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.2, \"k\": 5}\n",
    ")\n",
    "\n",
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce400da-f757-4691-a656-2aad09a7a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.5, \"k\": 5}\n",
    ")\n",
    "\n",
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a1177f-f9b0-4bd7-9274-cbb4f657affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.7, \"k\": 5}\n",
    ")\n",
    "\n",
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2855c8-f541-48b3-b0c6-0968bf79e004",
   "metadata": {},
   "source": [
    "### 如何取得文檔的分數?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fbffa6-450f-4994-b11a-587e35b95b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"傍晚心情鬱悶，登高望景。眼前的夕陽極為壯麗，但它即將沉沒，這就像人生或理想，美好卻轉瞬即逝\"\n",
    "\n",
    "vectorstore.similarity_search_with_score(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96048b42-5d83-4f89-b52a-ee686d93e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"傍晚心情鬱悶，登高望景。眼前的夕陽極為壯麗，但它即將沉沒，這就像人生或理想，美好卻轉瞬即逝\"\n",
    "\n",
    "vectorstore._similarity_search_with_relevance_scores(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71cd261-f11f-4bc5-bf94-1ab6b7609307",
   "metadata": {},
   "source": [
    "我們可以看到透過_similarity_search_with_relevance_scores 我們可以取得 cosine similarity 的分數\n",
    "\n",
    "### 試試看翻譯跟原文的相似度有多少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2532be-e70b-4369-bd33-0122e7d7585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"傍晚時分，心中感到鬱悶不快，我便驅車登上古老的高原。極目遠望，晚霞映照的夕陽格外壯麗動人，然而這份美景卻接近黃昏，轉瞬將要消逝。\"\n",
    "\n",
    "vectorstore._similarity_search_with_relevance_scores(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17f3c51-2da0-455e-a3e9-f76dd4a8a1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"人生中最美好的事物，往往正如夕陽般壯麗，卻難免走向衰落與消亡。\"\n",
    "\n",
    "vectorstore._similarity_search_with_relevance_scores(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a2212f-f887-4def-8abc-ba6900d4c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = dedent(\"\"\"\n",
    "傍晚時分，心裡難以言說的惆悵悄然浮起，我便乘車登上那片古老的高原。天地遼闊，霞光萬丈，夕陽的光彩無比絢麗，彷彿要將最後的熱情全部燃盡。可惜它再怎麼燦爛，也只是黃昏的前奏，美麗正因將逝而更添傷感。\n",
    "\"\"\")\n",
    "\n",
    "vectorstore._similarity_search_with_relevance_scores(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bf1f05-0b11-41f7-8747-0dd62cab0565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 這些分數在幾何上看起來如何?\n",
    "\n",
    "import math\n",
    "\n",
    "print(math.acos(0.5351006626402812)/math.pi * 180)\n",
    "\n",
    "print(math.acos(0.6803903535716722)/math.pi * 180)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8fdd0f-932b-4299-a498-e70c738d26ed",
   "metadata": {},
   "source": [
    "有沒人有想要挑戰能不能超過0.68?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1641feed-795f-4d07-8af6-2592d3af8492",
   "metadata": {},
   "source": [
    "** 自動化評分系統 **\n",
    "\n",
    "國文考試喜歡問作者在想啥，但是不同的老師評分標準可能不一樣。\n",
    "那乾脆用一個Embedding系統來計分，保證公平性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7ec1ad-7c59-49b6-aea7-5a5b0ef81bb0",
   "metadata": {},
   "source": [
    "### 3. MMR, Maximum Marginal Relevance (MMR, 最大邊際相關性):\n",
    "\n",
    "- 這種方法在找到與你的查詢相似的文檔的同時，也確保結果是多樣的。這就像是在一個主題上尋求多種意見，避免得到過多相同的東西。它有助於避免搜索結果的冗餘。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405ec7ff-cb27-4753-ab27-da1ccaffbddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://miro.medium.com/v2/resize:fit:720/format:webp/1*c0c19i2tPSWZaHwQ7cVMrg.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6fa28b-9b5e-4c88-88ce-e5df98033621",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type='mmr', search_kwargs={'k': 3, 'fetch_k': 50, 'lambda_mult': 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a612076-ff28-4aed-bae4-0cd3aee30d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"傍晚時分，心中感到鬱悶不快，我便驅車登上古老的高原。極目遠望，晚霞映照的夕陽格外壯麗動人，然而這份美景卻接近黃昏，轉瞬將要消逝。\"\n",
    "\n",
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5160437-1d37-4e08-ac25-7a6f28ed40c8",
   "metadata": {},
   "source": [
    "### 如何使用Metadata?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76537b1f-c3b3-44e0-a1d5-7a0e2fcf3b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type='mmr', search_kwargs={'k': 3, 'fetch_k': 50, 'lambda_mult': 0.1,\n",
    "                                                                       \"filter\": {'詩體': \"五言絕句\"}})\n",
    "\n",
    "query = \"傍晚時分，心中感到鬱悶不快，我便驅車登上古老的高原。極目遠望，晚霞映照的夕陽格外壯麗動人，然而這份美景卻接近黃昏，轉瞬將要消逝。\"\n",
    "\n",
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148fa795-f70d-4ac9-ad9c-520c566f7220",
   "metadata": {},
   "source": [
    "更多古典詩在這裡，你有辦法把他們抓下來並且整理成Structured Data嗎?\n",
    "\n",
    "https://github.com/rainrambler/QTS/blob/main/qts_zht.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b97f58-2e9a-452c-b6d2-31c3182524ef",
   "metadata": {},
   "source": [
    "## 複數條件過濾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d91d4a3-4d0d-49e1-9986-504a78a871a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poem[df_poem[\"作者\"]=='李商隱']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b3467f-fc04-4aa0-b2e9-e1fa6e6e9992",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={'k': 3,\n",
    "                                                                              'filter': {'詩體': \"五言律詩\",\n",
    "                                                                                         '作者': '李商隱'}})\n",
    "\n",
    "T = retriever.invoke(query)\n",
    "\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b3f7e-b7a3-41e6-8c9a-0b83f198b01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={'k': 3, 'fetch_k': 100,\n",
    "                                                                              'filter': {'詩體': \"五言律詩\",\n",
    "                                                                                         '作者': '李商隱'}})\n",
    "\n",
    "T = retriever.invoke(query)\n",
    "\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5abb7f-e451-48ed-9feb-9d6d48c57cf1",
   "metadata": {},
   "source": [
    "這是因為FAISS 使用 Post-filter: 先使用相似度排序前fetch_k，然後再用filter過濾。\n",
    "\n",
    "可以試試看其他的檢索器，像是QRANT (沒正式在工作上使用過)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d236cca3-a64b-41e0-a73e-169b2ad21f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU langchain-qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c52604-e319-40fa-973d-b5675a8ee462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接從FAISS vectorstore將vectors抽取出來\n",
    "faiss_index = vectorstore.index  \n",
    "\n",
    "# Extract all vectors from the FAISS index\n",
    "# (returns numpy array of shape [n_vectors, dim])\n",
    "vectors = faiss_index.reconstruct_n(0, faiss_index.ntotal)\n",
    "\n",
    "dimension = vectors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce49638-c473-44af-af6d-032f08deb465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore, RetrievalMode\n",
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "\n",
    "client = QdrantClient(path=\"/tmp/langchain_qdrant\")\n",
    "\n",
    "collection_name = \"demo_collection\"\n",
    "\n",
    "# Qdrant server初始化\n",
    "try:\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=dimension, distance=Distance.COSINE),\n",
    "    )\n",
    "except ValueError:\n",
    "    client.delete_collection(collection_name=collection_name)\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=dimension, distance=Distance.COSINE),\n",
    "    )\n",
    "\"\"\"\n",
    "Method create_collection is defining a new vector collection inside Qdrant (kind of like creating a table in SQL).\n",
    "- Creates a named collection in Qdrant where your vectors + metadata will live.\n",
    "- Each collection has its own configuration: vector dimensionality, distance metric, storage options, etc.\n",
    "\n",
    "collection_name: just a string identifier (like a table name).\n",
    "- You’ll later refer to it in your QdrantVectorStore and queries.\n",
    "- In your example: \"demo_collection\" is the container where all vectors will be stored.\n",
    "\n",
    "The dimension of your embedding vectors (must match your embedding model’s output size).\n",
    "\n",
    "Remove collection:\n",
    "client.delete_collection(collection_name=\"demo_collection\")\n",
    "\"\"\"\n",
    "\n",
    "# 將數據上載到server裡\n",
    "client.upsert(\n",
    "    collection_name=\"demo_collection\",\n",
    "    points=[models.PointStruct(id=idx + 1,\n",
    "                               vector=vector,\n",
    "                               payload={\"page_content\": document.page_content,\n",
    "                                        \"metadata\": document.metadata}) for idx, (document, vector) in enumerate(zip(documents, vectors))]\n",
    ")\n",
    "\n",
    "# 建立 vectorstore\n",
    "vectorstore_QVS = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"demo_collection\",\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fe9b53-efa3-4550-adf3-8e062da4dccc",
   "metadata": {},
   "source": [
    "### Challenge: 你可以使用method from_documents 來創立一個vectorstore嗎?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901f2a3-f4c5-4a7e-8861-83f05cd73a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_QVS = vectorstore_QVS.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})\n",
    "retriever_QVS.invoke(\"夕陽無限好\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7baf60-5140-4e6a-8c7d-0db9a4ede807",
   "metadata": {},
   "source": [
    "### Qdrant透過filter過濾內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca225fa-2224-4d18-a0b1-2cd1cca7da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import Filter, FieldCondition, MatchValue\n",
    "\n",
    "filter_ = Filter(\n",
    "    must=[\n",
    "        FieldCondition(key=\"metadata.作者\", match=MatchValue(value=\"李商隱\")),\n",
    "        FieldCondition(key=\"metadata.詩體\", match=MatchValue(value=\"五言律詩\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retriever_QVS = vectorstore_QVS.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5, \n",
    "                                                                                      'filter': filter_})\n",
    "retriever_QVS.invoke(\"夕陽無限好\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93735c5c-cf46-408a-b50a-82b66c816391",
   "metadata": {},
   "source": [
    "### Question \n",
    "\n",
    "假設你寫了一個穿越小說，角色穿越到了古代，為了凸顯主角的文學素養，你希望他可以吟詩作對。\n",
    "如何寫一個小App，根據需求，來幫助你完成這件事情。\n",
    "\n",
    "(15分鐘)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e80e7d-c9c8-470b-b03d-88fa92f92c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe9900d-c533-4a12-af77-5418ab2ff41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poem['詩體'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54616b0-8872-4984-92ec-383bafced661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "class requirements(BaseModel):\n",
    "\n",
    "    question: str = Field(description=\"\")\n",
    "    answer: Literal['五言古詩', '七言古詩', '七言律詩', '五言絕句', '樂府', '七言絕句', '五言律詩'] = Field(description=\"\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c2149-28d0-494b-9d51-bff820042618",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = PydanticOutputParser(pydantic_object=requirements)\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "system_template = dedent(\"\"\"\n",
    "                  \"\"\")\n",
    "\n",
    "human_template = dedent(\"\"\"\n",
    "                 format instruction: {format_instructions}\n",
    "                 \"\"\")\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variable\": [],\n",
    "                    \"partial_variables\": {\"format_instructions\": \n",
    "                                          format_instructions}}}\n",
    "\n",
    "requirement_prompt_template = build_standard_chat_prompt_template(input_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc50ad2-8895-4c02-8ccc-55ed3565f783",
   "metadata": {},
   "source": [
    "# LangChain Expression Language (LCEL)\n",
    "\n",
    "> 🎯 **本章學完你將能學會什麼：**\n",
    "> - 理解 **LangChain Expression Language (LCEL)** 的設計理念與語法特性  \n",
    "> - 掌握 LCEL 如何以「鏈式運算子 `|`」實現資料流的模組化組合  \n",
    "> - 熟悉 **Runnable** 的核心概念，了解各類 Runnable（如 `RunnableLambda`、`RunnableParallel`、`RunnablePassthrough`）的用途  \n",
    "> - 學會構建多階段 Pipeline：從 Prompt → LLM → Parser 的自動化串接  \n",
    "> - 能運用 LCEL 進行 **生成 → 評估 → 改進（Reflection Agent）** 的循環架構設計  \n",
    "> - 理解 **Runtime Configuration** 的動態參數傳遞方法，實現可重組與條件化檢索  \n",
    "> - 掌握 LCEL 在 **語意檢索（Semantic Retriever）** 中的整合實務  \n",
    "> - 能夠將同步與異步流（Synchronization / Asynchronization）轉換，以提升高併發執行效率  \n",
    "> - 學會使用 LCEL 建立 **平行化工作流（RunnableParallel）** 與 **自定義任務鏈**  \n",
    "> - 了解如何利用 LLM 實現 **程式生成（Code Generation）** 與自動執行（`exec()`）  \n",
    "> - 綜合應用 LCEL 的思維，設計可擴展、可維護的 AI 工作流架構  \n",
    "\n",
    "\n",
    "**LangChain Expression Language (LCEL)** 是一種強大且靈活的語法，用於建構高效的資料處理流水線（Pipeline）。它允許開發者以鏈式（Chain）方式將多個操作（如檢索、生成、處理）無縫串聯，將前一個節點的輸出作為下一個節點的輸入，形成流暢的資料流。LCEL 的設計強調模組化、可讀性和可維護性，特別適用於結合大型語言模型（LLM）與外部工具（如向量資料庫、API）來解決複雜任務。\n",
    "\n",
    "## 為什麼使用 LCEL？\n",
    "- **高效能與可擴展性**：透過異步處理（Asynchronous Flow）與並行執行（Parallelization），LCEL 能在高併發場景下顯著提升效率。\n",
    "- **簡潔的語法**：使用 `|` 運算子串聯操作，代碼簡潔且易於理解，類似於 Unix 的管道（Pipe）概念。\n",
    "- **整合性強**：LCEL 能輕鬆整合 LangChain 的各種組件（如 Retriever、PromptTemplate、OutputParser）與外部工具（如 FAISS、Qdrant）。\n",
    "\n",
    "## 核心概念\n",
    "1. **Runnable 物件**：LCEL 的基本單位，代表一個可執行的操作（如檢索、模型推理、資料轉換）。常見的 Runnable 包括 `RunnablePassthrough`（保留輸入）、`RunnableLambda`（自訂函數）等。\n",
    "2. **流水線操作**：使用 `|` 將多個 Runnable 串聯，前一階段的輸出自動傳遞到下一階段。例如：`prompt | model | parser`。\n",
    "4. **並行與異步**：支援 `RunnableParallel` 同時執行多個獨立任務，以及 `ainvoke` 方法進行異步處理，適用於高吞吐量應用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd952993-29ad-4877-8795-5cf49e084105",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Official diagram flow\n",
    "\n",
    "Image(filename= \"tutorial/LLM+Langchain/Week-2/lcel pipeline.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48a82ea-35b8-4252-976c-ea418dd3848d",
   "metadata": {},
   "source": [
    "## Base of Reflection Agent\n",
    "\n",
    "- https://huggingface.co/blog/Kseniase/reflection\n",
    "- https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/reflection/reflection.ipynb\n",
    "\n",
    "generate → critique → improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b18730-aa1b-4158-8eb2-e0be657e8e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "query = dedent(\"\"\"\n",
    "俗話說：「龍生九子，各有不同。」在廣闊浩瀚的海洋之中，就有一頭孤獨的鯨魚——五十二赫茲鯨魚。牠聲音的頻率天生便比同伴還要高，這項特別之處，也導致了牠與同伴產生了無法溝通的鴻溝。看見這則故事的我，不禁思考，在如此多元的人間，是否也有像五十二赫茲鯨魚一般，天生便與眾不同？\n",
    "\n",
    "回首童年，我印象最為深刻的一刻，是初識字時，與文字互相理解的那一瞬、是當我第一次讀完一個句子時，它將自身的意義傳入我腦中的那一瞬。自此，我便對文字、語言抱有特殊的感情，也十分享受閱讀與朗誦。那種將自身與文字經由一點一滴積累而連接起來的感情，使我心靈感到十分富足。\n",
    "\n",
    "而當我步入校園接觸同儕時，驀然驚覺我與別人的閱讀速度十分不同。每當我已讀完一篇文章，但同學可能只完成了一半甚至三分之二。同時，我在生字讀音方面也異常的執著，因此被同學抱怨有「文字潔癖」。面對同儕抱怨的我，也只好強忍對耳邊時而出現字錯讀音的不適，開始刻意忽略心裡對它的執念，只為想要與別人一樣，想要和朋友互相理解。\n",
    "\n",
    "直到多年前，因緣際會之下認識了「五十二赫茲」這獨特的存在。牠的身影在我心中烙下一道深刻的痕跡。因為牠，我開始接受自己與他人的不同；也因為牠，我明白了，我對文字的執著，並不是一種負面的特質，而是上天賜予我的禮物，我開始在寫作上揮灑自如。這讓我知道，不要在一開始便用否定的眼光看待自己的特質。也許這特別之處，會使我們與五十二赫茲鯨魚一般孤獨，會使我們遭受他人的不理解與排斥，但也會讓我們與眾不同。\n",
    "\n",
    "關於此，我想說的是，勇敢地綻放自己的特別，也讓自己成為自己和世人眼中，最閃耀的五十二赫茲鯨魚。\n",
    "\"\"\")\n",
    "\n",
    "## Teacher LLM\n",
    "system_template = dedent(\"\"\"\n",
    "你是一個教學與寫作經驗豐富的台灣大學中文系教授，你要來負責給予作文評分與回饋。\n",
    "\"\"\")\n",
    "\n",
    "human_template = dedent(\"\"\"\n",
    "Title: {title}\n",
    "\n",
    "Article:\n",
    "{article}\n",
    "\"\"\")\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variable\": [\"title\", \"article\"],\n",
    "                    }}\n",
    "\n",
    "chat_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "chat_prompt = chat_prompt_template.invoke({\"article\": query,\n",
    "                                           \"title\": \"關於五十二赫茲，我想說的是…\"})\n",
    "\n",
    "feedback = model.invoke(chat_prompt)\n",
    "\n",
    "print(feedback.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b8bdb4-5c3f-4a32-88e1-cafd5eb6b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將所有邏輯用 pipeline 符號 |\n",
    "\n",
    "feedback_pipeline = chat_prompt_template|model|StrOutputParser()\n",
    "\n",
    "feedback = feedback_pipeline.invoke({\"article\": query,\n",
    "                                     \"title\": \"關於五十二赫茲，我想說的是…\"})\n",
    "\n",
    "print(feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18052a06-c2cd-447f-891b-a4d83ed87eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "class Output(BaseModel):\n",
    "    name: str = Field(description=\"The revised article in traditional Chinese (繁體中文), please do not include the title.\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Output)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "## Generate\n",
    "system_template = dedent(\"\"\"\n",
    "你是一個在準備考試的高中生，你將根據反饋強化作文的內容。\n",
    "\"\"\")\n",
    "\n",
    "human_template = dedent(\"\"\"\n",
    "Title: {title}\n",
    "\n",
    "Old Article:\n",
    "{article}\n",
    "\n",
    "Feedback:\n",
    "{feedback}\n",
    "\n",
    "Output instruction: {format_instructions}\n",
    "\n",
    "Revised Article:\n",
    "\"\"\")\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variable\": [\"title\", \"article\", \"feedback\"],\n",
    "                    \"partial_variables\": {'format_instructions': format_instructions}\n",
    "                    }}\n",
    "\n",
    "chat_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "revision_pipeline = chat_prompt_template|model|output_parser\n",
    "\n",
    "revised_result = revision_pipeline.invoke({\"article\": query,\n",
    "                                           \"title\": \"關於五十二赫茲，我想說的是…\",\n",
    "                                           \"feedback\": feedback})\n",
    "\n",
    "print(revised_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c34d0-b697-4783-b2ea-6884a46e1c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(revised_result.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d70884-54e9-436a-b822-e5bf94f401a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback = feedback_pipeline.invoke({\"article\": revised_result.name,\n",
    "                                     \"title\": \"關於五十二赫茲，我想說的是…\"})\n",
    "\n",
    "print(feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a02a43-d680-4112-84cf-63734c190a41",
   "metadata": {},
   "source": [
    "### 如何結合 feedback_pipeline 和 revision_pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8200a866-4571-43aa-850b-c58c1f4097cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RunnablePassThrough: 酒肉穿腸過 佛祖心中留\n",
    "# 技術一點的說法: 它是一個 no-op（無操作）的 runnable，常用來保留數據流的連貫性，或作為調試／替換的 placeholder。\n",
    "\n",
    "whole_pipeline = RunnablePassthrough.assign(feedback=feedback_pipeline)|revision_pipeline\n",
    "\n",
    "revised_version = whole_pipeline.invoke({\"article\": query,\n",
    "                                         \"title\": \"關於五十二赫茲，我想說的是…\"})\n",
    "\n",
    "print(revised_version.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c13cd44-58dc-4669-8995-72d5b15e5f46",
   "metadata": {},
   "source": [
    "assign 就像是 在 Pipeline 中加入一個「中途站」或「資訊亭」，在主數據流（例如 article, title）繼續向前時，它同時執行一個子流程（例如 feedback_pipeline），並將子流程的結果（feedback）以新的 Key 注入到主數據流中，以便後續步驟使用。\n",
    "\n",
    "這是Generate - Reflection的雛型。可以隨需求將它的架構弄得更複雜。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c1be5-f855-4d66-841a-9d993431daa4",
   "metadata": {},
   "source": [
    "## 延續上周\n",
    "\n",
    "上週我們使用BM25做Retriever\n",
    "這次我們把BM25替換成Semantic Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66413ce-ccb2-4e2f-b3ee-fa6880e4baa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "class Output(BaseModel):\n",
    "    name: str = Field(description=\"The generated poem in traditional Chinese (繁體中文)\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Output)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "query = dedent(\"\"\"\n",
    "蒹葭蒼蒼、白露為霜。\n",
    "所謂伊人、在水一方。\n",
    "遡洄從之、道阻且長。\n",
    "遡遊從之、宛在水中央。\n",
    "\"\"\")\n",
    "\n",
    "system_template = dedent(\"\"\"\n",
    "You are a helpful AI assistant with expertise in classical Chinese literature.\n",
    "You understand all the nuance and history background of all the content.\n",
    "\"\"\")\n",
    "\n",
    "human_template = dedent(\"\"\"\n",
    "Create a {poetic_form} which shares the same semantic of {query}\n",
    "\n",
    "Examples of {poetic_form}:\n",
    "\n",
    "{context}\n",
    "\n",
    "Output instruction: {format_instructions}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variable\": [\"query\", \"context\", \"poetic_form\"],\n",
    "                    \"partial_variables\": {'format_instructions': format_instructions}}}\n",
    "\n",
    "chat_prompt_template = build_standard_chat_prompt_template(input_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce7c75c-8eae-42d8-9640-59acc96edc17",
   "metadata": {},
   "source": [
    "### Runtime Configuration (運行時配置)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499532a9-b4b5-4ade-9ab0-73f912b9dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableField\n",
    "\n",
    "poetic_form = \"五言絕句\"\n",
    "\n",
    "retriever_QVS = vectorstore_QVS.as_retriever(search_type=\"similarity\")\n",
    "retriever_QVS = retriever_QVS.configurable_fields(search_kwargs=ConfigurableField(id=\"qdrant_search_kwargs\"))\n",
    "\n",
    "filter_ = Filter(\n",
    "    must=[\n",
    "        FieldCondition(key=\"metadata.詩體\", match=MatchValue(value=poetic_form)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "semantic_documents = retriever_QVS.invoke(query, config={\"configurable\":\n",
    "                                                          {\"qdrant_search_kwargs\":{\n",
    "                                                                \"k\": 5,\n",
    "                                                                \"filter\": filter_}}})\n",
    "\n",
    "semantic_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce780acd-eecc-4054-9a63-042c89170c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\\n\\n\".join([c.page_content for c in semantic_documents])\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e5b300-18b9-44db-b442-c8babd7bacfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = chat_prompt_template.invoke({\"query\": query,\n",
    "                                           \"poetic_form\": \"五言絕句\",\n",
    "                                           \"context\": context})\n",
    "print(chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188e6bdd-86fd-4e0d-a95f-fed4e908c7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_poem = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                        model_name=\"gpt-4o\", temperature=0)\n",
    "\n",
    "output = model_poem.invoke(chat_prompt)\n",
    "output_parser.parse(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9652740-0406-46b9-a230-ae54e56af15c",
   "metadata": {},
   "source": [
    "上述的操作中有兩個挑戰:\n",
    "1. semantic_documents = retriever_QVS.invoke(query, config={\"configurable\":\n",
    "                                                          {\"qdrant_search_kwargs\":{\n",
    "                                                                \"k\": 5,\n",
    "                                                                \"filter\": filter_}}})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   沒有辦法直接pass config (至少我目前還不知道)\n",
    "\n",
    "3. context = \"\\n\".join([c.page_content for c in semantic_documents])\n",
    "\n",
    "   這一步不是一個Runnable\n",
    "\n",
    "\n",
    "解法: 套殼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b888c628-1a2b-4698-86cc-9dfc05e144df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import chain, RunnableLambda\n",
    "\n",
    "# Runnable只能接收一個變數。所以當你要送入複數變數的時候，請用dictionary\n",
    "\n",
    "@chain\n",
    "def config_retriever(kwargs):\n",
    "\n",
    "    # 在實際上的軟體工程這會比較複雜一些，因為有時候不見得會有條件\n",
    "    \n",
    "    query = kwargs['query']\n",
    "    filter_ = Filter(\n",
    "    must=[\n",
    "        FieldCondition(key=\"metadata.詩體\", match=MatchValue(value=kwargs[\"poetic_form\"])),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    semantic_documents = retriever_QVS.invoke(query, config={\"configurable\":\n",
    "                                                              {\"qdrant_search_kwargs\":{\n",
    "                                                                    \"k\": 5,\n",
    "                                                                    \"filter\": filter_}}})\n",
    "\n",
    "    return semantic_documents\n",
    "\n",
    "\n",
    "@chain\n",
    "def document_2_context(documents):\n",
    "\n",
    "    context = \"\\n\\n\".join([c.page_content for c in documents])\n",
    "\n",
    "    return context\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67ce875-7c51-4fa7-913c-3f0f67907144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一路Combo開到底\n",
    "\n",
    "context_pipeline = config_retriever|document_2_context\n",
    "\n",
    "poem_pipeline = RunnablePassthrough.assign(context=context_pipeline)|chat_prompt_template|model_poem|output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9110c7d7-12f0-442c-a912-488435294362",
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_pipeline.invoke({\"query\": query,\n",
    "                      \"poetic_form\": \"五言絕句\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba419208-49a4-48b6-b96a-626963d9e798",
   "metadata": {},
   "source": [
    "### 平行運算 (Parallelize steps)\n",
    "\n",
    "將複數但相互獨立的流程同時啟動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c25e8c-eda5-464d-9abf-75ee04f70cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "poem_pipeline = RunnablePassthrough.assign(context=context_pipeline)|chat_prompt_template|model_poem|output_parser\n",
    "\n",
    "poem_pipeline_1 = RunnablePassthrough.assign(poetic_form=itemgetter(\"poetic_form_1\"))|poem_pipeline\n",
    "poem_pipeline_2 = RunnablePassthrough.assign(poetic_form=itemgetter(\"poetic_form_2\"))|poem_pipeline\n",
    "\n",
    "map_chain = RunnableParallel(poem_1=poem_pipeline_1, poem_2=poem_pipeline_2)\n",
    "\n",
    "map_chain.invoke({\"poetic_form_1\": \"五言絕句\", \"poetic_form_2\": \"七言絕句\", \"query\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21acde53-82c9-451b-ae23-373a10544e13",
   "metadata": {},
   "source": [
    "### 異步流 (Asynchronization)\n",
    "\n",
    "當一個流程進入等待狀態（例如等待外部 API 回應、讀寫檔案、資料庫查詢），這個工作會「讓出執行權」給事件迴圈 (event loop)。\n",
    "此時事件迴圈可以去執行其他等待中的工作，而不是卡在原地。\n",
    "\n",
    "價值：\n",
    "在高併發的 AI 應用場景（例如大量查詢、同時呼叫模型 API），異步流能顯著提升資源利用率，減少等待時間 → 提升整體吞吐量。\n",
    "（注意：異步不會讓單一請求變快，而是讓系統能同時處理更多請求。）\n",
    "\n",
    "建議的開發方法：\n",
    "\n",
    "1. 先建立同步流程：確保邏輯正確，方便除錯。\n",
    "\n",
    "2. 再轉成異步流程：將 I/O 密集的部分（API 呼叫、DB 存取、檔案處理）改寫成 async / await，或用 asyncio.to_thread 包裝同步函式。\n",
    "\n",
    "3. 測試效能與正確性：確認異步版本在高並發情境下能穩定運作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a284c47-41dc-4c3a-b021-d9888e78ea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "async def config_retriever_async(kwargs):\n",
    "    \"\"\"Async retriever\"\"\"\n",
    "\n",
    "    query = kwargs['query']\n",
    "    filter_ = Filter(\n",
    "        must=[\n",
    "            FieldCondition(\n",
    "                key=\"metadata.詩體\",\n",
    "                match=MatchValue(value=kwargs[\"poetic_form\"])\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # retriever_QVS must support ainvoke()\n",
    "    semantic_documents = await retriever_QVS.ainvoke(\n",
    "        query,\n",
    "        config={\n",
    "            \"configurable\": {\n",
    "                \"qdrant_search_kwargs\": {\n",
    "                    \"k\": 5,\n",
    "                    \"filter\": filter_,\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return semantic_documents\n",
    "\n",
    "\n",
    "@chain\n",
    "async def document_2_context_async(documents):\n",
    "    \"\"\"Async doc -> context\"\"\"\n",
    "    context = \"\\n\\n\".join([c.page_content for c in documents])\n",
    "    return context\n",
    "\n",
    "\n",
    "# Pipeline definition (works for sync + async)\n",
    "context_pipeline_async = config_retriever_async | document_2_context_async\n",
    "\n",
    "poem_pipeline_async = (\n",
    "    RunnablePassthrough.assign(context=context_pipeline)\n",
    "    | chat_prompt_template\n",
    "    | model_poem\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb9bc35-2929-4275-97f1-13112414acdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await poem_pipeline_async.ainvoke({\"query\": query, \"poetic_form\": \"五言絕句\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef76605-1a48-4e09-9187-909050ef0e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3161208-0793-4f4d-8ff9-3db014141726",
   "metadata": {},
   "source": [
    "比較同步流(Synchronization)和異步流(Asynchronization)的時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c36690-5f7a-43e9-b40a-1ad1972ba703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "begin = datetime.now()\n",
    "\n",
    "for _ in range(5):\n",
    "    _ = poem_pipeline.invoke({\"query\": query, \"poetic_form\": \"五言絕句\"})\n",
    "\n",
    "end = datetime.now()\n",
    "\n",
    "print(end - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed49e613-b5ed-451c-9e7d-261600b4b24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = datetime.now()\n",
    "\n",
    "for _ in range(5):\n",
    "    _ = await poem_pipeline_async.ainvoke({\"query\": query, \"poetic_form\": \"五言絕句\"})\n",
    "\n",
    "end = datetime.now()\n",
    "\n",
    "print(end - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a84124-4603-4937-ae18-e8fbc3af4cc9",
   "metadata": {},
   "source": [
    "## Coding with LLM\n",
    "\n",
    "如何使用大語言模型(LLM)產生代碼.\n",
    "\n",
    "1. 在使用ChatGPT的時候，可以順利地讓語言模型生成代碼\n",
    "2. 有些問題可以借助代碼的方式來得到正確的答案，像是一些數學上的計算問題。\n",
    "3. 如何透過API實現用LLM生成代碼解決問題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f70cb53-9c4b-426d-99aa-a041dd7c8f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "system_template = (\n",
    "    \"You are a highly skilled Python developer. Your task is to generate Python code strictly based on the user's instructions.\\n\"\n",
    "    \"Leverage statistical and mathematical libraries such as `statsmodels`, `scipy`, and `numpy` where appropriate to solve the problem.\\n\"\n",
    "    \"Your response must contain only the Python code — no explanations, comments, or additional text.\\n\\n\"\n",
    ")\n",
    "\n",
    "human_template = '{query}\\n\\nCode:'\n",
    "\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variable\": [\"query\"]}}\n",
    "\n",
    "chat_prompt = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "code_pipeline = chat_prompt|model|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbc9ea9-79fc-4175-a7f7-3d73db8c0879",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = code_pipeline.invoke({\"query\": \"Calculate the area of a circle with radius 3.8976\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ef6a1e-c69c-4cda-b459-166dc4bb6e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3002919a-25d2-48e1-ae57-d6f660a75720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "match = re.findall(r\"python\\n(.*?)\\n```\", code, re.DOTALL)\n",
    "python_code = match[0]\n",
    "\n",
    "exec(python_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b7aeaa-73e0-46f6-ab33-6fb4169d7922",
   "metadata": {},
   "source": [
    "代碼能夠順利執行，但如何提取出答案?\n",
    "\n",
    "其他人應該也有過類似的問題而應該已經有人提出解決辦法了，所以我就去問ChatGPT。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be55232-b794-4f39-9bbd-42a625f39906",
   "metadata": {},
   "source": [
    "### ✅ `exec(...)`\n",
    "\n",
    "- `exec()` runs the code you give it **as if it was a Python script**.\n",
    "- It does **not return values**; it just executes statements (like `import`, assignments, function definitions, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ `{}` — the *global namespace*\n",
    "\n",
    "- An **empty dictionary** is passed as the *global namespace*.\n",
    "- This isolates the execution from your actual global scope, which is **good for sandboxing** and avoiding side effects.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ `local_vars` — the *local namespace*\n",
    "\n",
    "- This dictionary collects all **local variables** defined during execution.\n",
    "- After the code runs, `local_vars` will contain all the variables and their values.\n",
    "\n",
    "```python\n",
    "{\n",
    "  'np': <module 'numpy'...>,\n",
    "  'radius': 3.8976,\n",
    "  'area': 47.73155744152567\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae8ff1a-f9eb-4b37-8105-9736989fad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79549ba-c6f2-43c9-87d4-3f3a6e36b470",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = python_code.strip().split('\\n')\n",
    "*stmts, last_line = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba95f8-d4fe-4246-bbd4-a6d3ef51575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e4bc4d-4a66-40b9-b004-2467a64eae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_vars = {}\n",
    "exec('\\n'.join(stmts), {}, local_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8bcc6d-cc75-4b8a-9957-dfae60542b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be9456b-ad99-4a17-9bb1-0813e483637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "math.pi * 3.8976 * 3.8976"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01bd704-15fa-4bdd-a40c-1f27a0f8acc2",
   "metadata": {},
   "source": [
    "What if we calculate the area without the code part?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee93fd-89c1-4377-9ba6-21a83709f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.invoke(\"Calculate the area of a circile with radius 3.8976\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a18250f-f2bc-4cea-ba41-0ff329aa2579",
   "metadata": {},
   "source": [
    "### Combine the code generation and code execution in LCEL\n",
    "\n",
    "生成代碼 -> 執行代碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdb1749-012a-45e3-b14e-17d07f375dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "\n",
    "\n",
    "@chain\n",
    "def code_execution(code):\n",
    "\n",
    "    match = re.findall(r\"python\\n(.*?)\\n```\", code, re.DOTALL)\n",
    "    python_code = match[0]\n",
    "    \n",
    "    lines = python_code.strip().split('\\n')\n",
    "    *stmts, last_line = lines\n",
    "\n",
    "    local_vars = {}\n",
    "    exec('\\n'.join(stmts), {}, local_vars)\n",
    "\n",
    "    return local_vars\n",
    "\n",
    "\n",
    "code_pipeline = chat_prompt|model|StrOutputParser()|code_execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ce4979-e6dc-48f2-bbc3-d8f2c7c30ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "17 * 89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ecd61c-c78c-4134-833e-a9e4d7d9e374",
   "metadata": {},
   "outputs": [],
   "source": [
    "17 * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcf0462-e14a-4ac6-9c99-b63ea69156f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_pipeline.invoke(\"What is the GCD of 1513 and 119?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4941cff8-c9a5-4d38-8f8e-bf51592563a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "5 * 10 * np.sin(35/180 * math.pi) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe482da-00d1-4119-8bbc-0045638f4564",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = code_pipeline.invoke(\"What is the area of a triangle, with two sides with length 10 and 5, and the angle between them is 35 degrees?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c084ada-d40a-40bf-954c-019d92179ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b32aff-9f4b-4975-847a-06a6c428fb02",
   "metadata": {},
   "source": [
    "能夠同時回傳問題，答案，過程嗎?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7070031b-abeb-428c-a7ca-a8a4ebd134e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_pipeline = RunnablePassthrough.assign(code=chat_prompt|model|StrOutputParser())|RunnablePassthrough.assign(answer=itemgetter('code')|code_execution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f388a737-8996-400c-8a23-6f8ca3071d8f",
   "metadata": {},
   "source": [
    "國小經典題目: 雞兔同籠。講真的我國小時完全不知道這怎麼做。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcc8817-3b74-47b3-bbac-ccf9af21dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = code_pipeline.invoke({\"query\":\"現有一籠子，裡面有雞和兔子若干隻，數一數，共有頭14個，腿38條。請問一共有幾隻雞?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db9bc92-22c6-420e-acc5-ad3ca687d23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "382dea26-4813-4d08-86a2-f3e98c93b980",
   "metadata": {},
   "source": [
    "高中機率問題: 在一副52張牌的常規樸克牌中，任意選出五張，得到full house的機率是多少，請用分數(numerator/denominator)的方式呈現答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a6d696-7d92-4361-8c78-4291365a17f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = code_pipeline.invoke({\"query\":\"在一副52張牌的常規樸克牌中，任意選出五張，得到full house的機率是多少?請用分數(numerator/denominator)的方式呈現答案。\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bea70f-c532-4e0c-8943-6fbd90aa0adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2259cf-b0bc-49b9-8dd4-58fe058ba8b3",
   "metadata": {},
   "source": [
    "有辦法做抽象代數嗎?\n",
    "1. 小角度單擺: 給繩長L， 重力常數g。求單擺週期\n",
    "2. 給予地球質量M，萬有引力係數G，地球半徑R。求從地面脫離地球重力場影響的最低初始速度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c5b973-48a4-4c2f-b462-82e49b8cd0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = code_pipeline.invoke(\"小角度單擺: 給繩長L， 重力常數g。求單擺週期。Give me the analytical expression.\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bad683-0ff7-47fb-94d5-94298174f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = code_pipeline.invoke(\"給予地球質量M，萬有引力係數G，地球半徑R。求從地面脫離地球重力場影響的最低初始速度。Give me the analytical expression.\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c243a9-d174-4bfa-97fb-60af9b69499d",
   "metadata": {},
   "source": [
    "這種有標準答案的題目其實非常適合測試LLM，因為只有對錯，沒有立場。\n",
    "像是剛剛用LLM生成詩，在格式的方面可以檢驗(平仄規則啥的)，但是內容品質很難檢驗。\n",
    "至於複雜的文章，可能品質檢驗就更困難了。\n",
    "\n",
    "那剛剛的生成結果有另一個問題，那就是答案的key都不固定。這會導致無法規模化生成，那我們要如何控制輸出來進行規模化生成?\n",
    "想像你是一個高中數學老師，段考題大概一次是40題，你總不希望一直要copy/paste..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9471293-55b6-4c8f-a3d8-670946f4661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "system_template = dedent(\"\"\"You are a highly skilled Python developer. Your task is to generate Python code strictly based on the user's instructions.\n",
    "                            Leverage statistical and mathematical libraries such as `statsmodels`, `scipy`, and `numpy` where appropriate to solve the problem.\n",
    "                            Your response must contain only the Python code — no explanations, comments, or additional text.\n",
    "                         \"\"\"\n",
    ")\n",
    "\n",
    "# 多加一行 'Always copy the final answer to a variable `answer`\n",
    "# 沒有訣竅，多試就行\n",
    "human_template = dedent(\"\"\"{query}\\n\\n\n",
    "                            Always copy the final answer to a variable `answer`\n",
    "                            Code:\n",
    "                        \"\"\")\n",
    "\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variable\": [\"query\"]}}\n",
    "\n",
    "chat_prompt = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "code_pipeline = chat_prompt|model|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac6e5b-c195-409b-bed8-0a8672e5393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = code_pipeline.invoke(\"What is the GCD of 1513 and 119?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8051423-81f5-432d-91b7-8d0a822f1534",
   "metadata": {},
   "outputs": [],
   "source": [
    "code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0992d6f9-fe12-4ca5-9169-eac34d4ddd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 你看到產生的結果改變了，所以函數code_execution也要跟著改變\n",
    "\n",
    "@chain\n",
    "def code_execution(code):\n",
    "    \n",
    "    match = re.findall(r\"python\\n(.*?)\\n```\", code, re.DOTALL)\n",
    "    python_code = match[0]\n",
    "    \n",
    "    lines = python_code.strip()#.split('\\n')\n",
    "    # *stmts, last_line = lines\n",
    "\n",
    "    local_vars = {}\n",
    "    exec(lines, {}, local_vars)\n",
    "\n",
    "    return local_vars\n",
    "\n",
    "code_execution.invoke(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a5aa63-4b5c-4c98-b9e2-7ca0fd8ec98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = code_pipeline.invoke(\"小角度單擺: 給繩長L， 重力常數g。求單擺週期。Give me the analytical expression.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d1d8c6-a462-46bd-997f-73b0a48da052",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_execution.invoke(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a44e1dd-db39-426c-9458-ace02e13527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_execution.invoke(code)['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec6a394-a5b8-4b64-b675-d338877faf5d",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "> 🎯 **本章學完你將能學會什麼：**\n",
    "> - 理解「模型評估（Model Evaluation）」在 AI 專案生命週期中的關鍵角色  \n",
    "> - 能分辨並監測三種常見的模型變化類型：  \n",
    ">   - **Model Drift**：模型行為隨版本或訓練資料改變的偏移  \n",
    ">   - **Data Drift**：輸入數據分佈隨時間演化而產生的變異  \n",
    ">   - **Model Resilience**：模型面對干擾（perturbation）時的穩定性與魯棒性    \n",
    "> - 能實作 **Input Perturbation（輸入干擾）** 技術，模擬實際噪音情境  \n",
    ">   - 文字錯誤（typos, case change, unicode homoglyphs）  \n",
    ">   - 同義改寫（paraphrasing）  \n",
    ">   - 隨機噪音與對抗攻擊（adversarial perturbations）  \n",
    "> - 理解 **Consistency Checking** 的概念：如何不依賴人工評估進行自我驗證  \n",
    ">   - 輸出語義相似度檢查（cosine similarity via embeddings）  \n",
    ">   - 自洽性（Self-consistency）與多次重試一致性量測  \n",
    ">   - 翻譯回譯（Round-trip Validation）策略  \n",
    "> - 能運用向量化工具（如 **SBERT / HuggingFace Embeddings**）進行輸出相似度比較  \n",
    "> - 學會使用 **Perplexity** 衡量文本流暢度與自然度（以 GPT-2 為基準模型）  \n",
    "> - 熟悉 **同步與異步批次運算（batch / abatch）** 技巧，提高測試效率  \n",
    "> - 能撰寫自動化流程：  \n",
    ">   - 清潔輸入 → 污染輸入 → 產生輸出 → 嵌入相似度 → Perplexity 評估  \n",
    "> - 具備分析模型在擾動下語義穩定性與語言流暢性的能力  \n",
    "> - 能以資料科學思維建立自動化模型評估系統，為模型持續優化提供量化依據  \n",
    "\n",
    "\n",
    "\n",
    "最近在找工作。評估(Evaluation)算是一個蠻被看重的技能。\n",
    "\n",
    "  1. Model Drift (模型隨著迭代的變化)\n",
    "     - 建立Golden Benchmark -> 測量輸出結果隨模型改變的變化\n",
    "  2. Data Drift (數據隨著時間的變化)\n",
    "     - 量測數據的變化\n",
    "  3. Model Resiliece (模型有多Robust)\n",
    "     - 建立Golen Benchmark -> 干擾輸入數據，量測輸出和原始輸出的差異"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c19d0d-bb4b-45f1-bca3-c1acb7372e92",
   "metadata": {},
   "source": [
    "## Model Resilience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e29d494-2579-4366-8336-def8d3ae3838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Define the HTML to display images side by side\n",
    "html = \"\"\"\n",
    "<div style=\"display: flex; justify-content: space-around;\">\n",
    "    <div>\n",
    "        <img src=\"Model_resilience.png\" height=\"600\" width=\"1200\" />\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# Display the HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4df693a-47d2-4ba9-bf93-ca7be022e56c",
   "metadata": {},
   "source": [
    "### Input Perturbation (Automatic Input Variation) \n",
    "\n",
    "- Text corruption: Introduce typos, spelling variations, case changes, unicode homoglyphs.\n",
    "\n",
    "- Paraphrasing: Use another LLM or rule-based synonym replacement to rephrase prompts.\n",
    "\n",
    "- Noise injection: Add irrelevant but related sentences or random tokens.\n",
    "\n",
    "- Adversarial perturbations: Apply known NLP attack techniques (e.g., TextFooler, DeepWordBug)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876e0d52-ec2f-4e68-bd84-6ee85915f88e",
   "metadata": {},
   "source": [
    "### Consistency Checking (Self-Evaluation without Humans)\n",
    "\n",
    "- Semantic similarity of outputs: Use embeddings (e.g., cosine similarity via SBERT, OpenAI embeddings) to compare outputs across perturbed inputs. Robust pipelines should produce semantically close answers.\n",
    "\n",
    "- Round-trip validation: For tasks like translation, translate back and compare with original.\n",
    "\n",
    "- Self-consistency: Run the pipeline multiple times with the same input (temperature > 0) and measure variance in answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e97fe10-5f2a-4986-8b6c-ece91437b55a",
   "metadata": {},
   "source": [
    "#### Example: Text Corruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4094d36-38ec-4bc3-917e-aa2dc61de99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "出處: Warhammer 40k: The Horus Heresy\n",
    "\"\"\"\n",
    "\n",
    "cleaned_inputs = dedent(\"\"\"\n",
    "                  I never wanted this, I never wanted to unleash my legions.\n",
    "                  \n",
    "                  Together we banished the ignorance of Old Night, but you betrayed me, you betrayed us all.\n",
    "\n",
    "                  You stole power from the Gods and lied to your sons.\n",
    "\n",
    "                  Mankind has only one chance to prosper, if you will not seize it then I will.\n",
    "\n",
    "                  So let it be war, from the skies of Terra to the Galactic rim.\n",
    "\n",
    "                  Let the seas boil, let the stars fall.\n",
    "\n",
    "                  Though it takes the last drop of my blood, I will see the galaxy freed once more and \n",
    "                  if I can not save it from your failure Father, then let the galaxy burn!\n",
    "                  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220ee238-131d-45bc-98fe-b9ea6fcacdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 調高溫度，因為我們會希望結果出現一些變化\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-mini\", temperature=0.3)\n",
    "\n",
    "system_template = dedent(\"\"\"\n",
    "    You are a helpful AI assistant and you are responsible for language model resilience test.\n",
    "    You will introduce typos, spelling variations, case changes, unicode homoglyphs to the given text.\n",
    "\"\"\")\n",
    "\n",
    "human_template = '{query}'\n",
    "\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variable\": [\"query\"]}}\n",
    "\n",
    "chat_prompt = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "corruption_pipeline = chat_prompt|model|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa519d9-5a9e-490d-aed9-12f08338ae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corruption_pipeline.invoke({\"query\": cleaned_inputs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b897769-a978-4e24-9d12-d272b354cd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corruption_pipeline.invoke({\"query\": cleaned_inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df440579-1605-473e-abaf-31fb9cf84ccb",
   "metadata": {},
   "source": [
    "- Cleaned input -> Cleaned output\n",
    "- Dirty input -> \"Dirty\" output\n",
    "\n",
    "#### Cosine similarity\n",
    "\n",
    "使用 Cosine similarity衡量輸出的相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad9de47-92c8-4139-a130-88f7bef3eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "# 通常是由你的項目主題決定這裡要做啥\n",
    "\n",
    "system_template = dedent(\"\"\"\n",
    "    You are a helpful AI assistant and you are responsible for guess the story beind the monologue.\n",
    "\"\"\")\n",
    "\n",
    "human_template = '{query}'\n",
    "\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variable\": [\"query\"]}}\n",
    "\n",
    "chat_prompt = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "semantic_pipeline = chat_prompt|model|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218c6578-fc1f-4a35-944d-38eca77d27d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用一個英文的embedding，這個比較小一些\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4154a57-cbd0-4772-9c37-b69bcfc698bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_output = semantic_pipeline.invoke({\"query\": cleaned_inputs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a5af73-b055-44ae-9c3b-3e4adb7ef407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 汙染來源\n",
    "dirty_input = corruption_pipeline.invoke({\"query\": cleaned_inputs})\n",
    "\n",
    "# 根據汙染後的數據產出結果\n",
    "dirty_output = semantic_pipeline.invoke({\"query\": dirty_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63dedbb-5a98-4215-862b-219704ac64c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算乾淨產出的embedding\n",
    "\n",
    "embedding_cleaned_output = embedding.embed_documents([cleaned_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91818a3-9ca3-46f8-9b17-13e99b80f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算汙染後產出的embedding\n",
    "\n",
    "embedding_dirty_output = embedding.embed_documents([dirty_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d842ae-1b77-4125-b244-134db0b5ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 比較兩者的相似程度\n",
    "\n",
    "cosine_similarity(embedding_cleaned_output, embedding_dirty_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eed9a45-50ef-46cd-9429-0f911b7c84b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一個毫不相關的比較\n",
    "\n",
    "random_embedding = embedding.embed_documents([\"The weather is wonderful and we are going to hiking in the nearby forest.\"])\n",
    "\n",
    "cosine_similarity(embedding_cleaned_output, random_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0387a00-5eb1-4a37-b933-f7662df630a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a batch of pertubed inputs\n",
    "\n",
    "batch = [cleaned_inputs] * 10\n",
    "\n",
    "corrupted_data = await corruption_pipeline.abatch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d83aef-5e73-4ab0-ae33-2982af97edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6b17f3-74a5-471b-bfdb-2247c6cfa37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data = [[a] for a in corrupted_data], columns=['dirty_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89a444e-ff3d-46e2-b407-89706b230845",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687107c2-fbb8-4c56-8759-3c383ae25774",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fc5ef6-7d0f-4fd7-a6fb-10e40801d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_output = await semantic_pipeline.abatch(df.rename(columns={\"dirty_input\": \"query\"}).to_dict(\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebff044a-e882-4cd1-993b-513f4c4da8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dirty_output'] = dirty_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85869253-e996-4291-a41b-51613c0b2488",
   "metadata": {},
   "source": [
    "### Perplexity Measurement:\n",
    "\n",
    "對於輸入進行干擾後，利用Perplexity (不是那個AI搜索公司) 計算輸出的流暢性\n",
    "\n",
    "Perplexity 數值越高，表示模型對這段文字感到『越困惑』，亦即這段文字的流暢性或自然度越低；反之，數值越低則越流暢\n",
    "\n",
    "這裡我們使用GPT2模型作為量測工具。硬體夠力的話也可以選擇更大的模型像是Llama-3。\n",
    "\n",
    "如果 Cosine Similarity 很高，但 Perplexity 差距很大，代表模型在受到干擾後輸出的語意沒變，但語言組織能力下降了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd92585-181d-47d4-bce3-e0884eee8398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "def calculate_perplexity(text):\n",
    "    encodings = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encodings, labels=encodings[\"input_ids\"])\n",
    "    loss = outputs.loss\n",
    "    return torch.exp(loss).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee376703-6f92-478c-8bab-5742a17ba3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculate_perplexity(cleaned_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c599213-9015-4488-83b3-8f61fec2b13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['perplexity'] = df['dirty_output'].apply(lambda x: calculate_perplexity(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e1441c-4900-472a-9b79-be73d2443b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955f24b7-88ef-4faa-b034-5fd25d888598",
   "metadata": {},
   "source": [
    "### Model Drift\n",
    "\n",
    "固定住輸入，然後使用不同的模型輸出。最後比較輸出。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
