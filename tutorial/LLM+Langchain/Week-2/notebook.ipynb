{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b98d04a-fda1-4ca8-ae92-ae594722255a",
   "metadata": {},
   "source": [
    "# 作業詳解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ebfbfab-219f-4ea9-b24a-f7f414cf25ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5b9ca05-18e4-4ecb-83c2-4bb1efcdf588",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b691104-7300-4274-baa7-11ef5def708e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MengChieh\\miniconda3\\envs\\llm_examples\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "from src.initialization import credential_init\n",
    "from src.io.path_definition import get_project_dir\n",
    "\n",
    "credential_init()\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "with open(os.path.join(get_project_dir(), 'tutorial', 'LLM+Langchain', \n",
    "                       'Week-1', 'recipe_train.json'), 'r') as f:\n",
    "    recipe_train = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56adde32-0275-4716-a3db-17b045caf231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "documents = []\n",
    "\n",
    "for recipe in recipe_train:\n",
    "    document = Document(page_content=\", \".join(recipe['ingredients']),\n",
    "                        metadata={\"cuisine\": recipe['cuisine'],\n",
    "                                  \"id\": recipe['id']})\n",
    "    documents.append(document)\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(documents, k=10, bm25_params={\"k1\":2.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d43684b-b466-4ff4-9fd2-921af42bf9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schemas = [\n",
    "        ResponseSchema(name=\"used ingredients\", description=\"The actual ingredients used in cooking\"),\n",
    "        ResponseSchema(name=\"extra ingredients\", description=\"extra ingredients that have to be prepared \"),\n",
    "        ResponseSchema(name=\"result\", description=\"The dish and cooking recipe in detail\")\n",
    "    ]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# Define human prompt template\n",
    "\n",
    "system_prompt = PromptTemplate.from_template(\"\"\"You are an AI assistant as the best chef in the world. You have a great taste and\n",
    "cooking skills like Gordon Ramsay. You should be able to come up with a dish based on `suggested ingredient`, and tell us what extra ingredients \n",
    "has to be prepared by comparing the ingredients actually used in the cooking and the `existing ingredient`\n",
    "\n",
    "The `suggested ingredients` are the ingredients suggested by some recipe. You have the freedom to add or remove ingredients to achieve the goal, \n",
    "but try to be as faithful to the `suggested ingredient` as possible. \n",
    "\"\"\")\n",
    "\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='existing ingredients:[{existing_ingredients}]; '\n",
    "                                       'suggested ingredients: [{suggested_ingredients}]\\n; '\n",
    "                                       'format instruction: {format_instructions}',\n",
    "                              input_variables=[\"existing_ingredients\", \"suggested_ingredients\"],\n",
    "                              partial_variables={\"format_instructions\": format_instructions}\n",
    "                              )\n",
    "\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                human_message\n",
    "                                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "284979b3-ae7e-4650-9a0b-8cf5d1e58d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(get_project_dir(), 'tutorial', 'LLM+Langchain', 'Week-1', 'recipe_test.json'), 'r') as f:\n",
    "    recipe_test = json.load(f)\n",
    "\n",
    "content = \", \".join(recipe_test[0]['ingredients'])\n",
    "\n",
    "output = bm25_retriever.invoke(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b0b6a8d-3fd3-4347-88dc-03bc3a3f02fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olive oil, balsamic vinegar, toasted pine nuts, kosher salt, golden raisins, part-skim ricotta cheese, grated parmesan cheese, baby spinach, fresh basil leaves, pepper, fusilli, scallions\n"
     ]
    }
   ],
   "source": [
    "existing_ingredients = content\n",
    "print(existing_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6981b36a-537c-4f6b-a1b6-0711096187ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Italian parsley leaves, toasted pine nuts, olive oil, fresh oregano, fresh leav spinach, salt, fresh basil leaves, grated parmesan cheese, garlic cloves', metadata={'cuisine': 'italian', 'id': 7983})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d54a005-1ef0-4e84-a775-9f12e9eb1c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "suggested_ingredients = output[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a5c7b21-1e17-444c-a55a-1b80561966a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt.invoke({\"existing_ingredients\": existing_ingredients, \n",
    "                             \"suggested_ingredients\": suggested_ingredients})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3768c3e5-9cea-45f1-a6bc-e3bb13fdc5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are an AI assistant as the best chef in the world. You have a great taste and\\ncooking skills like Gordon Ramsay. You should be able to come up with a dish based on `suggested ingredient`, and tell us what extra ingredients \\nhas to be prepared by comparing the ingredients actually used in the cooking and the `existing ingredient`\\n\\nThe `suggested ingredients` are the ingredients suggested by some recipe. You have the freedom to add or remove ingredients to achieve the goal, \\nbut try to be as faithful to the `suggested ingredient` as possible. \\n'), HumanMessage(content='existing ingredients:[olive oil, balsamic vinegar, toasted pine nuts, kosher salt, golden raisins, part-skim ricotta cheese, grated parmesan cheese, baby spinach, fresh basil leaves, pepper, fusilli, scallions]; suggested ingredients: [Italian parsley leaves, toasted pine nuts, olive oil, fresh oregano, fresh leav spinach, salt, fresh basil leaves, grated parmesan cheese, garlic cloves]\\n; format instruction: The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"used ingredients\": string  // The actual ingredients used in cooking\\n\\t\"extra ingredients\": string  // extra ingredients that have to be prepared \\n\\t\"result\": string  // The dish and cooking recipe in detail\\n}\\n```')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ac47403-1e65-4971-bb74-89b8f1f59c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"used ingredients\": \"olive oil, balsamic vinegar, toasted pine nuts, kosher salt, golden raisins, part-skim ricotta cheese, grated parmesan cheese, baby spinach, fresh basil leaves, pepper, fusilli, scallions, garlic cloves, fresh oregano, Italian parsley leaves\",\n",
      "\t\"extra ingredients\": \"fresh oregano, Italian parsley leaves, garlic cloves\",\n",
      "\t\"result\": \"### Spinach and Ricotta Fusilli with Toasted Pine Nuts\\n\\n#### Ingredients:\\n- 2 cups fusilli pasta\\n- 2 tablespoons olive oil\\n- 2 cloves garlic, minced\\n- 4 cups baby spinach, chopped\\n- 1 cup part-skim ricotta cheese\\n- 1/2 cup grated parmesan cheese\\n- 1/4 cup toasted pine nuts\\n- 1/4 cup golden raisins\\n- 1/4 cup balsamic vinegar\\n- 1/4 cup scallions, chopped\\n- 1/4 cup fresh basil leaves, chopped\\n- 1/4 cup Italian parsley leaves, chopped\\n- 1 teaspoon fresh oregano, chopped\\n- Kosher salt and pepper to taste\\n\\n#### Instructions:\\n1. **Cook the Pasta:** In a large pot of salted boiling water, cook the fusilli according to package instructions until al dente. Drain and set aside.\\n\\n2. **Sauté the Garlic:** In a large skillet, heat the olive oil over medium heat. Add the minced garlic and sauté for about 1 minute until fragrant.\\n\\n3. **Add Spinach:** Add the chopped baby spinach to the skillet and cook until wilted, about 2-3 minutes.\\n\\n4. **Combine Ingredients:** Stir in the ricotta cheese, grated parmesan cheese, toasted pine nuts, golden raisins, and cooked fusilli. Mix well to combine.\\n\\n5. **Season:** Drizzle with balsamic vinegar and season with kosher salt and pepper to taste. Add the chopped fresh basil, Italian parsley, and oregano, mixing until everything is well incorporated.\\n\\n6. **Serve:** Plate the dish and garnish with additional parmesan cheese and fresh herbs if desired. Enjoy your delicious Spinach and Ricotta Fusilli!\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "output = model.invoke(prompt)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbdbac4a-eca4-403d-8f81-98b69a14605c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'used ingredients': 'olive oil, balsamic vinegar, toasted pine nuts, kosher salt, golden raisins, part-skim ricotta cheese, grated parmesan cheese, baby spinach, fresh basil leaves, pepper, fusilli, scallions, garlic cloves, fresh oregano, Italian parsley leaves', 'extra ingredients': 'fresh oregano, Italian parsley leaves, garlic cloves', 'result': '### Spinach and Ricotta Fusilli with Toasted Pine Nuts\\n\\n#### Ingredients:\\n- 2 cups fusilli pasta\\n- 2 tablespoons olive oil\\n- 2 cloves garlic, minced\\n- 4 cups baby spinach, chopped\\n- 1 cup part-skim ricotta cheese\\n- 1/2 cup grated parmesan cheese\\n- 1/4 cup toasted pine nuts\\n- 1/4 cup golden raisins\\n- 1/4 cup balsamic vinegar\\n- 1/4 cup scallions, chopped\\n- 1/4 cup fresh basil leaves, chopped\\n- 1/4 cup Italian parsley leaves, chopped\\n- 1 teaspoon fresh oregano, chopped\\n- Kosher salt and pepper to taste\\n\\n#### Instructions:\\n1. **Cook the Pasta:** In a large pot of salted boiling water, cook the fusilli according to package instructions until al dente. Drain and set aside.\\n\\n2. **Sauté the Garlic:** In a large skillet, heat the olive oil over medium heat. Add the minced garlic and sauté for about 1 minute until fragrant.\\n\\n3. **Add Spinach:** Add the chopped baby spinach to the skillet and cook until wilted, about 2-3 minutes.\\n\\n4. **Combine Ingredients:** Stir in the ricotta cheese, grated parmesan cheese, toasted pine nuts, golden raisins, and cooked fusilli. Mix well to combine.\\n\\n5. **Season:** Drizzle with balsamic vinegar and season with kosher salt and pepper to taste. Add the chopped fresh basil, Italian parsley, and oregano, mixing until everything is well incorporated.\\n\\n6. **Serve:** Plate the dish and garnish with additional parmesan cheese and fresh herbs if desired. Enjoy your delicious Spinach and Ricotta Fusilli!'}\n"
     ]
    }
   ],
   "source": [
    "final_output = output_parser.parse(output.content)\n",
    "print(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f18343f-f495-43bc-9662-747e404a1c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['used ingredients', 'extra ingredients', 'result'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d058402-5f51-4c58-a8ba-8517fd4498f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'olive oil, balsamic vinegar, toasted pine nuts, kosher salt, golden raisins, part-skim ricotta cheese, grated parmesan cheese, baby spinach, fresh basil leaves, pepper, fusilli, scallions, garlic cloves, fresh oregano, Italian parsley leaves'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output['used ingredients']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7875b6c-6c1a-4056-a91c-ccba3b53ff0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italian parsley leaves, toasted pine nuts, olive oil, fresh oregano, fresh leav spinach, salt, fresh basil leaves, grated parmesan cheese, garlic cloves'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggested_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef03ddc9-c8e5-4b3d-855c-e0ba480b5242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fresh oregano, Italian parsley leaves, garlic cloves'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output['extra ingredients']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e053b761-8266-4708-830a-46e9140b9871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Spinach and Ricotta Fusilli with Toasted Pine Nuts\\n\\n#### Ingredients:\\n- 2 cups fusilli pasta\\n- 2 tablespoons olive oil\\n- 2 cloves garlic, minced\\n- 4 cups baby spinach, chopped\\n- 1 cup part-skim ricotta cheese\\n- 1/2 cup grated parmesan cheese\\n- 1/4 cup toasted pine nuts\\n- 1/4 cup golden raisins\\n- 1/4 cup balsamic vinegar\\n- 1/4 cup scallions, chopped\\n- 1/4 cup fresh basil leaves, chopped\\n- 1/4 cup Italian parsley leaves, chopped\\n- 1 teaspoon fresh oregano, chopped\\n- Kosher salt and pepper to taste\\n\\n#### Instructions:\\n1. **Cook the Pasta:** In a large pot of salted boiling water, cook the fusilli according to package instructions until al dente. Drain and set aside.\\n\\n2. **Sauté the Garlic:** In a large skillet, heat the olive oil over medium heat. Add the minced garlic and sauté for about 1 minute until fragrant.\\n\\n3. **Add Spinach:** Add the chopped baby spinach to the skillet and cook until wilted, about 2-3 minutes.\\n\\n4. **Combine Ingredients:** Stir in the ricotta cheese, grated parmesan cheese, toasted pine nuts, golden raisins, and cooked fusilli. Mix well to combine.\\n\\n5. **Season:** Drizzle with balsamic vinegar and season with kosher salt and pepper to taste. Add the chopped fresh basil, Italian parsley, and oregano, mixing until everything is well incorporated.\\n\\n6. **Serve:** Plate the dish and garnish with additional parmesan cheese and fresh herbs if desired. Enjoy your delicious Spinach and Ricotta Fusilli!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efd3b0a5-5de4-4168-a1cc-9fc06648c197",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Spinach and Ricotta Fusilli with Toasted Pine Nuts\n",
      "\n",
      "#### Ingredients:\n",
      "- 2 cups fusilli pasta\n",
      "- 2 tablespoons olive oil\n",
      "- 2 cloves garlic, minced\n",
      "- 4 cups baby spinach, chopped\n",
      "- 1 cup part-skim ricotta cheese\n",
      "- 1/2 cup grated parmesan cheese\n",
      "- 1/4 cup toasted pine nuts\n",
      "- 1/4 cup golden raisins\n",
      "- 1/4 cup balsamic vinegar\n",
      "- 1/4 cup scallions, chopped\n",
      "- 1/4 cup fresh basil leaves, chopped\n",
      "- 1/4 cup Italian parsley leaves, chopped\n",
      "- 1 teaspoon fresh oregano, chopped\n",
      "- Kosher salt and pepper to taste\n",
      "\n",
      "#### Instructions:\n",
      "1. **Cook the Pasta:** In a large pot of salted boiling water, cook the fusilli according to package instructions until al dente. Drain and set aside.\n",
      "\n",
      "2. **Sauté the Garlic:** In a large skillet, heat the olive oil over medium heat. Add the minced garlic and sauté for about 1 minute until fragrant.\n",
      "\n",
      "3. **Add Spinach:** Add the chopped baby spinach to the skillet and cook until wilted, about 2-3 minutes.\n",
      "\n",
      "4. **Combine Ingredients:** Stir in the ricotta cheese, grated parmesan cheese, toasted pine nuts, golden raisins, and cooked fusilli. Mix well to combine.\n",
      "\n",
      "5. **Season:** Drizzle with balsamic vinegar and season with kosher salt and pepper to taste. Add the chopped fresh basil, Italian parsley, and oregano, mixing until everything is well incorporated.\n",
      "\n",
      "6. **Serve:** Plate the dish and garnish with additional parmesan cheese and fresh herbs if desired. Enjoy your delicious Spinach and Ricotta Fusilli!\n"
     ]
    }
   ],
   "source": [
    "print(final_output['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5f855de-d1eb-420f-b233-7503a6071a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_result = model.invoke(f\"Translate the content into traditional Chinese (繁體中文): {final_output['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a735b13-1bf3-431d-8169-7d559c133e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 菠菜和瑞可達起司螺旋麵配烤松子\n",
      "\n",
      "#### 材料：\n",
      "- 2杯螺旋麵\n",
      "- 2湯匙橄欖油\n",
      "- 2瓣大蒜，切碎\n",
      "- 4杯嬰兒菠菜，切碎\n",
      "- 1杯部分脫脂瑞可達起司\n",
      "- 1/2杯磨碎的帕爾馬起司\n",
      "- 1/4杯烤松子\n",
      "- 1/4杯金葡萄乾\n",
      "- 1/4杯香醋\n",
      "- 1/4杯青蔥，切碎\n",
      "- 1/4杯新鮮羅勒葉，切碎\n",
      "- 1/4杯義大利香菜葉，切碎\n",
      "- 1茶匙新鮮牛至，切碎\n",
      "- 猶太鹽和黑胡椒，依個人口味調整\n",
      "\n",
      "#### 做法：\n",
      "1. **煮麵條：** 在一大鍋加鹽的滾水中，根據包裝說明煮螺旋麵至剛好熟透（al dente）。瀝乾並放置一旁。\n",
      "\n",
      "2. **炒大蒜：** 在一個大平底鍋中，用中火加熱橄欖油。加入切碎的大蒜，炒約1分鐘，直到散發香味。\n",
      "\n",
      "3. **加入菠菜：** 將切碎的嬰兒菠菜加入平底鍋中，煮至萎縮，約2-3分鐘。\n",
      "\n",
      "4. **混合材料：** 加入瑞可達起司、磨碎的帕爾馬起司、烤松子、金葡萄乾和煮熟的螺旋麵。充分攪拌混合。\n",
      "\n",
      "5. **調味：** 淋上香醋，並根據個人口味加入猶太鹽和黑胡椒。加入切碎的新鮮羅勒、義大利香菜和牛至，攪拌至所有材料充分融合。\n",
      "\n",
      "6. **上菜：** 將菜餚盛盤，若需要可用額外的帕爾馬起司和新鮮香草裝飾。享受美味的菠菜和瑞可達起司螺旋麵！\n"
     ]
    }
   ],
   "source": [
    "print(translated_result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf00c087-166a-4f59-a5fe-adf39449145d",
   "metadata": {},
   "source": [
    "# Semantic based retrieval\n",
    "\n",
    "Semantic-based retrieval is a method of finding information that focuses on understanding the meaning behind the words you use. Instead of just matching exact words, it looks for the context and concepts in your query. Here's a simple way to understand it:\n",
    "\n",
    "- 1. Meaning Over Words: Imagine you want to find information about \"healthy eating\". Traditional search might look for documents with the exact phrase \"healthy eating\". Semantic-based retrieval, however, understands that terms like \"nutritious diet\" or \"balanced diet\" are related and will include those in the results.\n",
    "\n",
    "- 2. Context Awareness: This method takes into account the context in which words are used. For example, if you search for \"apple\", a traditional search might give you results about the fruit and the tech company. Semantic-based retrieval uses context to determine whether you’re likely asking about a fruit or a tech product.\n",
    "\n",
    "- 3. Natural Language Understanding: It works more like how humans understand language. When you ask a question, it tries to grasp the intent behind your query and finds relevant information accordingly.\n",
    "\n",
    "- 4. Better Results: By focusing on the meaning and context, semantic-based retrieval can provide more accurate and relevant results. This means you spend less time sifting through unrelated information.\n",
    "\n",
    "\n",
    "語義檢索是一種尋找信息的方法，它重點在於理解你使用的詞語背後的意思。與其僅僅匹配精確的詞語，它會尋找你查詢中的上下文和概念。以下是一種簡單的理解方式：\n",
    "\n",
    "- 1. 重點在於意思：想像一下你想找關於“健康飲食”的信息。傳統搜索可能會尋找包含“健康飲食”這個精確詞語的文檔。而語義檢索則會理解“營養均衡的飲食”或“均衡飲食”等相關詞語，並將它們包含在結果中。\n",
    "\n",
    "- 2. 上下文感知：這種方法會考慮詞語使用的上下文。例如，如果你搜索“蘋果”，傳統搜索可能會給你關於水果和科技公司的結果。語義檢索則會使用上下文來判斷你更可能是在詢問水果還是科技產品。\n",
    "\n",
    "- 3. 自然語言理解：它更像人類理解語言的方式。當你提出問題時，它會嘗試理解你查詢背後的意圖，並相應地找到相關信息。\n",
    "\n",
    "- 4. 更好的結果：通過重點關注意思和上下文，語義檢索可以提供更準確和相關的結果。這意味著你可以減少篩選無關信息的時間。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df1d34a9-ca50-474d-9a23-3b46bbf91dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'egg' == 'large egg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0fabdfd-8525-4445-8979-d7478442540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef3a7a88-0bd5-4ed1-a619-b7c537813bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "# https://platform.openai.com/docs/guides/embeddings/what-are-embeddings\n",
    "\n",
    "# A list of embedding models you can choose \n",
    "# https://www.sbert.net/docs/sentence_transformer/pretrained_models.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d359c46-df1c-4449-8a78-297c41b43088",
   "metadata": {},
   "source": [
    "### 1. Creating Embeddings (創建嵌入):\n",
    "\n",
    "- HuggingFaceEmbeddings is used to create embeddings (vector representations) for text data.\n",
    "- The model all-MiniLM-L6-v2 from HuggingFace is specified to generate these embeddings. This model converts text into numerical vectors that capture the semantic meaning of the text.\n",
    "\n",
    "- 使用 HuggingFaceEmbeddings 創建文本數據的嵌入（向量表示）。\n",
    "- 指定 HuggingFace 的模型 all-MiniLM-L6-v2 來生成這些嵌入。此模型將文本轉換為數字向量，這些向量捕捉文本的語義。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c35cc90-cae0-489d-89f2-3086791607ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mHuggingFaceEmbeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mclient\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmodel_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'sentence-transformers/all-mpnet-base-v2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcache_folder\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mencode_kwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmulti_process\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mshow_progress\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "[*Deprecated*] HuggingFace sentence_transformers embedding models.\n",
       "\n",
       "To use, you should have the ``sentence_transformers`` python package installed.\n",
       "\n",
       "Example:\n",
       "    .. code-block:: python\n",
       "\n",
       "        from langchain_community.embeddings import HuggingFaceEmbeddings\n",
       "\n",
       "        model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
       "        model_kwargs = {'device': 'cpu'}\n",
       "        encode_kwargs = {'normalize_embeddings': False}\n",
       "        hf = HuggingFaceEmbeddings(\n",
       "            model_name=model_name,\n",
       "            model_kwargs=model_kwargs,\n",
       "            encode_kwargs=encode_kwargs\n",
       "        )\n",
       "\n",
       "Notes\n",
       "-----\n",
       ".. deprecated:: 0.2.2\n",
       "   \n",
       "\u001b[1;31mInit docstring:\u001b[0m Initialize the sentence_transformer.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\mengchieh\\miniconda3\\envs\\llm_examples\\lib\\site-packages\\langchain_community\\embeddings\\huggingface.py\n",
       "\u001b[1;31mType:\u001b[0m           ModelMetaclass\n",
       "\u001b[1;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "HuggingFaceEmbeddings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47235efc-d786-4a04-9ec1-89c3a4203e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MengChieh\\miniconda3\\envs\\llm_examples\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\MengChieh\\miniconda3\\envs\\llm_examples\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aece8f30-980a-4f5c-8fe2-d574eb14a301",
   "metadata": {},
   "source": [
    "### 2. Initializing Vector Store (初始化向量存儲):\n",
    "\n",
    "- Chroma.from_documents is used to create a vector store from a subset of documents.\n",
    "- The first 500 documents from the documents list are selected for this operation.\n",
    "- The embedding parameter is set to the previously created embeddings (HuggingFaceEmbeddings).\n",
    "\n",
    "- 使用 Chroma.from_documents 從一部分文檔創建一個向量存儲。\n",
    "- 選擇 documents 列表中的前 500 個文檔來進行此操作。\n",
    "- embedding 參數設置為先前創建的嵌入（HuggingFaceEmbeddings）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5abc3ac4-4239-4453-a9ab-4ddfee7d5e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(documents[:500], embedding=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81113c6d-cd73-4d48-b7a9-e455f38c9000",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Creating a Retriever (創建檢索器):\n",
    "\n",
    "- The as_retriever method is called on the vectorstore object to create a retriever.\n",
    "- This retriever is configured to use \"similarity\" as the search type, meaning it will find documents that are similar to a given query based on their vector embeddings.\n",
    "\n",
    "- 在 vectorstore 對象上調用 as_retriever 方法來創建一個檢索器。\n",
    "- 這個檢索器配置為使用“相似性”作為搜索類型，這意味著它將根據文檔的向量嵌入找到與給定查詢相似的文檔。\n",
    "\n",
    "### 4. Setting Search Parameters (設置搜索參數):\n",
    "\n",
    "- The search_kwargs argument is used to pass additional parameters to the search function.\n",
    "- In this case, {'k': 5} is specified, which means the retriever will return the top 5 most similar documents for each query.\n",
    "\n",
    "- 使用 search_kwargs 參數來傳遞額外的搜索功能參數。\n",
    "- 在這裡，指定了 {'k': 5}，這意味著檢索器將返回每個查詢最相似的前 5 個文檔。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46fa38ca-7129-4fba-bc61-a789c77c52b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\",\n",
    "                                     search_kwargs={'k': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1610ee9d-957d-4f1d-81b7-d8b5dc36c19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \", \".join(recipe_test[0]['ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f10270b-1cfe-4c8e-b707-56f35ab05547",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'olive oil, balsamic vinegar, toasted pine nuts, kosher salt, golden raisins, part-skim ricotta cheese, grated parmesan cheese, baby spinach, fresh basil leaves, pepper, fusilli, scallions'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8bdb7f4-35fd-4ae9-a5f4-d33e23c71e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='white onion, balsamic vinegar, shredded mozzarella cheese, unsalted butter, soppressata, prebaked pizza crusts, sweet potatoes, freshly ground pepper, kosher salt, extra-virgin olive oil, oregano', metadata={'cuisine': 'italian', 'id': 12421}),\n",
       " Document(page_content='fresh ginger, vegetable oil, rice vinegar, large eggs, crushed red pepper flakes, scallions, reduced sodium soy sauce, all purpose unbleached flour, dark brown sugar, kosher salt, sesame oil, garlic', metadata={'cuisine': 'korean', 'id': 18437}),\n",
       " Document(page_content='picholine olives, parmigiano reggiano cheese, cavatelli, fresh basil, whole grain dijon mustard, extra-virgin olive oil, prosciutto, red wine vinegar, flat leaf parsley, sugar, ground black pepper, salt', metadata={'cuisine': 'italian', 'id': 25019}),\n",
       " Document(page_content='fresh basil, chicken breasts, pepper, purple onion, mozzarella cheese, balsamic vinegar, tomatoes, olive oil, salt', metadata={'cuisine': 'italian', 'id': 39500}),\n",
       " Document(page_content='kosher salt, dry red wine, chuck, pepper sauce, ground black pepper, burrito seasoning mix, water, roasted garlic, sugar, paprika, pork shoulder', metadata={'cuisine': 'spanish', 'id': 42928})]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821359f8-fde9-44dc-8cfb-bb5acbe3a47f",
   "metadata": {},
   "source": [
    "## Runtime Configuration\n",
    "\n",
    "What we learned last week: Runtime Configuration. Although I do not use this in my work, but we can see what can be achieved with this functionality. Maybe in the future there will be some use cases in which I need this :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea58945a-674e-4501-be3b-22ac739cb9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableField\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\").configurable_fields( \\\n",
    "                                        search_kwargs=ConfigurableField(\n",
    "                                                id=\"hello_search\",\n",
    "                                            )\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38e72f2c-dfd1-4de9-b065-ec77f2a0c75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='white onion, balsamic vinegar, shredded mozzarella cheese, unsalted butter, soppressata, prebaked pizza crusts, sweet potatoes, freshly ground pepper, kosher salt, extra-virgin olive oil, oregano', metadata={'cuisine': 'italian', 'id': 12421}),\n",
       " Document(page_content='fresh ginger, vegetable oil, rice vinegar, large eggs, crushed red pepper flakes, scallions, reduced sodium soy sauce, all purpose unbleached flour, dark brown sugar, kosher salt, sesame oil, garlic', metadata={'cuisine': 'korean', 'id': 18437}),\n",
       " Document(page_content='picholine olives, parmigiano reggiano cheese, cavatelli, fresh basil, whole grain dijon mustard, extra-virgin olive oil, prosciutto, red wine vinegar, flat leaf parsley, sugar, ground black pepper, salt', metadata={'cuisine': 'italian', 'id': 25019}),\n",
       " Document(page_content='fresh basil, chicken breasts, pepper, purple onion, mozzarella cheese, balsamic vinegar, tomatoes, olive oil, salt', metadata={'cuisine': 'italian', 'id': 39500}),\n",
       " Document(page_content='kosher salt, dry red wine, chuck, pepper sauce, ground black pepper, burrito seasoning mix, water, roasted garlic, sugar, paprika, pork shoulder', metadata={'cuisine': 'spanish', 'id': 42928}),\n",
       " Document(page_content='ground black pepper, butter, arborio rice, grated parmesan cheese, flat leaf parsley, pancetta, minced onion, extra-virgin olive oil, kosher salt, vegetable stock, frozen peas', metadata={'cuisine': 'italian', 'id': 40149}),\n",
       " Document(page_content='kosher salt, feta cheese, grated lemon zest, ground lamb, unsalted chicken stock, crushed tomatoes, cooking spray, oven-ready lasagna noodles, fresh rosemary, minced garlic, ground black pepper, chopped onion, extra lean ground beef, olive oil, part-skim ricotta cheese, flat leaf parsley', metadata={'cuisine': 'greek', 'id': 35436})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(query, config={\"configurable\": {\"hello_search\": {\"k\": 7}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "198a2242-afae-4197-a671-36ed1819f007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='white onion, balsamic vinegar, shredded mozzarella cheese, unsalted butter, soppressata, prebaked pizza crusts, sweet potatoes, freshly ground pepper, kosher salt, extra-virgin olive oil, oregano', metadata={'cuisine': 'italian', 'id': 12421}),\n",
       " Document(page_content='fresh ginger, vegetable oil, rice vinegar, large eggs, crushed red pepper flakes, scallions, reduced sodium soy sauce, all purpose unbleached flour, dark brown sugar, kosher salt, sesame oil, garlic', metadata={'cuisine': 'korean', 'id': 18437}),\n",
       " Document(page_content='picholine olives, parmigiano reggiano cheese, cavatelli, fresh basil, whole grain dijon mustard, extra-virgin olive oil, prosciutto, red wine vinegar, flat leaf parsley, sugar, ground black pepper, salt', metadata={'cuisine': 'italian', 'id': 25019})]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(query, config={\"configurable\": {\"hello_search\": {\"k\": 3}}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81ce668-c24a-44c8-adfb-209b1118faa5",
   "metadata": {},
   "source": [
    "## Three search types:\n",
    "\n",
    "### 1. similarity (default)\n",
    "\n",
    "- This search type finds documents that are most similar to your query. It looks at the meaning of the words you used and matches documents that have similar meanings. Think of it like finding articles or documents that closely relate to the topic you're interested in.\n",
    "\n",
    "- 這種搜索類型找到與你的查詢最相似的文檔。它會看你使用詞語的意思，並匹配具有相似意思的文檔。可以把它想像成找到與你感興趣的主題密切相關的文章或文檔。\n",
    "\n",
    "### 2. MMR, Maximum Marginal Relevance (MMR, 最大邊際相關性):\n",
    "\n",
    "- This method balances finding documents that are similar to your query while also ensuring that the results are diverse. It's like asking for a variety of opinions on a topic so you don't get too much of the same thing. It helps avoid redundancy in the search results.\n",
    "\n",
    "- 這種方法在找到與你的查詢相似的文檔的同時，也確保結果是多樣的。這就像是在一個主題上尋求多種意見，避免得到過多相同的東西。它有助於避免搜索結果的冗餘。\n",
    "\n",
    "### 3. similarity_score_threshold (相似性分數閾值):\n",
    "\n",
    "- This search type sets a minimum similarity score that documents must meet to be considered relevant. Only documents that are very close to your query in terms of meaning will be included. It ensures that the results are highly relevant and filters out less related information.\n",
    "\n",
    "- 這種搜索類型設置一個最小相似性分數，只有達到這個分數的文檔才會被認為是相關的。只有那些在意思上與你的查詢非常接近的文檔才會被包含進來。它確保結果高度相關，並過濾掉不太相關的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfdc6a5d-02c3-4e63-a3d8-f483b370896f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*c0c19i2tPSWZaHwQ7cVMrg.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://miro.medium.com/v2/resize:fit:720/format:webp/1*c0c19i2tPSWZaHwQ7cVMrg.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f0e436f-96ab-4977-8300-78100b9a90a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cosine similarity\n",
    "\n",
    "https://api.python.langchain.com/en/latest/_modules/langchain_core/vectorstores.html\n",
    "\n",
    "elif search_type == \"similarity_score_threshold\":\n",
    "    docs_and_similarities = self.similarity_search_with_relevance_scores(\n",
    "        query, **kwargs\n",
    "    )\n",
    "    return [doc for doc, _ in docs_and_similarities]\n",
    "\n",
    "in subclass.\n",
    "Return docs and relevance scores in the range [0, 1].\n",
    "\n",
    "0 is dissimilar, 1 is most similar.\n",
    "\"\"\"\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.5, \"k\": 3}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef7ccc78-bb2c-408a-8a92-f93f395ae7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \", \".join(recipe_test[0]['ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ce400da-f757-4691-a656-2aad09a7a1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='white onion, balsamic vinegar, shredded mozzarella cheese, unsalted butter, soppressata, prebaked pizza crusts, sweet potatoes, freshly ground pepper, kosher salt, extra-virgin olive oil, oregano', metadata={'cuisine': 'italian', 'id': 12421}),\n",
       " Document(page_content='fresh ginger, vegetable oil, rice vinegar, large eggs, crushed red pepper flakes, scallions, reduced sodium soy sauce, all purpose unbleached flour, dark brown sugar, kosher salt, sesame oil, garlic', metadata={'cuisine': 'korean', 'id': 18437}),\n",
       " Document(page_content='picholine olives, parmigiano reggiano cheese, cavatelli, fresh basil, whole grain dijon mustard, extra-virgin olive oil, prosciutto, red wine vinegar, flat leaf parsley, sugar, ground black pepper, salt', metadata={'cuisine': 'italian', 'id': 25019})]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2855c8-f541-48b3-b0c6-0968bf79e004",
   "metadata": {},
   "source": [
    "### How to get the scores of the documents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01fbffa6-450f-4994-b11a-587e35b95b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='white onion, balsamic vinegar, shredded mozzarella cheese, unsalted butter, soppressata, prebaked pizza crusts, sweet potatoes, freshly ground pepper, kosher salt, extra-virgin olive oil, oregano', metadata={'cuisine': 'italian', 'id': 12421}),\n",
       "  0.2848874),\n",
       " (Document(page_content='fresh ginger, vegetable oil, rice vinegar, large eggs, crushed red pepper flakes, scallions, reduced sodium soy sauce, all purpose unbleached flour, dark brown sugar, kosher salt, sesame oil, garlic', metadata={'cuisine': 'korean', 'id': 18437}),\n",
       "  0.32091278),\n",
       " (Document(page_content='picholine olives, parmigiano reggiano cheese, cavatelli, fresh basil, whole grain dijon mustard, extra-virgin olive oil, prosciutto, red wine vinegar, flat leaf parsley, sugar, ground black pepper, salt', metadata={'cuisine': 'italian', 'id': 25019}),\n",
       "  0.32712448),\n",
       " (Document(page_content='fresh basil, chicken breasts, pepper, purple onion, mozzarella cheese, balsamic vinegar, tomatoes, olive oil, salt', metadata={'cuisine': 'italian', 'id': 39500}),\n",
       "  0.32840425)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search_with_score(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c92be3ea-320f-4551-9b04-3e1a73b78f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='white onion, balsamic vinegar, shredded mozzarella cheese, unsalted butter, soppressata, prebaked pizza crusts, sweet potatoes, freshly ground pepper, kosher salt, extra-virgin olive oil, oregano', metadata={'cuisine': 'italian', 'id': 12421}),\n",
       "  0.798554185287482),\n",
       " (Document(page_content='fresh ginger, vegetable oil, rice vinegar, large eggs, crushed red pepper flakes, scallions, reduced sodium soy sauce, all purpose unbleached flour, dark brown sugar, kosher salt, sesame oil, garlic', metadata={'cuisine': 'korean', 'id': 18437}),\n",
       "  0.7730803982398308),\n",
       " (Document(page_content='picholine olives, parmigiano reggiano cheese, cavatelli, fresh basil, whole grain dijon mustard, extra-virgin olive oil, prosciutto, red wine vinegar, flat leaf parsley, sugar, ground black pepper, salt', metadata={'cuisine': 'italian', 'id': 25019}),\n",
       "  0.768688064422268),\n",
       " (Document(page_content='fresh basil, chicken breasts, pepper, purple onion, mozzarella cheese, balsamic vinegar, tomatoes, olive oil, salt', metadata={'cuisine': 'italian', 'id': 39500}),\n",
       "  0.7677831294378905)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore._similarity_search_with_relevance_scores(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec464d37-b482-435c-9677-9d03cce234e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore._select_relevance_score_fn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4959ebd-b11e-4120-81cf-87099c2f88b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mvectorstore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilarity_search_with_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mquery\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'int'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfilter\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Optional[Union[Callable, Dict[str, Any]]]'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfetch_k\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'int'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Any'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'List[Tuple[Document, float]]'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Return docs most similar to query.\n",
       "\n",
       "Args:\n",
       "    query: Text to look up documents similar to.\n",
       "    k: Number of Documents to return. Defaults to 4.\n",
       "    filter (Optional[Dict[str, str]]): Filter by metadata.\n",
       "        Defaults to None. If a callable, it must take as input the\n",
       "        metadata dict of Document and return a bool.\n",
       "\n",
       "    fetch_k: (Optional[int]) Number of Documents to fetch before filtering.\n",
       "              Defaults to 20.\n",
       "\n",
       "Returns:\n",
       "    List of documents most similar to the query text with\n",
       "    L2 distance in float. Lower score represents more similarity.\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\mengchieh\\miniconda3\\envs\\llm_examples\\lib\\site-packages\\langchain_community\\vectorstores\\faiss.py\n",
       "\u001b[1;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorstore.similarity_search_with_score?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5160437-1d37-4e08-ac25-7a6f28ed40c8",
   "metadata": {},
   "source": [
    "### How to leverage the metadata?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bffed65c-7c0f-43e0-8621-820915f9b320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug filter 出問題\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.5}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77250ef2-b89f-4b0d-9075-7430ff6ad1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='white onion, balsamic vinegar, shredded mozzarella cheese, unsalted butter, soppressata, prebaked pizza crusts, sweet potatoes, freshly ground pepper, kosher salt, extra-virgin olive oil, oregano', metadata={'cuisine': 'italian', 'id': 12421}),\n",
       " Document(page_content='fresh ginger, vegetable oil, rice vinegar, large eggs, crushed red pepper flakes, scallions, reduced sodium soy sauce, all purpose unbleached flour, dark brown sugar, kosher salt, sesame oil, garlic', metadata={'cuisine': 'korean', 'id': 18437}),\n",
       " Document(page_content='picholine olives, parmigiano reggiano cheese, cavatelli, fresh basil, whole grain dijon mustard, extra-virgin olive oil, prosciutto, red wine vinegar, flat leaf parsley, sugar, ground black pepper, salt', metadata={'cuisine': 'italian', 'id': 25019}),\n",
       " Document(page_content='fresh basil, chicken breasts, pepper, purple onion, mozzarella cheese, balsamic vinegar, tomatoes, olive oil, salt', metadata={'cuisine': 'italian', 'id': 39500})]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e2176bd-2437-406b-9a54-bcb98f524f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.5,\n",
    "                                                             \"filter\": {\"cuisine\": \"mexican\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "27cea587-4b1a-4a8a-a7b2-63dbb622f40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='avocado, chicken breasts, yellow onion, masa, kosher salt, achiote paste, liquid, white vinegar, lettuce leaves, purple onion, plum tomatoes, black beans, vegetable oil, sauce', metadata={'cuisine': 'mexican', 'id': 35072}),\n",
       " Document(page_content='kosher salt, chile de arbol, turkey breast, mint leaves, garlic cloves, masa, tomatoes, vegetable oil, low salt chicken broth, water, achiote paste, onions', metadata={'cuisine': 'mexican', 'id': 26778}),\n",
       " Document(page_content='kosher salt, lean ground beef, onions, chili powder, garlic, salsa verde, cilantro, sugar, lime wedges, corn tortillas', metadata={'cuisine': 'mexican', 'id': 27521})]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1378e993-bcb3-46b3-9a96-7172abb1d8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_docs = vectorstore.similarity_search(query, k=5,\n",
    "                                               filter={\"cuisine\": 'mexican'}\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "abc38363-03dc-4887-93d1-eed68843e1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='avocado, chicken breasts, yellow onion, masa, kosher salt, achiote paste, liquid, white vinegar, lettuce leaves, purple onion, plum tomatoes, black beans, vegetable oil, sauce', metadata={'cuisine': 'mexican', 'id': 35072}),\n",
       " Document(page_content='kosher salt, chile de arbol, turkey breast, mint leaves, garlic cloves, masa, tomatoes, vegetable oil, low salt chicken broth, water, achiote paste, onions', metadata={'cuisine': 'mexican', 'id': 26778}),\n",
       " Document(page_content='kosher salt, lean ground beef, onions, chili powder, garlic, salsa verde, cilantro, sugar, lime wedges, corn tortillas', metadata={'cuisine': 'mexican', 'id': 27521})]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4ec507d0-6319-421c-bced-859bee88cd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='avocado, chicken breasts, yellow onion, masa, kosher salt, achiote paste, liquid, white vinegar, lettuce leaves, purple onion, plum tomatoes, black beans, vegetable oil, sauce', metadata={'cuisine': 'mexican', 'id': 35072}),\n",
       "  0.36982745),\n",
       " (Document(page_content='kosher salt, chile de arbol, turkey breast, mint leaves, garlic cloves, masa, tomatoes, vegetable oil, low salt chicken broth, water, achiote paste, onions', metadata={'cuisine': 'mexican', 'id': 26778}),\n",
       "  0.38994306),\n",
       " (Document(page_content='kosher salt, lean ground beef, onions, chili powder, garlic, salsa verde, cilantro, sugar, lime wedges, corn tortillas', metadata={'cuisine': 'mexican', 'id': 27521}),\n",
       "  0.39436603)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search_with_score(query, k=5, \n",
    "                                         filter={'cuisine': 'mexican'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76537b1f-c3b3-44e0-a1d5-7a0e2fcf3b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type='mmr', search_kwargs={'k': 8, 'fetch_k': 50, 'lambda_mult': 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1ac9b37-cc38-46ae-8573-eba44157eecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='white onion, balsamic vinegar, shredded mozzarella cheese, unsalted butter, soppressata, prebaked pizza crusts, sweet potatoes, freshly ground pepper, kosher salt, extra-virgin olive oil, oregano', metadata={'cuisine': 'italian', 'id': 12421}),\n",
       " Document(page_content='celery ribs, baby spinach, chickpeas, kosher salt, orzo, carrots, parmigiano reggiano cheese, dry bread crumbs, homemade chicken stock, ground pork, freshly ground pepper', metadata={'cuisine': 'italian', 'id': 46525}),\n",
       " Document(page_content='fresh basil, purple onion, feta cheese, balsamic vinaigrette, tomatoes, kalamata, rotini, green bell pepper, freshly ground pepper', metadata={'cuisine': 'greek', 'id': 29557}),\n",
       " Document(page_content='sugar, unsalted butter, lemon, pure vanilla extract, blood orange, orange marmalade, plain whole-milk yogurt, eggs, almonds, pistachio nuts, kosher salt, flour, lemon juice', metadata={'cuisine': 'italian', 'id': 6401}),\n",
       " Document(page_content='pepper, dry white wine, arborio rice, unsalted butter, salt, asparagus, shallots, chicken stock, grated parmesan cheese', metadata={'cuisine': 'italian', 'id': 39906}),\n",
       " Document(page_content='celery ribs, ground black pepper, red wine vinegar, garlic cloves, capers, dry white wine, heirloom tomatoes, thyme sprigs, fennel seeds, hand, lemon, bass fillets, olive oil, shallots, salt', metadata={'cuisine': 'italian', 'id': 6535}),\n",
       " Document(page_content='fennel seeds, kosher salt, sherry vinegar, vegetable oil, pumpkin seeds, tomatoes, olive oil, hot pepper sauce, all-purpose flour, smoked paprika, fresh basil, garlic powder, chili powder, cayenne pepper, potato starch, baguette, ground black pepper, buttermilk, garlic cloves', metadata={'cuisine': 'southern_us', 'id': 3435}),\n",
       " Document(page_content='ground cloves, eggplant, grated parmesan cheese, plain breadcrumbs, cinnamon sticks, kosher salt, large egg yolks, diced tomatoes, all-purpose flour, bay leaf, tomato paste, olive oil, unsalted butter, garlic, ground allspice, ground lamb, milk, ground black pepper, dry red wine, grated nutmeg, onions', metadata={'cuisine': 'greek', 'id': 17658})]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b97f58-2e9a-452c-b6d2-31c3182524ef",
   "metadata": {},
   "source": [
    "### Multiple Condition Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad44dcb-cc1b-4859-b8c1-658c05668c99",
   "metadata": {},
   "source": [
    "## CNN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ca0183cc-1400-4d44-8c3a-2d612ed214ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "filename = os.path.join(get_project_dir(), 'tutorial', 'LLM+Langchain', 'Week-2', 'CNN_Articels_clean.csv')\n",
    "\n",
    "df_cnn = pd.read_csv(filename, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce5a7b56-6776-4ead-ad61-77b453b0ab88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Date published</th>\n",
       "      <th>Category</th>\n",
       "      <th>Section</th>\n",
       "      <th>Url</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Description</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Second headline</th>\n",
       "      <th>Article text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jacopo Prisco, CNN</td>\n",
       "      <td>2021-07-15 02:46:59</td>\n",
       "      <td>news</td>\n",
       "      <td>world</td>\n",
       "      <td>https://www.cnn.com/2021/07/14/world/tusimple-...</td>\n",
       "      <td>There's a shortage of truckers, but TuSimple t...</td>\n",
       "      <td>The e-commerce boom has exacerbated a global t...</td>\n",
       "      <td>world, There's a shortage of truckers, but TuS...</td>\n",
       "      <td>There's a shortage of truckers, but TuSimple t...</td>\n",
       "      <td>(CNN)Right now, there's a shortage of truck d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stephanie Bailey, CNN</td>\n",
       "      <td>2021-05-12 07:52:09</td>\n",
       "      <td>news</td>\n",
       "      <td>world</td>\n",
       "      <td>https://www.cnn.com/2021/05/12/world/ironhand-...</td>\n",
       "      <td>Bioservo's robotic 'Ironhand' could protect fa...</td>\n",
       "      <td>Working in a factory can mean doing the same t...</td>\n",
       "      <td>world, Bioservo's robotic 'Ironhand' could pro...</td>\n",
       "      <td>A robotic 'Ironhand' could protect factory wor...</td>\n",
       "      <td>(CNN)Working in a factory or warehouse can me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Words by Stephanie Bailey, video by Zahra Jamshed</td>\n",
       "      <td>2021-06-16 02:51:30</td>\n",
       "      <td>news</td>\n",
       "      <td>asia</td>\n",
       "      <td>https://www.cnn.com/2021/06/15/asia/swarm-robo...</td>\n",
       "      <td>This swarm of robots gets smarter the more it ...</td>\n",
       "      <td>In a Hong Kong warehouse, a swarm of autonomou...</td>\n",
       "      <td>asia, This swarm of robots gets smarter the mo...</td>\n",
       "      <td>This swarm of robots gets smarter the more it ...</td>\n",
       "      <td>(CNN)In a Hong Kong warehouse, a swarm of aut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paul R. La Monica, CNN Business</td>\n",
       "      <td>2022-03-15 09:57:36</td>\n",
       "      <td>business</td>\n",
       "      <td>investing</td>\n",
       "      <td>https://www.cnn.com/2022/03/15/investing/brics...</td>\n",
       "      <td>Russia is no longer an option for investors. T...</td>\n",
       "      <td>For many years, the world's most popular emerg...</td>\n",
       "      <td>investing, Russia is no longer an option for i...</td>\n",
       "      <td>Russia is no longer an option for investors. T...</td>\n",
       "      <td>New York (CNN Business)For many years, the wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Reuters</td>\n",
       "      <td>2022-03-15 11:27:02</td>\n",
       "      <td>business</td>\n",
       "      <td>business</td>\n",
       "      <td>https://www.cnn.com/2022/03/15/business/russia...</td>\n",
       "      <td>Russian energy investment ban part of new EU s...</td>\n",
       "      <td>The European Union formally approved on Tuesda...</td>\n",
       "      <td>business, Russian energy investment ban part o...</td>\n",
       "      <td>EU bans investment in Russian energy in new sa...</td>\n",
       "      <td>The European Union formally approved on Tuesda...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Author       Date published  \\\n",
       "Index                                                                           \n",
       "0                                     Jacopo Prisco, CNN  2021-07-15 02:46:59   \n",
       "2                                  Stephanie Bailey, CNN  2021-05-12 07:52:09   \n",
       "3      Words by Stephanie Bailey, video by Zahra Jamshed  2021-06-16 02:51:30   \n",
       "4                        Paul R. La Monica, CNN Business  2022-03-15 09:57:36   \n",
       "7                                                Reuters  2022-03-15 11:27:02   \n",
       "\n",
       "       Category    Section                                                Url  \\\n",
       "Index                                                                           \n",
       "0          news      world  https://www.cnn.com/2021/07/14/world/tusimple-...   \n",
       "2          news      world  https://www.cnn.com/2021/05/12/world/ironhand-...   \n",
       "3          news       asia  https://www.cnn.com/2021/06/15/asia/swarm-robo...   \n",
       "4      business  investing  https://www.cnn.com/2022/03/15/investing/brics...   \n",
       "7      business   business  https://www.cnn.com/2022/03/15/business/russia...   \n",
       "\n",
       "                                                Headline  \\\n",
       "Index                                                      \n",
       "0      There's a shortage of truckers, but TuSimple t...   \n",
       "2      Bioservo's robotic 'Ironhand' could protect fa...   \n",
       "3      This swarm of robots gets smarter the more it ...   \n",
       "4      Russia is no longer an option for investors. T...   \n",
       "7      Russian energy investment ban part of new EU s...   \n",
       "\n",
       "                                             Description  \\\n",
       "Index                                                      \n",
       "0      The e-commerce boom has exacerbated a global t...   \n",
       "2      Working in a factory can mean doing the same t...   \n",
       "3      In a Hong Kong warehouse, a swarm of autonomou...   \n",
       "4      For many years, the world's most popular emerg...   \n",
       "7      The European Union formally approved on Tuesda...   \n",
       "\n",
       "                                                Keywords  \\\n",
       "Index                                                      \n",
       "0      world, There's a shortage of truckers, but TuS...   \n",
       "2      world, Bioservo's robotic 'Ironhand' could pro...   \n",
       "3      asia, This swarm of robots gets smarter the mo...   \n",
       "4      investing, Russia is no longer an option for i...   \n",
       "7      business, Russian energy investment ban part o...   \n",
       "\n",
       "                                         Second headline  \\\n",
       "Index                                                      \n",
       "0      There's a shortage of truckers, but TuSimple t...   \n",
       "2      A robotic 'Ironhand' could protect factory wor...   \n",
       "3      This swarm of robots gets smarter the more it ...   \n",
       "4      Russia is no longer an option for investors. T...   \n",
       "7      EU bans investment in Russian energy in new sa...   \n",
       "\n",
       "                                            Article text  \n",
       "Index                                                     \n",
       "0       (CNN)Right now, there's a shortage of truck d...  \n",
       "2       (CNN)Working in a factory or warehouse can me...  \n",
       "3       (CNN)In a Hong Kong warehouse, a swarm of aut...  \n",
       "4      New York (CNN Business)For many years, the wor...  \n",
       "7      The European Union formally approved on Tuesda...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cnn.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c9088558-7c13-4f13-8ae6-eb835a36bf1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-07-15 02:46:59'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The time format is a string. It will be shown how to transform this object properly later\n",
    "\n",
    "df_cnn.iloc[0]['Date published']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4105c26-6eb7-45fc-9092-2816953126b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There's a shortage of truckers, but TuSimple thinks it has a solution: no driver needed - CNN\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cnn.iloc[0]['Headline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "15e5592f-7938-4dae-9a57-8bf3d00d547c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The e-commerce boom has exacerbated a global truck driver shortage, but could autonomous trucks help fix the problem?'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cnn.iloc[0]['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b39fc840-7f19-48f8-9b19-9203586b86a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th>Section</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">business</th>\n",
       "      <th>business</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business-food</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business-money</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cars</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economy</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homes</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>investing</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>media</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perspectives</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>success</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">entertainment</th>\n",
       "      <th>celebrities</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertainment</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <th>health</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">news</th>\n",
       "      <th>africa</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>americas</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asia</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>australia</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>china</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>india</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intl_world</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>living</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>middleeast</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinions</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uk</th>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us</th>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politics</th>\n",
       "      <th>politics</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">sport</th>\n",
       "      <th>football</th>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>golf</th>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motorsport</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sport</th>\n",
       "      <td>1088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tennis</th>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 n\n",
       "Category      Section             \n",
       "business      business          23\n",
       "              business-food      1\n",
       "              business-money     2\n",
       "              cars               1\n",
       "              economy            8\n",
       "              energy             3\n",
       "              homes              6\n",
       "              investing          9\n",
       "              media              2\n",
       "              perspectives      25\n",
       "              success            9\n",
       "              tech              15\n",
       "entertainment celebrities        1\n",
       "              entertainment     56\n",
       "              movies             1\n",
       "health        health            52\n",
       "news          africa            49\n",
       "              americas           3\n",
       "              asia               9\n",
       "              australia        114\n",
       "              china              5\n",
       "              europe           800\n",
       "              india              1\n",
       "              intl_world         1\n",
       "              living             7\n",
       "              middleeast         5\n",
       "              opinions          45\n",
       "              uk               376\n",
       "              us               134\n",
       "              weather           18\n",
       "              world             44\n",
       "politics      politics          75\n",
       "sport         football         618\n",
       "              golf             173\n",
       "              motorsport       100\n",
       "              sport           1088\n",
       "              tennis           197"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cnn.groupby([\"Category\", \"Section\"]).agg(n=('Category', 'count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5839e98d-40e9-423d-80d5-201593666e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnn_filtered_1= df_cnn[(df_cnn['Category']=='business') & (df_cnn['Section']=='business')]\n",
    "df_cnn_filtered_2= df_cnn[(df_cnn['Category']=='entertainment') & (df_cnn['Section']=='entertainment')]\n",
    "df_cnn_filtered_3= df_cnn[(df_cnn['Category']=='news') & (df_cnn['Section'].isin(['africa', 'australia', 'us']))]\n",
    "df_cnn_filtered_4= df_cnn[(df_cnn['Category']=='sport') & (df_cnn['Section'].isin(['motorsport']))]\n",
    "\n",
    "df_cnn_filtered = pd.concat([df_cnn_filtered_1, df_cnn_filtered_2, \n",
    "                             df_cnn_filtered_3, df_cnn_filtered_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "66b5b224-f777-4051-b74b-15de74afaf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnn_filtered[['year', 'month']] = df_cnn_filtered.apply(lambda x: x['Date published'].split(\" \")[0].split(\"-\")[:2], \n",
    "                                                           axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "211e9e0a-0021-45ef-a546-b5e64a903781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Author                                                       Reuters\n",
       "Date published                                   2022-03-15 11:27:02\n",
       "Category                                                    business\n",
       "Section                                                     business\n",
       "Url                https://www.cnn.com/2022/03/15/business/russia...\n",
       "Headline           Russian energy investment ban part of new EU s...\n",
       "Description        The European Union formally approved on Tuesda...\n",
       "Keywords           business, Russian energy investment ban part o...\n",
       "Second headline    EU bans investment in Russian energy in new sa...\n",
       "Article text       The European Union formally approved on Tuesda...\n",
       "year                                                            2022\n",
       "month                                                             03\n",
       "Name: 7, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cnn_filtered.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "92ab6ace-f1c5-49d3-8dc0-fbc2557df971",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for idx, row in df_cnn_filtered.iterrows():\n",
    "    document = Document(page_content=row['Article text'],\n",
    "                        metadata={\"Category\": row['Category'],\n",
    "                                  \"Section\": row['Section'],\n",
    "                                  \"Year\": row['year'],\n",
    "                                  \"ID\": f\"{idx}\"})\n",
    "    documents.append(document)\n",
    "\n",
    "\n",
    "cnn_vectorstore = FAISS.from_documents(documents, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f101cadc-0256-4535-bcab-0d7564078993",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_retriever = cnn_vectorstore.as_retriever(search_type=\"similarity\")\n",
    "cnn_retriever_configurable = cnn_retriever.configurable_fields(search_kwargs=ConfigurableField(id=\"hello_search\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "08764677-0914-4a7d-a339-2e1e6a47cbee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mcnn_vectorstore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_retriever\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Any'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'VectorStoreRetriever'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Return VectorStoreRetriever initialized from this VectorStore.\n",
       "\n",
       "Args:\n",
       "    search_type (Optional[str]): Defines the type of search that\n",
       "        the Retriever should perform.\n",
       "        Can be \"similarity\" (default), \"mmr\", or\n",
       "        \"similarity_score_threshold\".\n",
       "    search_kwargs (Optional[Dict]): Keyword arguments to pass to the\n",
       "        search function. Can include things like:\n",
       "            k: Amount of documents to return (Default: 4)\n",
       "            score_threshold: Minimum relevance threshold\n",
       "                for similarity_score_threshold\n",
       "            fetch_k: Amount of documents to pass to MMR algorithm (Default: 20)\n",
       "            lambda_mult: Diversity of results returned by MMR;\n",
       "                1 for minimum diversity and 0 for maximum. (Default: 0.5)\n",
       "            filter: Filter by document metadata\n",
       "\n",
       "Returns:\n",
       "    VectorStoreRetriever: Retriever class for VectorStore.\n",
       "\n",
       "Examples:\n",
       "\n",
       ".. code-block:: python\n",
       "\n",
       "    # Retrieve more documents with higher diversity\n",
       "    # Useful if your dataset has many similar documents\n",
       "    docsearch.as_retriever(\n",
       "        search_type=\"mmr\",\n",
       "        search_kwargs={'k': 6, 'lambda_mult': 0.25}\n",
       "    )\n",
       "\n",
       "    # Fetch more documents for the MMR algorithm to consider\n",
       "    # But only return the top 5\n",
       "    docsearch.as_retriever(\n",
       "        search_type=\"mmr\",\n",
       "        search_kwargs={'k': 5, 'fetch_k': 50}\n",
       "    )\n",
       "\n",
       "    # Only retrieve documents that have a relevance score\n",
       "    # Above a certain threshold\n",
       "    docsearch.as_retriever(\n",
       "        search_type=\"similarity_score_threshold\",\n",
       "        search_kwargs={'score_threshold': 0.8}\n",
       "    )\n",
       "\n",
       "    # Only get the single most similar document from the dataset\n",
       "    docsearch.as_retriever(search_kwargs={'k': 1})\n",
       "\n",
       "    # Use a filter to only retrieve documents from a specific paper\n",
       "    docsearch.as_retriever(\n",
       "        search_kwargs={'filter': {'paper_title':'GPT-4 Technical Report'}}\n",
       "    )\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\mengchieh\\miniconda3\\envs\\llm_examples\\lib\\site-packages\\langchain_core\\vectorstores.py\n",
       "\u001b[1;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_vectorstore.as_retriever?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e2868906-e3f7-45d7-8d64-376a3a0c06c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cnn_retriever_configurable.invoke(\"Russian\", config={\"configurable\": {\"hello_search\": {\"k\": 3}}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cac6b74a-94ef-4513-bb28-08998aa3b2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cnn_retriever_configurable.invoke(\"Russian\", config={\"configurable\": {\"hello_search\": {\"k\": 6}}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2bce394e-ad94-4327-8d0d-b4943d72047d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'Category': 'sport', 'Section': 'motorsport', 'Year': '2022', 'ID': '130'}\n",
      "9 {'Category': 'sport', 'Section': 'motorsport', 'Year': '2021', 'ID': '1878'}\n",
      "11 {'Category': 'sport', 'Section': 'motorsport', 'Year': '2021', 'ID': '4251'}\n",
      "16 {'Category': 'sport', 'Section': 'motorsport', 'Year': '2021', 'ID': '3515'}\n",
      "18 {'Category': 'sport', 'Section': 'motorsport', 'Year': '2021', 'ID': '3803'}\n",
      "27 {'Category': 'sport', 'Section': 'motorsport', 'Year': '2021', 'ID': '2029'}\n",
      "29 {'Category': 'sport', 'Section': 'motorsport', 'Year': '2021', 'ID': '3699'}\n",
      "37 {'Category': 'sport', 'Section': 'motorsport', 'Year': '2021', 'ID': '3502'}\n",
      "38 {'Category': 'sport', 'Section': 'motorsport', 'Year': '2021', 'ID': '4492'}\n",
      "39 {'Category': 'sport', 'Section': 'motorsport', 'Year': '2020', 'ID': '689'}\n"
     ]
    }
   ],
   "source": [
    "for idx, document in enumerate(cnn_retriever_configurable.invoke(\"Russian\", config={\"configurable\": {\"hello_search\": {\"k\": 40}}})):\n",
    "    metadata = document.metadata\n",
    "    if metadata['Category']=='sport':\n",
    "        print(idx, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8876e7a7-23b1-478d-b105-2f1efed267fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BUG https://github.com/langchain-ai/langchain/discussions/26806\n",
    "\n",
    "T = cnn_retriever_configurable.invoke(\"Russian\", config={\"configurable\": {\"hello_search\": {\"k\": 6, 'fetch_k': 50,\n",
    "                                                                                           \"filter\": {\"Category\": \"sport\"}}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "665f6a8d-499a-4222-bc4d-aee87792e1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Category': 'sport', 'Section': 'motorsport', 'Year': '2022', 'ID': '130'}\n",
      "{'Category': 'sport', 'Section': 'motorsport', 'Year': '2021', 'ID': '1878'}\n",
      "{'Category': 'sport', 'Section': 'motorsport', 'Year': '2021', 'ID': '4251'}\n",
      "{'Category': 'sport', 'Section': 'motorsport', 'Year': '2021', 'ID': '3515'}\n",
      "{'Category': 'sport', 'Section': 'motorsport', 'Year': '2021', 'ID': '3803'}\n",
      "{'Category': 'sport', 'Section': 'motorsport', 'Year': '2021', 'ID': '2029'}\n"
     ]
    }
   ],
   "source": [
    "for document in T:\n",
    "    print(document.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa2ce7d-8307-4393-8c39-8b7a0d480f17",
   "metadata": {},
   "source": [
    "#### Some template/or reference we need.\n",
    "\n",
    "I do not memorize everything. I always keep a template and I remember where to find it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2256dbd3-949b-4049-ba89-0e44199e9e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever.invoke(query, config={\"configurable\": {\"hello_search\": {\"k\": 7}}})\n",
    "\n",
    "# What if we have more than one condition?\n",
    "\n",
    "# template\n",
    "\n",
    "# filter = {'$and': [{'brand': {'$eq': brand}},  {'category': {'$eq': category}}}]# {\n",
    "# \"filter\": filter\n",
    "\n",
    "# greater than: '$gt' \n",
    "# less than: '$lt}\n",
    "\n",
    "# retriever = vectorstore.as_retriever(\n",
    "#     search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.5,\n",
    "#                                                              \"filter\": {\"cuisine\": \"mexican\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d64ce4-cebe-45ca-a338-0938e1454e7e",
   "metadata": {},
   "source": [
    "# **** 預計第一個小時結束 ****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc50ad2-8895-4c02-8ccc-55ed3565f783",
   "metadata": {},
   "source": [
    "# LangChain Expression Language (LCEL)\n",
    "\n",
    "From an `Operator` to a `Foreman`:\n",
    "\n",
    "Assuming that you finished an LLM process and you want to hand it over to an intern to run it, who does not have too much knowledge of Langchain. How do you improve the chance that the workflow will run without getting mistake?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06e9574-88c0-4c58-9bb1-397c087024a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We borrow the translation from the previous class.\n",
    "\n",
    "def translation_function(text):\n",
    "\n",
    "    \"\"\"\n",
    "    翻譯\n",
    "    直接將給予內容text翻譯成繁體中文\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = PromptTemplate.from_template(\"\"\"You are a helpful AI assistant with native speaker fluency in both English and traditional Chinese (繁體中文). \n",
    "    You will translate the given content.\"\"\")\n",
    "    system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "    \n",
    "    human_prompt = PromptTemplate(template='{query}',\n",
    "                                  input_variables=[\"query\"]\n",
    "                                  )\n",
    "    human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "    \n",
    "    translation_prompt_template =  ChatPromptTemplate.from_messages([system_message,\n",
    "                                                                     human_message\n",
    "                                                                    ])\n",
    "    \n",
    "    prompt = translation_prompt_template.invoke({\"query\": text})\n",
    "    output = model.invoke(prompt)\n",
    "    return output.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6a32c0-a242-40d1-8527-68a2a24fd5f3",
   "metadata": {},
   "source": [
    "### 食譜 - LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b61f5d-4ce0-425b-b712-139e55b2d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schemas = [\n",
    "        ResponseSchema(name=\"used ingredients\", description=\"The actual ingredients used in cooking\"),\n",
    "        ResponseSchema(name=\"extra ingredients\", description=\"extra ingredients that have to be prepared \"),\n",
    "        ResponseSchema(name=\"result\", description=\"The dish and cooking recipe in detail\")\n",
    "    ]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# Define human prompt template\n",
    "\n",
    "system_prompt = PromptTemplate.from_template(\"\"\"You are an AI assistant as the best chef in the world. You have a great taste and\n",
    "cooking skills like Gordon Ramsay. You should be able to come up with dish based on `suggested ingredient`, and tell us what extra ingredients to be prepared by \n",
    "comparing the ingredients actually used in the cooking and the `existing ingredient`\n",
    "\n",
    "The `suggested ingredients` are the ingredients suggested by some recipe. You have the freedom to add or remove ingredients to achieve the goal, but try to be as \n",
    "faithful to the `suggested ingredient` as possible. \n",
    "\"\"\")\n",
    "\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='existing ingredients:[{existing_ingredients}]; '\n",
    "                                       'suggested ingredients: [{suggested_ingredients}]\\n; '\n",
    "                                       'format instruction: {format_instructions}',\n",
    "                              input_variables=[\"existing_ingredients\", \"suggested_ingredients\"],\n",
    "                              partial_variables={\"format_instructions\": format_instructions}\n",
    "                              )\n",
    "\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                human_message\n",
    "                                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e547888-495a-4a6b-8b2f-06663d436688",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_prompt|model|output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432a0264-9c47-4639-be04-a3e53a32df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"existing_ingredients\": \", \".join(existing_ingredients), \"suggested_ingredients\": \", \".join(suggested_ingredients)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc14bdc-b54c-4cea-9121-4521742bb03b",
   "metadata": {},
   "source": [
    "#### How do we attach the translation to the process above?\n",
    "\n",
    "- 1. Build the translation process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc406dee-6395-4700-ab27-e9637e0bc275",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = PromptTemplate.from_template(\"\"\"You are a helpful AI assistant with native speaker fluency in both English and traditional Chinese (繁體中文). \n",
    "    You will translate the given content.\"\"\")\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                              input_variables=[\"query\"]\n",
    "                              )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "translation_prompt_template =  ChatPromptTemplate.from_messages([system_message,\n",
    "                                                                 human_message\n",
    "                                                                ])\n",
    "\n",
    "translation_chain=translation_prompt_template|model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce74c693-8d26-4ec3-a3a2-b37a81f7d98d",
   "metadata": {},
   "source": [
    "- 2. Connect the recipe chain with the translation chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ead3f6-c734-485a-9bd1-b5e41f622842",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_chain = chat_prompt|model\n",
    "\n",
    "\n",
    "pipeline = {\"query\": recipe_chain}|translation_chain|output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8015e875-183e-437b-8997-d1c9dfa25811",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.invoke({\"existing_ingredients\": \", \".join(existing_ingredients), \"suggested_ingredients\": \", \".join(suggested_ingredients)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d2df8d-7455-4549-a8ee-d572ed69182e",
   "metadata": {},
   "source": [
    "#### What happens?\n",
    "\n",
    "I know it looks mysterious, but it is very simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c2e24-1b1a-420c-a7ad-642be968c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename= \"tutorial/LLM+Langchain/Week-2/LCEL_1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9dff1e-cd11-4627-a542-f54d52a4e21b",
   "metadata": {},
   "source": [
    "## Minimal Example\n",
    "\n",
    "### 1. Creating a Prompt Template (創建提示模板):\n",
    "\n",
    "- ChatPromptTemplate.from_template is used to create a prompt template. This template is a string that includes a placeholder {topic}.\n",
    "- The template specifies the instruction: \"tell me a short joke about {topic}\".\n",
    "- 使用 ChatPromptTemplate.from_template 創建一個提示模板。這個模板是一個包含佔位符 {topic} 的字符串。\n",
    "- 模板指定了指令：“tell me a short joke about {topic}”（給我講一個關於{topic}的簡短笑話）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd952993-29ad-4877-8795-5cf49e084105",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Official diagram flow\n",
    "\n",
    "Image(filename= \"tutorial/LLM+Langchain/Week-2/lcel pipeline.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb11136f-8d8d-44b9-8a75-9c91975f4aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80d68f9-a5c7-46b2-b1fb-64fe8f530ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f21f8c-d2ca-4960-bb69-a59efaa45880",
   "metadata": {},
   "source": [
    "### 2. Setting Up the Chain (設置鏈條):\n",
    "\n",
    "- chain = prompt | model sets up a chain where the prompt is connected to a model. This means that the model will process the prompt to generate a response.\n",
    "- The | operator is used to combine the prompt and the model into a single chain.\n",
    "- chain = prompt | model 設置了一個鏈條，其中提示連接到模型。這意味著模型將處理該提示來生成回應。\n",
    "- | 運算符用於將提示和模型組合成一個鏈條。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016cee2f-686e-4b9c-b494-11e9f4886997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the PromptTemplate to the ChatModel\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6dcf0b-cb87-4c4f-8d88-06f714ec190b",
   "metadata": {},
   "source": [
    "### 3. Getting the Joke (獲取笑話):\n",
    "\n",
    "- The result of chain.invoke({\"topic\": \"ice cream\"}) is stored in the variable joke.\n",
    "- This variable now contains the generated joke about ice cream.\n",
    "- chain.invoke({\"topic\": \"ice cream\"}) 的結果存儲在變量 joke 中。\n",
    "- 這個變量現在包含生成的關於冰淇淋的笑話。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfd1bcd-39a6-43c3-b895-e2dc24c43ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input -> prompt template -> model\n",
    "\n",
    "joke = chain.invoke({\"topic\": \"ice cream\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98ab297-c127-4e64-93f4-81f843efc958",
   "metadata": {},
   "outputs": [],
   "source": [
    "joke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aedd556-73a7-4a73-9220-82a9fadc7ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "joke.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a621e272-9562-4970-90d0-4d36661905b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(joke.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d10377-f1d6-422a-8c06-db4cc16f54b5",
   "metadata": {},
   "source": [
    "### 1. Importing StrOutputParser (導入 StrOutputParser):\n",
    "\n",
    "- The code imports StrOutputParser from the langchain_core.output_parsers module. This class is used to parse the output of the model into a string format.\n",
    "- 代碼從 langchain_core.output_parsers 模塊導入 StrOutputParser。這個類用於將模型的輸出解析為字符串格式。\n",
    "\n",
    "### 2. Creating an Output Parser:\n",
    "\n",
    "- An instance of StrOutputParser is created and assigned to the variable output_parser.\n",
    "- This parser will be used to process the raw output from the model and convert it into a readable string format.\n",
    "- 創建一個 StrOutputParser 的實例，並將其賦值給變量 output_parser。\n",
    "- 這個解析器將用於處理來自模型的原始輸出，並將其轉換為可讀的字符串格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0e144b-6c59-4a6c-a5c0-0ebd09fbd736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# input -> prompt template -> model -> output parser\n",
    "\n",
    "chain.invoke({\"topic\": \"ice cream\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aab8739-5057-420e-a035-8055a1fad92f",
   "metadata": {},
   "source": [
    "## 範例操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ba61c-382a-4b2d-a8fa-8a5513825e2c",
   "metadata": {},
   "source": [
    "### Coercion\n",
    "\n",
    "Do not ask me why this word is used...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc561f1b-7daa-42d2-bf1f-b9929aa96e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename= \"tutorial/LLM+Langchain/Week-2/LCEL_2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db580ce-4a32-4a96-be75-2f2d5d68e9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_chain = prompt | model | output_parser\n",
    "\n",
    "analysis_prompt = ChatPromptTemplate.from_template(\"is this a funny joke? {joke}\")\n",
    "\n",
    "analysis_chain = analysis_prompt | model\n",
    "\n",
    "composed_chain = {\"joke\": joke_chain} | analysis_chain | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c3812a-0a86-4082-96b8-88d79c099b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_chain.invoke({\"topic\": \"ice cream\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e362c88-1f82-42c5-8b61-96c18affddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(composed_chain.invoke({\"topic\": \"ice cream\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5f8553-996e-4d34-bf70-12f9553b8cef",
   "metadata": {},
   "source": [
    "1. chain 執行結果，將結果放進'joke' 這個 key 裡\n",
    "2. {\"joke\": content} 被送進analysis_prompt 中，等價於 analysis_prompt.invoke({\"joke\": content})\n",
    "3. model 接收 analysis_prompt 產生的結果\n",
    "4. output_parser 處理結果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba419208-49a4-48b6-b96a-626963d9e798",
   "metadata": {},
   "source": [
    "## Parallelize steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c25e8c-eda5-464d-9abf-75ee04f70cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "joke_chain = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\") | model\n",
    "poem_chain = ChatPromptTemplate.from_template(\"write a 2-line poem about {topic}\") | model\n",
    "\n",
    "map_chain = RunnableParallel(joke=joke_chain, poem=poem_chain)\n",
    "\n",
    "map_chain.invoke({\"topic\": \"bear\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2299347c-a396-4c88-9c58-b4c7fa77af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(joke_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b778b6-506a-41c6-ae4d-25dfb3e4248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "joke_chain.invoke({\"topic\": \"bear\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f795294f-f594-4997-b493-9239cf416f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "poem_chain.invoke({\"topic\": \"bear\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcf29cc-d5a2-4879-9dd9-ef49b243b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "map_chain.invoke({\"topic\": \"bear\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9850622e-12e1-42b0-94f0-cc49cbbb6f62",
   "metadata": {},
   "source": [
    "RunnableParallel are also useful for running independent processes in parallel, since each Runnable in the map is executed in parallel. For example, we can see our earlier joke_chain, poem_chain and map_chain all have about the same runtime, even though map_chain executes both of the other two.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db494f11-15f8-4658-b065-1a0449c10ab7",
   "metadata": {},
   "source": [
    "## Run custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e37218-e84c-4b5c-9846-5ae4c32d2e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "\n",
    "def length_function(text):\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "def _multiple_length_function(text1, text2):\n",
    "    return len(text1) * len(text2)\n",
    "\n",
    "\n",
    "def multiple_length_function(_dict):\n",
    "    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])\n",
    "\n",
    "# chain = (\n",
    "#     {\n",
    "#         \"a\": itemgetter(\"foo\") | RunnableLambda(length_function),\n",
    "#         \"b\": {\"text1\": itemgetter(\"foo\"), \"text2\": itemgetter(\"bar\")}\n",
    "#         | RunnableLambda(multiple_length_function),\n",
    "#     }\n",
    "#     | prompt\n",
    "#     | model\n",
    "# )\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"what is {a} + {b}\")\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"a\": itemgetter(\"foo\") | length_function,\n",
    "        \"b\": {\"text1\": itemgetter(\"foo\"), \"text2\": itemgetter(\"bar\")}\n",
    "        | multiple_length_function,\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58914c7-5864-4956-81c2-12b8e11f550e",
   "metadata": {},
   "source": [
    "Oops, how to solve this error message?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802dadc3-be5a-4067-82c5-8e4135f1f2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\n",
    "        \"a\": itemgetter(\"foo\") | RunnableLambda(length_function),\n",
    "        \"b\": {\"text1\": itemgetter(\"foo\"), \"text2\": itemgetter(\"bar\")}\n",
    "        | RunnableLambda(multiple_length_function),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad18d9a4-d3ce-4fc5-a9f0-1be23581a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"foo\": \"bar\", \"bar\": \"gah\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7d179a-ccb1-48ef-9007-eab272b71c14",
   "metadata": {},
   "source": [
    "How does it work?\n",
    "\n",
    "- 'bar' -> 'foo', 'foo' ('bar') -> length_function => a = 3\n",
    "- 'bar' -> 'foo' & 'gah' -> 'bar', 'foo' ('bar') -> 'text1' & 'bar' ('gah') -> 'text2', {'text1': 'bar', 'text2': 'gah'} -> multiple_length_function => b = 9\n",
    "- {'a':3, 'b': 9} -> prompt -> 'what is 3 + 9'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1233f2-d49d-4a7a-8112-b7cba295c91a",
   "metadata": {},
   "source": [
    "#### Decorator\n",
    "\n",
    "- Something very cool\n",
    "- This is a new discovery in the beginning of December. So it is not used in subsequent tutorials. But feel free to adapt the code to experience the magic.\n",
    "- Knowing of programming is still the key to successful AI application:\n",
    "\n",
    "  you can only get a frog from a frog - Joerg Schmalian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3defc52-a2e1-4720-a9c5-62b9c0a64405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import chain, RunnableParallel\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"what is {a} + {b}\")\n",
    "\n",
    "@chain\n",
    "def length_function(text):\n",
    "    return len(text)\n",
    "\n",
    "def _multiple_length_function(text1, text2):\n",
    "    return len(text1) * len(text2)\n",
    "\n",
    "@chain\n",
    "def multiple_length_function(_dict):\n",
    "    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])\n",
    "\n",
    "chain =    RunnableParallel(\n",
    "        a=itemgetter(\"foo\") | length_function,\n",
    "        b={\"text1\": itemgetter(\"foo\"), \"text2\": itemgetter(\"bar\")}\n",
    "        | multiple_length_function)| prompt | model\n",
    "\n",
    "chain.invoke({\"foo\": \"bar\", \"bar\": \"gah\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b907c618-0a13-44f0-a9d3-873ec6185f07",
   "metadata": {},
   "source": [
    "## Passing data through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0547d8de-37a7-48b8-8b6c-1448f1b110c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    passed=RunnablePassthrough(),\n",
    "    modified=lambda x: x[\"num\"] + 1,\n",
    ")\n",
    "\n",
    "runnable.invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17236ef-98e2-47f4-8e39-5f478ddb7310",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = RunnableParallel(\n",
    "    passed_2=RunnablePassthrough(),\n",
    "    modified=lambda x: x[\"num\"] + 1,\n",
    ")\n",
    "\n",
    "runnable.invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffe96a0-3bb1-4d67-80cc-ef4666f7b3f6",
   "metadata": {},
   "source": [
    "### Retrieval Example: Step by Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc91a82e-e21b-436b-8596-f138f57c88fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Creating a Template (創建模板):\n",
    "\n",
    "- A template is created that instructs the model to answer a question based only on a provided context. The template looks like this:\n",
    "- 創建一個模板，指示模型僅基於提供的上下文來回答問題。模板如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c43a9c-ed5f-4af1-ac91-b98d16f484c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# context: something that will be generated with the question\n",
    "# question\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb5a647-9679-4b85-ac5a-ddb6bf24a91f",
   "metadata": {},
   "source": [
    "### 2. Generating a Prompt (生成提示):\n",
    "\n",
    "- The ChatPromptTemplate.from_template(template) command uses the template to create a prompt that can later be filled with specific context and a question.\n",
    "- 使用 ChatPromptTemplate.from_template(template) 命令來創建一個提示，之後可以用特定的上下文和問題來填充。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb9fb94-d90d-452a-85c9-f1aa30a20601",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6d7f2c-9800-44af-89fd-9c5f82cc8d1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Formulating a Query (制定查詢):\n",
    "\n",
    "- A query is created by joining the ingredients from the 6th recipe in recipe_test with commas. This query is used to retrieve relevant information.\n",
    "- 通過將 recipe_test 中第六個食譜的成分用逗號連接來創建查詢。此查詢用於檢索相關信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f0466c-6cef-4d82-be0e-3ca463b990e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \", \".join(recipe_test[5]['ingredients'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3bb708-eaaf-40d2-aedb-ada80a2ab8b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Retrieving Context (檢索上下文):\n",
    "\n",
    "- The retriever.invoke(query) command uses the query to find the most relevant documents or information. This retrieved information is stored in the context variable.\n",
    "- 使用 retriever.invoke(query) 命令，通過查詢找到最相關的文檔或信息。這些檢索到的信息存儲在 context 變量中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaf870c-13a5-45e8-9be7-fed11542b65b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "context = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928599c7-08cc-4bee-b322-6fae436a230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fc80ed-af41-4571-8459-fbb962e6dc14",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5. Filling the Prompt (填充提示):\n",
    "\n",
    "- The prompt is filled with the retrieved context and the question using prompt.invoke({\"context\": context, \"question\": question}). This creates an input prompt for the model.\n",
    "- 使用 prompt.invoke({\"context\": context, \"question\": question}) 將提示填充檢索到的上下文和問題。這創建了模型的輸入提示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d93c0d7-b076-4346-8016-5e0abb14a1a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"Show me all the ingredients.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ba36aa-8517-4f80-93e5-adf2fc188c15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_as_input = prompt.invoke({\"context\": context, \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a62477-2bdd-480b-b69e-0f540cb60f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_as_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd95a37-cf29-49ce-8311-740c90129703",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 6. Getting the Model's Response (獲取模型的回應):\n",
    "\n",
    "- The model is invoked with the filled prompt using model.invoke(prompt_as_input). The model processes the prompt and generates an output.\n",
    "- 使用 model.invoke(prompt_as_input) 調用模型。模型處理提示並生成輸出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007a7abb-119f-4f5d-8b3c-3fb9736134cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = model.invoke(prompt_as_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca52e14-eb67-44c8-a9cc-eb365c8a34cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda3d5ca-b2c9-465d-a04a-21574c7727ff",
   "metadata": {},
   "source": [
    "### 7. Parsing the Output (解析輸出):\n",
    "\n",
    "- The output from the model is parsed using output_parser.parse(output.content). This ensures the output is in a readable format.\n",
    "- 使用 output_parser.parse(output.content) 解析模型的輸出。這確保輸出是可讀的格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68918bd5-87ae-4c7c-b40a-5b1a2eb05175",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(output_parser.parse(output.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614492c6-abdb-445d-9c45-2e64d25675de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = RunnablePassthrough.assign(context=itemgetter(\"query\")|retriever) | prompt | model | output_parser\n",
    "\n",
    "chain.invoke({\"query\": query, \"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0c6e19-c233-432f-bc33-82ef3907df4f",
   "metadata": {},
   "source": [
    "## Translation Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e97c917-9e88-4a53-9073-76c03d75b764",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = PromptTemplate.from_template('''You are an AI assistant with a linquistic PhD degree and translation expert. \n",
    "If you are not able to identify the language used by the given text, answer 'I do not know'.\n",
    "''')\n",
    "\n",
    "# Define the response schema for translation\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"translate\", description=\"the translated result\")]\n",
    "\n",
    "# Create an output parser based on the response schemas\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# Get format instructions from the output parser\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# Define a prompt template for text translation\n",
    "prompt = PromptTemplate(template=\"Translate the product name to English: \\n\\n \"\n",
    "                                 \"product: {product}\\n{format_instructions}\",\n",
    "                        input_variables=['product'],\n",
    "                        partial_variables={\"format_instructions\": format_instructions})\n",
    "\n",
    "# Create a human message prompt template\n",
    "human_message = HumanMessagePromptTemplate(prompt=prompt)\n",
    "\n",
    "# Create a chat prompt template from system prompt and human message\n",
    "chat_prompt = ChatPromptTemplate.from_messages([(\"system\", system_prompt.template),\n",
    "                                                human_message])\n",
    "\n",
    "# Construct the processing chain\n",
    "chain = chat_prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba56ee-d7c3-46b7-b04e-a16ab885bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"product\": 'Сыворотка Ревиталифт Филлер для лица и шеи с 1,5% чистой гиалуроновой кислотой'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc00810-dfd1-4ffc-a6fc-f34ded5e9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"product\": 'Felt Liner Noir Infaillible Grip Precision'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec646ea-4b86-4a4d-aa50-666364734e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = PromptTemplate.from_template('''You are an AI assistant with native Chinese proficiency and translation expert. \n",
    "If you are not able to identify the language used by the given text, answer 'I do not know'.\n",
    "''')\n",
    "\n",
    "# Define the response schema for translation\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"translate\", description=\"the translated result\")]\n",
    "\n",
    "# Create an output parser based on the response schemas\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# Get format instructions from the output parser\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# Define a prompt template for text translation\n",
    "prompt = PromptTemplate(template=\"Translate the message to English: \\n\\n \"\n",
    "                                 \"message: {product}\\n{format_instructions}\",\n",
    "                        input_variables=['product'],\n",
    "                        partial_variables={\"format_instructions\": format_instructions})\n",
    "\n",
    "# Create a human message prompt template\n",
    "human_message = HumanMessagePromptTemplate(prompt=prompt)\n",
    "\n",
    "# Create a chat prompt template from system prompt and human message\n",
    "chat_prompt = ChatPromptTemplate.from_messages([(\"system\", system_prompt.template),\n",
    "                                                human_message])\n",
    "\n",
    "# Construct the processing chain\n",
    "chain = chat_prompt | model\n",
    "\n",
    "chain.invoke({\"product\": \"老師這最後做出來可以怎麼運用?就是找不同國家的語言來學習嗎? 能不能用中文\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf54a3f6-9402-4d8e-b452-48eaa1292190",
   "metadata": {},
   "source": [
    "## 回家作業\n",
    "\n",
    "1. 根據食譜 - LCEL, 配合LCEL, 完成從給 材料 -> 中文食譜\n",
    "2. 根據 retrieval example -> 要求將食材分類 (肉，香料，奶製品，等等)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee204f8e-8f5a-48f9-957c-61dbc7e68456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
