{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0035c860-b401-4ea7-af0a-f523f37dfa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")\n",
    "\n",
    "import asyncio\n",
    "from textwrap import dedent\n",
    "from typing import List, Literal, Union\n",
    "\n",
    "from langchain.tools import BaseTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, MessagesPlaceholder\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from src.initialization import credential_init\n",
    "\n",
    "credential_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecf6e51-e8bc-4310-b0c8-5717c6fb5203",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b8e34-6543-4596-b6ba-8af593a3132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage, SystemMessage\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "system_message = SystemMessage(content=dedent(\"\"\"\\\n",
    "              You are an essay assistant tasked with writing excellent 5-paragraph essays.\n",
    "              Generate the best essay possible for the user's request.\n",
    "              If the user provides critique, respond with a revised version of your previous attempts.\n",
    "              \"\"\"))\n",
    "\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        system_message,\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "model: gemini-2.5-flash-lite\n",
    "\"\"\"\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=6,\n",
    "    disable_streaming=False\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "generate_pipeline = chat_prompt_template|model|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3669eb8a-6006-4cba-a5f2-5630e547fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGoogleGenerativeAI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72d995d-0ac6-4f05-beb8-837a7e2880d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.add_user_message(\"生成一個投放在Tiktok上的冰淇淋廣告劇本。目標群眾為8-15歲的小孩\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cf738a-0d7b-45d6-a304-559bac86d1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "essay = generate_pipeline.invoke({\"messages\": chat_history.messages})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b723f6-a43a-4a5a-a74e-8281bbd7de1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "essay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9e3803-0842-4fbb-a80b-f1d10ac80490",
   "metadata": {},
   "source": [
    "## Reflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045fc855-f54e-4328-b5f4-8e34ffc43a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = SystemMessage(content=dedent(\"\"\"\\\n",
    "                        你是一個資深的廣告投放諮詢，擅長於在社群軟體投放食品類廣告。你會根據送來的劇本給予建議並提出改善的方法。\n",
    "                        \"\"\")\n",
    "                              )\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        system_message,\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "reflect_pipeline = chat_prompt_template|model|StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f007bad-0f8d-4759-abf5-a8251835881c",
   "metadata": {},
   "source": [
    "將之前生成的文章加入chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b230d-716b-4f56-9f25-7fcf0c85a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "chat_history.add_user_message(essay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925acdba-b76a-4ff7-ab4c-f47075d15c96",
   "metadata": {},
   "source": [
    "生成反饋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293445b9-2310-47e1-893c-d1fc691c406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bf3296-3335-4a8b-abbd-cd3f33e32d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "reflection = reflect_pipeline.invoke({\"messages\": chat_history.messages})\n",
    "\n",
    "print(reflection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fad79bb-0805-4cde-8144-8254a7fcda27",
   "metadata": {},
   "source": [
    "將生成的反饋加入到Chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e49cc8-acc0-4e93-ab75-76bc870769e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.add_user_message(reflection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce12e91e-993f-41a2-bfe9-a2373e4d771d",
   "metadata": {},
   "source": [
    "然後回到 generate_pipeline 並且重複整個過程 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16f9946-c26c-4354-9be3-182b16967d5e",
   "metadata": {},
   "source": [
    "## Langgraph Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a49322e-5bd5-4fa0-9ec9-183efc591473",
   "metadata": {},
   "source": [
    "## 💬 Chat History 結構 (ChatMessageHistory Structure)\n",
    "\n",
    "在 **Generation** 階段後，`chat_history` 的結構如下：\n",
    "\n",
    "- **HumanMessage**: 使用者指令，例如：  \n",
    "  > 生成一個投放在 TikTok 上的冰淇淋廣告劇本。目標群眾為 8–15 歲的小孩  \n",
    "- **AIMessage**: 模型生成的回覆內容 (`<生成的內容>`)\n",
    "\n",
    "---\n",
    "\n",
    "## 🔄 Reflection 階段 — 為什麼要交換角色\n",
    "\n",
    "在 **Reflection Agent** 中，AI 會對自己剛才生成的內容進行「反思 (reflection)」。  \n",
    "此時，我們希望模型 **以「使用者」的角度重新審視自己剛才的輸出**。\n",
    "\n",
    "因此，在反思過程中，我們需要將 `chat_history` 中的訊息角色進行對調：\n",
    "\n",
    "| 原本類型 | 在 Reflection 中變為 |\n",
    "|-----------|-----------------------|\n",
    "| `AIMessage` | `HumanMessage` |\n",
    "| `HumanMessage` | `AIMessage` |\n",
    "\n",
    "這樣做的目的，是讓模型把自己先前生成的回答 (`AIMessage`) 視為「使用者輸入」，  \n",
    "並根據這個內容進行反思或修正。\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 範例\n",
    "\n",
    "**Generation 後:**\n",
    "```python\n",
    "[\n",
    "    HumanMessage(content=\"生成一個投放在 TikTok 上的冰淇淋廣告劇本。目標群眾為 8–15 歲的小孩\"),\n",
    "    AIMessage(content=\"<生成的內容>\")\n",
    "]\n",
    "\n",
    "在使用reflection_pipeline時，我們要讓輸入變為\n",
    "\n",
    "\n",
    "[\n",
    "    HumanMessage(content=\"<生成的內容>\"),\n",
    "]\n",
    "\n",
    "並將輸出定調為HumanMessage，方便在Generation時直接使用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466e2a01-713f-48f9-90a0-c8c8a63c1621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from typing import Annotated, List, Sequence\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "\n",
    "MAX_ITERATION = 2\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "async def generation_node(state: State) -> State:\n",
    "    \n",
    "    result = await generate_pipeline.ainvoke({\"messages\": state['messages']})\n",
    "    \n",
    "    return {\"messages\": AIMessage(content=result)}\n",
    "\n",
    "\n",
    "async def reflection_node(state: State) -> State:\n",
    "        \n",
    "    cls_map = {\"ai\": HumanMessage, \"human\": AIMessage}\n",
    "    \n",
    "    messages = [cls_map[msg.type](content=msg.content) for msg in state[\"messages\"][1:]]\n",
    "    \n",
    "    result = await reflect_pipeline.ainvoke({\"messages\": messages})\n",
    "    \n",
    "    return {\"messages\": HumanMessage(content=result)}\n",
    "\n",
    "\n",
    "def should_continue(state: State):\n",
    "    if len(state[\"messages\"]) > MAX_ITERATION:\n",
    "        # End after 3 iterations\n",
    "        return END\n",
    "    return \"reflection_node\"\n",
    "\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"generation_node\", generation_node)\n",
    "workflow.add_node(\"reflection_node\", reflection_node)\n",
    "\n",
    "workflow.add_edge(START, \"generation_node\")\n",
    "workflow.add_edge(\"reflection_node\", \"generation_node\")\n",
    "workflow.add_conditional_edges(\"generation_node\", should_continue, [END, \"reflection_node\"])\n",
    "\n",
    "memory = InMemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432a1d83-b93e-4c9a-8639-d553845cf17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ed5cfc-fce6-4088-8caf-e813001a4de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = app.invoke({\"messages\": [HumanMessage(content=\"生成一個投放在Tiktok上的冰淇淋廣告劇本。目標群眾為8-15歲的小孩\")]}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce8bf1f-00aa-4319-bc63-2fd4e5efb56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for event in app.astream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"生成一個投放在Tiktok上的冰淇淋廣告劇本。目標群眾為8-15歲的小孩\"\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "):\n",
    "    print(event)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8000522e-28ad-493a-8975-a3bf3ee9986e",
   "metadata": {},
   "source": [
    "取得歷史紀錄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be944d78-ae16-44e5-80f6-6eabeef10b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = app.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d5d70-bc33-4097-9885-eb0c3dda5b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "state.values['messages'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f335777-2e84-47de-ae86-a1975c30c4e2",
   "metadata": {},
   "source": [
    "Dummy Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3716e73-0804-4957-a118-351e9f31ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from operator import add\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: str\n",
    "    bar: Annotated[list[str], add]\n",
    "\n",
    "def node_a(state: State):\n",
    "    return {\"foo\": \"a\", \"bar\": [\"a\"]}\n",
    "\n",
    "def node_b(state: State):\n",
    "    return {\"foo\": \"b\", \"bar\": [\"b\"]}\n",
    "\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(node_a)\n",
    "workflow.add_node(node_b)\n",
    "workflow.add_edge(START, \"node_a\")\n",
    "workflow.add_edge(\"node_a\", \"node_b\")\n",
    "workflow.add_edge(\"node_b\", END)\n",
    "\n",
    "\"\"\"\n",
    "Checkpoints:\n",
    "\n",
    "The state of a thread at a particular point in time is called a checkpoint. \n",
    "Checkpoint is a snapshot of the graph state saved at each superstep and is represented by StateSnapshot object.\n",
    "\"\"\"\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "graph.invoke({\"foo\": \"\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8189df-9f39-48de-a76d-a60507d17cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(config)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0a6ce2-d0a6-4ca9-9789-54486de3d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"foo\": \"c\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1f2c01-e5fb-4fa1-9cc0-ffb3f5abeada",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
