{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fabc653-5ca9-484b-a864-0b6a363ac275",
   "metadata": {},
   "source": [
    "# ğŸ“– Agent å¯¦ä½œç¯„ä¾‹ï¼šè‡ªå‹•åŒ–æœ‰è²æ›¸ç”Ÿæˆ\n",
    "\n",
    "æœ¬ Notebook å±•ç¤ºå¦‚ä½•é€é Agent ä¸²æ¥ **æ•…äº‹ â†’ åœ–åƒ â†’ èªéŸ³** çš„è‡ªå‹•åŒ–æµç¨‹ã€‚  \n",
    "æ¯å€‹æ­¥é©Ÿéƒ½æœƒå°‡è¼¸å‡ºä¿å­˜ç‚ºæª”æ¡ˆï¼Œé¿å…é‡è¤‡ Token æ¶ˆè€—ï¼Œä¸¦æ–¹ä¾¿å¾ŒçºŒæµç¨‹ä½¿ç”¨ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ æ•´é«”æµç¨‹\n",
    "1. æ•…äº‹å…§å®¹ç”Ÿæˆ  \n",
    "2. åœ–ç‰‡å…§å®¹ç”Ÿæˆ  \n",
    "3. èªéŸ³å…§å®¹ç”Ÿæˆ  \n",
    "\n",
    "---\n",
    "\n",
    "## 1ï¸âƒ£ æ•…äº‹å…§å®¹ç”Ÿæˆ\n",
    "**è¼¸å…¥**  \n",
    "- è‰ç¨¿æ–‡å­—  \n",
    "- æ—¢æœ‰å…§å®¹ (`.txt` æª”æ¡ˆ)  \n",
    "\n",
    "**è™•ç†æµç¨‹**  \n",
    "1. å°‡æ–‡å­—é€å…¥ Langserve æœå‹™  \n",
    "2. æ¥æ”¶ç”Ÿæˆçš„æ•…äº‹æ®µè½  \n",
    "\n",
    "**è¼¸å‡º**  \n",
    "- å°‡çµæœå­˜ç‚º `.txt` æª”  \n",
    "- é¿å… Agent ä¸€ç›´å‚³éæ•´ä»½æ•…äº‹ï¼Œé™ä½ Token æ¶ˆè€—  \n",
    "\n",
    "---\n",
    "\n",
    "## 2ï¸âƒ£ åœ–ç‰‡å…§å®¹ç”Ÿæˆ\n",
    "**è¼¸å…¥**  \n",
    "- æœ€æ–°ç”Ÿæˆçš„æ•…äº‹æ–‡å­—  \n",
    "- æ—¢æœ‰åœ–ç‰‡ (`.png`)  \n",
    "\n",
    "**è™•ç†æµç¨‹**  \n",
    "1. å°‡åœ–ç‰‡ç·¨ç¢¼ç‚º base64  \n",
    "2. æ–‡å­—èˆ‡åœ–ç‰‡é€å…¥ Langserve æœå‹™  \n",
    "3. æ¥æ”¶å›å‚³çš„åœ–ç‰‡ï¼ˆbase64 æ ¼å¼ï¼‰  \n",
    "\n",
    "**è¼¸å‡º**  \n",
    "- å°‡ base64 è§£ç¢¼ç‚ºäºŒé€²ä½è³‡æ–™ï¼Œå­˜æˆ `.png` æª”  \n",
    "\n",
    "---\n",
    "\n",
    "## 3ï¸âƒ£ èªéŸ³å…§å®¹ç”Ÿæˆ\n",
    "**è¼¸å…¥**  \n",
    "- æœ€æ–°ç”Ÿæˆçš„æ•…äº‹æ–‡å­—  \n",
    "\n",
    "**è™•ç†æµç¨‹**  \n",
    "1. å°‡æ–‡å­—é€å…¥ Langserve æœå‹™  \n",
    "2. æ¥æ”¶å›å‚³çš„èªéŸ³ï¼ˆbase64 æ ¼å¼ï¼‰  \n",
    "\n",
    "**è¼¸å‡º**  \n",
    "- å°‡ base64 è§£ç¢¼ç‚ºäºŒé€²ä½è³‡æ–™ï¼Œå­˜æˆ `.mp3` æˆ– `.wav` æª”  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”„ æµç¨‹åœ–\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    A[æ•…äº‹è‰ç¨¿/èˆŠå…§å®¹ .txt] --> B[é€å…¥ Langserve ç”Ÿæˆæ•…äº‹]\n",
    "    B --> C[æ•…äº‹å…§å®¹ .txt]\n",
    "    C --> D[é€å…¥ Langserve ç”Ÿæˆåœ–ç‰‡ (base64)]\n",
    "    D --> E[è§£ç¢¼ä¸¦å­˜ç‚º .png]\n",
    "    C --> F[é€å…¥ Langserve ç”ŸæˆèªéŸ³ (base64)]\n",
    "    F --> G[è§£ç¢¼ä¸¦å­˜ç‚º .mp3 / .wav]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28811758-cd03-42fc-a88f-1be3988b70fb",
   "metadata": {},
   "source": [
    "## LangServe æœå‹™æ¸¬è©¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c95db07-6153-4ec9-863c-61a0a49a8288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314b6765-7764-46ec-bc16-dfa8b5ed4c86",
   "metadata": {},
   "source": [
    "æ¸¬è©¦æ•…äº‹ç”Ÿæˆæœå‹™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d168449-4550-49b8-acd2-21b4d3009efa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    \"http://localhost:8080/story_telling/invoke\",\n",
    "    json={\"input\":{'scratch': \"Create a chapter of a baby owl capturing a rodent in the night as his dinner\",\n",
    "                   'context': \"\"}\n",
    "         }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2882f0e-1aff-4e8f-b7f1-1c101683aa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "story_json = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ff1e2-79b3-4b5c-acc7-71fd70025553",
   "metadata": {},
   "outputs": [],
   "source": [
    "story_json['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3654b3-4cf9-4587-a4cd-b023b6e11613",
   "metadata": {},
   "source": [
    "æ¸¬è©¦å½±åƒç”Ÿæˆæœå‹™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174143dd-8f26-486d-9d7e-f22db96d5e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "image_generation_module = importlib.import_module(\"tutorial.LLM+Langchain.Week-8.logic.image_generation\")\n",
    "image_create_pipeline = image_generation_module.image_create_pipeline(image_generation_module.system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f923fa-d406-482b-855b-b0e869afeada",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_image = requests.post(\n",
    "    \"http://localhost:8080/image_generation/invoke\",\n",
    "    json={\"input\": {'story': story_json['output'],\n",
    "                    \"image_io\": []}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1011d1-ebd2-47b3-9e7e-a1845ac0fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_image.json()['output']['nl_prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4f4f2a-2262-40cc-985a-86d4ecfd3f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "# Decode to bytes\n",
    "image_bytes = base64.b64decode(response_image.json()['output']['image_base64'])\n",
    "\n",
    "with open(\"tutorial/LLM+Langchain/Week-8/story_2_image.png\", \"wb\") as fh:\n",
    "    fh.write(image_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30494746-8671-4ece-81d8-83037a8a1075",
   "metadata": {},
   "source": [
    "æ¸¬è©¦ç”Ÿæˆå¾ŒçºŒå¾ŒçºŒçš„æ•…äº‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592e7b42-5213-41be-9ee8-f0bc0d069453",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_next_tory = requests.post(\n",
    "    \"http://localhost:8080/story_telling/invoke\",\n",
    "    json={\"input\":{'scratch': \"Create the next chapter following the context\",\n",
    "                   'context': story_json['output']}\n",
    "         }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe8ed59-f76c-4069-913a-8e6d482856ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_chapter = response_next_tory.json()['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57512583-d7ba-4593-9a9a-3eb67d71849b",
   "metadata": {},
   "source": [
    "æ ¹æ“šæ•…äº‹å’Œä¸Šä¸€å¼µåœ–ç‰‡ï¼Œç”¢ç”Ÿå‡ºä¸‹ä¸€å¼µåœ–ç‰‡\n",
    "\n",
    "é€érequestsé€å‡ºbase64 string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951b9a93-38e3-46d5-a052-3cc958095de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    \"http://localhost:8080/image_generation/invoke\",\n",
    "    json={\"input\": {'story': next_chapter + f\"\\nPrevious image description:\\n\\n{response_image.json()['output']['nl_prompt']}\",\n",
    "                    # 'image_io': [response_image.json()['output']['image_base64']]\n",
    "                    'image_io': []\n",
    "                   }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0003108d-c97c-4c40-8db9-39594eae610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['output']['nl_prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f6c0b-6904-4e79-aa5c-05dffb0fac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "image_bytes = base64.b64decode(response.json()['output']['image_base64'])\n",
    "\n",
    "with open(\"tutorial/LLM+Langchain/Week-8/story_3_image.png\", \"wb\") as fh:\n",
    "    fh.write(image_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35819f5-9fa1-4dea-ad1e-1f04a98303bb",
   "metadata": {},
   "source": [
    "æ¸¬è©¦èªéŸ³ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c3044-274f-4b64-a310-aeb1a37780da",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    \"http://localhost:8080/audio_generation/invoke\",\n",
    "    json={\"input\": {'input': \"How are you doing?\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41234ade-3023-4889-91e1-a9c0230a8452",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_bytes = base64.b64decode(response.json()['output'])\n",
    "\n",
    "with open(\"tutorial/LLM+Langchain/Week-8/test_sample.mp3\", \"wb\") as f:\n",
    "    f.write(audio_bytes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62454159-038d-4e37-999b-ff81159fb7de",
   "metadata": {},
   "source": [
    "## ç”Ÿæˆå·¥å…·æ¨¡æ¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2768e64a-de75-4196-b7b5-640b189e1669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "from typing import Optional, Any, List, Tuple, Callable\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.tools import BaseTool\n",
    "from langchain_core.runnables import Runnable\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic import FilePath\n",
    "\n",
    "from src.initialization import credential_init\n",
    "\n",
    "\n",
    "class ToolTemplate(BaseTool):\n",
    "\n",
    "    \"\"\"\n",
    "    ToolTemplateHTTP: ä¸€å€‹å°ˆé–€ç”¨ä¾†å‘¼å« Langserve REST API çš„ Agent Tool\n",
    "\n",
    "    - ä½¿ç”¨ PydanticOutputParser ä¿è­‰è¼¸å…¥æ ¼å¼æ­£ç¢º\n",
    "    - æ”¯æ´å¤šæ¬„ä½ input/output è™•ç†å™¨\n",
    "    - å° API å‘¼å«åŠ ä¸ŠéŒ¯èª¤è™•ç†\n",
    "    \"\"\"\n",
    "    \n",
    "    runnable: str = Field(..., description='The Langserve endpoint')\n",
    "    name: str\n",
    "    input_parser: PydanticOutputParser\n",
    "    description: str\n",
    "    input_data_processors: Optional[List[Tuple[str, Callable[[Any], Any]]]] = None\n",
    "    output_data_processors: Optional[List[Tuple[Optional[str], Callable[[Any], Any]]]] = None\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, runnable: str, name: str, description_template: str,\n",
    "               input_parser: PydanticOutputParser, input_data_processors: Optional=None,\n",
    "               output_data_processors: Optional=None):\n",
    "\n",
    "        \"\"\"å»ºç«‹ Tool å¯¦ä¾‹ï¼Œæœƒè‡ªå‹•æŠŠè¼¸å…¥æ ¼å¼éœ€æ±‚åŠ å…¥ description\"\"\"\n",
    "        \n",
    "        input_format_instruction = input_parser.get_format_instructions()\n",
    "        \n",
    "        description = description_template.format(\n",
    "            input_format_instruction=input_format_instruction\n",
    "        )\n",
    "        \n",
    "        return cls(runnable=runnable, name=name, description=description,\n",
    "                   input_parser=input_parser, input_data_processors=input_data_processors,\n",
    "                   output_data_processors=output_data_processors)\n",
    "    \n",
    "    def _run(self, query: str):\n",
    "\n",
    "        \"\"\"åŸ·è¡Œ Toolï¼ŒåŒæ­¥ç‰ˆæœ¬\"\"\"\n",
    "        \n",
    "        # 1. é©—è­‰ & parse è¼¸å…¥\n",
    "        try:\n",
    "            input_ = self.input_parser.parse(query)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Failed to parse input with parser: {e}, query={query}\")\n",
    "        \n",
    "        runnable_inputs = input_.model_dump()\n",
    "\n",
    "        # 2. input processorsï¼ˆå‰è™•ç†ï¼‰\n",
    "        if self.input_data_processors:\n",
    "            for field, fn in self.input_data_processors:\n",
    "                if field in runnable_inputs:\n",
    "                    runnable_inputs[field] = fn(runnable_inputs[field])\n",
    "            \n",
    "        # 3. å‘¼å« Langserve REST API\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                str(self.runnable),\n",
    "                json={\"input\": runnable_inputs},\n",
    "                timeout=60,\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Langserve call failed: {e}, inputs={runnable_inputs}\")\n",
    "\n",
    "        if \"output\" not in result:\n",
    "            raise RuntimeError(f\"Invalid response format from Langserve: {result}\")\n",
    "        \n",
    "        output = result['output']\n",
    "\n",
    "        # 4. update the state varaibles:\n",
    "        for key in session_state.keys():\n",
    "            if key in output:\n",
    "                session_state[key] = output[key]\n",
    "        \n",
    "        # 5. output processorsï¼ˆå¾Œè™•ç†ï¼‰\n",
    "        if self.output_data_processors:\n",
    "            for field, fn in self.output_data_processors:\n",
    "                if not field:\n",
    "                    fn(output, runnable_inputs['filename'])\n",
    "                else:\n",
    "                    fn(output[field], runnable_inputs['filename'])\n",
    "                    \n",
    "        # é è¨­å›å‚³ã€Œæª”åã€å¦‚æœæœ‰ filenameï¼Œå¦å‰‡å›å‚³è¼¸å‡ºçš„å­—ä¸²\n",
    "        return runnable_inputs.get(\"filename\", output)\n",
    "\n",
    "    def _arun(self, query: str):\n",
    "\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a7685-7318-4349-89a4-159e2879d88e",
   "metadata": {},
   "source": [
    "### State Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd71fca-8a1e-4842-acc9-572921972b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_state = {}\n",
    "\n",
    "session_state['nl_prompt'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253ad6e-6831-4399-be92-59af97e4c3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class StoryInput(BaseModel):\n",
    "    scratch: str = Field(description=dedent(\"\"\"\\\n",
    "                                            The draft, notes, or rough idea for the current page of the story.\n",
    "                                           ï¼ˆæ•…äº‹ç•¶å‰é é¢çš„è‰ç¨¿ã€ç­†è¨˜æˆ–åˆæ­¥æ§‹æƒ³\n",
    "                                            \"\"\"))\n",
    "    context: List[FilePath] = Field(default_factory=list, description=dedent(\"\"\"\\\n",
    "                                                              A list of previously generated .txt files that contain story content.  \n",
    "                                                              Used to maintain narrative consistency and continuity across images.  \n",
    "                                                              å…ˆå‰ç”Ÿæˆçš„ .txt æª”æ¡ˆæ¸…å–®ï¼Œå…¶ä¸­åŒ…å«æ•…äº‹å…§å®¹ã€‚  \n",
    "                                                              ç”¨æ–¼ä¿æŒå½±åƒç”Ÿæˆéç¨‹ä¸­çš„æ•˜äº‹ä¸€è‡´æ€§èˆ‡é€£è²«æ€§ã€‚\n",
    "                                                              \"\"\"))\n",
    "    filename: str = Field(..., description=dedent(\"\"\"\\\n",
    "                                             The file path where the generated story text will be saved.\n",
    "                                            ï¼ˆç”Ÿæˆçš„æ•…äº‹æ–‡æœ¬å°‡è¢«å„²å­˜çš„æª”æ¡ˆè·¯å¾‘ï¼‰\n",
    "                                             \"\"\"))\n",
    "\n",
    "\n",
    "def export_to_txt(text, filename: Path):\n",
    "\n",
    "    dir_ = Path(filename).parent\n",
    "\n",
    "    if not os.path.isdir(dir_):\n",
    "        os.makedirs(dir_)\n",
    "    \n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text)\n",
    "\n",
    "\n",
    "def read_from_txt(filename) -> str:\n",
    "\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    return content\n",
    "\n",
    "\n",
    "def read_from_list_of_text(filenames) -> str:\n",
    "\n",
    "    return \"\\n\\n\".join([read_from_txt(f) for f in filenames])\n",
    "\n",
    "\n",
    "story_input_data_processors = [(\"context\", read_from_list_of_text)]\n",
    "\n",
    "story_output_data_processors = [(None, export_to_txt)]\n",
    "\n",
    "story_telling_tool = ToolTemplate.create(\n",
    "    runnable=\"http://localhost:8080/story_telling/invoke\",\n",
    "    name=\"Story generation tool\",\n",
    "    description_template=dedent(\"\"\"\\\n",
    "                                This tool is designed to generate a story one page at a time.\n",
    "                                Provide a draft or idea for the current page (`scratch`), along with \n",
    "                                the preceding story context stored as .txt files (`context`), \n",
    "                                and specify where the generated text should be saved (`filename`).\n",
    "                                    \n",
    "                                Input format: {input_format_instruction}\n",
    "                                \"\"\"\n",
    "                                ),\n",
    "    input_parser=PydanticOutputParser(pydantic_object=StoryInput),\n",
    "    output_data_processors = story_output_data_processors,\n",
    "    input_data_processors = story_input_data_processors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eacf5e2-200b-4a00-8cbd-202ee93ef350",
   "metadata": {},
   "source": [
    "### å½±åƒç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc7ff16-8827-4c9d-a68c-35681e0e071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageInput(BaseModel):\n",
    "    story: str = Field(description=dedent(\"\"\"\\\n",
    "                                          The narrative or context used to generate the image prompt.  \n",
    "                                          æ•…äº‹æƒ…ç¯€æˆ–ä¸Šä¸‹æ–‡ï¼Œç”¨æ–¼ç”Ÿæˆå½±åƒæç¤ºã€‚\n",
    "                                          \"\"\")\n",
    "                      )\n",
    "    # FilePath ensures the input path exists and is a valid file\n",
    "    image_io: List[str] = Field([], description=dedent(\"\"\"\\\n",
    "                                                   Path to the previously generated image.  \n",
    "                                                   Used in img2img generation to maintain visual and texture consistency.  \n",
    "                                                   å…ˆå‰ç”Ÿæˆå½±åƒçš„è·¯å¾‘ã€‚  \n",
    "                                                   åœ¨ img2img ç”Ÿæˆä¸­ç”¨æ–¼ä¿æŒè¦–è¦ºèˆ‡æè³ªçš„ä¸€è‡´æ€§ã€‚\n",
    "                                                   \"\"\")\n",
    "                                    )\n",
    "    # Path allows flexibility: file may not exist yet but must be a valid path object.\n",
    "    filename: str = Field(..., description=dedent(\"\"\"\\\n",
    "                                                  Destination file path where the generated image will be saved.  \n",
    "                                                  ç”Ÿæˆå½±åƒçš„å„²å­˜æª”æ¡ˆè·¯å¾‘ã€‚\n",
    "                                                  \"\"\")\n",
    "                          )\n",
    "\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    \n",
    "    with Image.open(image_path) as image:\n",
    "        \n",
    "        # Save the Image to a Buffer\n",
    "        buffered = io.BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        \n",
    "        # Encode the Image to Base64\n",
    "        image_str = base64.b64encode(buffered.getvalue())\n",
    "    \n",
    "    return image_str.decode('utf-8')\n",
    "\n",
    "\n",
    "def image_to_base64_from_list(filenames) -> List[Optional[str]]:\n",
    "\n",
    "    # return [image_to_base64(f) for f in filenames]\n",
    "    return []\n",
    "\n",
    "\n",
    "def export_to_image(content, filename):\n",
    "    \n",
    "    dir_ = Path(filename).parent\n",
    "\n",
    "    if not os.path.isdir(dir_):\n",
    "        os.makedirs(dir_)\n",
    "    \n",
    "    image_bytes = base64.b64decode(content)\n",
    "    \n",
    "    with open(filename, \"wb\") as fh:\n",
    "        fh.write(image_bytes)\n",
    "\n",
    "\n",
    "def story_adaptation(story: str):\n",
    "\n",
    "    nl_prompt = session_state['nl_prompt']\n",
    "    \n",
    "    if nl_prompt:\n",
    "        story += f\"\\nPrevious image description:\\n\\n{nl_prompt}\"\n",
    "\n",
    "    print(f\"******\\n{story}\\n*******\")\n",
    "    \n",
    "    return story\n",
    "    \n",
    "\n",
    "\n",
    "image_output_data_processors = [('image_base64', export_to_image)]\n",
    "\n",
    "image_input_data_processors = [(\"story\", story_adaptation),\n",
    "                                (\"image_io\", image_to_base64_from_list)]\n",
    "\n",
    "image_tool = ToolTemplate.create(\n",
    "    runnable=\"http://localhost:8080/image_generation/invoke\",\n",
    "    name=\"Image generation tool\",\n",
    "    description_template=dedent(\"\"\"\\\n",
    "                                This tool is designed to generate an image to the correspoinding narrative.\n",
    "                                Provide a narrative (`story`), along with \n",
    "                                the preceding images stored as .png files (`image_io`), \n",
    "                                and specify where the generated text should be saved (`filename`).\n",
    "                                    \n",
    "                                Input format: {input_format_instruction}\n",
    "                                \"\"\"\n",
    "                                ),\n",
    "    input_parser=PydanticOutputParser(pydantic_object=ImageInput),\n",
    "    output_data_processors = image_output_data_processors,\n",
    "    input_data_processors = image_input_data_processors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eace21c-9917-4f4c-8a3e-7afc8765cc49",
   "metadata": {},
   "source": [
    "### èªéŸ³ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0fa546-d99b-4ae3-920e-0bf4963a2bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioInput(BaseModel):\n",
    "    input: str = Field(description=dedent(\"\"\"\\\n",
    "                                          The narrative or context used to generate the audio content with text to sound (TTS).  \n",
    "                                          æ•…äº‹æƒ…ç¯€æˆ–ä¸Šä¸‹æ–‡ï¼Œç”¨æ–¼TTSæ–‡å­—è½‰èªéŸ³ã€‚\n",
    "                                          \"\"\")\n",
    "                                    )\n",
    "    # Path allows flexibility: file may not exist yet but must be a valid path object.\n",
    "    filename: str = Field(..., description=dedent(\"\"\"\\\n",
    "                                                  Destination mp3 file path where the generated audio will be saved.  \n",
    "                                                  mp3èªéŸ³æª”çš„å„²å­˜æª”æ¡ˆè·¯å¾‘ã€‚\n",
    "                                                  \"\"\")\n",
    "                         )\n",
    "\n",
    "def export_to_audio(content, filename):\n",
    "\n",
    "    dir_ = Path(filename).parent\n",
    "\n",
    "    if not os.path.isdir(dir_):\n",
    "        os.makedirs(dir_)\n",
    "    \n",
    "    audio_bytes = base64.b64decode(content)\n",
    "    \n",
    "    with open(filename, \"wb\") as fh:\n",
    "        fh.write(audio_bytes)\n",
    "\n",
    "\n",
    "audio_output_data_processors = [(None, export_to_audio)]\n",
    "\n",
    "audio_tool = ToolTemplate.create(\n",
    "    runnable=\"http://localhost:8080/audio_generation/invoke\",\n",
    "    name=\"Audio generation tool\",\n",
    "    description_template=dedent(\"\"\"\\\n",
    "                                This tool is designed to generate an .mp3 file to a corresponding narrative.\n",
    "                                Provide a narrative (`story`), along with \n",
    "                                and specify where the generated audio should be saved (`filename`).\n",
    "                                    \n",
    "                                Input format: {input_format_instruction}\n",
    "                                \"\"\"\n",
    "                                ),\n",
    "    input_parser = PydanticOutputParser(pydantic_object=AudioInput),\n",
    "    output_data_processors = audio_output_data_processors,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8281faeb-b553-47c7-9b03-b7f9b6c671e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "from src.agent.react_zero_shot import prompt_template as zero_shot_prompt_template\n",
    "\n",
    "prompt = PromptTemplate.from_template(zero_shot_prompt_template)\n",
    "\n",
    "tools = [story_telling_tool, image_tool, audio_tool]\n",
    "\n",
    "credential_init()\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o\", temperature=0, \n",
    "                  )\n",
    "\n",
    "zero_shot_agent = create_react_agent(\n",
    "    llm=model,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=zero_shot_agent, tools=tools, verbose=True, handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60f298a-18b7-4b23-96a4-7757b5f1aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = dedent(\"\"\"\n",
    "Create a chapter of a baby owl capturing a rodent in the night as his dinner.\n",
    "After having the final answer, please create a corresponding image and a corresponding mp3 file.\n",
    "The saved image (.png), text (.txt), and audio (.mp3) should have same name in the folder `tutorial/LLM+Langchain/Week-8/story_test`\n",
    "\"\"\")\n",
    "\n",
    "agent_executor.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25bad6b-5459-440d-bf6f-4b4258abf2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7613df9-de89-4546-b738-323a7cc3a9c9",
   "metadata": {},
   "source": [
    "æˆåŠŸçš„ç”Ÿæˆäº†ä¸€é çš„å…§å®¹ï¼ŒAgentå¯ä»¥å¹«æˆ‘å€‘ç”Ÿæˆæ•´å€‹æ•…äº‹å—?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89f39ff-aeb8-433f-b18b-e20b622e5739",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "         I want to create an 4 pages story for a child. He likes snow owl.\n",
    "         For each page, please create a corresponding image and record the story as an mp3.\n",
    "         After having the final answer, please create a corresponding image and record the story as an mp3. \n",
    "         The saved image and mp3 should have same name, following the structure of \n",
    "         <Page - idx>, with idx as a number starting from 1, in the folder `tutorial/LLM+Langchain/Week-8/story_automation`\n",
    "         \"\"\"\n",
    "\n",
    "agent_executor.invoke({\"input\": prompt})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3683842a-53ee-420d-9423-637ce9cd723a",
   "metadata": {},
   "source": [
    "## ğŸ§ äº’å‹•å¼æœ‰è²æ›¸å…§å®¹ç”Ÿæˆ\n",
    "\n",
    "- ä¸ä¸€å®šéœ€è¦å®Œæ•´çš„ **Agent æ¶æ§‹**ï¼Œå› ç‚ºæµç¨‹çš„æ¯ä¸€æ­¥ï¼ˆæ•…äº‹ â†’ åœ–åƒ â†’ èªéŸ³ï¼‰éƒ½å·²ç¶“æ˜ç¢ºå®šç¾©ï¼Œèƒ½ç”±ä½¿ç”¨è€…ä¸»å‹•è§¸ç™¼ã€‚  \n",
    "- å¯ä»¥ç›´æ¥åŸºæ–¼ **èŠå¤©æ©Ÿå™¨äºº** çš„äº’å‹•å½¢å¼é€²è¡Œï¼Œæ¯æ¬¡è¼¸å…¥ä½¿ç”¨è€…çš„éœ€æ±‚æˆ–æŒ‡ä»¤å¾Œï¼Œç³»çµ±ä¾ç…§æŒ‡å®šæ­¥é©Ÿç”Ÿæˆå°æ‡‰å…§å®¹ã€‚  \n",
    "- ä½¿ç”¨è€…å¯ä»¥åœ¨æ•…äº‹ç”Ÿæˆéç¨‹ä¸­å³æ™‚èª¿æ•´æ–¹å‘ï¼Œä¾‹å¦‚æŒ‡å®šè§’è‰²ã€æƒ…ç¯€èµ°å‘æˆ–èªæ°£ï¼Œæå‡ **å®¢è£½åŒ–é«”é©—**ã€‚  \n",
    "- é€™ç¨®äº’å‹•æ–¹å¼éå¸¸é©åˆ **èªè¨€å­¸ç¿’** å ´æ™¯ï¼š  \n",
    "  - å­¸ç¿’è€…èƒ½ä¸€é‚Šé–±è®€æ•…äº‹ã€ä¸€é‚Šè½æœ‰è²è¼¸å‡º  \n",
    "  - å¯å³æ™‚ä¿®æ”¹æ•…äº‹æƒ…ç¯€ï¼Œç”¢ç”Ÿæ›´è²¼è¿‘å­¸ç¿’éœ€æ±‚çš„å…§å®¹  \n",
    "  - æ­é…åœ–ç‰‡èˆ‡èªéŸ³ï¼Œæå‡æ²‰æµ¸å¼å­¸ç¿’æ•ˆæœ  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adda8172-d8ae-4bf0-80be-14810309324a",
   "metadata": {},
   "source": [
    "# ğŸ§© LangGraph æ¡†æ¶èˆ‡è¨ˆåŠƒ-è¡Œå‹•ä»£ç†äººç°¡ä»‹\n",
    "\n",
    "## ä¸€ã€LangGraph æ˜¯ä»€éº¼ï¼Ÿ\n",
    "\n",
    "**LangGraph** æ˜¯ä¸€å€‹å°ˆé–€ç‚ºæ§‹å»º **å¤šæ™ºèƒ½é«”ç³»çµ±ï¼ˆMulti-Agent Systemsï¼‰** è€Œè¨­è¨ˆçš„æ¡†æ¶ï¼Œæä¾›äº†çµæ§‹åŒ–çš„æ–¹å¼ä¾†è¨­è¨ˆã€å”èª¿èˆ‡ç®¡ç†å¤šå€‹æ™ºèƒ½é«”ä¹‹é–“çš„äº’å‹•ã€‚  \n",
    "å®ƒå»ºç«‹åœ¨ **LangChain** çš„æ¦‚å¿µä¹‹ä¸Šï¼Œä¸¦å¼•å…¥äº†ã€Œåœ–ï¼ˆGraphï¼‰ã€çš„æ€ç¶­æ¨¡å‹ï¼š  \n",
    "æ¯å€‹æ™ºèƒ½é«”ï¼ˆAgentï¼‰è¢«è¦–ç‚ºåœ–ä¸­çš„ä¸€å€‹ç¯€é»ï¼ˆNodeï¼‰ï¼Œç¯€é»ä¹‹é–“çš„é‚Šï¼ˆEdgeï¼‰ä»£è¡¨ä»»å‹™æµæˆ–è³‡è¨Šäº¤æ›çš„é—œä¿‚ã€‚\n",
    "\n",
    "### ğŸŒŸ LangGraph çš„æ ¸å¿ƒç‰¹é»\n",
    "\n",
    "- ğŸ”— **ç¯€é»å°å‘è¨­è¨ˆ**ï¼šæ¯å€‹ç¯€é»å¯ä»£è¡¨ä¸€å€‹æ™ºèƒ½é«”ã€å·¥å…·æˆ–æ±ºç­–æ¨¡çµ„ã€‚  \n",
    "- ğŸ”„ **éˆæ´»çš„ä»»å‹™æµç¨‹**ï¼šæ”¯æ´æœ‰æ¢ä»¶çš„ä»»å‹™è½‰ç§»ï¼ˆä¾‹å¦‚æ ¹æ“šä¸Šä¸‹æ–‡æˆ–ä»»å‹™ç‹€æ…‹å‹•æ…‹é¸æ“‡ä¸åŒæ™ºèƒ½é«”ï¼‰ã€‚  \n",
    "- ğŸ§  **æ¨¡å‹äº’è£œæ€§**ï¼šå¯åŒæ™‚ä½¿ç”¨å¤šç¨®å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMsï¼‰æˆ–ä¸åŒçš„å¤–éƒ¨å·¥å…·ã€‚  \n",
    "- ğŸ“Š **å¯è¦–åŒ–å·¥ä½œæµ**ï¼šé–‹ç™¼è€…å¯ä»¥ç›´è§€åœ°è§€å¯Ÿæ™ºèƒ½é«”ä¹‹é–“çš„äº’å‹•èˆ‡ä»»å‹™æµå‘ã€‚  \n",
    "- ğŸ§© **æœ‰ç‹€æ…‹çš„ä»»å‹™æ§åˆ¶**ï¼šæ”¯æ´ä»»å‹™å›æº¯ã€é‡è©¦èˆ‡æµç¨‹ä¸­æ–·æ¢å¾©ç­‰åŠŸèƒ½ã€‚  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## äºŒã€LangChain vs. LangGraph\n",
    "\n",
    "åœ¨ç¾ä»£ LLM æ‡‰ç”¨é–‹ç™¼ä¸­ï¼Œ**LangChain** å’Œ **LangGraph** æ˜¯å…©å€‹å¸¸è¢«æåŠçš„æ¡†æ¶ã€‚  \n",
    "å®ƒå€‘çš†æ—¨åœ¨ç°¡åŒ–èˆ‡å¤§å‹èªè¨€æ¨¡å‹çš„æ•´åˆæµç¨‹ï¼Œä½†åœ¨è¨­è¨ˆç†å¿µèˆ‡ä½¿ç”¨å ´æ™¯ä¸Šæœ‰æ‰€ä¸åŒã€‚\n",
    "\n",
    "| ç‰¹é» | LangChain | LangGraph |\n",
    "|------|-----------|-----------|\n",
    "| æ¶æ§‹é¢¨æ ¼ | å‡½å¼å°å‘ï¼ˆFunction-basedï¼‰ | åœ–å½¢å°å‘ï¼ˆGraph-basedï¼‰ |\n",
    "| æ ¸å¿ƒç”¨é€” | çµ„åˆä¸åŒçš„å·¥å…·èˆ‡éˆï¼ˆChainsï¼‰ä»¥è™•ç†ä»»å‹™ | å®šç¾©ç‹€æ…‹è½‰æ›èˆ‡æµç¨‹æ§åˆ¶çš„ç‹€æ…‹æ©Ÿ |\n",
    "| é©åˆå ´æ™¯ | ç·šæ€§æµç¨‹ã€å¤šå·¥å…·ä¸²æ¥ã€å–®ä¸€ä»»å‹™ä»£ç†äºº | æœ‰ç‹€æ…‹çš„å·¥ä½œæµç¨‹ã€å¤šæ­¥é©Ÿæ±ºç­–ã€å‹•æ…‹æµç¨‹åˆ‡æ› |\n",
    "| æ§åˆ¶æµç¨‹èƒ½åŠ› | è¼ƒå¼±ï¼Œéœ€é€éç¨‹å¼é‚è¼¯æ§åˆ¶ | è¼ƒå¼·ï¼Œå…§å»ºç‹€æ…‹ç®¡ç†èˆ‡å‹•æ…‹ç¯€é»åˆ‡æ› |\n",
    "| æ˜“å­¸ç¨‹åº¦ | ç›¸å°å®¹æ˜“ä¸Šæ‰‹ | åˆæœŸéœ€ç†è§£ç‹€æ…‹æ©Ÿèˆ‡åœ–çµæ§‹æ¦‚å¿µ |\n",
    "| é€šç”¨æ€§ | æ¨¡çµ„å¤šã€é€šç”¨æ€§å¼· | æ›´é©åˆè¤‡é›œèˆ‡é•·æœŸä»»å‹™ç®¡ç† |\n",
    "\n",
    "> ğŸ’¡ **ç°¡è€Œè¨€ä¹‹**ï¼š  \n",
    "> - **LangChain** åƒæ˜¯ä¸€å€‹ã€Œç©æœ¨ç®±ã€ï¼Œæä¾›å„ç¨®æ¨¡çµ„ä¾›ä½ è‡ªç”±çµ„åˆã€‚  \n",
    "> - **LangGraph** å‰‡åƒæ˜¯ä¸€å€‹ã€Œæµç¨‹ç·¨è¼¯å™¨ã€ï¼Œè®“ä½ æ¸…æ¥šå®šç¾©ä»»å‹™ç¯€é»èˆ‡æµç¨‹é‚è¼¯ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ä¸‰ã€ç‚ºä»€éº¼é¸æ“‡ LangGraphï¼Ÿ\n",
    "\n",
    "LangGraph å»ºç«‹åœ¨ LangChain çš„åŸºç¤ä¸Šï¼Œä½†æä¾›äº†æ›´æ˜ç¢ºçš„ **æµç¨‹æ§åˆ¶èƒ½åŠ›**ã€‚  \n",
    "é€éã€Œæœ‰å‘åœ–ï¼ˆDirected Graphï¼‰ã€å®šç¾©ç¯€é»ï¼ˆNodeï¼‰èˆ‡ç‹€æ…‹è½‰ç§»ï¼ˆEdgeï¼‰ï¼Œé–‹ç™¼è€…å¯ä»¥è¼•é¬†è¨­è¨ˆå‡ºå…·å‚™ä»¥ä¸‹ç‰¹æ€§çš„ LLM æ‡‰ç”¨ï¼š\n",
    "\n",
    "- âœ… **è¨˜æ†¶ç‹€æ…‹ï¼ˆStatefulï¼‰**ï¼šèƒ½ä¿å­˜ä¸Šä¸‹æ–‡èˆ‡ä»»å‹™é€²åº¦ã€‚  \n",
    "- ğŸ” **å¯å›æº¯ï¼ˆReversibleï¼‰**ï¼šæ”¯æ´ä»»å‹™å¤±æ•—æ™‚çš„é‡è©¦èˆ‡å›æº¯ã€‚  \n",
    "- âš¡ **å‹•æ…‹æµç¨‹ï¼ˆDynamic Flowï¼‰**ï¼šæ ¹æ“šçµæœæˆ–ä¸Šä¸‹æ–‡å‹•æ…‹åˆ‡æ›ä¸‹ä¸€æ­¥ç¯€é»ã€‚  \n",
    "- ğŸ§© **å¤šæ™ºèƒ½é«”å”ä½œï¼ˆMulti-Agent Coordinationï¼‰**ï¼šæ”¯æ´å¤šå€‹æ™ºèƒ½é«”å”åŒå·¥ä½œã€‚  \n",
    "\n",
    "é€™ä½¿å¾— LangGraph ç‰¹åˆ¥é©åˆéœ€è¦é•·æœŸè¦åŠƒã€æ±ºç­–ã€ä»¥åŠå¤šéšæ®µä»»å‹™çš„æ‡‰ç”¨å ´æ™¯ï¼Œä¾‹å¦‚ï¼š\n",
    "- AI åŠ©ç†å·¥ä½œæµç¨‹ç®¡ç†  \n",
    "- è‡ªå‹•åŒ–æ±ºç­–ç³»çµ±  \n",
    "- è¤‡é›œä»»å‹™è¦åŠƒèˆ‡åŸ·è¡Œï¼ˆå¦‚ç§‘ç ”åŠ©ç†ã€å°ˆæ¡ˆç®¡ç†ä»£ç†äººï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "## å››ã€è¨ˆåŠƒ-è¡Œå‹•ä»£ç†äººï¼ˆPlan-Action Agentï¼‰\n",
    "\n",
    "### ğŸ” ä»€éº¼æ˜¯è¨ˆåŠƒ-è¡Œå‹•ä»£ç†äººï¼Ÿ\n",
    "\n",
    "è¨ˆåŠƒ-è¡Œå‹•ä»£ç†äººæ˜¯ä¸€ç¨®åŸºæ–¼ã€Œ**è¨ˆåŠƒï¼ˆPlanï¼‰** â†’ **è¡Œå‹•ï¼ˆActionï¼‰** â†’ **åé¥‹ï¼ˆFeedbackï¼‰**ã€è¿­ä»£å¾ªç’°çš„æ™ºèƒ½é«”ã€‚  \n",
    "å®ƒæœƒæ ¹æ“šç’°å¢ƒç‹€æ³ç”Ÿæˆè¨ˆåŠƒï¼Œä¸¦é€æ­¥åŸ·è¡Œèˆ‡èª¿æ•´ï¼Œç›´åˆ°é”æˆç›®æ¨™ã€‚\n",
    "\n",
    "å…¸å‹çš„å·¥ä½œæµç¨‹å¦‚ä¸‹ï¼š\n",
    "\n",
    "1. **è§€å¯Ÿç’°å¢ƒ**ï¼šæ”¶é›†ç•¶å‰ç’°å¢ƒç‹€æ…‹æˆ–ä¸Šä¸‹æ–‡ã€‚  \n",
    "2. **è¨ˆåŠƒç”Ÿæˆ**ï¼šæ ¹æ“šè§€å¯Ÿçµæœç”Ÿæˆä¸€ç³»åˆ—è¡Œå‹•è¨ˆåŠƒã€‚  \n",
    "3. **è¡Œå‹•åŸ·è¡Œ**ï¼šé€æ­¥åŸ·è¡Œæ¯å€‹è¨ˆåŠƒæ­¥é©Ÿã€‚  \n",
    "4. **åé¥‹èˆ‡èª¿æ•´**ï¼šæ ¹æ“šåŸ·è¡Œçµæœèˆ‡ç’°å¢ƒè®ŠåŒ–èª¿æ•´è¨ˆåŠƒï¼Œç¢ºä¿æœ€çµ‚ç›®æ¨™çš„é”æˆã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## äº”ã€åœ¨ LangGraph ä¸­å¯¦ç¾è¨ˆåŠƒ-è¡Œå‹•ä»£ç†äºº\n",
    "\n",
    "LangGraph ç‚ºæ§‹å»ºé€™é¡ä»£ç†äººæä¾›äº†ç†æƒ³çš„çµæ§‹ã€‚  \n",
    "åœ¨ LangGraph ä¸­ï¼Œæˆ‘å€‘å¯ä»¥é€éã€Œç¯€é»ã€å®šç¾©ä¸åŒçš„æ™ºèƒ½é«”è§’è‰²ï¼ˆå¦‚è¨ˆåŠƒç”Ÿæˆå™¨ã€åŸ·è¡Œè€…ã€ç›£ç£è€…ï¼‰ï¼Œä¸¦ä»¥ã€Œé‚Šã€å®šç¾©ä»–å€‘ä¹‹é–“çš„äº’å‹•æµç¨‹ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼š\n",
    "\n",
    "[è§€å¯Ÿç¯€é»] â†’ [è¨ˆåŠƒç”Ÿæˆç¯€é»] â†’ [è¡Œå‹•åŸ·è¡Œç¯€é»] â†’ [åé¥‹ç¯€é»]\n",
    "\n",
    "â†˜â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â†—ï¼ˆæ ¹æ“šåé¥‹å‹•æ…‹å›åˆ°è¨ˆåŠƒç”Ÿæˆï¼‰\n",
    "\n",
    "\n",
    "é€™æ¨£çš„è¨­è¨ˆå…è¨±ä»£ç†äººåœ¨ä»»å‹™åŸ·è¡Œä¸­é€²è¡Œï¼š\n",
    "- ä»»å‹™é‡è©¦ï¼ˆretryï¼‰  \n",
    "- å‹•æ…‹æ±ºç­–ï¼ˆdynamic routingï¼‰  \n",
    "- è‡ªé©æ‡‰ç­–ç•¥èª¿æ•´ï¼ˆadaptive planningï¼‰  \n",
    "\n",
    "---\n",
    "\n",
    "## å…­ã€æ¥ä¸‹ä¾†çš„å…§å®¹\n",
    "\n",
    "æ¥ä¸‹ä¾†ï¼Œæˆ‘å€‘å°‡é€éå¯¦ä½œä¸€å€‹ **è¨ˆåŠƒ-è¡Œå‹•ä»£ç†äººï¼ˆPlan-Action Agentï¼‰** çš„ç¯„ä¾‹ï¼Œ  \n",
    "å±•ç¤ºå¦‚ä½•ä½¿ç”¨ LangGraph ä¾†ï¼š\n",
    "\n",
    "- å®šç¾©å¤šå€‹æ™ºèƒ½é«”ç¯€é»  \n",
    "- è¨­è¨ˆä»»å‹™æµç¨‹èˆ‡æ¢ä»¶è½‰ç§»  \n",
    "- ç®¡ç†ç‹€æ…‹èˆ‡ä»»å‹™å›æº¯  \n",
    "\n",
    "é€éé€™å€‹å¯¦ä½œï¼Œä½ å°‡èƒ½ç†è§£ LangGraph åœ¨ **å¤šæ™ºèƒ½é«”å”ä½œ**ã€**å‹•æ…‹æ±ºç­–** èˆ‡ **æœ‰ç‹€æ…‹ä»»å‹™æ§åˆ¶** æ–¹é¢çš„å¼·å¤§èƒ½åŠ›ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1856cc-79de-4822-b617-42d6c1b16df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "from src.initialization import credential_init\n",
    "\n",
    "credential_init()\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-mini\", \n",
    "                   temperature=0\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931bc721-634e-410f-95f2-6efe391d2b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, Tuple, Union, Optional\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# The State\n",
    "\n",
    "class PlanExecute(TypedDict):\n",
    "    input: str\n",
    "    plan: List[str]\n",
    "    past_steps: List[Tuple]\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3a9d27-84a2-4237-b99b-883458533bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal, Union\n",
    "from textwrap import dedent\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"\n",
    "    Plan to follow in the future\n",
    "    \"\"\"\n",
    "    type: Literal['plan'] = 'plan'\n",
    "    steps: List[str] = Field(description=\"different steps to follow, should be in sorted order\")\n",
    "\n",
    "\n",
    "planner_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\n",
    "        dedent(\"\"\"\\\n",
    "        For the given objective, come up with a simple step by step plan.\n",
    "        This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps.\n",
    "        The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
    "        \"\"\")),\n",
    "        (\"placeholder\", \"{messages}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_planner = model.with_structured_output(Plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b7f45-cc73-419d-9758-3d7c062029e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = planner_prompt|model_planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92635c74-5dfa-48ed-a421-66da1310d7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"user\", \"What is the hometown of the current Australia open winner\")\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db72109-c583-4f59-8db8-44118c619f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Response(BaseModel):\n",
    "    \"\"\"Response to user.\"\"\"\n",
    "    type: Literal['response'] = 'response'\n",
    "    response: str\n",
    "\n",
    "\n",
    "class Act(BaseModel):\n",
    "    \"\"\"Action to perform.\"\"\"\n",
    "\n",
    "    action: Union[Response, Plan] = Field(\n",
    "        description=dedent(\"\"\"\\\n",
    "        Action to perform. If you want to respond to user, use `response`.\n",
    "        If you need to further use tools to get the answer, use `plan`.\n",
    "        \"\"\"\n",
    "    )\n",
    "    )\n",
    "\n",
    "replanner_prompt = ChatPromptTemplate.from_template(\n",
    "    dedent(\"\"\"For the given objective, come up with a simple step by step plan. \\\n",
    "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
    "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
    "\n",
    "Your objective was this:\n",
    "{input}\n",
    "\n",
    "Your original plan was this:\n",
    "{plan}\n",
    "\n",
    "You have currently done the follow steps:\n",
    "{past_steps}\n",
    "\n",
    "Update your plan accordingly. If no more steps are needed and you can return to the user, then respond with that. Otherwise, fill out the plan. Only add steps to the plan that still NEED to be done. Do not return previously done steps as part of the plan.\"\"\"\n",
    "))\n",
    "\n",
    "model_act = model.with_structured_output(Act)\n",
    "\n",
    "replanner = replanner_prompt | model_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484482cd-3357-4f15-9c23-0225528edcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "replanner.invoke({\"plan\": \"Identify the current Australian Open winner for the most recent tournament.\",\n",
    "                  \"past_steps\": [],\n",
    "                  \"input\": \"What is the hometown of the current Australia open winner\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaecd86e-f890-45ac-9648-c182d650ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f86669-8576-407b-8bb7-4030e8087ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from openai import OpenAI\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "class Inputs(BaseModel):\n",
    "    query: str = Field(description=\"User query\")\n",
    "\n",
    "\n",
    "class SearchTool(BaseTool):\n",
    "\n",
    "    input_parser: PydanticOutputParser = PydanticOutputParser(pydantic_object=Inputs)\n",
    "    input_format_instructions: str = input_parser.get_format_instructions()\n",
    "    \n",
    "    name:str = \"websearch tool\"\n",
    "    description_template: str = dedent(\"\"\"\n",
    "    Currently it is 2025.    \n",
    "    Use this tool to collect information from the internet, when you are not sure you know the answer.\n",
    "    Action Input format instructions: {input_format_instructions}\n",
    "    \"\"\")\n",
    "\n",
    "    description: str = description_template.format(input_format_instructions=input_format_instructions)\n",
    "    \n",
    "    def _run(self, query):\n",
    "        \n",
    "        input_ = self.input_parser.parse(query)\n",
    "        \n",
    "        query = input_.query\n",
    "        \n",
    "        messages = [{\"role\": \"user\",\n",
    "                     \"content\": query}]\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model='gpt-4o-mini-search-preview',\n",
    "            web_search_options={\"search_context_size\": 'medium',\n",
    "                                \"user_location\": {\n",
    "                                        \"type\": \"approximate\",\n",
    "                                        \"approximate\": {\n",
    "                                            \"country\": \"TW\",\n",
    "                                        }\n",
    "                                    },\n",
    "                                },\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    async def _arun(self, query: str):\n",
    "        \"\"\"Asynchronous version of the run method.\"\"\"\n",
    "        input_ = self.input_parser.parse(query)\n",
    "        query = input_.query\n",
    "        \n",
    "        messages = [{\"role\": \"user\", \"content\": query}]\n",
    "        \n",
    "        # Run the synchronous API call in an asynchronous way using asyncio.to_thread\n",
    "        response = await asyncio.to_thread(\n",
    "            client.chat.completions.create,\n",
    "            model='gpt-4o-mini-search-preview',\n",
    "            web_search_options={\n",
    "                \"search_context_size\": 'medium',\n",
    "                \"user_location\": {\n",
    "                    \"type\": \"approximate\",\n",
    "                    \"approximate\": {\n",
    "                        \"country\": \"TW\",\n",
    "                    }\n",
    "                },\n",
    "            },\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc969039-04eb-4b23-8b06-a149ad764a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_template = dedent(\"\"\"\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "\n",
    "Thought: you should always think about what to do\n",
    "\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "\n",
    "Action Input: the input to the action\n",
    "\n",
    "Observation: the result of the action\n",
    "\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "\n",
    "Thought: I now know the final answer\n",
    "\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Previous conversation history:\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "agent_prompt_template = PromptTemplate.from_template(agent_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d394e5ab-4ec7-412b-bd27-3eb73c3623e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langgraph.graph import END\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "# from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "tools = [SearchTool()]\n",
    "agent_model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "zero_shot_agent = create_react_agent(llm=agent_model, tools=tools, prompt=agent_prompt_template)\n",
    "agent_executor = AgentExecutor(agent=zero_shot_agent, tools=tools, verbose=True, handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e7f912-1194-4f19-9520-def70d4aa36c",
   "metadata": {},
   "source": [
    "### Define the functionalities of the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a8892-d9a6-429f-9f39-4023457db696",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def execute_step(state: PlanExecute):\n",
    "    \"\"\"\n",
    "    æ­¤æ–¹æ³•è² è²¬åŸ·è¡Œç›®å‰è¨ˆåŠƒï¼ˆplanï¼‰ä¸­çš„ç¬¬ä¸€å€‹æ­¥é©Ÿã€‚\n",
    "    åœ¨ LangGraph ç¯€é»ä¸­ï¼Œå®ƒé€šå¸¸ä½œç‚ºã€Œä»»å‹™åŸ·è¡Œç¯€é»ã€ï¼Œè² è²¬æ ¹æ“šè¨ˆåŠƒæŒ‡ä»¤å‘¼å«ä»£ç†æ¨¡å‹ï¼ˆagentï¼‰ä¾†åŸ·è¡Œå…·é«”ä»»å‹™ï¼Œä¸¦å°‡åŸ·è¡Œçµæœè¨˜éŒ„åˆ°ç‹€æ…‹ï¼ˆstateï¼‰ä¸­ã€‚\n",
    "    \n",
    "    ä¸»è¦é‚è¼¯ï¼š\n",
    "    \n",
    "    å¾ state è®€å–ç›®å‰çš„è¨ˆåŠƒ (plan)ã€‚\n",
    "    \n",
    "    ä»¥ç·¨è™Ÿæ–¹å¼å°‡æ•´å€‹è¨ˆåŠƒæ ¼å¼åŒ–æˆå¯è®€å­—ä¸²ã€‚\n",
    "    \n",
    "    å–å‡ºè¨ˆåŠƒä¸­çš„ç¬¬ä¸€å€‹æ­¥é©Ÿä½œç‚ºè¦åŸ·è¡Œçš„ä»»å‹™ã€‚\n",
    "    \n",
    "    å‘¼å« agent_executor.ainvoke()ï¼Œè®“æ™ºèƒ½ä»£ç†åŸ·è¡Œè©²ä»»å‹™ã€‚\n",
    "    \n",
    "    å°‡åŸ·è¡Œçµæœèˆ‡ä»»å‹™åç¨±ä»¥ tuple å½¢å¼å­˜å…¥ past_stepsã€‚\n",
    "    \n",
    "    è‹¥ state ä¸­å°šç„¡éå»ç´€éŒ„ï¼Œå»ºç«‹æ–°çš„ past_stepsï¼›å¦å‰‡å°‡æ–°çµæœé™„åŠ åˆ°ç¾æœ‰ç´€éŒ„ä¸­ã€‚\n",
    "    \n",
    "    åƒæ•¸ï¼š\n",
    "    \n",
    "    state (PlanExecute)ï¼šåŒ…å«è¨ˆåŠƒã€éå¾€æ­¥é©Ÿèˆ‡ç•¶å‰è¼¸å…¥çš„åŸ·è¡Œç‹€æ…‹ã€‚\n",
    "    \n",
    "    å›å‚³ï¼š\n",
    "    \n",
    "    dictï¼šåŒ…å«æ›´æ–°å¾Œçš„ past_stepsï¼Œå³åŸ·è¡Œä»»å‹™çš„æ­·å²ç´€éŒ„ã€‚\n",
    "    \n",
    "    æ‡‰ç”¨æƒ…å¢ƒï¼š\n",
    "    æ­¤ç¯€é»å¯ç”¨æ–¼å¤šæ­¥é©Ÿä»»å‹™åŸ·è¡Œæµç¨‹ï¼Œä¾‹å¦‚ï¼š\n",
    "    \n",
    "    æ ¹æ“šè¨ˆåŠƒé€æ­¥åŸ·è¡Œå‹•ä½œï¼ˆå¦‚è³‡æ–™è’é›†ã€åˆ†æã€å ±å‘Šæ’°å¯«ç­‰ï¼‰ã€‚\n",
    "    \n",
    "    åœ¨å¤šä»£ç†ç³»çµ±ä¸­ç”±ç‰¹å®š agent åŸ·è¡Œåˆ†é…ä»»å‹™ã€‚\n",
    "    \"\"\"\n",
    "    plan = state[\"plan\"]\n",
    "    plan_str = \"\\n\".join(f\"{i + 1}. {step}\" for i, step in enumerate(plan))\n",
    "    task = plan[0]\n",
    "    task_formatted = f\"\"\"For the following plan:{plan_str}\\n\\nYou are tasked with executing step {1}, {task}.\"\"\"\n",
    "    \n",
    "    agent_response = await agent_executor.ainvoke(\n",
    "        {\"input\": task_formatted}\n",
    "    )\n",
    "\n",
    "    current_step = [(task, agent_response['output'])]\n",
    "    \n",
    "    if \"past_steps\" not in state:\n",
    "        return {\"past_steps\": current_step}\n",
    "    else:\n",
    "        return {\"past_steps\": state[\"past_steps\"] + current_step}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1399c-c278-4e57-92eb-a628e8a31e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def plan_step(state: PlanExecute):\n",
    "    \"\"\"\n",
    "    æ­¤æ–¹æ³•è² è²¬æ ¹æ“šä½¿ç”¨è€…è¼¸å…¥å»ºç«‹å®Œæ•´çš„è¨ˆåŠƒï¼ˆplanï¼‰ã€‚\n",
    "    åœ¨ LangGraph ç¯€é»ä¸­ï¼Œå®ƒé€šå¸¸ä½œç‚ºã€Œè¨ˆåŠƒç”Ÿæˆç¯€é»ã€ï¼Œè®“è¦åŠƒå™¨ï¼ˆplannerï¼‰æ ¹æ“šä½¿ç”¨è€…æŒ‡ä»¤ç”¢ç”Ÿä¸€ç³»åˆ—å¯åŸ·è¡Œæ­¥é©Ÿã€‚\n",
    "    \n",
    "    ä¸»è¦é‚è¼¯ï¼š\n",
    "    \n",
    "    å‘¼å« planner.ainvoke()ï¼Œå°‡ä½¿ç”¨è€…è¼¸å…¥çš„è¨Šæ¯å‚³å…¥è¦åŠƒæ¨¡å‹ã€‚\n",
    "    \n",
    "    æ¥æ”¶è¦åŠƒå™¨è¼¸å‡ºçš„æ­¥é©Ÿï¼ˆplan.stepsï¼‰ã€‚\n",
    "    \n",
    "    å°‡é€™äº›æ­¥é©Ÿå­˜å…¥ stateï¼Œä»¥ä¾¿å¾ŒçºŒç¯€é»åŸ·è¡Œã€‚\n",
    "    \n",
    "    åƒæ•¸ï¼š\n",
    "    \n",
    "    state (PlanExecute)ï¼šåŒ…å«ä½¿ç”¨è€…è¼¸å…¥çš„åŸ·è¡Œç‹€æ…‹ï¼ˆstate[\"input\"] ç‚ºç”¨æˆ¶çš„ä¸»è¦æŒ‡ä»¤ï¼‰ã€‚\n",
    "    \n",
    "    å›å‚³ï¼š\n",
    "    \n",
    "    dictï¼šåŒ…å«ä¸€å€‹éµå€¼å° { \"plan\": plan.steps }ï¼Œå³æ¨¡å‹ç”Ÿæˆçš„ä»»å‹™æ­¥é©Ÿæ¸…å–®ã€‚\n",
    "    \n",
    "    æ‡‰ç”¨æƒ…å¢ƒï¼š\n",
    "    æ­¤ç¯€é»å¯ç”¨æ–¼ä»»å‹™å°å‘ç³»çµ±çš„é–‹é ­éšæ®µï¼Œä¾‹å¦‚ï¼š\n",
    "    \n",
    "    å°‡ã€Œæ’°å¯«å¸‚å ´å ±å‘Šã€åˆ†è§£ç‚ºã€Œè³‡æ–™è’é›† â†’ æ•´ç† â†’ åˆ†æ â†’ æ’°å¯«ã€ã€‚\n",
    "    \n",
    "    åœ¨å¤šéšæ®µæ¨ç†æˆ–è‡ªå‹•åŒ–ä»»å‹™ä¸­ç”Ÿæˆå…·é«”å·¥ä½œè¨ˆåŠƒã€‚\n",
    "    \"\"\"\n",
    "    \n",
    "    plan = await planner.ainvoke({\"messages\": [(\"user\", state[\"input\"])]})\n",
    "    return {\"plan\": plan.steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597949a2-3dd0-473d-b33b-9e0556bad85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def replan_step(state: PlanExecute):\n",
    "\n",
    "    \"\"\"\n",
    "    æ­¤æ–¹æ³•è² è²¬åœ¨ä»»å‹™åŸ·è¡Œéç¨‹ä¸­é€²è¡Œå‹•æ…‹é‡æ–°è¦åŠƒï¼ˆReplanningï¼‰ã€‚\n",
    "    ç•¶ä»£ç†åŸ·è¡Œä¸­é‡åˆ°å•é¡Œã€æ¢ä»¶æ”¹è®Šæˆ–4ä»»å‹™æœªå®Œæˆæ™‚ï¼Œè©²ç¯€é»å¯å‘¼å«ã€Œå†è¦åŠƒå™¨ã€ï¼ˆreplannerï¼‰ç”Ÿæˆæ–°çš„è¨ˆåŠƒæˆ–ç›´æ¥è¼¸å‡ºæœ€çµ‚å›æ‡‰ã€‚\n",
    "    \n",
    "    ä¸»è¦é‚è¼¯ï¼š\n",
    "    \n",
    "    å‘¼å« replanner.ainvoke()ï¼Œå°‡ç•¶å‰åŸ·è¡Œç‹€æ…‹ä½œç‚ºè¼¸å…¥ã€‚\n",
    "    \n",
    "    è‹¥è¿”å›çµæœåŒ…å« Response é¡å‹çš„å‹•ä½œï¼Œè¡¨ç¤ºå¯ç›´æ¥è¼¸å‡ºæœ€çµ‚å›è¦†ã€‚\n",
    "    \n",
    "    è‹¥çµæœç‚ºæ–°çš„è¨ˆåŠƒæ­¥é©Ÿï¼Œå‰‡æ›´æ–° planã€‚\n",
    "    \n",
    "    è‹¥ç„¡æ–°æ­¥é©Ÿå¯åŸ·è¡Œï¼Œå‰‡ä½¿ç”¨æœ€å¾Œä¸€æ¬¡åŸ·è¡Œçš„çµæœä½œç‚ºå›æ‡‰ã€‚\n",
    "    \n",
    "    åƒæ•¸ï¼š\n",
    "    \n",
    "    state (PlanExecute)ï¼šåŒ…å«ç›®å‰çš„åŸ·è¡Œç‹€æ…‹ã€æ­·å²æ­¥é©Ÿèˆ‡å·²çŸ¥è¨ˆåŠƒã€‚\n",
    "    \n",
    "    å›å‚³ï¼š\n",
    "    \n",
    "    dictï¼šåŒ…å«æ–°çš„ plan æˆ–æœ€çµ‚ responseã€‚\n",
    "    \n",
    "    æ‡‰ç”¨æƒ…å¢ƒï¼š\n",
    "    æ­¤ç¯€é»ç”¨æ–¼ï¼š\n",
    "    \n",
    "    åŸ·è¡Œä»»å‹™æ™‚æ ¹æ“šå¤±æ•—æ­¥é©Ÿæˆ–ç’°å¢ƒè®ŠåŒ–èª¿æ•´è¨ˆåŠƒã€‚\n",
    "    \n",
    "    è®“æ™ºèƒ½é«”å…·å‚™ã€Œè‡ªæˆ‘ä¿®æ­£ã€èƒ½åŠ›ã€‚\n",
    "    \n",
    "    åœ¨é•·ç¨‹ä»»å‹™ä¸­æ ¹æ“šä¸­é–“è¼¸å‡ºé‡æ–°å®‰æ’å¾ŒçºŒæ­¥é©Ÿã€‚\n",
    "    \"\"\"\n",
    "    \n",
    "    output = await replanner.ainvoke(state)\n",
    "    if isinstance(output.action, Response):\n",
    "        return {\"response\": output.action.response}\n",
    "    else:\n",
    "        if output.action.steps:\n",
    "            return {\"plan\": output.action.steps}\n",
    "        else:\n",
    "            return {\"response\": state['past_steps'][-1][1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891decb3-0846-4687-bc28-73a849dbcce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_end(state: PlanExecute):\n",
    "    \"\"\"\n",
    "    æ­¤æ–¹æ³•è² è²¬æ±ºå®šå·¥ä½œæµç¨‹æ˜¯å¦çµæŸã€‚\n",
    "    åœ¨ LangGraph ç¯€é»ä¸­ï¼Œå®ƒé€šå¸¸æ˜¯æ¢ä»¶åˆ†æ”¯ï¼ˆconditional edgeï¼‰çš„åˆ¤æ–·é‚è¼¯ï¼Œç”¨ä¾†æª¢æŸ¥ä»»å‹™æ˜¯å¦å®Œæˆæˆ–æ˜¯å¦æ‡‰è©²å›åˆ°ä»£ç†ç¹¼çºŒåŸ·è¡Œã€‚\n",
    "    \n",
    "    ä¸»è¦é‚è¼¯ï¼š\n",
    "    \n",
    "    è‹¥ state ä¸­å­˜åœ¨ response ä¸”å…¶å€¼éç©ºï¼Œä»£è¡¨ä»»å‹™å·²å®Œæˆ â†’ å›å‚³ ENDã€‚\n",
    "    \n",
    "    å¦å‰‡ï¼Œå›å‚³ \"agent\"ï¼Œè¡¨ç¤ºä»éœ€ç”±ä»£ç†ç¯€é»ç¹¼çºŒåŸ·è¡Œã€‚\n",
    "    \n",
    "    åƒæ•¸ï¼š\n",
    "    \n",
    "    state (PlanExecute)ï¼šç›®å‰çš„åŸ·è¡Œç‹€æ…‹ã€‚\n",
    "    \n",
    "    å›å‚³ï¼š\n",
    "    \n",
    "    ENDï¼ˆä»»å‹™å®Œæˆï¼ŒçµæŸç¯€é»ï¼‰æˆ– \"agent\"ï¼ˆç¹¼çºŒåŸ·è¡Œä¸‹ä¸€éšæ®µï¼‰ã€‚\n",
    "    \n",
    "    æ‡‰ç”¨æƒ…å¢ƒï¼š\n",
    "    æ­¤ç¯€é»å¸¸ç”¨æ–¼ï¼š\n",
    "    \n",
    "    æµç¨‹æ§åˆ¶ï¼ˆæ±ºå®šä»»å‹™æ˜¯å¦çµæŸï¼‰ã€‚\n",
    "    \n",
    "    å¤šç¯€é» LangGraph æµç¨‹ä¸­è¨­ç½®çµ‚æ­¢æ¢ä»¶ã€‚\n",
    "    \n",
    "    ç¢ºä¿ç³»çµ±åœ¨ä»»å‹™å®Œæˆå¾Œé©æ™‚åœæ­¢ï¼Œä¸é€²è¡Œå¤šé¤˜æ“ä½œã€‚\n",
    "    \"\"\"\n",
    "    \n",
    "    if \"response\" in state and state[\"response\"]:\n",
    "        return END\n",
    "    else:\n",
    "        return \"agent\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e7ad6-5d36-4928-b96a-0a572f9b8b55",
   "metadata": {},
   "source": [
    "LangGraph æ˜¯å®£å‘Šå¼ï¼ˆdeclarativeï¼‰çš„ï¼Œè€Œéç´”ç²¹å‹•æ…‹ï¼ˆpurely dynamicï¼‰çš„ã€‚\n",
    "é€™è¡¨ç¤ºç•¶ä½ åœ¨å»ºç«‹å·¥ä½œæµç¨‹åœ–ï¼ˆworkflow graphï¼‰æ™‚ï¼ˆä¹Ÿå°±æ˜¯åœ¨åŸ·è¡Œä¹‹å‰ï¼‰ï¼ŒLangGraph éœ€è¦äº‹å…ˆçŸ¥é“æ‰€æœ‰å¯èƒ½çš„åˆ†æ”¯â€”â€”\n",
    "å³ä½¿ä½ çš„æ¢ä»¶å‡½å¼ï¼ˆshould_endï¼‰æœƒåœ¨åŸ·è¡Œéšæ®µæ‰æ±ºå®šå¯¦éš›è¦èµ°å“ªä¸€å€‹åˆ†æ”¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ac6db2-e3ce-499a-94fe-77bf5b9eede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "workflow = StateGraph(PlanExecute)\n",
    "\n",
    "# Add the plan node\n",
    "workflow.add_node(\"planner\", plan_step)\n",
    "\n",
    "# Add the execution step\n",
    "workflow.add_node(\"agent\", execute_step)\n",
    "\n",
    "# Add a replan node\n",
    "workflow.add_node(\"replan\", replan_step)\n",
    "\n",
    "workflow.add_edge(START, \"planner\")\n",
    "\n",
    "# From plan we go to agent\n",
    "workflow.add_edge(\"planner\", \"agent\")\n",
    "\n",
    "# From agent, we replan\n",
    "workflow.add_edge(\"agent\", \"replan\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"replan\",\n",
    "    should_end,\n",
    "    [\"agent\", END]\n",
    ")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20752f84-b2b2-4e21-a791-9daaa2d6af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abd4647-a4d8-47d9-9b1c-040907d48006",
   "metadata": {},
   "source": [
    "### Reserved / Special Parts of `config`\n",
    "\n",
    "Below are the reserved or commonly used keys in the `config` dictionary when working with **LangGraph**:\n",
    "\n",
    "| Key | Purpose | Example |\n",
    "|------|----------|----------|\n",
    "| `\"configurable\"` | âœ… **Main section for user-defined and framework config.** Used by checkpointers, node settings, etc. | `{\"configurable\": {\"thread_id\": \"abc123\"}}` |\n",
    "| `\"checkpoint_ns\"` | **Namespace for checkpoints** (advanced use). Useful when you want to separate stored states across different workflows. | `{\"checkpoint_ns\": \"my_namespace\"}` |\n",
    "| `\"recursion_limit\"` | **Limits graph recursion depth.** Prevents infinite loops or too-deep graph calls. | `{\"recursion_limit\": 10}` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a1255-a90c-43d7-a2f8-7330fe15d71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"recursion_limit\": 50}\n",
    "inputs = {\"input\": \"what is the hometown of the mens 2023 Australia open winner?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22f0040-bcf8-463c-9e92-b32da959e533",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for event in app.astream(inputs, config=config):\n",
    "    for k, v in event.items():\n",
    "        if k != \"__end__\":\n",
    "            print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a29ef6-8697-47bf-a461-aae3989d56c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"recursion_limit\": 50}\n",
    "inputs = {\"input\": \"å¯Œé‚¦æ‚å°‡çš„å•¦å•¦éšŠä¸‰æœ¬æŸ±æ˜¯èª°?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7f25ad-9e27-41d1-bdbb-f5fbcc4d6e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for event in app.astream(inputs, config=config):\n",
    "    for k, v in event.items():\n",
    "        if k != \"__end__\":\n",
    "            print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c91039-b819-4532-ac19-413968f9a645",
   "metadata": {},
   "source": [
    "## ğŸ’¬ è©•è«–ï¼šLangGraph ä»»å‹™åŸ·è¡Œè§€å¯Ÿ4èˆ‡å„ªåŒ–å»ºè­°\n",
    "\n",
    "é€™æ¬¡çš„æœ€çµ‚ç­”æ¡ˆæ˜¯æ­£ç¢ºçš„â€”â€”**ã€Œå¯Œé‚¦æ‚å°‡å•¦å•¦éšŠçš„ä¸‰æœ¬æŸ±ç‚ºæç ç¢ã€æé›…è‹±ã€å—ç‰è²ã€**ï¼Œçµæœç¬¦åˆäº‹å¯¦ã€‚  \n",
    "ä¸éæ•´é«”æ¨ç†èˆ‡è¡Œå‹•éç¨‹é¡¯å¾—æœ‰äº›ã€Œç¬¨æ‹™ã€ï¼Œå­˜åœ¨æ˜é¡¯çš„å„ªåŒ–ç©ºé–“ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§  å•é¡Œè§€å¯Ÿ\n",
    "1. **é‡è¤‡èˆ‡ä½æ•ˆçš„æŸ¥è©¢æ­¥é©Ÿ**  \n",
    "   å¤šæ¬¡åŸ·è¡Œé¡ä¼¼çš„ `websearch`ï¼ŒæŸ¥è©¢é—œéµå­—å·®ç•°ä¸å¤§ï¼Œå°è‡´ç³»çµ±é‡è¤‡ç²å–ç›¸è¿‘å…§å®¹ï¼Œæµªè²»è³‡æºèˆ‡æ™‚é–“ã€‚  \n",
    "\n",
    "2. **ä¸Šä¸‹æ–‡ç†è§£ä¸è¶³**  \n",
    "   ç•¶å·²ç¶“åœ¨å‰ä¸€æ­¥ç¢ºå®šã€Œä¸‰æœ¬æŸ±ã€æŒ‡çš„æ˜¯å¯Œé‚¦æ‚å°‡çš„éŸ“ç±å•¦å•¦éšŠæˆå“¡æ™‚ï¼Œå¾ŒçºŒæ­¥é©Ÿä»ç„¶é‡æ–°æŸ¥è©¢ã€Œä¸‰ä½æˆå“¡çš„åå­—ã€ï¼Œ  \n",
    "   é¡¯ç¤ºæ¨¡å‹æ²’æœ‰æœ‰æ•ˆåˆ©ç”¨å…ˆå‰çš„ç‹€æ…‹ï¼ˆ`past_steps`ï¼‰ã€‚  \n",
    "\n",
    "3. **è¡Œå‹•éˆï¼ˆAgent Chainï¼‰éé•·ä¸”ç¼ºä¹åˆ¤æ–·ä¸­æ­¢æ¢ä»¶**  \n",
    "   ç³»çµ±åœ¨æ‡‰è©²å¯ä»¥çµæŸçš„éšæ®µä»ç¹¼çºŒå˜—è©¦åŸ·è¡ŒæŸ¥è©¢ï¼Œæœ€çµ‚å¤šæ¬¡å‡ºç¾ `\"Agent stopped due to iteration limit or time limit\"`ã€‚  \n",
    "\n",
    "4. **æ ¼å¼éŒ¯èª¤é »ç¹**  \n",
    "   å¤šæ¬¡å‡ºç¾ `Invalid Format: Missing 'Action:' after 'Thought:'`ï¼Œ  \n",
    "   é¡¯ç¤ºä»£ç†åœ¨ç”¢ç”ŸæŒ‡ä»¤æ™‚çš„æ ¼å¼åŒ–é‚è¼¯éœ€è¦åŠ å¼·ã€‚  \n",
    "\n",
    "---\n",
    "\n",
    "### âš™ï¸ æ”¹é€²å»ºè­°\n",
    "1. **å¼·åŒ–ä¸Šä¸‹æ–‡è¨˜æ†¶ä½¿ç”¨ï¼ˆState Managementï¼‰**  \n",
    "   - åœ¨ `execute_step` æˆ– `replan_step` éšæ®µä¸­ï¼Œæ˜ç¢ºè®“ agent æª¢æŸ¥ `past_steps`ï¼Œé¿å…é‡è¤‡æŸ¥è©¢ç›¸åŒå•é¡Œã€‚  \n",
    "\n",
    "2. **åŠ å…¥å‹•æ…‹åœæ­¢æ¢ä»¶ï¼ˆDynamic Stop Conditionï¼‰**  \n",
    "   - è‹¥ `agent_response` å·²åŒ…å«é«˜ç½®ä¿¡åº¦çš„å…·é«”åç¨±ï¼ˆä¾‹å¦‚ä¸‰å€‹äººåï¼‰ï¼Œå¯ç›´æ¥å°‡ç‹€æ…‹åˆ‡æ›ç‚º `END`ï¼Œç„¡éœ€ç¹¼çºŒå¾ªç’°ã€‚  \n",
    "\n",
    "3. **å„ªåŒ–æœå°‹ç­–ç•¥**  \n",
    "   - å°‡å¤šæ­¥æŸ¥è©¢æ•´åˆç‚ºå–®ä¸€æ˜ç¢ºæŸ¥è©¢ï¼Œä¾‹å¦‚ï¼š  \n",
    "     ã€Œå¯Œé‚¦æ‚å°‡ å•¦å•¦éšŠ ä¸‰æœ¬æŸ± 2025 æˆå“¡åå–®ã€ï¼Œä»¥æ¸›å°‘å™ªéŸ³ã€‚  \n",
    "\n",
    "4. **ä¿®æ­£è¼¸å‡ºæ ¼å¼ç”Ÿæˆé‚è¼¯**  \n",
    "   - åœ¨ LLM Prompt Template ä¸­ï¼Œä½¿ç”¨çµæ§‹åŒ–æ ¼å¼ï¼ˆå¦‚ JSON æˆ– YAMLï¼‰æ˜ç¢ºå®šç¾© `Thought / Action / Observation` å€å¡Šï¼Œæ¸›å°‘æ ¼å¼éŒ¯èª¤ã€‚  \n",
    "\n",
    "5. **å¯è€ƒæ…®åŠ å…¥ Re-Planning åˆ¤æ–·å¼·åŒ–**  \n",
    "   - ç•¶ç³»çµ±åµæ¸¬åˆ°é‡è¤‡æŸ¥è©¢æˆ–å…§å®¹ç„¡è®ŠåŒ–æ™‚ï¼Œå¯è‡ªå‹•è§¸ç™¼ `replan_step`ï¼Œåˆ‡æ›ç­–ç•¥æˆ–ç›´æ¥è¼¸å‡ºçµæœã€‚  \n",
    "\n",
    "---\n",
    "\n",
    "### âœ… ç¸½çµ\n",
    "æ•´é«”è€Œè¨€ï¼Œç³»çµ±æœ€çµ‚å¾—å‡ºäº†æ­£ç¢ºç­”æ¡ˆï¼Œèªªæ˜ä»»å‹™è¨­è¨ˆé‚è¼¯æœ‰æ•ˆï¼›  \n",
    "ä½†åœ¨éç¨‹ä¸­è¡¨ç¾å‡ºç¼ºä¹ä¸Šä¸‹æ–‡è¨˜æ†¶ã€é‡è¤‡æŸ¥è©¢èˆ‡æ ¼å¼éŒ¯èª¤ç­‰å•é¡Œã€‚  \n",
    "\n",
    "è‹¥èƒ½åŠ å¼·ç‹€æ…‹åˆ¤æ–·ã€çµæœç½®ä¿¡åº¦è©•ä¼°èˆ‡æŸ¥è©¢æ•´åˆï¼Œå°‡èƒ½é¡¯è‘—æå‡æ•ˆç‡èˆ‡æ™ºèƒ½ç¨‹åº¦ã€‚\n",
    "4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
