{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15e8b0e1-922d-401b-b946-848a591f1c9c",
   "metadata": {},
   "source": [
    "## Reflexion: 有強迫症的完美主義者\n",
    "\n",
    "## 什麼是反思代理人（Reflexion Agent）？\n",
    "\n",
    "反思代理人（Reflexion Agent）是一種具備「自我反思能力」的智能體架構。與傳統的行動導向代理人不同，反思代理人不僅僅執行任務或根據環境反應，而是能夠**在執行過程中分析自己的決策、識別錯誤、並自我改進**。這使得代理人能夠在長期任務中逐步提升表現，達成更高層次的智能行為。\n",
    "\n",
    "反思代理人的核心概念是「反思循環（Reflexion Loop）」，其工作流程通常包含以下幾個步驟：  \n",
    "\n",
    "1. **行動執行（Action Execution）**：代理人根據當前策略或任務目標執行行動。  \n",
    "2. **結果評估（Outcome Evaluation）**：代理人觀察行動結果，並比較預期結果與實際結果之間的差異。  \n",
    "3. **反思與推理（Reflection and Reasoning）**：代理人分析造成錯誤或效率低下的原因，生成新的策略或改進方案。  \n",
    "4. **策略更新（Strategy Update）**：根據反思結果，代理人調整自己的決策模型或行動計劃。  \n",
    "\n",
    "透過這種循環，反思代理人能夠像人類一樣「學習如何學習」，不斷優化自身行為。\n",
    "\n",
    "---\n",
    "\n",
    "## Langgraph 中的反思代理人\n",
    "\n",
    "在 **Langgraph** 框架中，反思代理人（Reflexion Agent）通常結合了**記憶模組（Memory Module）**與**推理模組（Reasoning Module）**，用以支援自我監控與策略修正的過程。  \n",
    "\n",
    "其主要特點包括：  \n",
    "\n",
    "- **任務回顧（Task Review）**：Langgraph 允許代理人記錄過去的任務過程與結果，作為反思依據。  \n",
    "- **錯誤分析（Error Analysis）**：代理人可自動生成「自我評估報告」，指出任務中的失誤與改進方向。  \n",
    "- **策略再生成（Strategy Regeneration）**：透過反思機制，Langgraph 代理人能夠動態更新行動規劃，提升成功率。  \n",
    "\n",
    "這使得 Langgraph 的反思代理人不僅能夠完成任務，還能**自主學習並優化自己的決策邏輯**，非常適合應用於需要長期學習、持續改進的智能系統，例如程式生成、知識推理或多步任務解決等場景。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3844d00b-a2fd-4a47-907a-10d5472c93a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from textwrap import dedent\n",
    "\n",
    "os.chdir(\"../../../\")\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n",
    "from langchain_core.messages.tool import ToolMessage\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from src.initialization import credential_init\n",
    "\n",
    "credential_init()\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=6,\n",
    "    disable_streaming=False\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "\n",
    "class Reflection(BaseModel):\n",
    "    missing: str = Field(description=\"Critique of what is missing.\")\n",
    "    superfluous: str = Field(description=\"Critique of what is superfluous\")\n",
    "\n",
    "\n",
    "class AnswerQuestion(BaseModel):\n",
    "    \"\"\"Answer the question. Provide an answer, reflection, and then follow up with search queries to improve the answer.\"\"\"\n",
    "\n",
    "    answer: str = Field(description=\"~250 word detailed answer to the question.\")\n",
    "    reflection: Reflection = Field(description=\"Your reflection on the current answer.\")\n",
    "    search_queries: list[str] = Field(\n",
    "        description=\"1-3 search queries for researching improvements to address the critique of your current answer.\"\n",
    "    )\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=AnswerQuestion)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "這算是一個偷懶的作法: 一次性生成答案和反思。\n",
    "也許先有一個答案，可以是使用LLM生成或是由人生成，再讓respond 專注於反思是一個比較好的做法\n",
    "\"\"\"\n",
    "\n",
    "system_template =  dedent(\"\"\"\n",
    "                            You are expert researcher.\n",
    "                            Current time: {time}\n",
    "                            \n",
    "                            1. {first_instruction}\n",
    "                            2. Reflect and critique your answer. Be severe to maximize improvement.\n",
    "                            3. Recommend search queries to research information and improve your answer.\n",
    "\n",
    "                            Please the answer in traditional Chinese (繁體中文).\n",
    "                            \"\"\")\n",
    "\n",
    "system_prompt_template = PromptTemplate(template=system_template,\n",
    "                                        partial_variables={\"time\": datetime.datetime.now().isoformat(),\n",
    "                                                           \"first_instruction\": \"Provide a detailed ~250 word answer.\"})\n",
    "\n",
    "human_template = dedent(\"\"\"\n",
    "                        <system>Reflect on the user's original question and the actions taken thus far.</reminder>\n",
    "                        output format instruction: {format_instruction}\n",
    "                        \"\"\"\n",
    "                        )\n",
    "\n",
    "human_prompt_template = PromptTemplate(template=human_template,\n",
    "                                       partial_variables={\"format_instruction\": format_instructions})\n",
    "\n",
    "messages = [SystemMessagePromptTemplate(prompt=system_prompt_template),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            HumanMessagePromptTemplate(prompt=human_prompt_template)]\n",
    "\n",
    "respond_chat_prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "respond_pipeline = respond_chat_prompt_template|model|output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be65bb6-4252-4412-8fc1-2ee64322a931",
   "metadata": {},
   "source": [
    "## Respond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd9b2d6-b89e-4ce3-ae53-7fb8c886ba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_question = \"花蓮縣光復鄉因為馬太鞍溪堰塞湖潰堤，導致被泥石流淹過。就安全的考量，沒接受過專業訓練的平民是否應該去花蓮縣光復鄉參與救災。\"\n",
    "messages = [HumanMessage(content=example_question)]\n",
    "\n",
    "initial_response = respond_pipeline.invoke({\"messages\": messages})\n",
    "\n",
    "search_queries = initial_response.search_queries\n",
    "\n",
    "print(search_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac43875c-8545-4670-b9da-5aa16792622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(initial_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685ee3c7-9952-4afc-abf3-6da780b7697c",
   "metadata": {},
   "source": [
    "## Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb06efac-b23e-409c-9185-4e54661d5d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "\n",
    "search = TavilySearchAPIWrapper()\n",
    "tavily_tool = TavilySearchResults(api_wrapper=search, max_results=1)\n",
    "\n",
    "@tool\n",
    "def run_queries(search_queries: list[str]):\n",
    "    \"\"\"Run the generated queries.\"\"\"\n",
    "    return tavily_tool.batch([{\"query\": query} for query in search_queries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98138536-5353-47c7-9302-ca6f7b665362",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_search = model.bind_tools(tools=[run_queries], tool_choice='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2529b38-3bdc-407c-a6ff-4dd045f21c4b",
   "metadata": {},
   "source": [
    "### Basic Tool Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011acb29-3d82-4363-8742-23adcc9ac9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model_search.invoke([HumanMessage(content=search_queries)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1920c2f-e01c-4100-b23a-a24e038fb083",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_calls = response.tool_calls\n",
    "tool_call = tool_calls[0]\n",
    "\n",
    "search_results = eval(tool_call['name'])(tool_call['args'])\n",
    "\n",
    "# 將工具產生的結果傳給 content，並且將tool_call_id設定為 AIMessage裡給定的tool_call['id']\n",
    "tool_message = ToolMessage(content=[r[0]['content'] for r in search_results], \n",
    "                           tool_call_id=tool_call['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c9cf67-3796-4c73-b3a0-0114b571fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = model.invoke([HumanMessage(content=search_queries),\n",
    "                        response,\n",
    "                        tool_message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1ea31e-0414-4a3a-a1a6-2059450c9c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    " message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf24b4a-bf5b-4ca1-9991-9cbc4ea52a75",
   "metadata": {},
   "source": [
    "## Revise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76846c79-fbee-4f9a-8570-1ce62648794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "revise_instructions = dedent(\"\"\"\\\n",
    "Using the reflection feedback and new information, revise your last answer to correct errors, clarify reasoning, and improve overall quality.\n",
    "Output only the improved answer. \n",
    "\n",
    "- You MUST include numerical citations in your revised answer to ensure it can be verified.\n",
    "- Add a \"References\" section to the bottom of your answer (which does not count towards the word limit). In form of:\n",
    "    - [1] https://example.com\n",
    "    - [2] https://example.com\n",
    "- Update the `reflection` and `search_queries` according to your current answer.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b26756f-72f3-4d30-b494-8b8a6a47ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend the initial answer schema to include references.\n",
    "# Forcing citation in the model encourages grounded responses\n",
    "\n",
    "\n",
    "class ReviseAnswer(AnswerQuestion):\n",
    "    \"\"\"Revise your original answer to your question. Provide an answer, reflection,\n",
    "    Cite your reflection with references, and finally\n",
    "    add search queries to improve the answer.\"\"\"\n",
    "\n",
    "    references: list[str] = Field(\n",
    "        description=\"Citations motivating your updated answer.\"\n",
    "    )\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=ReviseAnswer)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "system_template =  dedent(\"\"\"\n",
    "                            You are expert researcher.\n",
    "                            Current time: {time}\n",
    "                            \n",
    "                            1. {first_instruction}\n",
    "                            2. Reflect and critique your answer. Be severe to maximize improvement.\n",
    "                            3. Recommend search queries to research information and improve your answer.\n",
    "\n",
    "                            Please the answer in traditional Chinese (繁體中文).\n",
    "                            \"\"\")\n",
    "\n",
    "system_prompt_template = PromptTemplate(template=system_template,\n",
    "                                        partial_variables={\"time\": datetime.datetime.now().isoformat(),\n",
    "                                                           \"first_instruction\": revise_instructions})\n",
    "\n",
    "human_template = dedent(\"\"\"\n",
    "                        <system>Reflect on the user's original question and the actions taken thus far.</reminder>\n",
    "                        output format instruction: {format_instruction}\n",
    "                        \"\"\"\n",
    "                        )\n",
    "\n",
    "human_prompt_template = PromptTemplate(template=human_template,\n",
    "                                       partial_variables={\"format_instruction\": format_instructions})\n",
    "\n",
    "messages = [SystemMessagePromptTemplate(prompt=system_prompt_template),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            HumanMessagePromptTemplate(prompt=human_prompt_template)]\n",
    "\n",
    "revise_chat_prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "revision_pipeline = revise_chat_prompt_template|model|output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5719d24-32ab-41f2-ae35-800d12d81762",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beff1edf-6ac1-4704-8585-61390e7fb539",
   "metadata": {},
   "outputs": [],
   "source": [
    "revised_message = revision_pipeline.invoke({\"messages\": [HumanMessage(content=\"花蓮縣光復鄉因為馬太鞍溪堰塞湖潰堤，導致被泥石流淹過。就安全的考量，沒接受過專業訓練的平民是否應該去花蓮縣光復鄉參與救災。\"),\n",
    "                                                         AIMessage(content=initial_response.model_dump_json()),\n",
    "                                                         HumanMessage(content=message.content)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff964f9-8135-49b5-87e2-9cc6b1a6778a",
   "metadata": {},
   "outputs": [],
   "source": [
    "revised_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f6fb9-efbc-4d7a-b2e3-cfa9912a5ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_response.reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c236c5f-f4a7-4048-bbc7-cd640f99ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "revised_message.reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abca627-3841-44f4-bf33-64ec75ee2d43",
   "metadata": {},
   "source": [
    "**** 接下來就是重複 Tool -> Revision的過程 ****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951037c0-d2ba-46f5-b819-6426ce1ad44d",
   "metadata": {},
   "source": [
    "## Langgaph Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90029fe8-b8b9-40cc-8338-62059eacb014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "MESSAGES = \"messages\"\n",
    "MAX_ITERATION = 3\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "async def respond(state: State):\n",
    "\n",
    "    respond = await respond_pipeline.ainvoke({\"messages\": state[MESSAGES]})\n",
    "\n",
    "    return {MESSAGES: AIMessage(content=respond.model_dump_json())}\n",
    "    \n",
    "\n",
    "async def tool(state: State):\n",
    "\n",
    "    last_message = state[MESSAGES][-1]\n",
    "\n",
    "    search_query = json.loads(last_message.content)[\"search_queries\"]\n",
    "\n",
    "    response = await model_search.ainvoke([HumanMessage(content=search_queries)])\n",
    "\n",
    "    tool_calls = response.tool_calls\n",
    "    tool_call = tool_calls[0]\n",
    "    \n",
    "    search_results = eval(tool_call['name'])(tool_call['args'])\n",
    "    \n",
    "    # 將工具產生的結果傳給 content，並且將tool_call_id設定為 AIMessage裡給定的tool_call['id']\n",
    "    tool_message = ToolMessage(content=[r[0]['content'] for r in search_results], \n",
    "                               tool_call_id=tool_call['id'])\n",
    "\n",
    "    message = await model.ainvoke([HumanMessage(content=search_queries),\n",
    "                                  response,\n",
    "                                  tool_message])\n",
    "\n",
    "    return {MESSAGES: HumanMessage(content=message.content)}\n",
    "\n",
    "\n",
    "async def revise(state: State):\n",
    "\n",
    "    revised = await revision_pipeline.ainvoke({\"messages\": state[MESSAGES]})\n",
    "    \n",
    "    return {MESSAGES: AIMessage(content=revised.model_dump_json())}\n",
    "\n",
    "\n",
    "def should_end(state: State):\n",
    "\n",
    "    COUNTER = sum([1 for message in state[MESSAGES] if message.type=='ai'])\n",
    "\n",
    "    if COUNTER < MAX_ITERATION:\n",
    "        return \"tool\"\n",
    "    else:\n",
    "        return END\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78560d38-6e0c-44e6-a3ea-4cc833c2b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Add the plan node\n",
    "workflow.add_node(\"respond\", respond)\n",
    "\n",
    "# Add the execution step\n",
    "workflow.add_node(\"tool\", tool)\n",
    "\n",
    "workflow.add_node(\"revise\", revise)\n",
    "\n",
    "workflow.add_edge(START, \"respond\")\n",
    "\n",
    "workflow.add_edge(\"respond\", \"tool\")\n",
    "\n",
    "# From agent, we replan\n",
    "workflow.add_edge(\"tool\", \"revise\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"revise\",\n",
    "    should_end,\n",
    "    [\"tool\", END]\n",
    ")\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "app = workflow.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ab7c6a-b9c0-4d06-ad79-6957d37a0bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482da2c4-2732-49a3-bb85-865a7b07f2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d674d927-022d-4dea-bd62-df539e3fe2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for event in app.astream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"花蓮縣光復鄉因為馬太鞍溪堰塞湖潰堤，導致被泥石流淹過。就安全的考量，沒接受過專業訓練的平民是否應該去花蓮縣光復鄉參與救災。\"\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "):\n",
    "    print(event)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f3a24f-02d3-462c-ba93-7190e65f32b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
