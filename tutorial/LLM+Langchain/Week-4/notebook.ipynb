{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c30f7bc9-d9ba-4f35-b95e-7bc03e4f950a",
   "metadata": {},
   "source": [
    "# MLflow Part 2\n",
    "\n",
    "\n",
    "mlflow server --host 127.0.0.1 --port 8080\n",
    "\n",
    "## 紀錄內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff0a3f8-6c8c-450d-b161-e50b6ad71400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed358d5-7c46-4e7e-8d98-eb8765f43208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from textwrap import dedent\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_community.callbacks import MlflowCallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from src.initialization import credential_init\n",
    "\n",
    "def build_standard_chat_prompt_template(kwargs):\n",
    "\n",
    "    messages = []\n",
    " \n",
    "    if 'system' in kwargs:\n",
    "        content = kwargs.get('system')\n",
    "        prompt = PromptTemplate(**content)\n",
    "        message = SystemMessagePromptTemplate(prompt=prompt)\n",
    "        messages.append(message)  \n",
    "\n",
    "    if 'human' in kwargs:\n",
    "        content = kwargs.get('human')\n",
    "        prompt = PromptTemplate(**content)\n",
    "        message = HumanMessagePromptTemplate(prompt=prompt)\n",
    "        messages.append(message)\n",
    "        \n",
    "    chat_prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "    \n",
    "    return chat_prompt_template\n",
    "\n",
    "experiment = \"Week-4\"\n",
    "\n",
    "credential_init()\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Start or get an MLflow run explicitly\n",
    "mlflow.set_experiment(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b59d40d-378e-4961-98ef-f64636caf775",
   "metadata": {},
   "source": [
    "### MlflowCallbackHandler\n",
    "\n",
    "追蹤並記錄語言模型的輸入和輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84faca3b-fe2e-48ad-bb74-bca05a95ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"my-llm-run\") as run:\n",
    "    run_id = run.info.run_id\n",
    "    print(f\"Using run_id={run_id}\")\n",
    "\n",
    "    # Attach the run_id so all logs go into this run\n",
    "    mlflow_cb = MlflowCallbackHandler(\n",
    "        experiment=experiment,\n",
    "        run_id=run_id,\n",
    "        tracking_uri=\"http://127.0.0.1:8080\",\n",
    "    )\n",
    "\n",
    "    model = ChatOpenAI(\n",
    "        model_name=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        callbacks=[mlflow_cb]\n",
    "    )\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"product\"],\n",
    "        template=\"What is a good name for a company that makes {product}?\",\n",
    "    )\n",
    "\n",
    "    chain = LLMChain(llm=model, prompt=prompt)\n",
    "\n",
    "    # First call logs into this run\n",
    "    chain.invoke({\"product\": \"陽電子攻城炮\"})\n",
    "\n",
    "    # Second call also logs into the SAME run_id\n",
    "    chain.invoke({\"product\": \"旋風魚雷 (Warhammer 40k, Exterminatus)\"})\n",
    "\n",
    "    chain.invoke({\"product\": \"人形MS/Gundam\"})\n",
    "    \n",
    "    # Finally flush once\n",
    "    mlflow_cb.flush_tracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b7fd37-b372-43e9-8e1b-fbaa7a0ff807",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = run_id\n",
    "artifact_path = \"table_action_records.html\"   # relative path inside artifacts\n",
    "\n",
    "# Download to a local directory\n",
    "local_dir = mlflow.artifacts.download_artifacts(run_id=run_id, artifact_path=artifact_path,\n",
    "                                                dst_path=\"tutorial/LLM+Langchain/Week-4\", \n",
    "                                                tracking_uri=\"http://127.0.0.1:8080\",\n",
    "                                                )\n",
    "\n",
    "print(\"Downloaded to:\", local_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf672043-aeb5-47ab-b252-ae3191983549",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.artifacts.download_artifacts?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22f7f1c-b1fd-4fb5-9ed3-c3c495e56c78",
   "metadata": {},
   "source": [
    "## Autolog\n",
    "\n",
    "This mode doesn’t write JSON files at all — instead, it captures traces (spans) of your LangChain runs into MLflow’s experiment tracking + tracing UI. That means you see inputs/outputs, timings, and nested structure in the MLflow UI, not .json artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09058a8a-aae9-4b86-8b7c-f86dffa5aa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d2a57-e219-46c2-905b-800eb4b43c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autologging — this instruments LangChain automatically\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=model, prompt=prompt)\n",
    "\n",
    "# Run the chain\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"Week-4\")\n",
    "\n",
    "with mlflow.start_run(run_id=run_id) as run:\n",
    "    chain.invoke({\"product\": \"光茅 (戰槌40k)\"})\n",
    "    chain.invoke({\"product\": \"旋風魚雷 (Warhammer 40k, Exterminatus)\"})\n",
    "    chain.invoke({\"product\": \"人形MS/Gundam\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa601924-3194-430c-83c8-57a831fa159d",
   "metadata": {},
   "source": [
    "## 一個模型不夠，你可以用兩個\n",
    "\n",
    "這兩個範例都只用了一個模型，還沒外加RAG之類的\n",
    "\n",
    "使用Reflect作為例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd48e595-8b29-425c-ac1f-6b5e69cde646",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = dedent(\"\"\"\n",
    "俗話說：「龍生九子，各有不同。」在廣闊浩瀚的海洋之中，就有一頭孤獨的鯨魚——五十二赫茲鯨魚。牠聲音的頻率天生便比同伴還要高，這項特別之處，也導致了牠與同伴產生了無法溝通的鴻溝。看見這則故事的我，不禁思考，在如此多元的人間，是否也有像五十二赫茲鯨魚一般，天生便與眾不同？\n",
    "\n",
    "回首童年，我印象最為深刻的一刻，是初識字時，與文字互相理解的那一瞬、是當我第一次讀完一個句子時，它將自身的意義傳入我腦中的那一瞬。自此，我便對文字、語言抱有特殊的感情，也十分享受閱讀與朗誦。那種將自身與文字經由一點一滴積累而連接起來的感情，使我心靈感到十分富足。\n",
    "\n",
    "而當我步入校園接觸同儕時，驀然驚覺我與別人的閱讀速度十分不同。每當我已讀完一篇文章，但同學可能只完成了一半甚至三分之二。同時，我在生字讀音方面也異常的執著，因此被同學抱怨有「文字潔癖」。面對同儕抱怨的我，也只好強忍對耳邊時而出現字錯讀音的不適，開始刻意忽略心裡對它的執念，只為想要與別人一樣，想要和朋友互相理解。\n",
    "\n",
    "直到多年前，因緣際會之下認識了「五十二赫茲」這獨特的存在。牠的身影在我心中烙下一道深刻的痕跡。因為牠，我開始接受自己與他人的不同；也因為牠，我明白了，我對文字的執著，並不是一種負面的特質，而是上天賜予我的禮物，我開始在寫作上揮灑自如。這讓我知道，不要在一開始便用否定的眼光看待自己的特質。也許這特別之處，會使我們與五十二赫茲鯨魚一般孤獨，會使我們遭受他人的不理解與排斥，但也會讓我們與眾不同。\n",
    "\n",
    "關於此，我想說的是，勇敢地綻放自己的特別，也讓自己成為自己和世人眼中，最閃耀的五十二赫茲鯨魚。\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def create_feedback_pipeline(mlflow_callback):\n",
    "\n",
    "    ## Teacher LLM\n",
    "    system_template = dedent(\"\"\"\n",
    "    你是一個教學與寫作經驗豐富的台灣大學中文系教授，你要來負責給予作文評分與回饋。\n",
    "    \"\"\")\n",
    "    \n",
    "    human_template = dedent(\"\"\"\n",
    "    Title: {title}\n",
    "    \n",
    "    Article:\n",
    "    {article}\n",
    "    \"\"\")\n",
    "    \n",
    "    model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                       model_name=\"gpt-4o-mini\", temperature=0,\n",
    "                       callbacks=[mlflow_callback])\n",
    "    \n",
    "    input_ = {\"system\": {\"template\": system_template},\n",
    "              \"human\": {\"template\": human_template,\n",
    "                        \"input_variable\": [\"title\", \"article\"],\n",
    "                        }}\n",
    "    \n",
    "    chat_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "    \n",
    "    feedback_pipeline = chat_prompt_template|model|StrOutputParser()\n",
    "\n",
    "    return feedback_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2ca87c-445d-49b4-b4e5-87fc31beff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "\n",
    "class Output(BaseModel):\n",
    "    name: str = Field(description=\"The revised article in traditional Chinese (繁體中文), please do not include the title.\")\n",
    "\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Output)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "def create_revision_pipeline(mlflow_callback):\n",
    "    ## Generate\n",
    "    system_template = dedent(\"\"\"\n",
    "    你是一個在準備考試的高中生，你將根據反饋強化的作文內容。\n",
    "    \"\"\")\n",
    "    \n",
    "    human_template = dedent(\"\"\"\n",
    "    Title: {title}\n",
    "    \n",
    "    Old Article:\n",
    "    {article}\n",
    "    \n",
    "    Feedback:\n",
    "    {feedback}\n",
    "\n",
    "    Output format instructions: {format_instructions}\n",
    "    \n",
    "    Revised Article:\n",
    "    \"\"\")\n",
    "    \n",
    "    input_ = {\"system\": {\"template\": system_template},\n",
    "              \"human\": {\"template\": human_template,\n",
    "                        \"input_variable\": [\"title\", \"article\", \"feedback\"],\n",
    "                        \"partial_variables\": {'format_instructions': format_instructions}}}\n",
    "    \n",
    "    chat_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "    model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                       model_name=\"gpt-4o-mini\", temperature=0,\n",
    "                       callbacks=[mlflow_callback])\n",
    "    \n",
    "    revision_pipeline = chat_prompt_template|model|output_parser\n",
    "\n",
    "    return revision_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c1ea5f-8e11-42de-b9d9-d79155618ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Start or get an MLflow run explicitly\n",
    "mlflow.set_experiment(experiment)\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    run_id = run.info.run_id\n",
    "    print(f\"Using run_id={run_id}\")\n",
    "\n",
    "    # Attach the run_id so all logs go into this run\n",
    "    mlflow_cb = MlflowCallbackHandler(\n",
    "        experiment=experiment,\n",
    "        run_id=run_id,\n",
    "        tracking_uri=\"http://127.0.0.1:8080\",\n",
    "    )\n",
    "\n",
    "    feedback_pipeline = create_feedback_pipeline(mlflow_callback=mlflow_cb)\n",
    "    revision_pipeline = create_revision_pipeline(mlflow_callback=mlflow_cb)\n",
    "    \n",
    "    whole_pipeline = RunnablePassthrough.assign(feedback=feedback_pipeline)|revision_pipeline|RunnableLambda(lambda x: x.name)\n",
    "\n",
    "    result = whole_pipeline.invoke({\"article\": query,\n",
    "                                    \"title\": \"關於五十二赫茲，我想說的是…\"},\n",
    "                                    # config={\"callbacks\": [mlflow_cb]} \n",
    "                                  )\n",
    "    \n",
    "    \n",
    "# Finally flush once\n",
    "mlflow_cb.flush_tracker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b65ed21-8ce2-4f00-a821-428809a28a04",
   "metadata": {},
   "source": [
    "結合上週的內容，將這個Pipeline打包成一個Artifact上傳到MLflow Server，然後藉由MLflow調用Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3b45d5-768b-4c3a-9d16-789b9794b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "import pandas as pd\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "\n",
    "from src.io.path_definition import get_project_dir\n",
    "\n",
    "model_path = os.path.join(get_project_dir(), 'tutorial', 'LLM+Langchain', \n",
    "                          \"Week-4\", \"llmchain_mlflow_experiment_tracing.py\")\n",
    "\n",
    "# You need to know what you will put into it and what you will get out of it.\n",
    "input_schema = Schema([ColSpec(\"string\", \"title\"),\n",
    "                       ColSpec(\"string\", \"article\")])\n",
    "output_schema = Schema([ColSpec(\"string\")])\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "\n",
    "\n",
    "query = dedent(\"\"\"\n",
    "俗話說：「龍生九子，各有不同。」在廣闊浩瀚的海洋之中，就有一頭孤獨的鯨魚——五十二赫茲鯨魚。牠聲音的頻率天生便比同伴還要高，這項特別之處，也導致了牠與同伴產生了無法溝通的鴻溝。看見這則故事的我，不禁思考，在如此多元的人間，是否也有像五十二赫茲鯨魚一般，天生便與眾不同？\n",
    "\n",
    "回首童年，我印象最為深刻的一刻，是初識字時，與文字互相理解的那一瞬、是當我第一次讀完一個句子時，它將自身的意義傳入我腦中的那一瞬。自此，我便對文字、語言抱有特殊的感情，也十分享受閱讀與朗誦。那種將自身與文字經由一點一滴積累而連接起來的感情，使我心靈感到十分富足。\n",
    "\n",
    "而當我步入校園接觸同儕時，驀然驚覺我與別人的閱讀速度十分不同。每當我已讀完一篇文章，但同學可能只完成了一半甚至三分之二。同時，我在生字讀音方面也異常的執著，因此被同學抱怨有「文字潔癖」。面對同儕抱怨的我，也只好強忍對耳邊時而出現字錯讀音的不適，開始刻意忽略心裡對它的執念，只為想要與別人一樣，想要和朋友互相理解。\n",
    "\n",
    "直到多年前，因緣際會之下認識了「五十二赫茲」這獨特的存在。牠的身影在我心中烙下一道深刻的痕跡。因為牠，我開始接受自己與他人的不同；也因為牠，我明白了，我對文字的執著，並不是一種負面的特質，而是上天賜予我的禮物，我開始在寫作上揮灑自如。這讓我知道，不要在一開始便用否定的眼光看待自己的特質。也許這特別之處，會使我們與五十二赫茲鯨魚一般孤獨，會使我們遭受他人的不理解與排斥，但也會讓我們與眾不同。\n",
    "\n",
    "關於此，我想說的是，勇敢地綻放自己的特別，也讓自己成為自己和世人眼中，最閃耀的五十二赫茲鯨魚。\n",
    "\"\"\")\n",
    "\n",
    "run_name = \"Reflection\"\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "\n",
    "    os.environ['experiment'] = experiment\n",
    "    os.environ['run_id'] = run.info.run_id\n",
    "    os.environ['run_name'] = run_name\n",
    "    \n",
    "    mlflow.log_artifact(model_path, artifact_path=\"source_code\")\n",
    "\n",
    "    input_example = pd.DataFrame(data=[[query, \"關於五十二赫茲，我想說的是…\"]], columns=['article', 'title'])\n",
    "    \n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        python_model=model_path,  # Define the model as the path to the Python file\n",
    "        name=\"langchain_model\",\n",
    "        input_example=input_example,\n",
    "        signature=signature,\n",
    "        registered_model_name=\"Generation_Reflection_Demo\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80af810b-845e-465c-88b0-f9ce51f8f45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "\n",
    "    os.environ['experiment'] = experiment\n",
    "    os.environ['run_id'] = run.info.run_id\n",
    "    os.environ['run_name'] = run_name\n",
    "\n",
    "    loaded_model = mlflow.pyfunc.load_model(\"models:/Generation_Reflection_Demo/13\")\n",
    "    \n",
    "    input_ = pd.DataFrame(data=[['那一聲政委吹響的哨聲，代表著我對於帝皇的忠誠，衝鋒，殺光那些異端', '關於五十二赫茲，我想說的是…']], columns=['article', 'title'])\n",
    "    \n",
    "    output = loaded_model.predict(input_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec06a59-58b7-4955-95f3-3f019f2e36d5",
   "metadata": {},
   "source": [
    "# LangServe\n",
    "\n",
    "## 1. 客戶端 (client) 呼叫後端 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6eced7-3568-45c6-a80c-feefec6efb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.post(\n",
    "    \"http://localhost:5000/openai/invoke\",\n",
    "    json={'input': \"Where is Taiwan?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3d191c-3ba3-46d0-a265-2a00dce2e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75d27ef-15fa-4c09-bf68-78f36aebf7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['output']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82378be9-1287-4410-9bf0-93f1b4e9b49d",
   "metadata": {},
   "source": [
    "在Windows的CLI(command line interface)中:\n",
    "\n",
    "curl -X POST \"http://localhost:5000/openai/invoke\" -H \"Content-Type: application/json\" -d \"{\"\"input\"\": \"\"Where is Taiwan?\"\"}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8711bb4e-5f73-4a8c-8f0a-dc7eb0d0a5a1",
   "metadata": {},
   "source": [
    "## 2. 結合之前MLflow的應用。從MLflow server上下載模型，然後從客戶端呼叫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26bcb69-936a-4175-9b1c-484f4c0b6e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.post(\n",
    "    \"http://localhost:5000/demo/invoke\",\n",
    "    json={'input': {\"article\": \"那一聲政委吹響的哨聲，代表著我對於帝皇的忠誠，衝鋒，殺光那些異端.\",\n",
    "                    \"title\": \"關於五十二赫茲，我想說的是…\"}}\n",
    ")\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2a54e9-4f26-46bd-acf7-0735ec3d531d",
   "metadata": {},
   "source": [
    "## 3 RemoteRunnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4050cc8e-2aea-4af5-ab3d-9fb5c84405b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langserve import RemoteRunnable\n",
    "\n",
    "remote_llm = RemoteRunnable(\"http://localhost:5000/openai/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fc385a-fdc5-43e8-8d93-919243977e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supports astream\n",
    "async for msg in remote_llm.astream(\"Where is Taiwan?\"):\n",
    "    print(msg.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeb9026-e936-4d4b-ae28-f0c589787456",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830eab43-1635-4cb1-aa13-06e5665d2d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf36293-7cc5-49b4-aae6-88d4cf53302f",
   "metadata": {},
   "source": [
    "## 如何自動化生成country_code?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f702f519-37dd-4b45-a492-0c4bcdd521b0",
   "metadata": {},
   "source": [
    "# ChatBot\n",
    "\n",
    "1. N-Shot Learning 與對話歷史\n",
    "\n",
    "    - 歷史對話可以看成一個 Q&A pair 列表\n",
    "    - 當前模型在推理時，會把「之前的對話內容」作為 prompt 的一部分，再加上使用者最新的輸入，整合後丟進模型。這其實就是一種 few-shot / N-shot 的學習方式：模型從範例中抽取語境來理解「現在該怎麼回答」。\n",
    "\n",
    "2. Stateless vs. Stateful\n",
    "    - Stateless：如果每次請求都完全獨立，沒有任何歷史對話被帶入，那就叫無狀態 (stateless)。\n",
    "    - Stateful：如果系統會保存對話歷史（不論是把歷史傳回模型，還是外部記憶系統存起來），那就是有狀態的 (stateful)。\n",
    "    - 所以是否「能記住」過去，取決於設計，而不是模型本身自帶的能力。\n",
    "\n",
    "3. Tools 的角色\n",
    "    - 讓 ChatBot 強大的是 tools\n",
    "    - 模型本身雖然能生成語言，但 結合外部工具（例如資料庫查詢、計算器、網路搜尋、代碼執行、圖片生成）後，ChatBot 才能真正做到「會推理 + 會行動」，不再只受限於參數內的知識。\n",
    "\n",
    "    - 可以理解成：模型是「大腦」，Tools 是「手腳」。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22673222-780c-4356-a6d1-92c69b28d6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(url=\"https://python.langchain.com/v0.1/assets/images/chat_use_case-eb8a4883931d726e9f23628a0d22e315.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e0c8a7-fc37-4778-9dcc-91fd68d2db66",
   "metadata": {},
   "source": [
    "先學怎麼調動工具: 模型就像是一個訓練有素的阿斯塔特，工具就像是動力甲，噴射背包，爆彈槍，和鏈鋸劍。\n",
    "\n",
    "I accept these burdens, as the Imperium bleeds.\n",
    "\n",
    "I accept these burdens, knowing no fear.\n",
    "\n",
    "I accept these burdens, as an Angel of the Emperor.\n",
    "\n",
    "I sheathe my form in this second skin.\n",
    "\n",
    "This veil of machine muscle and false nerves.\n",
    "\n",
    "I stand firm against the alien.\n",
    "\n",
    "The mutant.\n",
    "\n",
    "The heretic.\n",
    "\n",
    "I grant no mercy.\n",
    "\n",
    "I give no ground.\n",
    "\n",
    "With humility, I bear the Imperialis, the symbol of loyalty unbroken.\n",
    "\n",
    "With reverence, I receive actuation, awakening the armor’s spirit.\n",
    "\n",
    "With pride, I wear the symbol of my Chapter, and join my brothers in war.\n",
    "\n",
    "I am Iron.\n",
    "\n",
    "I am Wrath.\n",
    "\n",
    "I. Am. Doom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b382daa-6e0c-4426-a04c-054de90c4c01",
   "metadata": {},
   "source": [
    "## 工具綁定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5c8762-d00d-4796-baf2-426e7374c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.chdir(\"../../../\")\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from src.initialization import credential_init\n",
    "\n",
    "credential_init()\n",
    "\n",
    "# Define a calculator tool\n",
    "@tool\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Adds two numbers together.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "# Create the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Bind the tool to the model\n",
    "llm_with_tools = llm.bind_tools([add_numbers])\n",
    "\n",
    "# Run\n",
    "resp = llm_with_tools.invoke(\"What is 42 + 58?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0983637-cd11-40d2-b763-708542e0d68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b898337-6b82-4d2c-b0c3-8ee0e4381cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.additional_kwargs['tool_calls'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02b7795-b6ec-4c82-8cf5-f3177b6a63f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.additional_kwargs['tool_calls'][0]['function']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddcdba1-be6f-4ea2-b9a8-068adde015c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = resp.additional_kwargs['tool_calls'][0]['function']['arguments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686aa0ab-a68e-4c95-8e37-fe5042e63e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = resp.additional_kwargs['tool_calls'][0]['function']['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e40a68-7d9a-429f-a62e-7ac5c84dd44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f37979-518a-487f-b024-d8a1e9fa21a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a076e61-2125-422c-ba7c-1d3fd61d95ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(name).invoke(eval(arguments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cce1070-5041-4117-b575-b77e4bf0283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_up = llm_with_tools.invoke(\n",
    "        f\"The tool '{name}' returned: 100. Give the final answer.\"\n",
    "    )\n",
    "\n",
    "print(follow_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8003fc29-36fc-414e-acba-45535dd60f36",
   "metadata": {},
   "source": [
    "## OpenAI WebSearch\n",
    "\n",
    "### 基本使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23060df1-9851-4229-a650-fce282385040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-search-preview\",\n",
    "        web_search_options={\"search_context_size\": \"medium\"},\n",
    "        messages=[{\"role\": \"user\",\n",
    "                   \"content\": \"幫我查詢`掄語`\"}]\n",
    "    )\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02360c51-807b-4372-8e1e-7842b3438a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-search-preview\",\n",
    "        web_search_options={\"search_context_size\": \"medium\",\n",
    "                            \"user_location\": {\n",
    "                                \"type\": \"approximate\",\n",
    "                                \"approximate\": {\n",
    "                                    \"country\": \"TW\",\n",
    "                                }\n",
    "                            }},\n",
    "        messages=[{\"role\": \"user\",\n",
    "                   \"content\": \"幫我查詢HunterXHunter 最新的進度\"}]\n",
    "    )\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25149c3a-7621-467c-b0a3-d81d40dd24ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-search-preview\",\n",
    "        web_search_options={\"search_context_size\": \"medium\",\n",
    "                            \"user_location\": {\n",
    "                                \"type\": \"approximate\",\n",
    "                                \"approximate\": {\n",
    "                                    \"country\": \"US\",\n",
    "                                }\n",
    "                            }},\n",
    "        messages=[{\"role\": \"user\",\n",
    "                   \"content\": \"幫我查詢omegazerore在tensorArt上的內容\"}]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd5f6dd-5457-41ca-a99f-c2b86ad35512",
   "metadata": {},
   "source": [
    "### 那個country重要嗎?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dd5e4b-8f14-457f-9ba1-7b13b5f60f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "from src.initialization import credential_init\n",
    "\n",
    "credential_init()\n",
    "\n",
    "\n",
    "class WebSearchService:\n",
    "    \"\"\"Service class responsible for querying OpenAI's web search endpoint.\"\"\"\n",
    "\n",
    "    def __init__(self, client: OpenAI, search_context_size: str, model: str):\n",
    "\n",
    "        self.client = client\n",
    "        self.search_context_size = search_context_size\n",
    "        self.model = model\n",
    "\n",
    "    def search(self, messages: List[Dict], country_code: Optional[str]=None) -> str:\n",
    "\n",
    "        # country_code: ISO 3166-1 alpha-2 of the country\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            web_search_options={\"search_context_size\": self.search_context_size,\n",
    "                                \"user_location\": {\n",
    "                                        \"type\": \"approximate\",\n",
    "                                        \"approximate\": {\n",
    "                                            \"country\": country_code,\n",
    "                                        }\n",
    "                                    },\n",
    "                                },\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "\n",
    "\n",
    "@chain\n",
    "def websearch_image(kwargs):\n",
    "\n",
    "    strategy = kwargs['strategy']\n",
    "    brand = kwargs['brand']\n",
    "    country_code = kwargs['country_code']\n",
    "    if country_code == 'UK':\n",
    "        country_code = \"GB\"\n",
    "    if pd.isnull(kwargs['country_code']):\n",
    "        country_code = None\n",
    "\n",
    "    messages = [{\"role\": \"user\",\n",
    "                 \"content\": f\"What is the cosmetic or skin care product under the concept {strategy} with brand {brand}?\\n\\n\"\n",
    "                            f\"Please provide me the page to the product of the brand.\\n\"\n",
    "                            f\"If the exact product cannot be found, please give me products with similar concept within {brand}.\\n\"\n",
    "                            f\"Ideally from the official website of the brand {brand}.\"\n",
    "                 }]\n",
    "\n",
    "    result = websearch_service.search(messages, country_code=country_code)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "openai_key = os.environ.get('OPENAI_API_KEY')\n",
    "client = OpenAI(api_key=openai_key)\n",
    "search_context_size = 'medium'\n",
    "\n",
    "websearch_service = WebSearchService(client=client, search_context_size=search_context_size,\n",
    "                                     model=\"gpt-4o-search-preview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f223f3-3322-409a-8339-c9a1a5937e0c",
   "metadata": {},
   "source": [
    "這裡使用一個很小的巴西品牌當作例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04d35a4-71d0-4289-aa08-78f6de1f9fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "websearch_image.invoke({\"strategy\": \"Ultra-light water\",\n",
    "                        \"brand\": \"Minéraux Beauty\",\n",
    "                        \"country_code\": None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5af13dd-2f89-4108-87e4-776cd8b52433",
   "metadata": {},
   "outputs": [],
   "source": [
    "websearch_image.invoke({\"strategy\": \"Ultra-light water\",\n",
    "                        \"brand\": \"Minéraux Beauty\",\n",
    "                        \"country_code\": \"BR\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5831cc4a-c7d0-45cf-b99b-0f049e123461",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cedbbd2c-4633-4ea4-a0b2-b6fa0179a1d6",
   "metadata": {},
   "source": [
    "有辦法根據內容物提取country的代碼嗎?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5027b693-e54e-4821-9c72-f01c1ce454a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def build_standard_chat_prompt_template(kwargs):\n",
    "\n",
    "    messages = []\n",
    " \n",
    "    if 'system' in kwargs:\n",
    "        content = kwargs.get('system')\n",
    "        prompt = PromptTemplate(**content)\n",
    "        message = SystemMessagePromptTemplate(prompt=prompt)\n",
    "        messages.append(message)  \n",
    "\n",
    "    if 'human' in kwargs:\n",
    "        content = kwargs.get('human')\n",
    "        prompt = PromptTemplate(**content)\n",
    "        message = HumanMessagePromptTemplate(prompt=prompt)\n",
    "        messages.append(message)\n",
    "        \n",
    "    chat_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "    \n",
    "    return chat_prompt\n",
    "\n",
    "\n",
    "class Output(BaseModel):\n",
    "    content: str = Field(description=\"Description.\")\n",
    "    url: str = Field(description=\"url of the content source.\")\n",
    "    country_code: str = Field(description=\"ISO 3166-1 alpha-2 of the country\")\n",
    "\n",
    "\n",
    "@chain\n",
    "def websearch(kwargs):\n",
    "\n",
    "    messages = [{\"role\": \"user\",\n",
    "                 \"content\": kwargs['query']\n",
    "                 }]\n",
    "\n",
    "    result = websearch_service.search(messages)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Output)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "human_template = dedent(\"\"\"\n",
    "Paragraph: {text}\n",
    "Output format instruction: {format_instructions}\n",
    "\"\"\")\n",
    "\n",
    "input_ = {\"human\": {\"template\": human_template,\n",
    "                    \"input_variables\": ['text'],\n",
    "                    \"partial_variables\": {\"format_instructions\": format_instructions}}\n",
    "          }\n",
    "\n",
    "prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "model = ChatOpenAI(\n",
    "        model_name=\"gpt-4o-mini\",\n",
    "        temperature=0\n",
    "    )\n",
    "step_2 = prompt_template|model|output_parser\n",
    "\n",
    "pipeline = RunnablePassthrough.assign(text=websearch)|RunnablePassthrough.assign(output=step_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364fed04-5b14-4a5a-b3bc-7899d9614cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline.invoke({\"query\": \"Where is Taipei 101?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e4605b-cbfa-41d5-9ffb-bb0406c08549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將結果轉換成Python Dictionary類別\n",
    "\n",
    "result['output'].model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc03788-f1b4-4a2b-8cb4-6e7165f50c5d",
   "metadata": {},
   "source": [
    "### 建立websearch工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0893d4df-9aea-4051-8f4e-e3df0858ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def websearh_tool(query: str) -> str:\n",
    "    \"\"\"Use this tool to find the latest information or information you are not sure\"\"\"\n",
    "    return websearch.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce1dcc-df81-4a08-b5c8-bb7197618730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind the tool to the model\n",
    "llm_with_tools = llm.bind_tools([websearh_tool])\n",
    "\n",
    "# Run\n",
    "resp = llm_with_tools.invoke(\"台灣2024總統大選結果\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99771f07-3b83-45f6-94ce-d9d1a244f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91347678-4c9c-4190-a486-0c44cbc122d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = resp.additional_kwargs['tool_calls'][0]['function']['arguments']\n",
    "name = resp.additional_kwargs['tool_calls'][0]['function']['name']\n",
    "\n",
    "eval(name).invoke(eval(arguments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8037c53b-040d-4da7-a11d-2c9fb2b628d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools.invoke(\"黃埔軍校的歷史\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b096b9-1fa3-474c-b41d-b7a7a61b38e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_function(additional_kwargs):\n",
    "    \n",
    "    arguments = additional_kwargs['tool_calls'][0]['function']['arguments']\n",
    "    name = additional_kwargs['tool_calls'][0]['function']['name']\n",
    "    \n",
    "    return eval(name).invoke(eval(arguments))\n",
    "\n",
    "\n",
    "def follow_up_answer(aiadditional_kwargs):\n",
    "\n",
    "    result = call_function(additional_kwargs)\n",
    "\n",
    "    name = additional_kwargs['tool_calls'][0]['function']['name']\n",
    "    \n",
    "    follow_up = llm_with_tools.invoke(\n",
    "        f\"The tool '{name}' returned: {result}. Give the final answer.\"\n",
    "    )\n",
    "\n",
    "    return follow_up\n",
    "\n",
    "follow_up_answer(resp.additional_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f7fe22-cd1d-470a-927b-31725616d95c",
   "metadata": {},
   "source": [
    "## ChatBot 本體\n",
    "\n",
    "### LLM 沒有記憶性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5f885c-cb85-477f-90e8-147e701e6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "message = HumanMessage(\n",
    "            content=\"Translate this sentence from English to Chinese (繁體中文): I love programming.\"\n",
    "        )\n",
    "\n",
    "model.invoke(\n",
    "    [message]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95345038-9a83-465c-a85a-9b2d5f1b6476",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.invoke([HumanMessage(content=\"What did you just say?\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71ee93d-2841-4cc0-b417-3fa5554ba1b3",
   "metadata": {},
   "source": [
    "### 外部記憶\n",
    "\n",
    "如何將外部記憶加入?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed4e110-9be7-4a67-be86-31b62451baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=\"Translate this sentence from English to  Chinese (繁體中文): I love programming.\"\n",
    "        ),\n",
    "        AIMessage(content=\"我愛程式設計.\"),\n",
    "        HumanMessage(content=\"What did you just say?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce0fbac-247d-4230-849c-b5475b1a4c00",
   "metadata": {},
   "source": [
    "透過 MessagePlaceholder接收外部記憶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea7e35-f9b4-4d78-8a8e-e85225c5fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate\n",
    "\n",
    "system_prompt = PromptTemplate(template=(\"You are a helpful assistant. Answer all questions to the best of your \"\n",
    "                                         \"ability.\"))\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        system_message,\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e88d592-3e03-4a5b-81b2-e792154f94ec",
   "metadata": {},
   "source": [
    "### 建立邏輯鍊條"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd2ed39-46d6-460e-b78e-5b0c4d06fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e2a159-a35a-47db-ac82-43c8d9f85887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "pipeline_.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "            content=\"Translate this sentence from English to Chinese (繁體中文): I love programming.\"\n",
    "            ),\n",
    "            AIMessage(content=\"我愛程式設計.\"),\n",
    "            HumanMessage(content=\"What did you just say?\"),\n",
    "            ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e0029f-228a-4ff5-afb0-91bf92f00d34",
   "metadata": {},
   "source": [
    "## 將對話記錄存入ChatMessageHistory裡\n",
    "\n",
    "### 導入並創建 ChatMessageHistory。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f65a6f-3d57-4cf9-8e8f-34623e7965e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "demo_chat_history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e08da2-cb06-41db-ab6a-69532596b405",
   "metadata": {},
   "source": [
    "### 添加用戶和 AI 消息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eaf68e-486a-44cb-8107-c81b2b11e578",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_chat_history.add_user_message(\"Translate this sentence from English to Chinese (繁體中文): I love programming.\")\n",
    "\n",
    "demo_chat_history.add_ai_message(\"我愛程式設計.\")\n",
    "\n",
    "demo_chat_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cb4014-b66b-40dc-8acc-3e052426ce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_chat_history.add_user_message(\n",
    "    \"What did you just say?\"\n",
    ")\n",
    "\n",
    "response = pipeline_.invoke({\"messages\": demo_chat_history.messages})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dd8248-d495-4798-8d35-7c36862720f4",
   "metadata": {},
   "source": [
    "### 最小範例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc02e090-7b0a-45a4-b377-2e37048340df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chat_history = ChatMessageHistory()\n",
    "pipeline_ = prompt|model|StrOutputParser()\n",
    "\n",
    "while True:\n",
    "    question = input(\"What do you want to ask: \")\n",
    "    if question == \"QUIT\":\n",
    "        break\n",
    "    chat_history.add_user_message(question)\n",
    "    response = pipeline_.invoke({\"messages\": chat_history.messages})\n",
    "\n",
    "    print(response)\n",
    "    chat_history.add_ai_message(response)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f147092-7b3c-4392-8d8e-90c65b09d5d2",
   "metadata": {},
   "source": [
    "# **** 預計第一個小時結束 ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec25caf-71ec-4064-923c-ff0c5afd4e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789cefac-0701-40ee-bbf9-d92c5259117a",
   "metadata": {},
   "source": [
    "### 檢索消息\n",
    "\n",
    "加入變數的敘述: 使用Pydantic schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb7abfb-9d66-4ca8-96c7-2358b21d009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_core.tools import tool\n",
    "from langchain.tools import StructuredTool\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder, \n",
    "SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "from src.io.path_definition import get_project_dir\n",
    "from src.initialization import credential_init\n",
    "\n",
    "\n",
    "credential_init()\n",
    "\n",
    "# 引入唐詩向量數據庫\n",
    "filename = os.path.join(get_project_dir(), \"tutorial\", \"LLM+Langchain\", \"Week-2\", \"poem_faiss_index\")\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "\n",
    "vectorstore = FAISS.load_local(\n",
    "    filename, embeddings, allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(seearch_type='similarity').configurable_fields(\\\n",
    "        search_kwargs=ConfigurableField(id=\"search_kwargs\")\n",
    "    )\n",
    "\n",
    "# # 建立Tool\n",
    "# @tool\n",
    "# def poem_retriever(query: str, k: int):\n",
    "#     \"\"\"\n",
    "#     使用這個工具來搜尋唐詩; Use this tool to search for Tang poems.\n",
    "#     The default number of retrieved poem is 1.\n",
    "#     \"\"\"\n",
    "\n",
    "#     output = retriever.invoke(query, config={\"configurable\": {\"search_kwargs\": {\"k\": k}}})\n",
    "    \n",
    "#     return output\n",
    "\n",
    "\n",
    "class PoemRetrieverArgs(BaseModel):\n",
    "    query: str = Field(description=\"The keyword or phrase to search for Tang poems. 用來搜尋唐詩的關鍵字或是句子\")\n",
    "    k: int = Field(1, description=\"The number of poems to retrieve.\")\n",
    "\n",
    "\n",
    "def _poem_retriever(query: str, k: int):\n",
    "    output = retriever.invoke(query, config={\"configurable\": {\"search_kwargs\": {\"k\": k}}})\n",
    "    return output\n",
    "\n",
    "\n",
    "poem_retriever = StructuredTool.from_function(\n",
    "    func=_poem_retriever,\n",
    "    args_schema=PoemRetrieverArgs,\n",
    "    description=\"使用這個工具來搜尋唐詩; Use this tool to search for Tang poems.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cdf253-b43a-45e2-8f92-2667ac5480ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = PromptTemplate(template=dedent(\"\"\"You are a helpful assistant. \n",
    "Answer all questions to the best of your ability.\n",
    "\"\"\"))\n",
    "\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        system_message,\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-2024-05-13\", temperature=0)\n",
    "\n",
    "model_with_tools = model.bind_tools([poem_retriever])\n",
    "\n",
    "chatbot_pipeline = prompt | model_with_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6d758f-2e4a-40b0-9775-ff872fae19db",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "question = \"幫我找3首關於對於人生感嘆的唐詩\"\n",
    "\n",
    "chat_history.add_user_message(question)\n",
    "\n",
    "output = chatbot_pipeline.invoke({\"messages\": chat_history.messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d0c399-c1ce-45ed-a54c-42bc6ff3e3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d032970-2c15-408f-9931-f54b1301a62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_function(additional_kwargs):\n",
    "\n",
    "    arguments = additional_kwargs['tool_calls'][0]['function']['arguments']\n",
    "    name = additional_kwargs['tool_calls'][0]['function']['name']\n",
    "    \n",
    "    return eval(name)(**eval(arguments))\n",
    "\n",
    "\n",
    "def follow_up_answer(human_message, ai_message, additional_kwargs):\n",
    "\n",
    "    result = call_function(additional_kwargs)\n",
    "\n",
    "    name = additional_kwargs['tool_calls'][0]['function']['name']\n",
    "\n",
    "    if ai_message == \"\":\n",
    "        query = dedent(f\"\"\"\n",
    "        human question: {human_message}\n",
    "        The tool {name} is applied and the tool returns {result}.\n",
    "        Give the final answer:\n",
    "        \"\"\")\n",
    "    else:\n",
    "        query = dedent(f\"\"\"\n",
    "        human question: {human_message}\n",
    "        ai response: {ai_message}\n",
    "        The tool {name} is applied and the tool returns {result}.\n",
    "        Give the final answer:\n",
    "        \"\"\")\n",
    "    \n",
    "    follow_up = model.invoke(query)\n",
    "\n",
    "    return follow_up\n",
    "\n",
    "follow_up_answer(human_message=question, ai_message=output.content, additional_kwargs=output.additional_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e077d123-6b59-46c8-8ab3-36c0ea9f7408",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "while True:\n",
    "    question = input(\"What do you want to ask: \")\n",
    "    if question == \"QUIT\":\n",
    "        break\n",
    "    chat_history.add_user_message(question)\n",
    "    output = chatbot_pipeline.invoke({\"messages\": chat_history.messages})\n",
    "\n",
    "    if output.content == \"\":\n",
    "        response = follow_up_answer(output.additional_kwargs).content\n",
    "    else:\n",
    "        response = output.content\n",
    "\n",
    "    print(\"***********************\")\n",
    "    print(response)\n",
    "    print(\"***********************\")\n",
    "    \n",
    "    chat_history.add_ai_message(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3142dd21-ccf2-4bd4-8714-d3995bb5d713",
   "metadata": {},
   "source": [
    "### 使用代碼解決數學問題工具\n",
    "\n",
    "1. 代碼產生的邏輯鍊條"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186123ce-d45c-4bf7-bd03-315cbf3eac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "def build_standard_chat_prompt_template(kwargs):\n",
    "\n",
    "    messages = []\n",
    " \n",
    "    if 'system' in kwargs:\n",
    "        content = kwargs.get('system')\n",
    "        prompt = PromptTemplate(**content)\n",
    "        message = SystemMessagePromptTemplate(prompt=prompt)\n",
    "        messages.append(message)  \n",
    "\n",
    "    if 'human' in kwargs:\n",
    "        content = kwargs.get('human')\n",
    "        prompt = PromptTemplate(**content)\n",
    "        message = HumanMessagePromptTemplate(prompt=prompt)\n",
    "        messages.append(message)\n",
    "        \n",
    "    chat_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "    \n",
    "    return chat_prompt\n",
    "\n",
    "\n",
    "@chain\n",
    "def code_execution(code):\n",
    "    \n",
    "    match = re.findall(r\"python\\n(.*?)\\n```\", code, re.DOTALL)\n",
    "    python_code = match[0]\n",
    "    \n",
    "    lines = python_code.strip()#.split('\\n')\n",
    "    # *stmts, last_line = lines\n",
    "\n",
    "    local_vars = {}\n",
    "    exec(lines, {}, local_vars)\n",
    "\n",
    "    return local_vars\n",
    "\n",
    "\n",
    "system_template = (\n",
    "    \"You are a highly skilled Python developer. Your task is to generate Python code strictly based on the user's instructions.\\n\"\n",
    "    \"Leverage statistical and mathematical libraries such as `statsmodels`, `scipy`, and `numpy` where appropriate to solve the problem.\\n\"\n",
    "    \"Your response must contain only the Python code — no explanations, comments, or additional text.\\n\\n\"\n",
    ")\n",
    "\n",
    "human_template = dedent(\"\"\"{query}\\n\\n\n",
    "                            Always copy the final answer to a variable `answer`\n",
    "                            Code:\n",
    "                        \"\"\")\n",
    "\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variable\": [\"query\"]}}\n",
    "\n",
    "chat_prompt = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "code_generation = chat_prompt|model|StrOutputParser()\n",
    "\n",
    "code_pipeline = code_generation|code_execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd20ef9-1d19-424e-95a7-aec635a6273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeArgs(BaseModel):\n",
    "    query: str = Field(description=\"User request; 用戶需求\")\n",
    "\n",
    "\n",
    "def _calculator(query: str,):\n",
    "    output = code_pipeline.invoke(query)\n",
    "    return output\n",
    "\n",
    "\n",
    "mathematic_tool = StructuredTool.from_function(\n",
    "    func=_calculator,\n",
    "    args_schema=CodeArgs,\n",
    "    description=\"Use this tool to solve mathematic related problem; 使用這個工具解決數學問題\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1c23eb-d494-49a2-b913-d23cdd4d8336",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools([mathematic_tool])\n",
    "\n",
    "chatbot_pipeline = prompt | model_with_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd7e55f-75ab-4323-bcdd-a13246308eab",
   "metadata": {},
   "source": [
    "北一女段考考題\n",
    "\n",
    "https://drive.google.com/file/d/1csHdgvc5WtbJZ4n39eozogVVPIkPWABf/view\n",
    "\n",
    "3. 在坐標平面上,下列有關圓的敘述哪些正確?\n",
    "(A) 滿足方程式 x\n",
    "2\n",
    "+ y\n",
    "2\n",
    "+ 2x −10y + 30 = 0 之點(x, y)的圖形是一個圓\n",
    "\n",
    "(B) 過三點 A( 1, − 3), B( 2, 6 ), C( 4, 24 )的圓恰有一個\n",
    "(C) 直線 3x −4y + 7 = 0 與圓(x − 2)2\n",
    "\n",
    "+ ( y + 3)2\n",
    "\n",
    "= 5 恰有一交點\n",
    "\n",
    "(D) 圓(x − 2)2\n",
    "\n",
    "+ ( y + 3)2\n",
    "\n",
    "= 5 上恰有二點與直線 3x −4y −13= 0 的距離等於 2\n",
    "\n",
    "(E) P a b ( , )為圓(x − 2)2\n",
    "\n",
    "+ ( y + 3)2\n",
    "\n",
    "= 4 上的點,則使 2 2 a b + 為整數的點共有 8 個"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a28d83-46e6-4efc-b743-d0bf3a4eeffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "question = dedent(\"\"\"\n",
    "以下敘述是否正確:\n",
    "\n",
    "滿足方程式 x^2 + y^2 + 2x −10y + 30 = 0 之點(x, y)的圖形是一個圓\n",
    "\"\"\")\n",
    "\n",
    "chat_history.add_user_message(question)\n",
    "\n",
    "output = chatbot_pipeline.invoke({\"messages\": chat_history.messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef887486-a18a-4f29-81b9-c70daef7623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a21da7e-8f76-414b-8cba-512e23986fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "question = dedent(\"\"\"\n",
    "以下敘述是否正確:\n",
    "\n",
    "過三點 A( 1, − 3), B( 2, 6 ), C( 4, 24 )的圓恰有一個\n",
    "\"\"\")\n",
    "\n",
    "chat_history.add_user_message(question)\n",
    "\n",
    "output = chatbot_pipeline.invoke({\"messages\": chat_history.messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ca5aa8-6ae0-4c0f-a0e0-2105902dddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_up_answer(human_message=question, ai_message=output.content, additional_kwargs=output.additional_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b22afe-974c-465d-94b3-3a04636fc1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "question = dedent(\"\"\"\n",
    "以下敘述是否正確:\n",
    "\n",
    "直線 3x −4y + 7 = 0 與圓 (x − 2)^2 + (y + 3)^2 = 5 恰有一交點\n",
    "\"\"\")\n",
    "\n",
    "chat_history.add_user_message(question)\n",
    "\n",
    "output = chatbot_pipeline.invoke({\"messages\": chat_history.messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a12a589-fb63-47e4-aa4c-e4f7762904d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9aa7cd-f0c9-4a99-af15-19d9a88c560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(follow_up_answer(human_message=question, ai_message=output.content, additional_kwargs=output.additional_kwargs).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711fccb3-4320-4fb4-92b6-5ea17b405c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "question = dedent(\"\"\"\n",
    "以下敘述是否正確:\n",
    "\n",
    "圓(x − 2)^2 + (y + 3)^2 = 5 上恰有二點與直線 3x −4y −13= 0 的距離等於 2\n",
    "\"\"\")\n",
    "\n",
    "chat_history.add_user_message(question)\n",
    "\n",
    "output = chatbot_pipeline.invoke({\"messages\": chat_history.messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2e11ba-6a60-4778-aa9b-3637a1779fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb228a12-42e1-4afc-bf10-2642f060ec60",
   "metadata": {},
   "source": [
    "換個方法問"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b942c49e-31fb-437d-95da-b73b9d5f5d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "question = dedent(\"\"\"\n",
    "空間中點(x, y) = (2, -3) 與直線 3x −4y −13= 0 的距離是多少?\n",
    "\"\"\")\n",
    "\n",
    "chat_history.add_user_message(question)\n",
    "\n",
    "output = chatbot_pipeline.invoke({\"messages\": chat_history.messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e6da5b-dbf5-4e9b-99ab-b599d4574a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39963073-0871-4e0d-a6a4-f839e20ac88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(follow_up_answer(human_message=question, ai_message=output.content, additional_kwargs=output.additional_kwargs).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f059b9d7-1f05-4d06-802a-0b2184ff9438",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "question = dedent(\"\"\"\n",
    "以下敘述是否正確:\n",
    "\n",
    "P(a, b) 為 圓 (x − 2)^2 + ( y + 3)^2 = 4 上的點,則使 (a^2 + b^2)^0.5 為整數的點共有 8 個\n",
    "\"\"\")\n",
    "\n",
    "chat_history.add_user_message(question)\n",
    "\n",
    "output = chatbot_pipeline.invoke({\"messages\": chat_history.messages})\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677b7414-0b19-4e9b-914e-643075ae723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(follow_up_answer(human_message=question, ai_message=output.content, additional_kwargs=output.additional_kwargs).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3ef13d-003d-45bd-a2bd-33eef0f00889",
   "metadata": {},
   "source": [
    "Which part went wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bfde6d-07eb-4e14-9844-6d065ff6eafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = code_generation.invoke({\"query\": \"P(a, b) 為 圓 (x − 2)^2 + ( y + 3)^2 = 4 上的點,則使 (a^2 + b^2)^0.5 為整數的點共有 8 個是否正確\"})\n",
    "\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02f81e8-0696-42b4-93a8-6c04db9f52f1",
   "metadata": {},
   "source": [
    "### 有辦法加入一些基本的機械學習來進行分析嗎?\n",
    "\n",
    "我還不知道，應該是會蠻有趣的\n",
    "\n",
    "到這裡你應該可以認識到，寫ChatBot本體並不困難，但一個ChatBot好不好用是由他所綑綁的工具決定。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaaadfb-880e-4107-bbae-bef8c0f8cd04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91a58350-7baf-45c7-9beb-bcd4c15f8a2c",
   "metadata": {},
   "source": [
    "## 加入Callback 進行追蹤ChatBot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55cfa64-3691-4e11-b576-c55cd61269be",
   "metadata": {},
   "source": [
    "## OpenAI Model Fine-tuning\n",
    "\n",
    "剛好有人來找我家教這個，整理了一下。。。\n",
    "\n",
    "參考:\n",
    "\n",
    "- https://cookbook.openai.com/examples/chat_finetuning_data_prep\n",
    "\n",
    "- {\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]} {\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some guy named William Shakespeare. Ever heard of him?\"}]} {\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72b7d19-baa8-48eb-9365-39a62b37214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.io.path_definition import get_project_dir\n",
    "\n",
    "jsonl = []\n",
    "\n",
    "with open(os.path.join(get_project_dir(), 'tutorial', 'LLM+Langchain', 'Week-1', 'recipe_train.json'), 'r') as f:\n",
    "    recipe_train = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce35b10-7af5-4e18-a333-65d06d84cfe5",
   "metadata": {},
   "source": [
    "### Create a jsonl format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a36fff-6e74-4c92-bada-1d3f687323b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_df = pd.DataFrame(data=[[rec['id'], rec['cuisine'], \", \".join(rec['ingredients'])] \n",
    "                               for rec in recipe_train], columns=['id', 'cuisine', 'ingredients'])\n",
    "\n",
    "\"\"\"\n",
    "train-test split\n",
    "\n",
    "- 固定random state，確保數據的重現性\n",
    "- 使用分層抽樣(stratified sampling)，保證訓練-測試集的class分佈是一致的\n",
    "\"\"\"\n",
    "\n",
    "train, test = train_test_split(recipe_df, test_size=0.2, random_state=42, stratify=recipe_df['cuisine'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58d3c8d-1520-4146-b788-43f4459039ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_template = \"\"\"You are a helpful AI assistant as a chef of a Michellin 3 stars restaurant. You have extensive knowledge about cuisines \n",
    "                            all over the world, and you are able to identify the origin of a cuisine based on the ingredients. You are assigned with a \n",
    "                            task of identifying the origin, as region, of cuisine based on the <ingredients>.                            \n",
    "                            \"\"\"\n",
    "\n",
    "for _, row in train.iterrows():\n",
    "\n",
    "    ingredients = row['ingredients']\n",
    "    content = f\"ingredients: [{ingredients}]\"\n",
    "    \n",
    "    jsonl.append({\"messages\": [{\"role\": \"system\", \"content\": system_prompt_template}, \n",
    "                               {\"role\": \"user\", \"content\": content}, \n",
    "                               {\"role\": \"assistant\", \"content\": row['cuisine']}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1271c822-d888-4181-977b-52528f2534bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 寫入檔案\n",
    "\n",
    "with open('openapi_finetuning_test.jsonl', 'w') as outfile:\n",
    "    for entry in jsonl:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2900e815-0375-40c4-bea7-ad3029b79f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接使用OpenAI提供的API\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "\n",
    "client.files.create?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3e8787-ee23-4881-bac8-c20c8a0ef1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.files.create(file=open('openapi_finetuning_test.jsonl', 'rb'),\n",
    "                    purpose='fine-tune')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adf281f-868a-469b-ad55-bb9ff6c174bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.fine_tuning.jobs.create?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a22bc9-d0f2-401d-a7cf-cd10929975a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.fine_tuning.jobs.create(model=\"gpt-4o-mini-2024-07-18\",\n",
    "                               training_file=\"file-SHpXusOxxMVGYRgwIGNj6mk9\",\n",
    "                               hyperparameters={\"batch_size\":4, \"learning_rate_multiplier\": 1e-6, \"n_epochs\": 5},\n",
    "                               suffix='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5b8282-603e-4f95-9ba7-3d17be3f5779",
   "metadata": {},
   "source": [
    "訓練完之後"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddd3e05-adba-4048-9057-51ca4938c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"ft:gpt-4o-mini-2024-07-18:cosnova-account:test:ANPq9Weh\", \n",
    "                   temperature=0 # a range from 0-2, the higher the value, the higher the `creativity`\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98182db0-19de-44e1-a483-397f92e7f401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "system_prompt = PromptTemplate.from_template(system_prompt_template)\n",
    "\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template=\"\"\"\n",
    "                                       ingredients: [{ingredients}]\n",
    "                                       \"\"\",\n",
    "                              input_variables=[\"ingredients\"]\n",
    "                              )\n",
    "\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                human_message\n",
    "                                                ])\n",
    "\n",
    "fine_tuned_chain = chat_prompt|model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf03979c-e472-4134-8945-2cef5cd1133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_chain.invoke({\"ingredients\": test.iloc[0]['ingredients']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d40de2-80a7-49e9-934b-c73da93b599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-mini-2024-07-18\", \n",
    "                   temperature=0 # a range from 0-2, the higher the value, the higher the `creativity`\n",
    "                  )\n",
    "\n",
    "chain = chat_prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5952eae8-02ac-40d6-a8d3-de8a78538ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"ingredients\": test.iloc[0]['ingredients']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10c0ba8-e333-4487-867b-9b92d1e5d8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
