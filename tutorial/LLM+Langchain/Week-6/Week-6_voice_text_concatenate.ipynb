{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eAu5cfSHw6cY",
    "outputId": "0d459e7c-a904-4fcf-fea7-7d1d8066905f"
   },
   "outputs": [],
   "source": [
    "!apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pr8P2tBIxBZv",
    "outputId": "28a9afad-0f92-4ac0-d99f-0615d4d0a28d"
   },
   "outputs": [],
   "source": [
    "!apt-get install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zr9keuSexKG9",
    "outputId": "90b77ae3-df46-4069-8ae4-c5920dae53e3"
   },
   "outputs": [],
   "source": [
    "!pip install langchain-community==0.2.5 langchain-core==0.2.9 langchain-openai==0.1.9 pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kIuUrAZcw9vO",
    "outputId": "009f2a59-17ea-4c65-a2be-0b43d17370ce"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "def credential_init():\n",
    "\n",
    "  credential_file = \"credentials.ini\"\n",
    "\n",
    "  if os.path.exists(credential_file):\n",
    "    credentials = configparser.ConfigParser()\n",
    "    credentials.read(credential_file)\n",
    "    os.environ['OPENAI_API_KEY'] = credentials['openai'].get('api_key')\n",
    "  else:\n",
    "    os.environ['OPENAI_API_KEY'] = os.environ['OPENAI']\n",
    "\n",
    "credential_init()\n",
    "\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "           model_name=\"gpt-4o-mini-2024-07-18\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPhKW9mMxc8Z"
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Experiment 1: two pieces\n",
    "# Explicit steps\n",
    "\n",
    "speech = AudioSegment.from_mp3(\"05_12_2013_Torti_CLAS_1.mp3\")\n",
    "\n",
    "one_second = 1000\n",
    "\n",
    "# PyDub handles time in milliseconds\n",
    "one_minute = 1 * 60 * one_second\n",
    "\n",
    "# 3 seconds overlap\n",
    "overlap = 3 * one_second\n",
    "\n",
    "signal_1 = speech[:one_minute]\n",
    "signal_2 = speech[one_minute - overlap: 2 * one_minute]\n",
    "\n",
    "signal_1.export(\"signal_1.mp3\", format=\"mp3\")\n",
    "signal_2.export(\"signal_2.mp3\", format='mp3')\n",
    "\n",
    "transcription_1 = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\",\n",
    "  file=open(\"signal_1.mp3\", 'rb')\n",
    ")\n",
    "\n",
    "transcription_2 = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\",\n",
    "  file=open(\"signal_2.mp3\", 'rb')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "Qq_deaEsyV2k",
    "outputId": "62e7d559-4914-40b3-9417-76e5a0c0e46d"
   },
   "outputs": [],
   "source": [
    "transcription_1.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "id": "DOoyNIRb2ufP",
    "outputId": "2c6086ee-a4ba-4cd3-a098-2eb9f2883c5f"
   },
   "outputs": [],
   "source": [
    "transcription_2.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FjFuhg4t2xFD"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "\n",
    "system_prompt = PromptTemplate(template=\n",
    "    \"\"\"\n",
    "    You are a AI assistant as a copywriter\n",
    "    You are assigned with a task of concatenate two texts <text_1> and <text_2>\n",
    "    \"\"\")\n",
    "\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template=\"\"\"\n",
    "                    <text_1>: {text_1};\n",
    "                    <text_2>: {text_2};\n",
    "                    \"\"\")\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                         human_message\n",
    "                          ])\n",
    "\n",
    "pipeline_ = chat_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "8vP9G_i430LG",
    "outputId": "3e5531ca-f889-42ac-a0d1-7cec9301836a"
   },
   "outputs": [],
   "source": [
    "pipeline_.invoke({\"text_1\":transcription_1.text,\n",
    "         \"text_2\":transcription_2.text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "H1TgWiM_4Chx",
    "outputId": "2e0bef06-cee9-4d0d-e7b7-1c7c70848888"
   },
   "outputs": [],
   "source": [
    "# system_prompt = PromptTemplate.from_template(\n",
    "#     \"\"\"\n",
    "#     You are a helpful AI assistant assigned with a task of concatenating\n",
    "#     two pieces of text <text_1> and <text_2> with the end of\n",
    "#     <text_1> and the begin of <text_2> are overlapped.\n",
    "\n",
    "#     Both <text_1> and <text_2> are extracted from the same piece of text.\n",
    "#     Please keep all the content.\n",
    "#     \"\"\")\n",
    "\n",
    "# system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "# human_prompt = PromptTemplate(template=\"\"\"\n",
    "#                       <text_1>: {text_1}\n",
    "#                       <text_2>: {text_2}\n",
    "#                       \"\"\")\n",
    "# human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "# chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "#                           human_message\n",
    "#                           ])\n",
    "\n",
    "# pipeline_ = chat_prompt | model | StrOutputParser()\n",
    "\n",
    "# pipeline_.invoke({\"text_1\":transcription_1.text, \"text_2\":transcription_2.text})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtLTSNUK4lyT"
   },
   "source": [
    "## 我們可以從頭到尾把整段錄音的文字接起來嗎? 想像一下若是音檔很大的話。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zDRNd6to41gM",
    "outputId": "2455e590-ba6b-4502-a9f9-80b2883baadb"
   },
   "outputs": [],
   "source": [
    "text_list = []\n",
    "\n",
    "speech = AudioSegment.from_mp3(\"05_12_2013_Torti_CLAS_1.mp3\")\n",
    "\n",
    "one_second = 1000\n",
    "\n",
    "# PyDub handles time in milliseconds\n",
    "one_minute = 2 * 60 * one_second\n",
    "\n",
    "# 5 seconds overlap\n",
    "overlap = 3 * one_second\n",
    "\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "  signal = speech[count * one_minute: (count + 1) * one_minute + overlap]\n",
    "  signal.export(\"signal.mp3\", format=\"mp3\")\n",
    "  transcription = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\",\n",
    "  file=open(\"signal.mp3\", 'rb')\n",
    "  )\n",
    "  print(\"\\n\")\n",
    "  print(f\"Paragraph {count}\")\n",
    "  print(transcription.text)\n",
    "  print(\"\\n\")\n",
    "  print(\"********************************************\")\n",
    "  text_list.append(transcription.text)\n",
    "  count += 1\n",
    "  if len(text_list) == 1:\n",
    "\n",
    "    continue\n",
    "  # else:\n",
    "  #   text_list.append(transcription.text)\n",
    "\n",
    "  result = pipeline_.invoke({\"text_1\":text_list[0], \"text_2\":text_list[1]})\n",
    "  text_list = [result]\n",
    "  if len(signal) < one_minute:\n",
    "    break\n",
    "\n",
    "  # 示範用 節省時間\n",
    "  if count == 5:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7pDALhP273HQ",
    "outputId": "05388905-ee23-4127-8ac7-d8d6f93cdc69"
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "id": "BCQOUn_XAG3j",
    "outputId": "77bd18cc-46f1-447e-d3f1-e7963a14cb56"
   },
   "outputs": [],
   "source": [
    "text_list[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qm_DgyBt_BGH"
   },
   "source": [
    "## 實踐出真理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "As_v-i8_74Sf",
    "outputId": "ac6eae2d-b9b5-4740-af91-116251a398a6"
   },
   "outputs": [],
   "source": [
    "signal = speech[:5 * one_minute]\n",
    "signal.export(\"signal.mp3\", format=\"mp3\")\n",
    "transcription = client.audio.transcriptions.create(\n",
    "model=\"whisper-1\",\n",
    "file=open(\"signal.mp3\", 'rb')\n",
    ")\n",
    "print(transcription.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "9YFWmIXy_Xsv",
    "outputId": "b88e391d-fdf9-456c-9b43-ff7b8725207e"
   },
   "outputs": [],
   "source": [
    "transcription.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "crOfYGvd_lip"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
