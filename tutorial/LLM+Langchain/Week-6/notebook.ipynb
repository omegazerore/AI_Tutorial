{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e9bd1a7-ba1e-491e-b83e-a31ac4dd06d9",
   "metadata": {},
   "source": [
    "# 語音轉文字 (Speech to Text)\n",
    "\n",
    "在許多應用中，語音資料需要被轉換為文字，例如字幕產生、語音助理、會議紀錄或多語言翻譯。OpenAI 提供了 **Whisper** 模型，可以高效地進行以下兩種主要任務：\n",
    "\n",
    "- **轉錄 (Transcribe)：** 將音訊檔案轉換成相同語言的文字。  \n",
    "- **翻譯轉錄 (Translate & Transcribe)：** 將音訊檔案的內容轉錄並翻譯成英文。  \n",
    "\n",
    "目前檔案上傳限制為 **25 MB**，支援的音訊檔案格式包括：  \n",
    "`mp3`, `mp4`, `mpeg`, `mpga`, `m4a`, `wav`, `webm`\n",
    "\n",
    "---\n",
    "\n",
    "# 文字轉語音 (Text to Speech, TTS)\n",
    "\n",
    "除了語音轉文字，OpenAI 也提供了 **文字轉語音 (TTS)** 功能。透過 TTS，我們可以將輸入的文字轉換為自然流暢的語音，適合應用於：  \n",
    "\n",
    "- **語音助理**：讓機器能以自然語音回覆使用者。  \n",
    "- **內容創作**：自動生成旁白或有聲讀物。  \n",
    "- **輔助功能**：幫助視覺障礙者或閱讀困難者更容易獲取資訊。  \n",
    "\n",
    "TTS 支援多種語音風格與音質選擇，能夠在不同應用場景中提供更自然的使用體驗。\n",
    "\n",
    "---\n",
    "\n",
    "接下來，我們將透過程式範例來展示如何使用 Python 串接 **Whisper** (語音轉文字) 與 **TTS** (文字轉語音)，並逐步完成音訊與文字的雙向轉換。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacd9ac3-0fd0-4ce8-9c63-87a94202ed22",
   "metadata": {},
   "source": [
    "## Audio models\n",
    "\n",
    "| Model   | Usage                                            |\n",
    "|---------|--------------------------------------------------|\n",
    "| Whisper |  \\$ 0.006 / minute rounded to the nearest second     |\n",
    "| TTS     |  \\$ 15.00 / 1M characters                          |\n",
    "| TTS HD  |  \\$ 30.00 / 1M characters                          |\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb5d86-d176-43a1-9f92-d0e3babe9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476b8dcb-ece8-4730-a8d9-5a0fad0e6abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.initialization import credential_init\n",
    "from src.io.path_definition import get_project_dir, get_file\n",
    "\n",
    "\n",
    "credential_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8465282-3b41-422d-a904-8c62ecd196f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baa97bc-b426-418e-820f-618b18a2df30",
   "metadata": {},
   "source": [
    "## Transcription\n",
    "\n",
    "### Batch Transcription\n",
    "\n",
    "在 非串流模式（使用 transcriptions.create 上傳檔案）時，Whisper 會等待整個音訊檔案完全上傳後，才會對完整音檔進行轉錄，並在完成後一次性回傳結果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cfb513-eefd-4db7-8dce-4998eb968e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file= open(\"tutorial/LLM+Langchain/Week-6/孩子上網，小心上當.mp3\", \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3973567-5159-4e06-9a12-6ed69cb77cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71566743-14a9-4c61-9cfb-156c973f8639",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ec60c1-a6b9-41f2-a239-cb134e6cb39b",
   "metadata": {},
   "source": [
    "假設你需要時間軸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78953051-5e05-40c0-8da2-6e7eeeafb2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file,\n",
    "  response_format='srt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82933478-f962-491e-b030-c1e4d64ebbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834ad423-1cdc-4ca4-bb51-cd5064b44d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file,\n",
    "  response_format='srt',\n",
    "  prompt=\"這是一個關於防詐騙的宣傳, 私line\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58477848-aedb-449c-9374-f58a8bdc600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef53b59d-769b-42b2-bacb-e271a07dd641",
   "metadata": {},
   "source": [
    "### Stream\n",
    "\n",
    "如果你在呼叫時使用 stream=True，SDK 仍然會先上傳整個音訊檔（它並不是一段一段分塊上傳），但不同的是，它不會等到完整的轉錄結束才回傳，而是會在 Whisper 生成的同時，逐步傳回結果。\n",
    "\n",
    "因此，你會在轉錄過程中陸續看到部分文字片段。\n",
    "\n",
    "等到 Whisper 完成後，你就會得到最終的完整轉錄結果。\n",
    "\n",
    "- 只支援 gpt-4o-mini or gpt-4o transcription\n",
    "\n",
    "- 在gpt-4o-transcript 和 gpt-4o-mini-transcript 模型記得加上語言編碼，不然中文輸出極大概率是簡體中文。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f974ba4b-a498-4df7-99cb-c7ab243e9186",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file= open(\"tutorial/LLM+Langchain/Week-6/孩子上網，小心上當.mp3\", \"rb\")\n",
    "\n",
    "stream = client.audio.transcriptions.create(\n",
    "  file=audio_file,\n",
    "  model=\"gpt-4o-mini-transcribe\",\n",
    "  stream=True,\n",
    "  language='zh-tw'\n",
    ")\n",
    "\n",
    "# for event in stream:\n",
    "#   print(event)\n",
    "\n",
    "for event in stream:\n",
    "    # Depending on the event format; e.g. maybe:\n",
    "    # - event.type might be “transcript.text.delta”\n",
    "    # - or event.delta or event.partial\n",
    "    try:\n",
    "        # Example if event has attribute 'delta'\n",
    "        partial = event.delta  \n",
    "        print(partial, end=\"\", flush=True)\n",
    "    except AttributeError:\n",
    "        # fallback / final result\n",
    "        print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd11eaf1-a31c-4dc6-b2f2-eed43d8cf552",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = client.audio.transcriptions.create(\n",
    "  file=audio_file,\n",
    "  model=\"gpt-4o-transcribe\",\n",
    "  stream=True,\n",
    "  language='zh-tw'\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    # Depending on the event format; e.g. maybe:\n",
    "    # - event.type might be “transcript.text.delta”\n",
    "    # - or event.delta or event.partial\n",
    "    try:\n",
    "        # Example if event has attribute 'delta'\n",
    "        partial = event.delta  \n",
    "        print(partial, end=\"\", flush=True)\n",
    "    except AttributeError:\n",
    "        # fallback / final result\n",
    "        print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a772b55-ecbe-4f2b-98dd-dec28fda608a",
   "metadata": {},
   "source": [
    "## 增加可靠度\n",
    "\n",
    "### Prompt\n",
    "\n",
    "- 給予Context\n",
    "- 給予關鍵字 (私line，應該只有台灣人用這個詞，別太指望OpenAI)\n",
    "\n",
    "### Timestamp_granularities\n",
    "\n",
    "- 可能有用\n",
    "\n",
    "一音多字可能沒辦法改善，畢竟把所有一音多字的情況標出來也不實際"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427eb795-30fc-4c62-86ca-c9f778939c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = client.audio.transcriptions.create(\n",
    "  file=audio_file,\n",
    "  model=\"gpt-4o-transcribe\",\n",
    "  stream=True,\n",
    "  language='zh-tw',\n",
    "  prompt=\"這是一個關於防詐騙的宣傳, 私line\",\n",
    "  timestamp_granularities=\"word\",\n",
    "  temperature=0\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "for event in stream:\n",
    "    # Depending on the event format; e.g. maybe:\n",
    "    # - event.type might be “transcript.text.delta”\n",
    "    # - or event.delta or event.partial\n",
    "    try:\n",
    "        # Example if event has attribute 'delta'\n",
    "        partial = event.delta\n",
    "        buffer += partial\n",
    "        print(\"\\r\" + buffer, end=\"\", flush=True)\n",
    "        # print(partial, end=\"\", flush=True)\n",
    "    except AttributeError:\n",
    "        # fallback / final result\n",
    "        print(\"\\r\" + \" \" * len(buffer), end=\"\")  # 清掉這行\n",
    "        print(\"\\r\" + event.text)  # 印最終結果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19f86f8-f939-4081-8b66-a59a684e2b67",
   "metadata": {},
   "source": [
    "# 閩南語語音辨識（ASR）可行性評估\n",
    "\n",
    "## ✅ 你的觀點正確的地方\n",
    "1. **書寫標準不統一是瓶頸**  \n",
    "   - 語音模型訓練需要「語音 + 對應文字轉錄」資料。  \n",
    "   - 閩南語存在多種書寫系統（漢字、台羅文、白話字/羅馬拼音），缺乏一致標準會造成資料集混亂，難以收斂。  \n",
    "\n",
    "2. **資源不足**  \n",
    "   - 相比英語、中文，閩南語的「語音–文字平行語料」極少。  \n",
    "   - 缺乏大量公開 dataset，從零開始訓練成本極高。  \n",
    "\n",
    "3. **實用性受限**  \n",
    "   - 沒有公認的書寫方式，ASR 輸出的結果難以被廣泛採用。  \n",
    "   - 例如：同一句話輸出為「漢字版」或「台羅文版」，使用者群體可能互不接受。  \n",
    "\n",
    "---\n",
    "\n",
    "## 💡 技術上值得補充的觀點\n",
    "1. **語音模型本身不依賴「官方標準」**  \n",
    "   - 模型只需要「統一的訓練標籤」。  \n",
    "   - 無論是台羅文、漢字或羅馬拼音，只要 dataset 標註一致，模型即可學習。  \n",
    "   - 困難點在於「社群能否就某種書寫系統達成共識」。  \n",
    "\n",
    "2. **可採「多輸出 / 後處理」策略**  \n",
    "   - 訓練時使用 **台羅文**（與音素對應性較佳）。  \n",
    "   - 應用層可透過轉換器將台羅文輸出轉換成漢字或其他拼音系統。  \n",
    "   - 這樣可繞過「標準未定」的問題。  \n",
    "\n",
    "3. **現代語音技術降低門檻**  \n",
    "   - Whisper 等大模型已證明：低資源語言只要有數百小時資料即可微調出可用系統。  \n",
    "   - 技術上「可行」，只是 **成本高 + 資料缺乏**。  \n",
    "\n",
    "4. **平行案例**  \n",
    "   - 客家話、藏語、威爾斯語、愛爾蘭語等語言也有「語料少、書寫多樣」的挑戰。  \n",
    "   - 仍有人成功建立 ASR → 證明並非「技術上不可能」。  \n",
    "\n",
    "---\n",
    "\n",
    "## 📌 綜合評估\n",
    "- **正確：** 在台灣現況下，缺乏書寫標準確實限制模型實用性與推廣。  \n",
    "- **補充：** 從純技術角度，書寫標準不是必要條件，只要 dataset 標註一致即可建模。  \n",
    "- **真正挑戰：**  \n",
    "  1. 語料不足（收集成本高）  \n",
    "  2. 缺乏社群共識（採哪一種文字標準）  \n",
    "  3. 下游應用有限（市場需求小）  \n",
    "\n",
    "➡️ **結論：** 技術上可行，但現實條件下效益有限。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead4005-affb-441d-abaf-bb32adf17eaf",
   "metadata": {},
   "source": [
    "### 試試看從電腦透過麥克風進行錄音然後使用 Transcribe\n",
    "\n",
    "- https://www.gyan.dev/ffmpeg/builds/\n",
    "- pip install sounddevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8025b19-c42e-4736-8beb-704b5f122c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sounddevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a45099b-b8cd-4223-8d24-d5cce1d6023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# AudioSegment.converter = r\"tutorial\\LLM+Langchain\\Week-6\\ffmpeg-essentials_build\\bin\\ffmpeg.exe\"\n",
    "\n",
    "\n",
    "DURATION = 5  # seconds\n",
    "FS = 44100    # sample rate\n",
    "\n",
    "print(\"Recording...\")\n",
    "\n",
    "# Record audio\n",
    "audio = sd.rec(int(DURATION * FS), samplerate=FS, channels=1, dtype='int16')\n",
    "sd.wait()  # Wait until recording is finished\n",
    "print(\"Recording finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d628ef-6e95-44c0-ad5d-deb96465a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy array to AudioSegment\n",
    "audio_bytes = audio.tobytes()\n",
    "\n",
    "audio_segment = AudioSegment(\n",
    "    data=audio_bytes,\n",
    "    sample_width=audio.dtype.itemsize,\n",
    "    frame_rate=FS,\n",
    "    channels=1\n",
    ")\n",
    "\n",
    "# Save as MP3 in-memory (as an object)\n",
    "mp3_io = io.BytesIO()\n",
    "audio_segment.export(mp3_io, format=\"mp3\")\n",
    "mp3_io.seek(0)  # Rewind to start\n",
    "\n",
    "# https://community.openai.com/t/openai-whisper-send-bytes-python-instead-of-filename/84786/3\n",
    "\n",
    "mp3_io.name = \"word.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cc61c8-ee07-456e-b6a0-af63a98b1319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將上述步驟寫成一函數\n",
    "\n",
    "def audio_to_mp3_io(audio, FS:int, channels: int):\n",
    "\n",
    "    # Convert numpy array to AudioSegment\n",
    "    audio_bytes = audio.tobytes()\n",
    "    \n",
    "    audio_segment = AudioSegment(\n",
    "        data=audio_bytes,\n",
    "        sample_width=audio.dtype.itemsize,\n",
    "        frame_rate=FS,\n",
    "        channels=channels\n",
    "    )\n",
    "    \n",
    "    # Save as MP3 in-memory (as an object)\n",
    "    mp3_io = io.BytesIO()\n",
    "    audio_segment.export(mp3_io, format=\"mp3\")\n",
    "    mp3_io.seek(0)  # Rewind to start\n",
    "\n",
    "    mp3_io.name = \"word.mp3\"\n",
    "\n",
    "    return mp3_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60919275-dec8-4f6c-bad1-7b2bab39ae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = client.audio.transcriptions.create(\n",
    "    model=\"gpt-4o-transcribe\", \n",
    "    file=mp3_io,\n",
    "    response_format=\"text\",\n",
    "    language='zh-tw',\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "for event in stream:\n",
    "    # Depending on the event format; e.g. maybe:\n",
    "    # - event.type might be “transcript.text.delta”\n",
    "    # - or event.delta or event.partial\n",
    "    try:\n",
    "        # Example if event has attribute 'delta'\n",
    "        partial = event.delta\n",
    "        buffer += partial\n",
    "        print(\"\\r\" + buffer, end=\"\", flush=True)\n",
    "        # print(partial, end=\"\", flush=True)\n",
    "    except AttributeError:\n",
    "        # fallback / final result\n",
    "        print(\"\\r\" + \" \" * len(buffer), end=\"\")  # 清掉這行\n",
    "        print(\"\\r\" + event.text)  # 印最終結果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a08467-5af8-4802-bb27-0b9e04f85a64",
   "metadata": {},
   "source": [
    "在先前的範例中，我們沒辦法決定從哪個時候開始錄音\n",
    "\n",
    "現在我們加入起始和結束的控制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982003f2-112d-4f98-99ab-201057574c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "FS = 44100\n",
    "CHANNELS = 1\n",
    "dtype = 'int16'\n",
    "\n",
    "recorded_frames = []\n",
    "\n",
    "def callback(indata, frames, time, status):\n",
    "    recorded_frames.append(indata.copy())\n",
    "\n",
    "def record_audio():\n",
    "    # 加入起始和結束的控制\n",
    "    with sd.InputStream(samplerate=FS, channels=CHANNELS, \n",
    "                        dtype=dtype, callback=callback):\n",
    "        input(\"Press Enter to start recording...\")\n",
    "        print(\"Recording... Press Enter again to stop.\")\n",
    "        input()\n",
    "        print(\"Recording stopped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d09aae-78a2-4346-99db-615fcd489d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear frames before each recording\n",
    "recorded_frames.clear()\n",
    "recording_thread = threading.Thread(target=record_audio)\n",
    "recording_thread.start()\n",
    "recording_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e535c9e-67ab-4b3b-8d55-9764ba6ad81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine recorded frames\n",
    "if recorded_frames:\n",
    "    audio_np = np.concatenate(recorded_frames, axis=0)\n",
    "else:\n",
    "    audio_np = np.array([], dtype=dtype)\n",
    "\n",
    "mp3_io =  audio_to_mp3_io(audio=audio_np, FS=FS, channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cca2fd-f0bd-4671-8900-d3e6ebf213ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = client.audio.transcriptions.create(\n",
    "    model=\"gpt-4o-transcribe\", \n",
    "    file=mp3_io,\n",
    "    response_format=\"text\",\n",
    "    language='zh-tw',\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "for event in stream:\n",
    "    # Depending on the event format; e.g. maybe:\n",
    "    # - event.type might be “transcript.text.delta”\n",
    "    # - or event.delta or event.partial\n",
    "    try:\n",
    "        # Example if event has attribute 'delta'\n",
    "        partial = event.delta\n",
    "        buffer += partial\n",
    "        print(\"\\r\" + buffer, end=\"\", flush=True)\n",
    "        # print(partial, end=\"\", flush=True)\n",
    "    except AttributeError:\n",
    "        # fallback / final result\n",
    "        print(\"\\r\" + \" \" * len(buffer), end=\"\")  # 清掉這行\n",
    "        print(\"\\r\" + event.text)  # 印最終結果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9127f2e6-d2c2-4a5b-a994-7e7619c02492",
   "metadata": {},
   "source": [
    "## Translations\n",
    "\n",
    "翻譯 API 接收支持的任何語言的音頻文件作為輸入，並轉錄為英文。這與我們的 /Transcriptions 端點不同，因為輸出不是原始輸入語言的文本，而是轉換為英文文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3587450c-e007-447b-8b10-e8d3fcf90cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "recorded_frames.clear()\n",
    "recording_thread = threading.Thread(target=record_audio)\n",
    "recording_thread.start()\n",
    "recording_thread.join()\n",
    "\n",
    "# Combine recorded frames\n",
    "if recorded_frames:\n",
    "    audio_np = np.concatenate(recorded_frames, axis=0)\n",
    "else:\n",
    "    audio_np = np.array([], dtype=dtype)\n",
    "\n",
    "mp3_io =  audio_to_mp3_io(audio=audio_np, FS=FS, channels=1)\n",
    "\n",
    "# 這個接口(end point)不支援 stream\n",
    "output = client.audio.translations.create(\n",
    "    model=\"whisper-1\", \n",
    "    file=mp3_io,\n",
    "    response_format=\"text\",\n",
    ")\n",
    "\n",
    "print(output.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddef2b1d-4a22-498a-b5ad-b031d184c084",
   "metadata": {},
   "source": [
    "## Text to Speech\n",
    "\n",
    "The Audio API provides a speech endpoint based on our TTS (text-to-speech) model. It comes with 6 built-in voices and can be used toming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118a2389-39ef-468f-9e43-cc553d897e2e",
   "metadata": {},
   "source": [
    "- Narrate a written blog post\n",
    "- Produce spoken audio in multiple languages\n",
    "    - Afrikaans,\n",
    "    - Arabic,\n",
    "    - Armenian,\n",
    "    - Azerbaijani,\n",
    "    - Belarusian,\n",
    "    - Bosnian,\n",
    "    - Bulgarian,\n",
    "    - Catalan,\n",
    "    - Chinese,\n",
    "    - Croatian,\n",
    "    - Czech,\n",
    "    - Danish,\n",
    "    - Dutch,\n",
    "    - English,\n",
    "    - Estonian,\n",
    "    - Finnish,\n",
    "    - French,\n",
    "    - Galician,\n",
    "    - German,\n",
    "    - Greek,\n",
    "    - Hebrew,\n",
    "    - Hindi,\n",
    "    - Hungarian,\n",
    "    - Icelandic,\n",
    "    - Indonesian,\n",
    "    - Italian,\n",
    "    - Japanese,\n",
    "    - Kannada,\n",
    "    - Kazakh,\n",
    "    - Korean,\n",
    "    - Latvian,\n",
    "    - Lithuanian,\n",
    "    - Macedonian,\n",
    "    - Malay,\n",
    "    - Marathi,\n",
    "    - Maori,\n",
    "    - Nepali,\n",
    "    - Norwegian,\n",
    "    - Persian,\n",
    "    - Polish,\n",
    "    - Portuguese,\n",
    "    - Romanian,\n",
    "    - Russian,\n",
    "    - Serbian,\n",
    "    - Slovak,\n",
    "    - Slovenian,\n",
    "    - Spanish,\n",
    "    - Swahili,\n",
    "    - Swedish,\n",
    "    - Tagalog,\n",
    "    - Tamil,\n",
    "    - Thai,\n",
    "    - Turkish,\n",
    "    - Ukrainian,\n",
    "    - Urdu,\n",
    "    - Vietnamese,\n",
    "    - Welsh.\n",
    "- Optimized for English\n",
    "- Give real time audio output using streaming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528843d3-7b42-4d4e-8e29-a40a8d61680c",
   "metadata": {},
   "source": [
    "!pip install playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29ac7ce-e1ca-4ec4-aeaf-649bbfae2751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "\n",
    "# By default, output format is in mp3\n",
    "\n",
    "speech_file_path = os.path.join(\"tutorial/LLM+Langchain/Week-6/Sample.mp3\")\n",
    "\n",
    "response = client.audio.speech.create(\n",
    "  model=\"tts-1\",\n",
    "  voice=\"alloy\",\n",
    "  input=\"Today is Saturday, how are you?\")\n",
    "\n",
    "# 儲存為檔案\n",
    "response.stream_to_file(speech_file_path)\n",
    "\n",
    "# 播放 (simple, blocking)\n",
    "playsound(speech_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ca4eaa-01cf-43f4-8de8-8e2a4d8be536",
   "metadata": {},
   "source": [
    "gpt-4o-mini-tts 和 gp4-4o-tts 可以透過 prompt來控制語調"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f7d509-5873-4a50-8947-72b33321576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_file_path = os.path.join(\"tutorial/LLM+Langchain/Week-6/Sample-gpt-4o-mini.mp3\")\n",
    "\n",
    "response = client.audio.speech.create(\n",
    "    model=\"gpt-4o-mini-tts\",\n",
    "    voice=\"alloy\",\n",
    "    input=(\"Today is Saturday, how are you?\"),\n",
    "    instructions=\"Speak in a tone of tiresome.\")\n",
    "\n",
    "response.stream_to_file(speech_file_path)\n",
    "\n",
    "playsound(speech_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c49c90-b92c-4998-a4a5-834bac529007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response.content\n",
    "# audio = AudioSegment.from_file(io.BytesIO(audio_bytes), format=\"mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758e0c1e-30cd-42d1-8a56-8a66b5b42c70",
   "metadata": {},
   "source": [
    "### pygame (good for GUI apps / async playback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79ad88c-46e0-4f7f-b543-f148726dbd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "\n",
    "pygame.mixer.init()\n",
    "pygame.mixer.music.load(speech_file_path)\n",
    "pygame.mixer.music.play()\n",
    "\n",
    "while pygame.mixer.music.get_busy():\n",
    "    pygame.time.Clock().tick(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a2fed0-5cc2-4f80-9c74-19bce586df66",
   "metadata": {},
   "source": [
    "### 直接撥放 + 串流\n",
    "\n",
    "相較於之前是先將結果存成檔案再撥放檔案，我們可以跳過儲存的步驟，這樣效率上來說更快一點\n",
    "將格式從壓縮的mp3換成無壓縮的wav\n",
    "\n",
    "** 開源社群臥虎藏龍\n",
    "\n",
    "https://community.openai.com/t/streaming-from-text-to-speech-api/493784/29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad57820-9be4-404a-a776-37171ea797f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c20973-e0fd-4998-ae32-4b9085368c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "input_ = dedent(\"\"\"\n",
    "鳴大鐘一次！\n",
    "推動杠杆，啟動活塞和泵……\n",
    "鳴大鐘兩次！\n",
    "按下按鈕，發動引擎，點燃渦輪，注入生命……\n",
    "鳴大鐘三次！\n",
    "齊聲歌唱，讚美萬機之神！\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75f4647-d525-4aac-b10c-ddb37cc40159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import sleep\n",
    "import wave\n",
    "import requests\n",
    "import pyaudio\n",
    "\n",
    "# WAV: Uncompressed WAV audio, suitable for low-latency applications to avoid decoding overhead.\n",
    "\n",
    "url = \"https://api.openai.com/v1/audio/speech\"\n",
    "headers = {\n",
    "    \"Authorization\": f'Bearer {os.getenv(\"OPENAI_API_KEY\")}',\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"model\": \"tts-1\",\n",
    "    \"input\": input_,\n",
    "    \"voice\": \"shimmer\",\n",
    "    \"response_format\": \"wav\",\n",
    "}\n",
    "\n",
    "# You send the request to the API (requests.post).\n",
    "response = requests.post(url, headers=headers, json=data, stream=True)\n",
    "\n",
    "CHUNK_SIZE = 1024\n",
    "\n",
    "if response.ok:\n",
    "    # You open the response audio data with wave.open.\n",
    "    with wave.open(response.raw, 'rb') as wf:\n",
    "        p = pyaudio.PyAudio()\n",
    "        # You configure the PyAudio stream (p.open(...)).\n",
    "        stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                        channels=wf.getnchannels(),\n",
    "                        rate=wf.getframerate(),\n",
    "                        output=True)\n",
    "\n",
    "        while len(data := wf.readframes(CHUNK_SIZE)):\n",
    "            #這行負責撥放聲音\n",
    "            stream.write(data)\n",
    "\n",
    "        # Sleep to make sure playback has finished before closing\n",
    "        sleep(1)\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "else:\n",
    "    response.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0c30fd-b30e-473e-aeab-38dfaa92e1cb",
   "metadata": {},
   "source": [
    "### 實時串流 (Real time streaming)\n",
    "\n",
    "The Speech API provides support for realtime audio streaming using chunk transfer encoding. This means the audio can be played before the full file is generated and made accessible.\n",
    "\n",
    "** For the fastest response times, we recommend using wav or pcm as the response format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8714661a-20ed-467a-ae94-a45a4799f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "from openai.helpers import LocalAudioPlayer\n",
    "\n",
    "async_openai = AsyncOpenAI()\n",
    "\n",
    "async def main() -> None:\n",
    "    async with async_openai.audio.speech.with_streaming_response.create(\n",
    "        model=\"gpt-4o-mini-tts\",\n",
    "        voice=\"coral\",\n",
    "        input=\"Today is a wonderful day to build something people love!\",\n",
    "        instructions=\"Speak in a cheerful and positive tone.\",\n",
    "        response_format=\"pcm\",\n",
    "    ) as response:\n",
    "        await LocalAudioPlayer().play(response)\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b73d33d-93b5-4a8a-baf4-46c6e3e489b0",
   "metadata": {},
   "source": [
    "## 語音自助點飲料系統\n",
    "\n",
    "這只是一個DEMO，所以會非常簡陋。我也不清楚這到底有沒有做的價值\n",
    "\n",
    "假設一個很簡單的使用情境: 一個人講了他對於飲料的需求，然後whisper從語音中抽取他對於飲料的需求:\n",
    "\n",
    "- 哪種飲料\n",
    "- 冰\n",
    "- 糖\n",
    "\n",
    "先不管利用TTS最回應機制，看看whisper能不能正確抽取內容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9042df29-7f51-4dc6-b357-9662d07b5954",
   "metadata": {},
   "source": [
    "### 清心\n",
    "\n",
    "正式做的話應該是直接開 WebScraping\n",
    "\n",
    "- 珍珠蜂蜜鮮奶普洱\n",
    "- 茶凍奶綠\n",
    "- 嚴選高山茶\n",
    "- 咖啡奶茶\n",
    "- 冬瓜檸檬\n",
    "\n",
    "冰熱: 正常冰 - 少冰 - 微冰 - 去冰\n",
    "甜度: 無糖 - 微糖 - 半糖 - 少糖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e08088a-d765-48bf-8354-00e631b359d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36f0ebdb-bc99-4a66-9ac1-34a3e9308b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from textwrap import dedent\n",
    "from typing import Literal, List\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts.image import ImagePromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain_core.runnables import Runnable, chain\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from src.initialization import credential_init\n",
    "\n",
    "\n",
    "def build_standard_chat_prompt_template(kwargs):\n",
    "    messages = []\n",
    "\n",
    "    if 'system' in kwargs:\n",
    "        content = kwargs.get('system')\n",
    "\n",
    "        # allow list of prompts for multimodal\n",
    "        if isinstance(content, list):\n",
    "            prompts = [PromptTemplate(**c) for c in content]\n",
    "        else:\n",
    "            prompts = [PromptTemplate(**content)]\n",
    "\n",
    "        message = SystemMessagePromptTemplate(prompt=prompts)\n",
    "        messages.append(message)\n",
    "\n",
    "    if 'human' in kwargs:\n",
    "        content = kwargs.get('human')\n",
    "\n",
    "        # allow list of prompts for multimodal\n",
    "        if isinstance(content, list):\n",
    "            prompts = []\n",
    "            for c in content:\n",
    "                if c.get(\"type\") == \"image\":\n",
    "                    prompts.append(ImagePromptTemplate(**c))\n",
    "                else:\n",
    "                    prompts.append(PromptTemplate(**c))\n",
    "        else:\n",
    "            if content.get(\"type\") == \"image\":\n",
    "                prompts = [ImagePromptTemplate(**content)]\n",
    "            else:\n",
    "                prompts = [PromptTemplate(**content)]\n",
    "\n",
    "        message = HumanMessagePromptTemplate(prompt=prompts)\n",
    "        messages.append(message)\n",
    "\n",
    "    chat_prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "    \n",
    "    return chat_prompt_template\n",
    "\n",
    "\n",
    "\n",
    "credential_init()\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-mini\", \n",
    "                   temperature=0 # a range from 0-2, the higher the value, the higher the `creativity`\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd818cd5-8ab0-4c90-a1bf-2365cb86ace3",
   "metadata": {},
   "source": [
    "### 定義輸出格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68478b3c-25a2-4ddf-b566-a59be9476f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Drink(BaseModel):\n",
    "\n",
    "    name: Literal['珍珠蜂蜜鮮奶普洱', '茶凍奶綠', '嚴選高山茶', \n",
    "                  '咖啡奶茶', '冬瓜檸檬'] = Field(description=\"飲料名稱\")\n",
    "    ice_level: Literal['正常冰', '少冰', '微冰', '去冰'] = Field(description='冰熱程度')\n",
    "    sugar_level: Literal['無糖', '微糖', '半糖' , '少糖'] = Field(description='糖度')\n",
    "\n",
    "\n",
    "class Order(BaseModel):\n",
    "\n",
    "    names: List[Drink] = Field(description=(\"用戶點的飲料\"))\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Order)\n",
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ba413b-344e-47d6-8cb7-9f24dd6326fc",
   "metadata": {},
   "source": [
    "### 模擬從whisper得到用戶需求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d81447a-54e2-48c0-8377-ec4207ea973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = dedent(\"\"\"\n",
    "                 {query}\n",
    "                 format instruction: {format_instructions}\n",
    "                 \"\"\")\n",
    "\n",
    "input_ = {\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variable\": [\"query\"],\n",
    "                    \"partial_variables\": {\"format_instructions\": \n",
    "                                          format_instructions}}}\n",
    "\n",
    "chat_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "pipeline = chat_prompt_template | model | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d80b9c-81e2-4d3e-af01-30880709edd3",
   "metadata": {},
   "source": [
    "## 透過語言模型提取關鍵字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb90e57f-b7c1-46bf-9531-dc42d870f970",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipeline.invoke({\"query\": \"我要一杯冬瓜檸檬，微糖，去冰\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e50d1547-2bdb-41b7-a85c-239bc1adbf6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Order(names=[Drink(name='冬瓜檸檬', ice_level='去冰', sugar_level='微糖')])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c17d4efd-a084-4437-979c-236f19459f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Order(names=[Drink(name='冬瓜檸檬', ice_level='去冰', sugar_level='微糖'), Drink(name='嚴選高山茶', ice_level='微冰', sugar_level='無糖')])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pipeline.invoke({\"query\": \"我要一杯冬瓜檸檬和一杯嚴選高山茶。冬瓜檸檬微糖去冰，嚴選高山茶無糖微冰\"})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3253472-0f80-46bf-aa53-8758bb13c60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omega\\miniconda3\\envs\\aicg\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import threading\n",
    "\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from openai import OpenAI\n",
    "from pydub import AudioSegment\n",
    "\n",
    "AudioSegment.converter = r\"tutorial\\LLM+Langchain\\Week-6\\ffmpeg-essentials_build\\bin\\ffmpeg.exe\"\n",
    "\n",
    "client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "\n",
    "FS = 44100\n",
    "CHANNELS = 1\n",
    "dtype = 'int16'\n",
    "\n",
    "recorded_frames = []\n",
    "\n",
    "def callback(indata, frames, time, status):\n",
    "    recorded_frames.append(indata.copy())\n",
    "\n",
    "def record_audio():\n",
    "    # 加入起始和結束的控制\n",
    "    with sd.InputStream(samplerate=FS, channels=CHANNELS, \n",
    "                        dtype=dtype, callback=callback):\n",
    "        input(\"Press Enter to start recording...\")\n",
    "        print(\"Recording... Press Enter again to stop.\")\n",
    "        input()\n",
    "        print(\"Recording stopped.\")\n",
    "\n",
    "def audio_to_mp3_io(audio, FS:int, channels: int):\n",
    "\n",
    "    # Convert numpy array to AudioSegment\n",
    "    audio_bytes = audio.tobytes()\n",
    "    \n",
    "    audio_segment = AudioSegment(\n",
    "        data=audio_bytes,\n",
    "        sample_width=audio.dtype.itemsize,\n",
    "        frame_rate=FS,\n",
    "        channels=channels\n",
    "    )\n",
    "    \n",
    "    # Save as MP3 in-memory (as an object)\n",
    "    mp3_io = io.BytesIO()\n",
    "    audio_segment.export(mp3_io, format=\"mp3\")\n",
    "    mp3_io.seek(0)  # Rewind to start\n",
    "\n",
    "    mp3_io.name = \"word.mp3\"\n",
    "\n",
    "    return mp3_io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03faf9d3-ac0a-40d8-86de-ae457ce3bf9f",
   "metadata": {},
   "source": [
    "我要一杯冬瓜檸檬和一杯嚴選高山茶。冬瓜檸檬微糖去冰，嚴選高山茶無糖微冰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b34a9c39-21db-424b-a570-ed25673753b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to start recording... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Press Enter again to stop.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording stopped.\n"
     ]
    }
   ],
   "source": [
    "recorded_frames.clear()\n",
    "recording_thread = threading.Thread(target=record_audio)\n",
    "recording_thread.start()\n",
    "recording_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27420898-7b98-4e6e-a8a0-f7fd15af957f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:04.080706\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "# Combine recorded frames\n",
    "if recorded_frames:\n",
    "    audio_np = np.concatenate(recorded_frames, axis=0)\n",
    "else:\n",
    "    audio_np = np.array([], dtype=dtype)\n",
    "\n",
    "mp3_io =  audio_to_mp3_io(audio=audio_np, FS=FS, channels=1)\n",
    "\n",
    "# 這個接口(end point)不支援 stream\n",
    "time_begin = datetime.now()\n",
    "whisper_output = client.audio.translations.create(\n",
    "    model=\"whisper-1\", \n",
    "    file=mp3_io,\n",
    "    response_format=\"text\",\n",
    "    prompt=\"用戶在點飲料, 微糖, 微冰\",\n",
    ")\n",
    "time_end = datetime.now()\n",
    "\n",
    "print(time_end - time_begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "204dba78-4324-42c4-890d-67a1eaaed187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我要一杯冬瓜檸檬和一杯嚴選高山茶, 冬瓜檸檬微糖去冰, 嚴選高山茶無糖微冰。\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fb412f-64a1-43f8-a4ad-a3c919f40be2",
   "metadata": {},
   "source": [
    "## 計算帳單和回應"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b565449d-4c00-4bc6-a7e3-c878388b841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = dedent(\"\"\"\n",
    "                 {query}\n",
    "                 format instruction: {format_instructions}\n",
    "                 \"\"\")\n",
    "\n",
    "input_ = {\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variable\": [\"query\"],\n",
    "                    \"partial_variables\": {\"format_instructions\": \n",
    "                                          format_instructions}}}\n",
    "\n",
    "chat_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "pipeline = chat_prompt_template | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aa296f07-fd6d-41fe-b270-59efac5ee546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=[PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"$defs\": {\"Drink\": {\"properties\": {\"name\": {\"description\": \"飲料名稱\", \"enum\": [\"珍珠蜂蜜鮮奶普洱\", \"茶凍奶綠\", \"嚴選高山茶\", \"咖啡奶茶\", \"冬瓜檸檬\"], \"title\": \"Name\", \"type\": \"string\"}, \"ice_level\": {\"description\": \"冰熱程度\", \"enum\": [\"正常冰\", \"少冰\", \"微冰\", \"去冰\"], \"title\": \"Ice Level\", \"type\": \"string\"}, \"sugar_level\": {\"description\": \"糖度\", \"enum\": [\"無糖\", \"微糖\", \"半糖\", \"少糖\"], \"title\": \"Sugar Level\", \"type\": \"string\"}}, \"required\": [\"name\", \"ice_level\", \"sugar_level\"], \"title\": \"Drink\", \"type\": \"object\"}}, \"properties\": {\"names\": {\"description\": \"用戶點的飲料\", \"items\": {\"$ref\": \"#/$defs/Drink\"}, \"title\": \"Names\", \"type\": \"array\"}}, \"required\": [\"names\"]}\\n```'}, template='\\n{query}\\nformat instruction: {format_instructions}\\n')], additional_kwargs={})])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5df62862-844f-45b5-94f7-8de7ecc1c2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = pipeline.invoke({\"query\": whisper_output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb54636f-fd31-43ff-996e-1f05663e6552",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_map = {\"珍珠蜂蜜鮮奶普洱\": 70,\n",
    "         \"茶凍奶綠\": 50,\n",
    "         \"嚴選高山茶\": 35,\n",
    "         \"咖啡奶茶\": 75,\n",
    "         \"冬瓜檸檬\": 60}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e07a22d7-1731-4a7b-83b2-e35281c31a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Drink(name='冬瓜檸檬', ice_level='去冰', sugar_level='微糖'),\n",
       " Drink(name='嚴選高山茶', ice_level='微冰', sugar_level='無糖')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ca6138e1-a737-4bb2-a165-bfb6ea0507ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_price = 0\n",
    "\n",
    "for order in orders.names:\n",
    "    total_price += price_map[order.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9209b457-86d6-44eb-903c-ac7d5981ee55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0dd991a8-6a16-4e3c-9d01-56c3a6e6f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "from openai.helpers import LocalAudioPlayer\n",
    "\n",
    "async_openai = AsyncOpenAI()\n",
    "\n",
    "async def main(price) -> None:\n",
    "    async with async_openai.audio.speech.with_streaming_response.create(\n",
    "        model=\"gpt-4o-mini-tts\",\n",
    "        voice=\"alloy\",\n",
    "        input=f\"一共{price}元 💕\",\n",
    "        instructions=\"Speak in a sweet, energetic, anime-girl style with a cute and playful tone.\",\n",
    "        response_format=\"pcm\",\n",
    "    ) as response:\n",
    "        await LocalAudioPlayer().play(response)\n",
    "\n",
    "await main(price=total_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da5c9e9b-ef26-44e2-b8da-c3a08d7a8429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "whisper_output = '我要一杯冬瓜檸檬和一杯嚴選高山茶, 冬瓜檸檬微糖去冰, 嚴選高山茶無糖微冰。'\n",
    "\n",
    "payload = {'input': {\"query\": whisper_output}}\n",
    "\n",
    "\"\"\"\n",
    "- ensure_ascii=False → keeps Chinese characters as-is.\n",
    "\n",
    "- .encode('utf-8') → ensures bytes sent are UTF-8.\n",
    "\n",
    "- Header \"charset=utf-8\" → tells the server the encoding.\n",
    "\"\"\"\n",
    "\n",
    "response = requests.post(\n",
    "        \"http://localhost:8080/drinking_app/invoke\",\n",
    "        json={'input': {\"query\": whisper_output}}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21cd72b-6880-4c29-b410-e52d5bcf298d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "c78c3efa-ad1a-416e-bd7a-74e39040d5b3",
   "metadata": {},
   "source": [
    "response.encoding = 'utf-8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d5998ed-e65c-498a-a72e-1f6b5f3e1566",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = eval(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a77f5fbf-1107-43fb-aee3-3aec63700a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': '冬瓜檸檬', 'ice_level': '去冰', 'sugar_level': '微糖'},\n",
       " {'name': '嚴選高山茶', 'ice_level': '微冰', 'sugar_level': '無糖'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order['output']['names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ed5299d-a748-479f-aa99-a45438a500c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "price_map = {\"珍珠蜂蜜鮮奶普洱\": 70,\n",
    "         \"茶凍奶綠\": 50,\n",
    "         \"嚴選高山茶\": 35,\n",
    "         \"咖啡奶茶\": 75,\n",
    "         \"冬瓜檸檬\": 60}\n",
    "\n",
    "df = pd.DataFrame(order['output']['names'])\n",
    "\n",
    "df['price'] = df['name'].map(price_map)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68c2e433-c5b8-4ef3-914b-445e523a6a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['price'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ec0b23-08c6-4fcc-946d-36ee03b5075e",
   "metadata": {},
   "source": [
    "## Ollama\n",
    "\n",
    "This package enables you using open-source LLM with ease.\n",
    "\n",
    "We borrow the content from last week\n",
    "\n",
    "https://medium.com/@abonia/running-ollama-in-google-colab-free-tier-545609258453\n",
    "\n",
    "- curl https://ollama.ai/install.sh | sh\n",
    "- ollama serve &\n",
    "- ollama pull llama3:8b\n",
    "- ollama pull dolphin-llama3:8b\n",
    "- ollama pull huihui_ai/qwen2.5-abliterate:14b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9fb9e0-16eb-4c03-a1b2-2af693b479d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52511b57-7779-4db4-8e8e-dd9d0071f50e",
   "metadata": {},
   "source": [
    "In Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89b5037-ba65-4dac-bf0f-c4d43daeb732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install colab-xterm\n",
    "# %load_ext colabxterm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04cc1ad-5440-4e65-bc38-07d2139afa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %xterm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd597a5-1f65-4b5d-935d-5bc97fb2ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from torch import cuda\n",
    "from langchain.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain_core.prompts.image import ImagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.runnables import Runnable, chain\n",
    "\n",
    "from src.io.path_definition import get_project_dir\n",
    "\n",
    "\n",
    "def build_standard_chat_prompt_template(kwargs):\n",
    "    messages = []\n",
    "\n",
    "    if 'system' in kwargs:\n",
    "        content = kwargs.get('system')\n",
    "\n",
    "        # allow list of prompts for multimodal\n",
    "        if isinstance(content, list):\n",
    "            prompts = [PromptTemplate(**c) for c in content]\n",
    "        else:\n",
    "            prompts = [PromptTemplate(**content)]\n",
    "\n",
    "        message = SystemMessagePromptTemplate(prompt=prompts)\n",
    "        messages.append(message)\n",
    "\n",
    "    if 'human' in kwargs:\n",
    "        content = kwargs.get('human')\n",
    "\n",
    "        # allow list of prompts for multimodal\n",
    "        if isinstance(content, list):\n",
    "            prompts = []\n",
    "            for c in content:\n",
    "                if c.get(\"type\") == \"image\":\n",
    "                    prompts.append(ImagePromptTemplate(**c))\n",
    "                else:\n",
    "                    prompts.append(PromptTemplate(**c))\n",
    "        else:\n",
    "            if content.get(\"type\") == \"image\":\n",
    "                prompts = [ImagePromptTemplate(**content)]\n",
    "            else:\n",
    "                prompts = [PromptTemplate(**content)]\n",
    "\n",
    "        message = HumanMessagePromptTemplate(prompt=prompts)\n",
    "        messages.append(message)\n",
    "\n",
    "    chat_prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "    \n",
    "    return chat_prompt_template\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888775f5-e632-41c5-99cf-406d70ee63b7",
   "metadata": {},
   "source": [
    "Ollama 使用模型跟 OpenAI API 沒有區別\n",
    "\n",
    "但建議架設在有強大算力的機器上，並且使用Langserve呼叫服務，來減輕本地的算力需求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3d7f97-f573-4350-a946-4a6a8af963df",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"You are a helpful AI assistant with excellent writing skill\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c5f546-eccf-4a24-a3e9-0229a454d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "stop_token_ids = None\n",
    "model_id = \"dolphin-llama3:8b\"\n",
    "\n",
    "device = f\"cuda:{cuda.current_device()}\" if cuda.is_available() else 'cpu'\n",
    "\n",
    "model = ChatOllama(model=model_id, temperature=0)\n",
    "\n",
    "summary_prompt_template = build_summary_prompt_template()\n",
    "\n",
    "summary_pipeline = summary_prompt_template | model | StrOutputParser()\n",
    "\n",
    "text_as_list = []\n",
    "for document in tqdm(documents):\n",
    "    content = summary_pipeline.invoke({\"text\": document.page_content})\n",
    "    text_as_list.append(content)\n",
    "\n",
    "final_text = \"\\n\".join(text_as_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a034f8-82cb-4784-ad35-f6d10fe01c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_pipeline.invoke({\"text\": final_text})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
