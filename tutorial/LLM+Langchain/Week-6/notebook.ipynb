{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e9bd1a7-ba1e-491e-b83e-a31ac4dd06d9",
   "metadata": {},
   "source": [
    "# èªéŸ³è½‰æ–‡å­— (Speech to Text)\n",
    "\n",
    "åœ¨è¨±å¤šæ‡‰ç”¨ä¸­ï¼ŒèªéŸ³è³‡æ–™éœ€è¦è¢«è½‰æ›ç‚ºæ–‡å­—ï¼Œä¾‹å¦‚å­—å¹•ç”¢ç”Ÿã€èªéŸ³åŠ©ç†ã€æœƒè­°ç´€éŒ„æˆ–å¤šèªè¨€ç¿»è­¯ã€‚OpenAI æä¾›äº† **Whisper** æ¨¡å‹ï¼Œå¯ä»¥é«˜æ•ˆåœ°é€²è¡Œä»¥ä¸‹å…©ç¨®ä¸»è¦ä»»å‹™ï¼š\n",
    "\n",
    "- **è½‰éŒ„ (Transcribe)ï¼š** å°‡éŸ³è¨Šæª”æ¡ˆè½‰æ›æˆç›¸åŒèªè¨€çš„æ–‡å­—ã€‚  \n",
    "- **ç¿»è­¯è½‰éŒ„ (Translate & Transcribe)ï¼š** å°‡éŸ³è¨Šæª”æ¡ˆçš„å…§å®¹è½‰éŒ„ä¸¦ç¿»è­¯æˆè‹±æ–‡ã€‚  \n",
    "\n",
    "ç›®å‰æª”æ¡ˆä¸Šå‚³é™åˆ¶ç‚º **25 MB**ï¼Œæ”¯æ´çš„éŸ³è¨Šæª”æ¡ˆæ ¼å¼åŒ…æ‹¬ï¼š  \n",
    "`mp3`, `mp4`, `mpeg`, `mpga`, `m4a`, `wav`, `webm`\n",
    "\n",
    "---\n",
    "\n",
    "# æ–‡å­—è½‰èªéŸ³ (Text to Speech, TTS)\n",
    "\n",
    "é™¤äº†èªéŸ³è½‰æ–‡å­—ï¼ŒOpenAI ä¹Ÿæä¾›äº† **æ–‡å­—è½‰èªéŸ³ (TTS)** åŠŸèƒ½ã€‚é€é TTSï¼Œæˆ‘å€‘å¯ä»¥å°‡è¼¸å…¥çš„æ–‡å­—è½‰æ›ç‚ºè‡ªç„¶æµæš¢çš„èªéŸ³ï¼Œé©åˆæ‡‰ç”¨æ–¼ï¼š  \n",
    "\n",
    "- **èªéŸ³åŠ©ç†**ï¼šè®“æ©Ÿå™¨èƒ½ä»¥è‡ªç„¶èªéŸ³å›è¦†ä½¿ç”¨è€…ã€‚  \n",
    "- **å…§å®¹å‰µä½œ**ï¼šè‡ªå‹•ç”Ÿæˆæ—ç™½æˆ–æœ‰è²è®€ç‰©ã€‚  \n",
    "- **è¼”åŠ©åŠŸèƒ½**ï¼šå¹«åŠ©è¦–è¦ºéšœç¤™è€…æˆ–é–±è®€å›°é›£è€…æ›´å®¹æ˜“ç²å–è³‡è¨Šã€‚  \n",
    "\n",
    "TTS æ”¯æ´å¤šç¨®èªéŸ³é¢¨æ ¼èˆ‡éŸ³è³ªé¸æ“‡ï¼Œèƒ½å¤ åœ¨ä¸åŒæ‡‰ç”¨å ´æ™¯ä¸­æä¾›æ›´è‡ªç„¶çš„ä½¿ç”¨é«”é©—ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "æ¥ä¸‹ä¾†ï¼Œæˆ‘å€‘å°‡é€éç¨‹å¼ç¯„ä¾‹ä¾†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ Python ä¸²æ¥ **Whisper** (èªéŸ³è½‰æ–‡å­—) èˆ‡ **TTS** (æ–‡å­—è½‰èªéŸ³)ï¼Œä¸¦é€æ­¥å®ŒæˆéŸ³è¨Šèˆ‡æ–‡å­—çš„é›™å‘è½‰æ›ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacd9ac3-0fd0-4ce8-9c63-87a94202ed22",
   "metadata": {},
   "source": [
    "## Audio models\n",
    "\n",
    "| Model   | Usage                                            |\n",
    "|---------|--------------------------------------------------|\n",
    "| Whisper |  \\$ 0.006 / minute rounded to the nearest second     |\n",
    "| TTS     |  \\$ 15.00 / 1M characters                          |\n",
    "| TTS HD  |  \\$ 30.00 / 1M characters                          |\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb5d86-d176-43a1-9f92-d0e3babe9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476b8dcb-ece8-4730-a8d9-5a0fad0e6abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.initialization import credential_init\n",
    "from src.io.path_definition import get_project_dir, get_file\n",
    "\n",
    "\n",
    "credential_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8465282-3b41-422d-a904-8c62ecd196f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baa97bc-b426-418e-820f-618b18a2df30",
   "metadata": {},
   "source": [
    "## Transcription\n",
    "\n",
    "### Batch Transcription\n",
    "\n",
    "åœ¨ éä¸²æµæ¨¡å¼ï¼ˆä½¿ç”¨ transcriptions.create ä¸Šå‚³æª”æ¡ˆï¼‰æ™‚ï¼ŒWhisper æœƒç­‰å¾…æ•´å€‹éŸ³è¨Šæª”æ¡ˆå®Œå…¨ä¸Šå‚³å¾Œï¼Œæ‰æœƒå°å®Œæ•´éŸ³æª”é€²è¡Œè½‰éŒ„ï¼Œä¸¦åœ¨å®Œæˆå¾Œä¸€æ¬¡æ€§å›å‚³çµæœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cfb513-eefd-4db7-8dce-4998eb968e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file= open(\"tutorial/LLM+Langchain/Week-6/å­©å­ä¸Šç¶²ï¼Œå°å¿ƒä¸Šç•¶.mp3\", \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3973567-5159-4e06-9a12-6ed69cb77cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71566743-14a9-4c61-9cfb-156c973f8639",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ec60c1-a6b9-41f2-a239-cb134e6cb39b",
   "metadata": {},
   "source": [
    "å‡è¨­ä½ éœ€è¦æ™‚é–“è»¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78953051-5e05-40c0-8da2-6e7eeeafb2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file,\n",
    "  response_format='srt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82933478-f962-491e-b030-c1e4d64ebbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834ad423-1cdc-4ca4-bb51-cd5064b44d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file,\n",
    "  response_format='srt',\n",
    "  prompt=\"é€™æ˜¯ä¸€å€‹é—œæ–¼é˜²è©é¨™çš„å®£å‚³, ç§line\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58477848-aedb-449c-9374-f58a8bdc600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef53b59d-769b-42b2-bacb-e271a07dd641",
   "metadata": {},
   "source": [
    "### Stream\n",
    "\n",
    "å¦‚æœä½ åœ¨å‘¼å«æ™‚ä½¿ç”¨ stream=Trueï¼ŒSDK ä»ç„¶æœƒå…ˆä¸Šå‚³æ•´å€‹éŸ³è¨Šæª”ï¼ˆå®ƒä¸¦ä¸æ˜¯ä¸€æ®µä¸€æ®µåˆ†å¡Šä¸Šå‚³ï¼‰ï¼Œä½†ä¸åŒçš„æ˜¯ï¼Œå®ƒä¸æœƒç­‰åˆ°å®Œæ•´çš„è½‰éŒ„çµæŸæ‰å›å‚³ï¼Œè€Œæ˜¯æœƒåœ¨ Whisper ç”Ÿæˆçš„åŒæ™‚ï¼Œé€æ­¥å‚³å›çµæœã€‚\n",
    "\n",
    "å› æ­¤ï¼Œä½ æœƒåœ¨è½‰éŒ„éç¨‹ä¸­é™¸çºŒçœ‹åˆ°éƒ¨åˆ†æ–‡å­—ç‰‡æ®µã€‚\n",
    "\n",
    "ç­‰åˆ° Whisper å®Œæˆå¾Œï¼Œä½ å°±æœƒå¾—åˆ°æœ€çµ‚çš„å®Œæ•´è½‰éŒ„çµæœã€‚\n",
    "\n",
    "- åªæ”¯æ´ gpt-4o-mini or gpt-4o transcription\n",
    "\n",
    "- åœ¨gpt-4o-transcript å’Œ gpt-4o-mini-transcript æ¨¡å‹è¨˜å¾—åŠ ä¸Šèªè¨€ç·¨ç¢¼ï¼Œä¸ç„¶ä¸­æ–‡è¼¸å‡ºæ¥µå¤§æ¦‚ç‡æ˜¯ç°¡é«”ä¸­æ–‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f974ba4b-a498-4df7-99cb-c7ab243e9186",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file= open(\"tutorial/LLM+Langchain/Week-6/å­©å­ä¸Šç¶²ï¼Œå°å¿ƒä¸Šç•¶.mp3\", \"rb\")\n",
    "\n",
    "stream = client.audio.transcriptions.create(\n",
    "  file=audio_file,\n",
    "  model=\"gpt-4o-mini-transcribe\",\n",
    "  stream=True,\n",
    "  language='zh-tw'\n",
    ")\n",
    "\n",
    "# for event in stream:\n",
    "#   print(event)\n",
    "\n",
    "for event in stream:\n",
    "    # Depending on the event format; e.g. maybe:\n",
    "    # - event.type might be â€œtranscript.text.deltaâ€\n",
    "    # - or event.delta or event.partial\n",
    "    try:\n",
    "        # Example if event has attribute 'delta'\n",
    "        partial = event.delta  \n",
    "        print(partial, end=\"\", flush=True)\n",
    "    except AttributeError:\n",
    "        # fallback / final result\n",
    "        print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd11eaf1-a31c-4dc6-b2f2-eed43d8cf552",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = client.audio.transcriptions.create(\n",
    "  file=audio_file,\n",
    "  model=\"gpt-4o-transcribe\",\n",
    "  stream=True,\n",
    "  language='zh-tw'\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    # Depending on the event format; e.g. maybe:\n",
    "    # - event.type might be â€œtranscript.text.deltaâ€\n",
    "    # - or event.delta or event.partial\n",
    "    try:\n",
    "        # Example if event has attribute 'delta'\n",
    "        partial = event.delta  \n",
    "        print(partial, end=\"\", flush=True)\n",
    "    except AttributeError:\n",
    "        # fallback / final result\n",
    "        print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a772b55-ecbe-4f2b-98dd-dec28fda608a",
   "metadata": {},
   "source": [
    "## å¢åŠ å¯é åº¦\n",
    "\n",
    "### Prompt\n",
    "\n",
    "- çµ¦äºˆContext\n",
    "- çµ¦äºˆé—œéµå­— (ç§lineï¼Œæ‡‰è©²åªæœ‰å°ç£äººç”¨é€™å€‹è©ï¼Œåˆ¥å¤ªæŒ‡æœ›OpenAI)\n",
    "\n",
    "### Timestamp_granularities\n",
    "\n",
    "- å¯èƒ½æœ‰ç”¨\n",
    "\n",
    "ä¸€éŸ³å¤šå­—å¯èƒ½æ²’è¾¦æ³•æ”¹å–„ï¼Œç•¢ç«ŸæŠŠæ‰€æœ‰ä¸€éŸ³å¤šå­—çš„æƒ…æ³æ¨™å‡ºä¾†ä¹Ÿä¸å¯¦éš›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427eb795-30fc-4c62-86ca-c9f778939c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = client.audio.transcriptions.create(\n",
    "  file=audio_file,\n",
    "  model=\"gpt-4o-transcribe\",\n",
    "  stream=True,\n",
    "  language='zh-tw',\n",
    "  prompt=\"é€™æ˜¯ä¸€å€‹é—œæ–¼é˜²è©é¨™çš„å®£å‚³, ç§line\",\n",
    "  timestamp_granularities=\"word\",\n",
    "  temperature=0\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "for event in stream:\n",
    "    # Depending on the event format; e.g. maybe:\n",
    "    # - event.type might be â€œtranscript.text.deltaâ€\n",
    "    # - or event.delta or event.partial\n",
    "    try:\n",
    "        # Example if event has attribute 'delta'\n",
    "        partial = event.delta\n",
    "        buffer += partial\n",
    "        print(\"\\r\" + buffer, end=\"\", flush=True)\n",
    "        # print(partial, end=\"\", flush=True)\n",
    "    except AttributeError:\n",
    "        # fallback / final result\n",
    "        print(\"\\r\" + \" \" * len(buffer), end=\"\")  # æ¸…æ‰é€™è¡Œ\n",
    "        print(\"\\r\" + event.text)  # å°æœ€çµ‚çµæœ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19f86f8-f939-4081-8b66-a59a684e2b67",
   "metadata": {},
   "source": [
    "# é–©å—èªèªéŸ³è¾¨è­˜ï¼ˆASRï¼‰å¯è¡Œæ€§è©•ä¼°\n",
    "\n",
    "## âœ… ä½ çš„è§€é»æ­£ç¢ºçš„åœ°æ–¹\n",
    "1. **æ›¸å¯«æ¨™æº–ä¸çµ±ä¸€æ˜¯ç“¶é ¸**  \n",
    "   - èªéŸ³æ¨¡å‹è¨“ç·´éœ€è¦ã€ŒèªéŸ³ + å°æ‡‰æ–‡å­—è½‰éŒ„ã€è³‡æ–™ã€‚  \n",
    "   - é–©å—èªå­˜åœ¨å¤šç¨®æ›¸å¯«ç³»çµ±ï¼ˆæ¼¢å­—ã€å°ç¾…æ–‡ã€ç™½è©±å­—/ç¾…é¦¬æ‹¼éŸ³ï¼‰ï¼Œç¼ºä¹ä¸€è‡´æ¨™æº–æœƒé€ æˆè³‡æ–™é›†æ··äº‚ï¼Œé›£ä»¥æ”¶æ–‚ã€‚  \n",
    "\n",
    "2. **è³‡æºä¸è¶³**  \n",
    "   - ç›¸æ¯”è‹±èªã€ä¸­æ–‡ï¼Œé–©å—èªçš„ã€ŒèªéŸ³â€“æ–‡å­—å¹³è¡Œèªæ–™ã€æ¥µå°‘ã€‚  \n",
    "   - ç¼ºä¹å¤§é‡å…¬é–‹ datasetï¼Œå¾é›¶é–‹å§‹è¨“ç·´æˆæœ¬æ¥µé«˜ã€‚  \n",
    "\n",
    "3. **å¯¦ç”¨æ€§å—é™**  \n",
    "   - æ²’æœ‰å…¬èªçš„æ›¸å¯«æ–¹å¼ï¼ŒASR è¼¸å‡ºçš„çµæœé›£ä»¥è¢«å»£æ³›æ¡ç”¨ã€‚  \n",
    "   - ä¾‹å¦‚ï¼šåŒä¸€å¥è©±è¼¸å‡ºç‚ºã€Œæ¼¢å­—ç‰ˆã€æˆ–ã€Œå°ç¾…æ–‡ç‰ˆã€ï¼Œä½¿ç”¨è€…ç¾¤é«”å¯èƒ½äº’ä¸æ¥å—ã€‚  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¡ æŠ€è¡“ä¸Šå€¼å¾—è£œå……çš„è§€é»\n",
    "1. **èªéŸ³æ¨¡å‹æœ¬èº«ä¸ä¾è³´ã€Œå®˜æ–¹æ¨™æº–ã€**  \n",
    "   - æ¨¡å‹åªéœ€è¦ã€Œçµ±ä¸€çš„è¨“ç·´æ¨™ç±¤ã€ã€‚  \n",
    "   - ç„¡è«–æ˜¯å°ç¾…æ–‡ã€æ¼¢å­—æˆ–ç¾…é¦¬æ‹¼éŸ³ï¼Œåªè¦ dataset æ¨™è¨»ä¸€è‡´ï¼Œæ¨¡å‹å³å¯å­¸ç¿’ã€‚  \n",
    "   - å›°é›£é»åœ¨æ–¼ã€Œç¤¾ç¾¤èƒ½å¦å°±æŸç¨®æ›¸å¯«ç³»çµ±é”æˆå…±è­˜ã€ã€‚  \n",
    "\n",
    "2. **å¯æ¡ã€Œå¤šè¼¸å‡º / å¾Œè™•ç†ã€ç­–ç•¥**  \n",
    "   - è¨“ç·´æ™‚ä½¿ç”¨ **å°ç¾…æ–‡**ï¼ˆèˆ‡éŸ³ç´ å°æ‡‰æ€§è¼ƒä½³ï¼‰ã€‚  \n",
    "   - æ‡‰ç”¨å±¤å¯é€éè½‰æ›å™¨å°‡å°ç¾…æ–‡è¼¸å‡ºè½‰æ›æˆæ¼¢å­—æˆ–å…¶ä»–æ‹¼éŸ³ç³»çµ±ã€‚  \n",
    "   - é€™æ¨£å¯ç¹éã€Œæ¨™æº–æœªå®šã€çš„å•é¡Œã€‚  \n",
    "\n",
    "3. **ç¾ä»£èªéŸ³æŠ€è¡“é™ä½é–€æª»**  \n",
    "   - Whisper ç­‰å¤§æ¨¡å‹å·²è­‰æ˜ï¼šä½è³‡æºèªè¨€åªè¦æœ‰æ•¸ç™¾å°æ™‚è³‡æ–™å³å¯å¾®èª¿å‡ºå¯ç”¨ç³»çµ±ã€‚  \n",
    "   - æŠ€è¡“ä¸Šã€Œå¯è¡Œã€ï¼Œåªæ˜¯ **æˆæœ¬é«˜ + è³‡æ–™ç¼ºä¹**ã€‚  \n",
    "\n",
    "4. **å¹³è¡Œæ¡ˆä¾‹**  \n",
    "   - å®¢å®¶è©±ã€è—èªã€å¨çˆ¾æ–¯èªã€æ„›çˆ¾è˜­èªç­‰èªè¨€ä¹Ÿæœ‰ã€Œèªæ–™å°‘ã€æ›¸å¯«å¤šæ¨£ã€çš„æŒ‘æˆ°ã€‚  \n",
    "   - ä»æœ‰äººæˆåŠŸå»ºç«‹ ASR â†’ è­‰æ˜ä¸¦éã€ŒæŠ€è¡“ä¸Šä¸å¯èƒ½ã€ã€‚  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Œ ç¶œåˆè©•ä¼°\n",
    "- **æ­£ç¢ºï¼š** åœ¨å°ç£ç¾æ³ä¸‹ï¼Œç¼ºä¹æ›¸å¯«æ¨™æº–ç¢ºå¯¦é™åˆ¶æ¨¡å‹å¯¦ç”¨æ€§èˆ‡æ¨å»£ã€‚  \n",
    "- **è£œå……ï¼š** å¾ç´”æŠ€è¡“è§’åº¦ï¼Œæ›¸å¯«æ¨™æº–ä¸æ˜¯å¿…è¦æ¢ä»¶ï¼Œåªè¦ dataset æ¨™è¨»ä¸€è‡´å³å¯å»ºæ¨¡ã€‚  \n",
    "- **çœŸæ­£æŒ‘æˆ°ï¼š**  \n",
    "  1. èªæ–™ä¸è¶³ï¼ˆæ”¶é›†æˆæœ¬é«˜ï¼‰  \n",
    "  2. ç¼ºä¹ç¤¾ç¾¤å…±è­˜ï¼ˆæ¡å“ªä¸€ç¨®æ–‡å­—æ¨™æº–ï¼‰  \n",
    "  3. ä¸‹æ¸¸æ‡‰ç”¨æœ‰é™ï¼ˆå¸‚å ´éœ€æ±‚å°ï¼‰  \n",
    "\n",
    "â¡ï¸ **çµè«–ï¼š** æŠ€è¡“ä¸Šå¯è¡Œï¼Œä½†ç¾å¯¦æ¢ä»¶ä¸‹æ•ˆç›Šæœ‰é™ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead4005-affb-441d-abaf-bb32adf17eaf",
   "metadata": {},
   "source": [
    "### è©¦è©¦çœ‹å¾é›»è…¦é€ééº¥å…‹é¢¨é€²è¡ŒéŒ„éŸ³ç„¶å¾Œä½¿ç”¨ Transcribe\n",
    "\n",
    "- https://www.gyan.dev/ffmpeg/builds/\n",
    "- pip install sounddevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8025b19-c42e-4736-8beb-704b5f122c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sounddevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a45099b-b8cd-4223-8d24-d5cce1d6023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# AudioSegment.converter = r\"tutorial\\LLM+Langchain\\Week-6\\ffmpeg-essentials_build\\bin\\ffmpeg.exe\"\n",
    "\n",
    "\n",
    "DURATION = 5  # seconds\n",
    "FS = 44100    # sample rate\n",
    "\n",
    "print(\"Recording...\")\n",
    "\n",
    "# Record audio\n",
    "audio = sd.rec(int(DURATION * FS), samplerate=FS, channels=1, dtype='int16')\n",
    "sd.wait()  # Wait until recording is finished\n",
    "print(\"Recording finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d628ef-6e95-44c0-ad5d-deb96465a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy array to AudioSegment\n",
    "audio_bytes = audio.tobytes()\n",
    "\n",
    "audio_segment = AudioSegment(\n",
    "    data=audio_bytes,\n",
    "    sample_width=audio.dtype.itemsize,\n",
    "    frame_rate=FS,\n",
    "    channels=1\n",
    ")\n",
    "\n",
    "# Save as MP3 in-memory (as an object)\n",
    "mp3_io = io.BytesIO()\n",
    "audio_segment.export(mp3_io, format=\"mp3\")\n",
    "mp3_io.seek(0)  # Rewind to start\n",
    "\n",
    "# https://community.openai.com/t/openai-whisper-send-bytes-python-instead-of-filename/84786/3\n",
    "\n",
    "mp3_io.name = \"word.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cc61c8-ee07-456e-b6a0-af63a98b1319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°‡ä¸Šè¿°æ­¥é©Ÿå¯«æˆä¸€å‡½æ•¸\n",
    "\n",
    "def audio_to_mp3_io(audio, FS:int, channels: int):\n",
    "\n",
    "    # Convert numpy array to AudioSegment\n",
    "    audio_bytes = audio.tobytes()\n",
    "    \n",
    "    audio_segment = AudioSegment(\n",
    "        data=audio_bytes,\n",
    "        sample_width=audio.dtype.itemsize,\n",
    "        frame_rate=FS,\n",
    "        channels=channels\n",
    "    )\n",
    "    \n",
    "    # Save as MP3 in-memory (as an object)\n",
    "    mp3_io = io.BytesIO()\n",
    "    audio_segment.export(mp3_io, format=\"mp3\")\n",
    "    mp3_io.seek(0)  # Rewind to start\n",
    "\n",
    "    mp3_io.name = \"word.mp3\"\n",
    "\n",
    "    return mp3_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60919275-dec8-4f6c-bad1-7b2bab39ae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = client.audio.transcriptions.create(\n",
    "    model=\"gpt-4o-transcribe\", \n",
    "    file=mp3_io,\n",
    "    response_format=\"text\",\n",
    "    language='zh-tw',\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "for event in stream:\n",
    "    # Depending on the event format; e.g. maybe:\n",
    "    # - event.type might be â€œtranscript.text.deltaâ€\n",
    "    # - or event.delta or event.partial\n",
    "    try:\n",
    "        # Example if event has attribute 'delta'\n",
    "        partial = event.delta\n",
    "        buffer += partial\n",
    "        print(\"\\r\" + buffer, end=\"\", flush=True)\n",
    "        # print(partial, end=\"\", flush=True)\n",
    "    except AttributeError:\n",
    "        # fallback / final result\n",
    "        print(\"\\r\" + \" \" * len(buffer), end=\"\")  # æ¸…æ‰é€™è¡Œ\n",
    "        print(\"\\r\" + event.text)  # å°æœ€çµ‚çµæœ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a08467-5af8-4802-bb27-0b9e04f85a64",
   "metadata": {},
   "source": [
    "åœ¨å…ˆå‰çš„ç¯„ä¾‹ä¸­ï¼Œæˆ‘å€‘æ²’è¾¦æ³•æ±ºå®šå¾å“ªå€‹æ™‚å€™é–‹å§‹éŒ„éŸ³\n",
    "\n",
    "ç¾åœ¨æˆ‘å€‘åŠ å…¥èµ·å§‹å’ŒçµæŸçš„æ§åˆ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982003f2-112d-4f98-99ab-201057574c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "FS = 44100\n",
    "CHANNELS = 1\n",
    "dtype = 'int16'\n",
    "\n",
    "recorded_frames = []\n",
    "\n",
    "def callback(indata, frames, time, status):\n",
    "    recorded_frames.append(indata.copy())\n",
    "\n",
    "def record_audio():\n",
    "    # åŠ å…¥èµ·å§‹å’ŒçµæŸçš„æ§åˆ¶\n",
    "    with sd.InputStream(samplerate=FS, channels=CHANNELS, \n",
    "                        dtype=dtype, callback=callback):\n",
    "        input(\"Press Enter to start recording...\")\n",
    "        print(\"Recording... Press Enter again to stop.\")\n",
    "        input()\n",
    "        print(\"Recording stopped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d09aae-78a2-4346-99db-615fcd489d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear frames before each recording\n",
    "recorded_frames.clear()\n",
    "recording_thread = threading.Thread(target=record_audio)\n",
    "recording_thread.start()\n",
    "recording_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e535c9e-67ab-4b3b-8d55-9764ba6ad81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine recorded frames\n",
    "if recorded_frames:\n",
    "    audio_np = np.concatenate(recorded_frames, axis=0)\n",
    "else:\n",
    "    audio_np = np.array([], dtype=dtype)\n",
    "\n",
    "mp3_io =  audio_to_mp3_io(audio=audio_np, FS=FS, channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cca2fd-f0bd-4671-8900-d3e6ebf213ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = client.audio.transcriptions.create(\n",
    "    model=\"gpt-4o-transcribe\", \n",
    "    file=mp3_io,\n",
    "    response_format=\"text\",\n",
    "    language='zh-tw',\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "for event in stream:\n",
    "    # Depending on the event format; e.g. maybe:\n",
    "    # - event.type might be â€œtranscript.text.deltaâ€\n",
    "    # - or event.delta or event.partial\n",
    "    try:\n",
    "        # Example if event has attribute 'delta'\n",
    "        partial = event.delta\n",
    "        buffer += partial\n",
    "        print(\"\\r\" + buffer, end=\"\", flush=True)\n",
    "        # print(partial, end=\"\", flush=True)\n",
    "    except AttributeError:\n",
    "        # fallback / final result\n",
    "        print(\"\\r\" + \" \" * len(buffer), end=\"\")  # æ¸…æ‰é€™è¡Œ\n",
    "        print(\"\\r\" + event.text)  # å°æœ€çµ‚çµæœ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9127f2e6-d2c2-4a5b-a994-7e7619c02492",
   "metadata": {},
   "source": [
    "## Translations\n",
    "\n",
    "ç¿»è­¯ API æ¥æ”¶æ”¯æŒçš„ä»»ä½•èªè¨€çš„éŸ³é »æ–‡ä»¶ä½œç‚ºè¼¸å…¥ï¼Œä¸¦è½‰éŒ„ç‚ºè‹±æ–‡ã€‚é€™èˆ‡æˆ‘å€‘çš„ /Transcriptions ç«¯é»ä¸åŒï¼Œå› ç‚ºè¼¸å‡ºä¸æ˜¯åŸå§‹è¼¸å…¥èªè¨€çš„æ–‡æœ¬ï¼Œè€Œæ˜¯è½‰æ›ç‚ºè‹±æ–‡æ–‡æœ¬ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3587450c-e007-447b-8b10-e8d3fcf90cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "recorded_frames.clear()\n",
    "recording_thread = threading.Thread(target=record_audio)\n",
    "recording_thread.start()\n",
    "recording_thread.join()\n",
    "\n",
    "# Combine recorded frames\n",
    "if recorded_frames:\n",
    "    audio_np = np.concatenate(recorded_frames, axis=0)\n",
    "else:\n",
    "    audio_np = np.array([], dtype=dtype)\n",
    "\n",
    "mp3_io =  audio_to_mp3_io(audio=audio_np, FS=FS, channels=1)\n",
    "\n",
    "# é€™å€‹æ¥å£(end point)ä¸æ”¯æ´ stream\n",
    "output = client.audio.translations.create(\n",
    "    model=\"whisper-1\", \n",
    "    file=mp3_io,\n",
    "    response_format=\"text\",\n",
    ")\n",
    "\n",
    "print(output.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddef2b1d-4a22-498a-b5ad-b031d184c084",
   "metadata": {},
   "source": [
    "## Text to Speech\n",
    "\n",
    "The Audio API provides a speech endpoint based on our TTS (text-to-speech) model. It comes with 6 built-in voices and can be used toming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118a2389-39ef-468f-9e43-cc553d897e2e",
   "metadata": {},
   "source": [
    "- Narrate a written blog post\n",
    "- Produce spoken audio in multiple languages\n",
    "    - Afrikaans,\n",
    "    - Arabic,\n",
    "    - Armenian,\n",
    "    - Azerbaijani,\n",
    "    - Belarusian,\n",
    "    - Bosnian,\n",
    "    - Bulgarian,\n",
    "    - Catalan,\n",
    "    - Chinese,\n",
    "    - Croatian,\n",
    "    - Czech,\n",
    "    - Danish,\n",
    "    - Dutch,\n",
    "    - English,\n",
    "    - Estonian,\n",
    "    - Finnish,\n",
    "    - French,\n",
    "    - Galician,\n",
    "    - German,\n",
    "    - Greek,\n",
    "    - Hebrew,\n",
    "    - Hindi,\n",
    "    - Hungarian,\n",
    "    - Icelandic,\n",
    "    - Indonesian,\n",
    "    - Italian,\n",
    "    - Japanese,\n",
    "    - Kannada,\n",
    "    - Kazakh,\n",
    "    - Korean,\n",
    "    - Latvian,\n",
    "    - Lithuanian,\n",
    "    - Macedonian,\n",
    "    - Malay,\n",
    "    - Marathi,\n",
    "    - Maori,\n",
    "    - Nepali,\n",
    "    - Norwegian,\n",
    "    - Persian,\n",
    "    - Polish,\n",
    "    - Portuguese,\n",
    "    - Romanian,\n",
    "    - Russian,\n",
    "    - Serbian,\n",
    "    - Slovak,\n",
    "    - Slovenian,\n",
    "    - Spanish,\n",
    "    - Swahili,\n",
    "    - Swedish,\n",
    "    - Tagalog,\n",
    "    - Tamil,\n",
    "    - Thai,\n",
    "    - Turkish,\n",
    "    - Ukrainian,\n",
    "    - Urdu,\n",
    "    - Vietnamese,\n",
    "    - Welsh.\n",
    "- Optimized for English\n",
    "- Give real time audio output using streaming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528843d3-7b42-4d4e-8e29-a40a8d61680c",
   "metadata": {},
   "source": [
    "!pip install playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29ac7ce-e1ca-4ec4-aeaf-649bbfae2751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "\n",
    "# By default, output format is in mp3\n",
    "\n",
    "speech_file_path = os.path.join(\"tutorial/LLM+Langchain/Week-6/Sample.mp3\")\n",
    "\n",
    "response = client.audio.speech.create(\n",
    "  model=\"tts-1\",\n",
    "  voice=\"alloy\",\n",
    "  input=\"Today is Saturday, how are you?\")\n",
    "\n",
    "# å„²å­˜ç‚ºæª”æ¡ˆ\n",
    "response.stream_to_file(speech_file_path)\n",
    "\n",
    "# æ’­æ”¾ (simple, blocking)\n",
    "playsound(speech_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ca4eaa-01cf-43f4-8de8-8e2a4d8be536",
   "metadata": {},
   "source": [
    "gpt-4o-mini-tts å’Œ gp4-4o-tts å¯ä»¥é€é promptä¾†æ§åˆ¶èªèª¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f7d509-5873-4a50-8947-72b33321576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_file_path = os.path.join(\"tutorial/LLM+Langchain/Week-6/Sample-gpt-4o-mini.mp3\")\n",
    "\n",
    "response = client.audio.speech.create(\n",
    "    model=\"gpt-4o-mini-tts\",\n",
    "    voice=\"alloy\",\n",
    "    input=(\"Today is Saturday, how are you?\"),\n",
    "    instructions=\"Speak in a tone of tiresome.\")\n",
    "\n",
    "response.stream_to_file(speech_file_path)\n",
    "\n",
    "playsound(speech_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c49c90-b92c-4998-a4a5-834bac529007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response.content\n",
    "# audio = AudioSegment.from_file(io.BytesIO(audio_bytes), format=\"mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758e0c1e-30cd-42d1-8a56-8a66b5b42c70",
   "metadata": {},
   "source": [
    "### pygame (good for GUI apps / async playback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79ad88c-46e0-4f7f-b543-f148726dbd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "\n",
    "pygame.mixer.init()\n",
    "pygame.mixer.music.load(speech_file_path)\n",
    "pygame.mixer.music.play()\n",
    "\n",
    "while pygame.mixer.music.get_busy():\n",
    "    pygame.time.Clock().tick(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a2fed0-5cc2-4f80-9c74-19bce586df66",
   "metadata": {},
   "source": [
    "### ç›´æ¥æ’¥æ”¾ + ä¸²æµ\n",
    "\n",
    "ç›¸è¼ƒæ–¼ä¹‹å‰æ˜¯å…ˆå°‡çµæœå­˜æˆæª”æ¡ˆå†æ’¥æ”¾æª”æ¡ˆï¼Œæˆ‘å€‘å¯ä»¥è·³éå„²å­˜çš„æ­¥é©Ÿï¼Œé€™æ¨£æ•ˆç‡ä¸Šä¾†èªªæ›´å¿«ä¸€é»\n",
    "å°‡æ ¼å¼å¾å£“ç¸®çš„mp3æ›æˆç„¡å£“ç¸®çš„wav\n",
    "\n",
    "** é–‹æºç¤¾ç¾¤è‡¥è™è—é¾\n",
    "\n",
    "https://community.openai.com/t/streaming-from-text-to-speech-api/493784/29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad57820-9be4-404a-a776-37171ea797f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c20973-e0fd-4998-ae32-4b9085368c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "input_ = dedent(\"\"\"\n",
    "é³´å¤§é˜ä¸€æ¬¡ï¼\n",
    "æ¨å‹•æ æ†ï¼Œå•Ÿå‹•æ´»å¡å’Œæ³µâ€¦â€¦\n",
    "é³´å¤§é˜å…©æ¬¡ï¼\n",
    "æŒ‰ä¸‹æŒ‰éˆ•ï¼Œç™¼å‹•å¼•æ“ï¼Œé»ç‡ƒæ¸¦è¼ªï¼Œæ³¨å…¥ç”Ÿå‘½â€¦â€¦\n",
    "é³´å¤§é˜ä¸‰æ¬¡ï¼\n",
    "é½Šè²æ­Œå”±ï¼Œè®šç¾è¬æ©Ÿä¹‹ç¥ï¼\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75f4647-d525-4aac-b10c-ddb37cc40159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import sleep\n",
    "import wave\n",
    "import requests\n",
    "import pyaudio\n",
    "\n",
    "# WAV: Uncompressed WAV audio, suitable for low-latency applications to avoid decoding overhead.\n",
    "\n",
    "url = \"https://api.openai.com/v1/audio/speech\"\n",
    "headers = {\n",
    "    \"Authorization\": f'Bearer {os.getenv(\"OPENAI_API_KEY\")}',\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"model\": \"tts-1\",\n",
    "    \"input\": input_,\n",
    "    \"voice\": \"shimmer\",\n",
    "    \"response_format\": \"wav\",\n",
    "}\n",
    "\n",
    "# You send the request to the API (requests.post).\n",
    "response = requests.post(url, headers=headers, json=data, stream=True)\n",
    "\n",
    "CHUNK_SIZE = 1024\n",
    "\n",
    "if response.ok:\n",
    "    # You open the response audio data with wave.open.\n",
    "    with wave.open(response.raw, 'rb') as wf:\n",
    "        p = pyaudio.PyAudio()\n",
    "        # You configure the PyAudio stream (p.open(...)).\n",
    "        stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                        channels=wf.getnchannels(),\n",
    "                        rate=wf.getframerate(),\n",
    "                        output=True)\n",
    "\n",
    "        while len(data := wf.readframes(CHUNK_SIZE)):\n",
    "            #é€™è¡Œè² è²¬æ’¥æ”¾è²éŸ³\n",
    "            stream.write(data)\n",
    "\n",
    "        # Sleep to make sure playback has finished before closing\n",
    "        sleep(1)\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "else:\n",
    "    response.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0c30fd-b30e-473e-aeab-38dfaa92e1cb",
   "metadata": {},
   "source": [
    "### å¯¦æ™‚ä¸²æµ (Real time streaming)\n",
    "\n",
    "The Speech API provides support for realtime audio streaming using chunk transfer encoding. This means the audio can be played before the full file is generated and made accessible.\n",
    "\n",
    "** For the fastest response times, we recommend using wav or pcm as the response format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8714661a-20ed-467a-ae94-a45a4799f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "from openai.helpers import LocalAudioPlayer\n",
    "\n",
    "async_openai = AsyncOpenAI()\n",
    "\n",
    "async def main() -> None:\n",
    "    async with async_openai.audio.speech.with_streaming_response.create(\n",
    "        model=\"gpt-4o-mini-tts\",\n",
    "        voice=\"coral\",\n",
    "        input=\"Today is a wonderful day to build something people love!\",\n",
    "        instructions=\"Speak in a cheerful and positive tone.\",\n",
    "        response_format=\"pcm\",\n",
    "    ) as response:\n",
    "        await LocalAudioPlayer().play(response)\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b73d33d-93b5-4a8a-baf4-46c6e3e489b0",
   "metadata": {},
   "source": [
    "## èªéŸ³è‡ªåŠ©é»é£²æ–™ç³»çµ±\n",
    "\n",
    "é€™åªæ˜¯ä¸€å€‹DEMOï¼Œæ‰€ä»¥æœƒéå¸¸ç°¡é™‹ã€‚æˆ‘ä¹Ÿä¸æ¸…æ¥šé€™åˆ°åº•æœ‰æ²’æœ‰åšçš„åƒ¹å€¼\n",
    "\n",
    "å‡è¨­ä¸€å€‹å¾ˆç°¡å–®çš„ä½¿ç”¨æƒ…å¢ƒ: ä¸€å€‹äººè¬›äº†ä»–å°æ–¼é£²æ–™çš„éœ€æ±‚ï¼Œç„¶å¾Œwhisperå¾èªéŸ³ä¸­æŠ½å–ä»–å°æ–¼é£²æ–™çš„éœ€æ±‚:\n",
    "\n",
    "- å“ªç¨®é£²æ–™\n",
    "- å†°\n",
    "- ç³–\n",
    "\n",
    "å…ˆä¸ç®¡åˆ©ç”¨TTSæœ€å›æ‡‰æ©Ÿåˆ¶ï¼Œçœ‹çœ‹whisperèƒ½ä¸èƒ½æ­£ç¢ºæŠ½å–å…§å®¹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9042df29-7f51-4dc6-b357-9662d07b5954",
   "metadata": {},
   "source": [
    "### æ¸…å¿ƒ\n",
    "\n",
    "æ­£å¼åšçš„è©±æ‡‰è©²æ˜¯ç›´æ¥é–‹ WebScraping\n",
    "\n",
    "- çç èœ‚èœœé®®å¥¶æ™®æ´±\n",
    "- èŒ¶å‡å¥¶ç¶ \n",
    "- åš´é¸é«˜å±±èŒ¶\n",
    "- å’–å•¡å¥¶èŒ¶\n",
    "- å†¬ç“œæª¸æª¬\n",
    "\n",
    "å†°ç†±: æ­£å¸¸å†° - å°‘å†° - å¾®å†° - å»å†°\n",
    "ç”œåº¦: ç„¡ç³– - å¾®ç³– - åŠç³– - å°‘ç³–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e08088a-d765-48bf-8354-00e631b359d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36f0ebdb-bc99-4a66-9ac1-34a3e9308b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from textwrap import dedent\n",
    "from typing import Literal, List\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts.image import ImagePromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain_core.runnables import Runnable, chain\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from src.initialization import credential_init\n",
    "\n",
    "\n",
    "def build_standard_chat_prompt_template(kwargs):\n",
    "    messages = []\n",
    "\n",
    "    if 'system' in kwargs:\n",
    "        content = kwargs.get('system')\n",
    "\n",
    "        # allow list of prompts for multimodal\n",
    "        if isinstance(content, list):\n",
    "            prompts = [PromptTemplate(**c) for c in content]\n",
    "        else:\n",
    "            prompts = [PromptTemplate(**content)]\n",
    "\n",
    "        message = SystemMessagePromptTemplate(prompt=prompts)\n",
    "        messages.append(message)\n",
    "\n",
    "    if 'human' in kwargs:\n",
    "        content = kwargs.get('human')\n",
    "\n",
    "        # allow list of prompts for multimodal\n",
    "        if isinstance(content, list):\n",
    "            prompts = []\n",
    "            for c in content:\n",
    "                if c.get(\"type\") == \"image\":\n",
    "                    prompts.append(ImagePromptTemplate(**c))\n",
    "                else:\n",
    "                    prompts.append(PromptTemplate(**c))\n",
    "        else:\n",
    "            if content.get(\"type\") == \"image\":\n",
    "                prompts = [ImagePromptTemplate(**content)]\n",
    "            else:\n",
    "                prompts = [PromptTemplate(**content)]\n",
    "\n",
    "        message = HumanMessagePromptTemplate(prompt=prompts)\n",
    "        messages.append(message)\n",
    "\n",
    "    chat_prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "    \n",
    "    return chat_prompt_template\n",
    "\n",
    "\n",
    "\n",
    "credential_init()\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-mini\", \n",
    "                   temperature=0 # a range from 0-2, the higher the value, the higher the `creativity`\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd818cd5-8ab0-4c90-a1bf-2365cb86ace3",
   "metadata": {},
   "source": [
    "### å®šç¾©è¼¸å‡ºæ ¼å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68478b3c-25a2-4ddf-b566-a59be9476f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Drink(BaseModel):\n",
    "\n",
    "    name: Literal['çç èœ‚èœœé®®å¥¶æ™®æ´±', 'èŒ¶å‡å¥¶ç¶ ', 'åš´é¸é«˜å±±èŒ¶', \n",
    "                  'å’–å•¡å¥¶èŒ¶', 'å†¬ç“œæª¸æª¬'] = Field(description=\"é£²æ–™åç¨±\")\n",
    "    ice_level: Literal['æ­£å¸¸å†°', 'å°‘å†°', 'å¾®å†°', 'å»å†°'] = Field(description='å†°ç†±ç¨‹åº¦')\n",
    "    sugar_level: Literal['ç„¡ç³–', 'å¾®ç³–', 'åŠç³–' , 'å°‘ç³–'] = Field(description='ç³–åº¦')\n",
    "\n",
    "\n",
    "class Order(BaseModel):\n",
    "\n",
    "    names: List[Drink] = Field(description=(\"ç”¨æˆ¶é»çš„é£²æ–™\"))\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Order)\n",
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ba413b-344e-47d6-8cb7-9f24dd6326fc",
   "metadata": {},
   "source": [
    "### æ¨¡æ“¬å¾whisperå¾—åˆ°ç”¨æˆ¶éœ€æ±‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d81447a-54e2-48c0-8377-ec4207ea973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = dedent(\"\"\"\n",
    "                 {query}\n",
    "                 format instruction: {format_instructions}\n",
    "                 \"\"\")\n",
    "\n",
    "input_ = {\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variable\": [\"query\"],\n",
    "                    \"partial_variables\": {\"format_instructions\": \n",
    "                                          format_instructions}}}\n",
    "\n",
    "chat_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "pipeline = chat_prompt_template | model | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d80b9c-81e2-4d3e-af01-30880709edd3",
   "metadata": {},
   "source": [
    "## é€éèªè¨€æ¨¡å‹æå–é—œéµå­—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb90e57f-b7c1-46bf-9531-dc42d870f970",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipeline.invoke({\"query\": \"æˆ‘è¦ä¸€æ¯å†¬ç“œæª¸æª¬ï¼Œå¾®ç³–ï¼Œå»å†°\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e50d1547-2bdb-41b7-a85c-239bc1adbf6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Order(names=[Drink(name='å†¬ç“œæª¸æª¬', ice_level='å»å†°', sugar_level='å¾®ç³–')])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c17d4efd-a084-4437-979c-236f19459f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Order(names=[Drink(name='å†¬ç“œæª¸æª¬', ice_level='å»å†°', sugar_level='å¾®ç³–'), Drink(name='åš´é¸é«˜å±±èŒ¶', ice_level='å¾®å†°', sugar_level='ç„¡ç³–')])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pipeline.invoke({\"query\": \"æˆ‘è¦ä¸€æ¯å†¬ç“œæª¸æª¬å’Œä¸€æ¯åš´é¸é«˜å±±èŒ¶ã€‚å†¬ç“œæª¸æª¬å¾®ç³–å»å†°ï¼Œåš´é¸é«˜å±±èŒ¶ç„¡ç³–å¾®å†°\"})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3253472-0f80-46bf-aa53-8758bb13c60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omega\\miniconda3\\envs\\aicg\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import threading\n",
    "\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from openai import OpenAI\n",
    "from pydub import AudioSegment\n",
    "\n",
    "AudioSegment.converter = r\"tutorial\\LLM+Langchain\\Week-6\\ffmpeg-essentials_build\\bin\\ffmpeg.exe\"\n",
    "\n",
    "client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "\n",
    "FS = 44100\n",
    "CHANNELS = 1\n",
    "dtype = 'int16'\n",
    "\n",
    "recorded_frames = []\n",
    "\n",
    "def callback(indata, frames, time, status):\n",
    "    recorded_frames.append(indata.copy())\n",
    "\n",
    "def record_audio():\n",
    "    # åŠ å…¥èµ·å§‹å’ŒçµæŸçš„æ§åˆ¶\n",
    "    with sd.InputStream(samplerate=FS, channels=CHANNELS, \n",
    "                        dtype=dtype, callback=callback):\n",
    "        input(\"Press Enter to start recording...\")\n",
    "        print(\"Recording... Press Enter again to stop.\")\n",
    "        input()\n",
    "        print(\"Recording stopped.\")\n",
    "\n",
    "def audio_to_mp3_io(audio, FS:int, channels: int):\n",
    "\n",
    "    # Convert numpy array to AudioSegment\n",
    "    audio_bytes = audio.tobytes()\n",
    "    \n",
    "    audio_segment = AudioSegment(\n",
    "        data=audio_bytes,\n",
    "        sample_width=audio.dtype.itemsize,\n",
    "        frame_rate=FS,\n",
    "        channels=channels\n",
    "    )\n",
    "    \n",
    "    # Save as MP3 in-memory (as an object)\n",
    "    mp3_io = io.BytesIO()\n",
    "    audio_segment.export(mp3_io, format=\"mp3\")\n",
    "    mp3_io.seek(0)  # Rewind to start\n",
    "\n",
    "    mp3_io.name = \"word.mp3\"\n",
    "\n",
    "    return mp3_io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03faf9d3-ac0a-40d8-86de-ae457ce3bf9f",
   "metadata": {},
   "source": [
    "æˆ‘è¦ä¸€æ¯å†¬ç“œæª¸æª¬å’Œä¸€æ¯åš´é¸é«˜å±±èŒ¶ã€‚å†¬ç“œæª¸æª¬å¾®ç³–å»å†°ï¼Œåš´é¸é«˜å±±èŒ¶ç„¡ç³–å¾®å†°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b34a9c39-21db-424b-a570-ed25673753b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to start recording... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Press Enter again to stop.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording stopped.\n"
     ]
    }
   ],
   "source": [
    "recorded_frames.clear()\n",
    "recording_thread = threading.Thread(target=record_audio)\n",
    "recording_thread.start()\n",
    "recording_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27420898-7b98-4e6e-a8a0-f7fd15af957f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:04.080706\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "# Combine recorded frames\n",
    "if recorded_frames:\n",
    "    audio_np = np.concatenate(recorded_frames, axis=0)\n",
    "else:\n",
    "    audio_np = np.array([], dtype=dtype)\n",
    "\n",
    "mp3_io =  audio_to_mp3_io(audio=audio_np, FS=FS, channels=1)\n",
    "\n",
    "# é€™å€‹æ¥å£(end point)ä¸æ”¯æ´ stream\n",
    "time_begin = datetime.now()\n",
    "whisper_output = client.audio.translations.create(\n",
    "    model=\"whisper-1\", \n",
    "    file=mp3_io,\n",
    "    response_format=\"text\",\n",
    "    prompt=\"ç”¨æˆ¶åœ¨é»é£²æ–™, å¾®ç³–, å¾®å†°\",\n",
    ")\n",
    "time_end = datetime.now()\n",
    "\n",
    "print(time_end - time_begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "204dba78-4324-42c4-890d-67a1eaaed187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'æˆ‘è¦ä¸€æ¯å†¬ç“œæª¸æª¬å’Œä¸€æ¯åš´é¸é«˜å±±èŒ¶, å†¬ç“œæª¸æª¬å¾®ç³–å»å†°, åš´é¸é«˜å±±èŒ¶ç„¡ç³–å¾®å†°ã€‚\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fb412f-64a1-43f8-a4ad-a3c919f40be2",
   "metadata": {},
   "source": [
    "## è¨ˆç®—å¸³å–®å’Œå›æ‡‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b565449d-4c00-4bc6-a7e3-c878388b841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = dedent(\"\"\"\n",
    "                 {query}\n",
    "                 format instruction: {format_instructions}\n",
    "                 \"\"\")\n",
    "\n",
    "input_ = {\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variable\": [\"query\"],\n",
    "                    \"partial_variables\": {\"format_instructions\": \n",
    "                                          format_instructions}}}\n",
    "\n",
    "chat_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "pipeline = chat_prompt_template | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aa296f07-fd6d-41fe-b270-59efac5ee546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=[PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"$defs\": {\"Drink\": {\"properties\": {\"name\": {\"description\": \"é£²æ–™åç¨±\", \"enum\": [\"çç èœ‚èœœé®®å¥¶æ™®æ´±\", \"èŒ¶å‡å¥¶ç¶ \", \"åš´é¸é«˜å±±èŒ¶\", \"å’–å•¡å¥¶èŒ¶\", \"å†¬ç“œæª¸æª¬\"], \"title\": \"Name\", \"type\": \"string\"}, \"ice_level\": {\"description\": \"å†°ç†±ç¨‹åº¦\", \"enum\": [\"æ­£å¸¸å†°\", \"å°‘å†°\", \"å¾®å†°\", \"å»å†°\"], \"title\": \"Ice Level\", \"type\": \"string\"}, \"sugar_level\": {\"description\": \"ç³–åº¦\", \"enum\": [\"ç„¡ç³–\", \"å¾®ç³–\", \"åŠç³–\", \"å°‘ç³–\"], \"title\": \"Sugar Level\", \"type\": \"string\"}}, \"required\": [\"name\", \"ice_level\", \"sugar_level\"], \"title\": \"Drink\", \"type\": \"object\"}}, \"properties\": {\"names\": {\"description\": \"ç”¨æˆ¶é»çš„é£²æ–™\", \"items\": {\"$ref\": \"#/$defs/Drink\"}, \"title\": \"Names\", \"type\": \"array\"}}, \"required\": [\"names\"]}\\n```'}, template='\\n{query}\\nformat instruction: {format_instructions}\\n')], additional_kwargs={})])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5df62862-844f-45b5-94f7-8de7ecc1c2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = pipeline.invoke({\"query\": whisper_output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb54636f-fd31-43ff-996e-1f05663e6552",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_map = {\"çç èœ‚èœœé®®å¥¶æ™®æ´±\": 70,\n",
    "         \"èŒ¶å‡å¥¶ç¶ \": 50,\n",
    "         \"åš´é¸é«˜å±±èŒ¶\": 35,\n",
    "         \"å’–å•¡å¥¶èŒ¶\": 75,\n",
    "         \"å†¬ç“œæª¸æª¬\": 60}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e07a22d7-1731-4a7b-83b2-e35281c31a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Drink(name='å†¬ç“œæª¸æª¬', ice_level='å»å†°', sugar_level='å¾®ç³–'),\n",
       " Drink(name='åš´é¸é«˜å±±èŒ¶', ice_level='å¾®å†°', sugar_level='ç„¡ç³–')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ca6138e1-a737-4bb2-a165-bfb6ea0507ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_price = 0\n",
    "\n",
    "for order in orders.names:\n",
    "    total_price += price_map[order.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9209b457-86d6-44eb-903c-ac7d5981ee55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0dd991a8-6a16-4e3c-9d01-56c3a6e6f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "from openai.helpers import LocalAudioPlayer\n",
    "\n",
    "async_openai = AsyncOpenAI()\n",
    "\n",
    "async def main(price) -> None:\n",
    "    async with async_openai.audio.speech.with_streaming_response.create(\n",
    "        model=\"gpt-4o-mini-tts\",\n",
    "        voice=\"alloy\",\n",
    "        input=f\"ä¸€å…±{price}å…ƒ ğŸ’•\",\n",
    "        instructions=\"Speak in a sweet, energetic, anime-girl style with a cute and playful tone.\",\n",
    "        response_format=\"pcm\",\n",
    "    ) as response:\n",
    "        await LocalAudioPlayer().play(response)\n",
    "\n",
    "await main(price=total_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da5c9e9b-ef26-44e2-b8da-c3a08d7a8429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "whisper_output = 'æˆ‘è¦ä¸€æ¯å†¬ç“œæª¸æª¬å’Œä¸€æ¯åš´é¸é«˜å±±èŒ¶, å†¬ç“œæª¸æª¬å¾®ç³–å»å†°, åš´é¸é«˜å±±èŒ¶ç„¡ç³–å¾®å†°ã€‚'\n",
    "\n",
    "payload = {'input': {\"query\": whisper_output}}\n",
    "\n",
    "\"\"\"\n",
    "- ensure_ascii=False â†’ keeps Chinese characters as-is.\n",
    "\n",
    "- .encode('utf-8') â†’ ensures bytes sent are UTF-8.\n",
    "\n",
    "- Header \"charset=utf-8\" â†’ tells the server the encoding.\n",
    "\"\"\"\n",
    "\n",
    "response = requests.post(\n",
    "        \"http://localhost:8080/drinking_app/invoke\",\n",
    "        json={'input': {\"query\": whisper_output}}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21cd72b-6880-4c29-b410-e52d5bcf298d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "c78c3efa-ad1a-416e-bd7a-74e39040d5b3",
   "metadata": {},
   "source": [
    "response.encoding = 'utf-8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d5998ed-e65c-498a-a72e-1f6b5f3e1566",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = eval(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a77f5fbf-1107-43fb-aee3-3aec63700a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'å†¬ç“œæª¸æª¬', 'ice_level': 'å»å†°', 'sugar_level': 'å¾®ç³–'},\n",
       " {'name': 'åš´é¸é«˜å±±èŒ¶', 'ice_level': 'å¾®å†°', 'sugar_level': 'ç„¡ç³–'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order['output']['names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ed5299d-a748-479f-aa99-a45438a500c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "price_map = {\"çç èœ‚èœœé®®å¥¶æ™®æ´±\": 70,\n",
    "         \"èŒ¶å‡å¥¶ç¶ \": 50,\n",
    "         \"åš´é¸é«˜å±±èŒ¶\": 35,\n",
    "         \"å’–å•¡å¥¶èŒ¶\": 75,\n",
    "         \"å†¬ç“œæª¸æª¬\": 60}\n",
    "\n",
    "df = pd.DataFrame(order['output']['names'])\n",
    "\n",
    "df['price'] = df['name'].map(price_map)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68c2e433-c5b8-4ef3-914b-445e523a6a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['price'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ec0b23-08c6-4fcc-946d-36ee03b5075e",
   "metadata": {},
   "source": [
    "## Ollama\n",
    "\n",
    "This package enables you using open-source LLM with ease.\n",
    "\n",
    "We borrow the content from last week\n",
    "\n",
    "https://medium.com/@abonia/running-ollama-in-google-colab-free-tier-545609258453\n",
    "\n",
    "- curl https://ollama.ai/install.sh | sh\n",
    "- ollama serve &\n",
    "- ollama pull llama3:8b\n",
    "- ollama pull dolphin-llama3:8b\n",
    "- ollama pull huihui_ai/qwen2.5-abliterate:14b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9fb9e0-16eb-4c03-a1b2-2af693b479d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52511b57-7779-4db4-8e8e-dd9d0071f50e",
   "metadata": {},
   "source": [
    "In Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89b5037-ba65-4dac-bf0f-c4d43daeb732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install colab-xterm\n",
    "# %load_ext colabxterm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04cc1ad-5440-4e65-bc38-07d2139afa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %xterm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd597a5-1f65-4b5d-935d-5bc97fb2ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from torch import cuda\n",
    "from langchain.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain_core.prompts.image import ImagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.runnables import Runnable, chain\n",
    "\n",
    "from src.io.path_definition import get_project_dir\n",
    "\n",
    "\n",
    "def build_standard_chat_prompt_template(kwargs):\n",
    "    messages = []\n",
    "\n",
    "    if 'system' in kwargs:\n",
    "        content = kwargs.get('system')\n",
    "\n",
    "        # allow list of prompts for multimodal\n",
    "        if isinstance(content, list):\n",
    "            prompts = [PromptTemplate(**c) for c in content]\n",
    "        else:\n",
    "            prompts = [PromptTemplate(**content)]\n",
    "\n",
    "        message = SystemMessagePromptTemplate(prompt=prompts)\n",
    "        messages.append(message)\n",
    "\n",
    "    if 'human' in kwargs:\n",
    "        content = kwargs.get('human')\n",
    "\n",
    "        # allow list of prompts for multimodal\n",
    "        if isinstance(content, list):\n",
    "            prompts = []\n",
    "            for c in content:\n",
    "                if c.get(\"type\") == \"image\":\n",
    "                    prompts.append(ImagePromptTemplate(**c))\n",
    "                else:\n",
    "                    prompts.append(PromptTemplate(**c))\n",
    "        else:\n",
    "            if content.get(\"type\") == \"image\":\n",
    "                prompts = [ImagePromptTemplate(**content)]\n",
    "            else:\n",
    "                prompts = [PromptTemplate(**content)]\n",
    "\n",
    "        message = HumanMessagePromptTemplate(prompt=prompts)\n",
    "        messages.append(message)\n",
    "\n",
    "    chat_prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "    \n",
    "    return chat_prompt_template\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888775f5-e632-41c5-99cf-406d70ee63b7",
   "metadata": {},
   "source": [
    "Ollama ä½¿ç”¨æ¨¡å‹è·Ÿ OpenAI API æ²’æœ‰å€åˆ¥\n",
    "\n",
    "ä½†å»ºè­°æ¶è¨­åœ¨æœ‰å¼·å¤§ç®—åŠ›çš„æ©Ÿå™¨ä¸Šï¼Œä¸¦ä¸”ä½¿ç”¨Langserveå‘¼å«æœå‹™ï¼Œä¾†æ¸›è¼•æœ¬åœ°çš„ç®—åŠ›éœ€æ±‚ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3d7f97-f573-4350-a946-4a6a8af963df",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"You are a helpful AI assistant with excellent writing skill\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c5f546-eccf-4a24-a3e9-0229a454d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "stop_token_ids = None\n",
    "model_id = \"dolphin-llama3:8b\"\n",
    "\n",
    "device = f\"cuda:{cuda.current_device()}\" if cuda.is_available() else 'cpu'\n",
    "\n",
    "model = ChatOllama(model=model_id, temperature=0)\n",
    "\n",
    "summary_prompt_template = build_summary_prompt_template()\n",
    "\n",
    "summary_pipeline = summary_prompt_template | model | StrOutputParser()\n",
    "\n",
    "text_as_list = []\n",
    "for document in tqdm(documents):\n",
    "    content = summary_pipeline.invoke({\"text\": document.page_content})\n",
    "    text_as_list.append(content)\n",
    "\n",
    "final_text = \"\\n\".join(text_as_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a034f8-82cb-4784-ad35-f6d10fe01c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_pipeline.invoke({\"text\": final_text})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
