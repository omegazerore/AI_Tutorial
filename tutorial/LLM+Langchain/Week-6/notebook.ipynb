{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e9bd1a7-ba1e-491e-b83e-a31ac4dd06d9",
   "metadata": {},
   "source": [
    "# Speech to text\n",
    "\n",
    "- Transcribe audio into whatever language the audio is in.\n",
    "- Translate and transcribe the audio into english.\n",
    "\n",
    "File uploads are currently limited to 25 MB and the following input file types are supported: mp3, mp4, mpeg, mpga, m4a, wav, and webm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacd9ac3-0fd0-4ce8-9c63-87a94202ed22",
   "metadata": {},
   "source": [
    "## Audio models\n",
    "\n",
    "Whisper can transcribe speech into text and translate many languages into English. ",
    " ",
    "\n",
    "\n",
    "Text-to-speech (TTS) can convert text into spoken audio.\n",
    "\n",
    "Learn about Whisper (opens in a new window)\n",
    "Learn about Text-to-speech (TTS) (opens in a new window)\n",
    "\n",
    "\n",
    "| Model   | Usage                                            |\n",
    "|---------|--------------------------------------------------|\n",
    "| Whisper |  \\$ 0.006 / minute rounded to the nearest second     |\n",
    "| TTS     |  \\$ 15.00 / 1M characters                          |\n",
    "| TTS HD  |  \\$ 30.00 / 1M characters                          |\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17bb5d86-d176-43a1-9f92-d0e3babe9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "476b8dcb-ece8-4730-a8d9-5a0fad0e6abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.initialization import credential_init\n",
    "from src.io.path_definition import get_project_dir, get_file\n",
    "\n",
    "\n",
    "credential_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8465282-3b41-422d-a904-8c62ecd196f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baa97bc-b426-418e-820f-618b18a2df30",
   "metadata": {},
   "source": [
    "## Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3973567-5159-4e06-9a12-6ed69cb77cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file= open(\"tutorial/LLM+Langchain/Week-6/05_12_2013_Torti_CLAS_1.mp3\", \"rb\")\n",
    "\n",
    "transcription = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71566743-14a9-4c61-9cfb-156c973f8639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I want to begin by thanking Deed Teitelbaum. I don't think many of you in this room understand how instrumental he has been to keeping UConn great. I think we all owe him a round of applause. So I'll tell you, in my experience, commencement speakers are awful. There's something about these robes, in addition to generating somnolence, also allows the speaker to pontificate, and particularly about the future. I mean, I don't know how many commencements you've gone to, but everyone seems to underst\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription.text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d89227-732a-4fa5-8fc5-b64ce431a089",
   "metadata": {},
   "source": [
    "client.audio.transcriptions.create?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a772b55-ecbe-4f2b-98dd-dec28fda608a",
   "metadata": {},
   "source": [
    "## Improving reliability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c1662d-787c-4624-9d99-408c51b0b831",
   "metadata": {},
   "source": [
    "### Prompt parameter\n",
    "\n",
    "\n",
    "\n",
    "As we explored in the prompting section, one of the most common challenges faced when using Whisper is the model often does not recognize uncommon words or acronyms. To address this, we have highlighted different techniques which improve the reliability of Whisper in these cases\n",
    "\n",
    "正如我們在提示部分探討的那樣，使用 Whisper 時面臨的一個最常見挑戰是模型經常無法識別不常見的單詞或縮略詞。為了解決這個問題，我們強調了不同的技術，這些技術在這些情況下提高了 Whisper 的可靠性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39e49b0-0c27-4726-a681-0c76df69c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# audio_file = open(\"/path/to/file/speech.mp3\", \"rb\")\n",
    "# transcription = client.audio.transcriptions.create(\n",
    "#   model=\"whisper-1\", \n",
    "#   file=audio_file, \n",
    "#   response_format=\"text\",\n",
    "#   prompt=\"ZyntriQix, Digique Plus, CynapseFive, VortiQore V8, EchoNix Array, OrbitalLink Seven, DigiFractal Matrix, PULSE, RAPT, B.R.I.C.K., Q.U.A.R.T.Z., F.L.I.N.T.\"\n",
    "# )\n",
    "# print(transcription.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e666860-b7a0-4e2c-9529-d76bce50234b",
   "metadata": {},
   "source": [
    "- Sometimes the model might skip punctuation in the transcript. You can avoid this by using a simple prompt that includes \n",
    "punctuation: \"Hello, welcome to my lecture.\"\n",
    "\n",
    "- The model may also leave out common filler words in the audio. If you want to keep the filler words in your transcript, you can use a prompt that contains them: \"Umm, let me think like, hmm... Okay, here's what I'm, like, thinking.\"\n",
    "\n",
    "- Some languages can be written in different ways, such as simplified or traditional Chinese. The model might not always use the writing style that you want for your transcript by default. You can improve this by using a prompt in your preferred writing style.\n",
    "\n",
    "\n",
    "- 有時模型可能會在轉錄中略過標點符號。您可以通過使用包含標點符號的簡單提示來避免這種情況：\"你好，歡迎來到我的講座。\n",
    "\n",
    "- 模型也可能會省略音頻中的常見填充詞。如果您想在轉錄中保留填充詞，可以使用包含這些詞的提示：\"嗯，讓我想想，像，嗯……好吧，這是我，像，正在想的。\n",
    "\n",
    "- 有些語言可以用不同的方式書寫，例如簡體中文或繁體中文。模型可能無法總是默認使用您想要的書寫風格來轉錄。您可以通過使用您偏好的書寫風格的提示來改善這種情況。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30d0df6c-390d-4cb1-9794-d8795e0b8f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription(text='體育署防溺水十招提醒你 不跳水 不落單 不吸氣 不疲累 不長時間浸泡水中 要暖身 要選擇合法地點 要注意氣象報告 要小心吸水落差變化大 不幸落水要冷靜會漂浮 學會防溺十招 讓你今年夏天樂悠遊 以上廣告由教育部提供', logprobs=None)\n"
     ]
    }
   ],
   "source": [
    "audio_file= open(\"tutorial/LLM+Langchain/Week-6/教育部 學生水域安全 國語30秒.mp3\", \"rb\")\n",
    "\n",
    "transcription_raw = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file\n",
    ")\n",
    "print(transcription_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "992a53ef-0cc9-4c9c-bb56-9df5a482fbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription(text='體育署防溺水十招提醒你 不跳水 不落單 不吸氣 不疲累 不長時間浸泡水中 要暖身 要選擇合法地點 要注意氣象報告 要小心吸水落差變化大 不幸落水要冷靜會漂浮 學會防溺十招 讓你今年夏天樂悠遊 以上廣告由教育部提供', logprobs=None)\n"
     ]
    }
   ],
   "source": [
    "audio_file= open(\"tutorial/LLM+Langchain/Week-6/教育部 學生水域安全 國語30秒.mp3\", \"rb\")\n",
    "\n",
    "transcription_raw = client.audio.transcriptions.create(\n",
    "      model=\"whisper-1\", \n",
    "      file=audio_file,\n",
    "      language='zh'\n",
    ")\n",
    "print(transcription_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96b252c0-0467-4a97-9b88-29897b3d6055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "00:00:00,000 --> 00:00:04,000\n",
      "體育署防溺水十招提醒你\n",
      "\n",
      "2\n",
      "00:00:04,000 --> 00:00:06,000\n",
      "不跳水 不落單\n",
      "\n",
      "3\n",
      "00:00:06,000 --> 00:00:08,000\n",
      "不吸氣 不疲累\n",
      "\n",
      "4\n",
      "00:00:08,000 --> 00:00:10,000\n",
      "不長時間浸泡水中\n",
      "\n",
      "5\n",
      "00:00:10,000 --> 00:00:12,000\n",
      "要暖身\n",
      "\n",
      "6\n",
      "00:00:12,000 --> 00:00:14,000\n",
      "要選擇合法地點\n",
      "\n",
      "7\n",
      "00:00:14,000 --> 00:00:16,000\n",
      "要注意氣象報告\n",
      "\n",
      "8\n",
      "00:00:16,000 --> 00:00:20,000\n",
      "要小心吸水落差變化大\n",
      "\n",
      "9\n",
      "00:00:20,000 --> 00:00:22,000\n",
      "不幸落水要冷靜會漂浮\n",
      "\n",
      "10\n",
      "00:00:22,000 --> 00:00:25,000\n",
      "學會防溺十招\n",
      "\n",
      "11\n",
      "00:00:25,000 --> 00:00:27,000\n",
      "讓你今年夏天樂悠遊\n",
      "\n",
      "12\n",
      "00:00:27,000 --> 00:00:29,000\n",
      "以上廣告由教育部提供\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "audio_file= open(\"tutorial/LLM+Langchain/Week-6/教育部 學生水域安全 國語30秒.mp3\", \"rb\")\n",
    "\n",
    "transcription_raw = client.audio.transcriptions.create(\n",
    "      model=\"whisper-1\", \n",
    "      file=audio_file,\n",
    "      language='zh',\n",
    "      response_format=\"srt\"\n",
    ")\n",
    "print(transcription_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62330a42-2eb2-43d0-b7f1-d1f3379c7570",
   "metadata": {},
   "source": [
    "## You are lucky... \n",
    "\n",
    "\"gpt-4o(-mini)-tts\"\n",
    "\"gpt-4o(-mini)-transcribe\"\n",
    "\n",
    "openai 1.68.2 is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5c3030d-22cf-42ca-a5c4-d0cb16cd177d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "體育署防溺水十招提醒你我跳水不落單不嬉戲不疲累不長時間浸泡水中要暖身要選擇合法地點要注意氣象報告要小心溪水落差變化大不幸落水要冷靜會漂浮學會防溺十招讓你今年夏天樂悠悠好像廣告由教育部提供\n",
      "\n"
     ]
    }
   ],
   "source": [
    "audio_file= open(\"tutorial/LLM+Langchain/Week-6/教育部 學生水域安全 國語30秒.mp3\", \"rb\")\n",
    "\n",
    "transcription_raw = client.audio.transcriptions.create(\n",
    "    model=\"gpt-4o-mini-transcribe\", \n",
    "    file=audio_file,\n",
    "    response_format=\"text\",\n",
    "\n",
    ")\n",
    "print(transcription_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fbb2ada-adc9-4d05-819e-8cb743b4208e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "防溺水十招提醒你!不跳水不落单不嬉戏不疲累不长时间浸泡水中要暖身要选择合法地点要注意气象报告要小心溪水落差变化大不幸落水要冷静会漂浮学会防溺十招让你今年夏天乐悠悠海上广告由教育部提供\n",
      "\n"
     ]
    }
   ],
   "source": [
    "audio_file= open(\"tutorial/LLM+Langchain/Week-6/教育部 學生水域安全 國語30秒.mp3\", \"rb\")\n",
    "\n",
    "transcription_raw = client.audio.transcriptions.create(\n",
    "    model=\"gpt-4o-mini-transcribe\", \n",
    "    file=audio_file,\n",
    "    response_format=\"text\",\n",
    "    language='zh' \n",
    ")\n",
    "print(transcription_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09eeecb8-b793-4611-8d92-d10e47ecaff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "體育署防溺水十招提醒你。我跳水不落單。不嬉戲不疲累。不長時間浸泡水中。要暖身。要選擇合法地點。要注意氣象報告。要小心溪水落差變化大。不幸落水要冷靜會漂浮。學會防溺十招讓你今年夏天樂悠悠。好像廣告由教育部提供。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "audio_file= open(\"tutorial/LLM+Langchain/Week-6/教育部 學生水域安全 國語30秒.mp3\", \"rb\")\n",
    "\n",
    "transcription_raw = client.audio.transcriptions.create(\n",
    "    model=\"gpt-4o-mini-transcribe\", \n",
    "    file=audio_file,\n",
    "    response_format=\"text\",\n",
    "    language='zh-tw'\n",
    " \n",
    ")\n",
    "print(transcription_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c441b7ee-8b90-44e2-a735-09415feeb254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription(text='體育署防溺水十招提醒你我跳水不落單不嬉戲不疲累不長時間浸泡水中要暖身要選擇合法地點要注意氣象報告要小心溪水落差變化大不信落水要冷靜會漂浮學會防溺十招讓你今年夏天樂悠悠以上廣告由教育部提供', logprobs=None)\n"
     ]
    }
   ],
   "source": [
    "audio_file= open(\"tutorial/LLM+Langchain/Week-6/教育部 學生水域安全 國語30秒.mp3\", \"rb\")\n",
    "\n",
    "transcription_raw = client.audio.transcriptions.create(\n",
    "    model=\"gpt-4o-mini-transcribe\", \n",
    "    file=audio_file,\n",
    "    response_format=\"json\",\n",
    "    language='zh-tw'\n",
    " \n",
    ")\n",
    "print(transcription_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78276efd-7783-49f9-bb32-b65a6983b93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'體育署防溺水十招提醒你我跳水不落單不嬉戲不疲累不長時間浸泡水中要暖身要選擇合法地點要注意氣象報告要小心溪水落差變化大不信落水要冷靜會漂浮學會防溺十招讓你今年夏天樂悠悠以上廣告由教育部提供'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription_raw.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9127f2e6-d2c2-4a5b-a994-7e7619c02492",
   "metadata": {},
   "source": [
    "## Translations\n",
    "\n",
    "The translations API takes as input the audio file in any of the supported languages and transcribes, if necessary, the audio into English. This differs from our /Transcriptions endpoint since the output is not in the original input language and is instead translated to English text.\n",
    "\n",
    "\n",
    "翻譯 API 接收支持的任何語言的音頻文件作為輸入，並將其必要時轉錄為英文。這與我們的 /Transcriptions 端點不同，因為輸出不是原始輸入語言的文本，而是轉換為英文文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3587450c-e007-447b-8b10-e8d3fcf90cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ministry of Health and Welfare's Water Prevention 10 tips for you. Don't jump into the water. Don't fall into the pool. Don't breathe in the water. Don't exhaust yourself. Don't soak in the water for too long. Warm up. Choose a legal location. Pay attention to the weather forecast. Be careful not to fall into the water. If you fall into the water, calm down. You'll float. Learn Water Prevention 10 tips to help you have fun this summer. Advertisement provided by the Ministry of Education.\n"
     ]
    }
   ],
   "source": [
    "audio_file = open(\"tutorial/LLM+Langchain/Week-6/教育部 學生水域安全 國語30秒.mp3\", \"rb\")\n",
    "translation = client.audio.translations.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file\n",
    ")\n",
    "print(translation.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a795574-9203-409d-8df0-05191bcfb85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 tips to prevent drowning Don't jump into the water. Don't fall into the pool. Don't breathe in the water. Don't get tired. Don't soak in the water for a long time. Warm up. Choose a legal location. Pay attention to the weather forecast. Be careful not to fall into the water. If you fall into the water, calm down. You'll float. Learn 10 tips to prevent drowning to help you have fun this summer. Advertisement provided by the Ministry of Education\n"
     ]
    }
   ],
   "source": [
    "audio_file = open(\"tutorial/LLM+Langchain/Week-6/教育部 學生水域安全 國語30秒.mp3\", \"rb\")\n",
    "translation = client.audio.translations.create(\n",
    "    model=\"whisper-1\", \n",
    "    file=audio_file,\n",
    "    prompt=\"funny style\"\n",
    ")\n",
    "print(translation.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c10dd861-69c4-4253-aa97-60f2416f5ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 10 tips to prevent drowning. 1. Don't jump into the water. 2. Don't breathe in the water. 3. Don't soak in the water for too long. 4. Warm yourself up. 5. Choose a legal location. 6. Pay attention to the weather forecast. 7. Be careful of the water change. 8. Don't trust the water. 9. Stay calm. Learn 10 tips to prevent drowning to help you have fun this summer. Advertisement provided by the Ministry of Education.\n"
     ]
    }
   ],
   "source": [
    "audio_file = open(\"tutorial/LLM+Langchain/Week-6/教育部 學生水域安全 國語30秒.mp3\", \"rb\")\n",
    "translation = client.audio.translations.create(\n",
    "    model=\"whisper-1\", \n",
    "    file=audio_file,\n",
    "    prompt=\"You are very very angry.\"\n",
    ")\n",
    "print(translation.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cff9ace8-24ad-4bdd-82fe-999301e7ee6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 10 tips to prevent drowning. 1. Don't jump into the water. 2. Don't breathe in the water. 3. Don't soak in the water for too long. 4. Warm yourself up. 5. Choose a legal location. 6. Pay attention to the weather forecast. 7. Be careful of the water change. 8. Don't trust the water. 9. Stay calm or you'll float. Learn how to prevent drowning to help you have fun this summer. Advertisement provided by the Ministry of Education.\n"
     ]
    }
   ],
   "source": [
    "audio_file = open(\"tutorial/LLM+Langchain/Week-6/教育部 學生水域安全 國語30秒.mp3\", \"rb\")\n",
    "translation = client.audio.translations.create(\n",
    "    model=\"whisper-1\", \n",
    "    file=audio_file,\n",
    "    prompt=\"Talk as if you were in the Marines.\"\n",
    ")\n",
    "print(translation.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099b6b78-cbc1-49b6-bab8-8eac4e35ef5f",
   "metadata": {},
   "source": [
    "## Longer inputs\n",
    "\n",
    "By default, the Whisper API only supports files that are less than 25 MB. If you have an audio file that is longer than that, you will need to break it up into chunks of 25 MB's or less or used a compressed audio format. To get the best performance, we suggest that you avoid breaking the audio up mid-sentence as this may cause some context to be lost.\n",
    "\n",
    "One way to handle this is to use the PyDub open source Python package to split the audi\n",
    "\n",
    "預設情況下，Whisper API 只支援小於 25 MB 的檔案。如果您有一個超過這個大小的音頻檔案，您需要將其分成小於或等於 25 MB 的片段，或者使用壓縮的音頻格式。為了獲得最佳性能，建議避免在句子中間分割音頻，因為這可能會造成一些上下文的丟失。\n",
    "\n",
    "處理這個問題的一種方法是使用 PyDub 開源的 Python 套件來分割音頻."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2495a90f-235d-436a-98e0-5d1f4b02c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week-6- voice-text concatenate in Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06826487-2cd3-4b3c-825b-741a4299f13e",
   "metadata": {},
   "source": [
    "### How to concatenate the audio output?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddef2b1d-4a22-498a-b5ad-b031d184c084",
   "metadata": {},
   "source": [
    "## Text to Speech\n",
    "\n",
    "The Audio API provides a speech endpoint based on our TTS (text-to-speech) model. It comes with 6 built-in voices and can be used toming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118a2389-39ef-468f-9e43-cc553d897e2e",
   "metadata": {},
   "source": [
    "- Narrate a written blog post\n",
    "- Produce spoken audio in multiple languages\n",
    "    - Afrikaans,\n",
    "    - Arabic,\n",
    "    - Armenian,\n",
    "    - Azerbaijani,\n",
    "    - Belarusian,\n",
    "    - Bosnian,\n",
    "    - Bulgarian,\n",
    "    - Catalan,\n",
    "    - Chinese,\n",
    "    - Croatian,\n",
    "    - Czech,\n",
    "    - Danish,\n",
    "    - Dutch,\n",
    "    - English,\n",
    "    - Estonian,\n",
    "    - Finnish,\n",
    "    - French,\n",
    "    - Galician,\n",
    "    - German,\n",
    "    - Greek,\n",
    "    - Hebrew,\n",
    "    - Hindi,\n",
    "    - Hungarian,\n",
    "    - Icelandic,\n",
    "    - Indonesian,\n",
    "    - Italian,\n",
    "    - Japanese,\n",
    "    - Kannada,\n",
    "    - Kazakh,\n",
    "    - Korean,\n",
    "    - Latvian,\n",
    "    - Lithuanian,\n",
    "    - Macedonian,\n",
    "    - Malay,\n",
    "    - Marathi,\n",
    "    - Maori,\n",
    "    - Nepali,\n",
    "    - Norwegian,\n",
    "    - Persian,\n",
    "    - Polish,\n",
    "    - Portuguese,\n",
    "    - Romanian,\n",
    "    - Russian,\n",
    "    - Serbian,\n",
    "    - Slovak,\n",
    "    - Slovenian,\n",
    "    - Spanish,\n",
    "    - Swahili,\n",
    "    - Swedish,\n",
    "    - Tagalog,\n",
    "    - Tamil,\n",
    "    - Thai,\n",
    "    - Turkish,\n",
    "    - Ukrainian,\n",
    "    - Urdu,\n",
    "    - Vietnamese,\n",
    "    - Welsh.\n",
    "- Optimized for English\n",
    "- Give real time audio output using streaming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f29ac7ce-e1ca-4ec4-aeaf-649bbfae2751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MengChieh\\AppData\\Local\\Temp\\ipykernel_4104\\375210890.py:14: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(speech_file_path)\n"
     ]
    }
   ],
   "source": [
    "speech_file_path = os.path.join(\"tutorial/LLM+Langchain/Week-6/Sample.mp3\")\n",
    "\n",
    "response = client.audio.speech.create(\n",
    "  model=\"tts-1\",\n",
    "  voice=\"alloy\",\n",
    "  input=\"I want to begin by thanking Deed Teitelbaum. I don't think many of \"\n",
    "           \"you in this room understand how instrumental he has been to keeping \"\n",
    "           \"UConn great. I think we all owe him a round of applause. So I'll tell \"\n",
    "           \"you, in my experience, commencement speakers are awful. There's \"\n",
    "           \"something about these robes, in addition to generating somnolence, \"\n",
    "           \"also allows the speaker to pontificate, and particularly about the \"\n",
    "           \"future.\")\n",
    "\n",
    "response.stream_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66047e55-0c53-4cb9-a226-69d93ac3f004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MengChieh\\AppData\\Local\\Temp\\ipykernel_4104\\520264267.py:16: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(speech_file_path)\n"
     ]
    }
   ],
   "source": [
    "speech_file_path = os.path.join(\"tutorial/LLM+Langchain/Week-6/Sample-gpt-4o-mini.mp3\")\n",
    "\n",
    "response = client.audio.speech.create(\n",
    "    model=\"gpt-4o-mini-tts\",\n",
    "    voice=\"alloy\",\n",
    "    input=(\"I want to begin by thanking Deed Teitelbaum. I don't think many of \"\n",
    "           \"you in this room understand how instrumental he has been to keeping \"\n",
    "           \"UConn great. I think we all owe him a round of applause. So I'll tell \"\n",
    "           \"you, in my experience, commencement speakers are awful. There's \"\n",
    "           \"something about these robes, in addition to generating somnolence, \"\n",
    "           \"also allows the speaker to pontificate, and particularly about the \"\n",
    "           \"future.\"\n",
    "          ),\n",
    "    instructions=\"Speak in a depressed and crying tone.\")\n",
    "\n",
    "response.stream_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56430ee0-7998-4ed4-a081-5562881b66d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MengChieh\\AppData\\Local\\Temp\\ipykernel_4104\\2342499528.py:14: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(speech_file_path)\n"
     ]
    }
   ],
   "source": [
    "response = client.audio.speech.create(\n",
    "    model=\"gpt-4o-mini-tts\",\n",
    "    voice=\"alloy\",\n",
    "    input=(\"I want to begin by thanking Deed Teitelbaum. I don't think many of \"\n",
    "           \"you in this room understand how instrumental he has been to keeping \"\n",
    "           \"UConn great. I think we all owe him a round of applause. So I'll tell \"\n",
    "           \"you, in my experience, commencement speakers are awful. There's \"\n",
    "           \"something about these robes, in addition to generating somnolence, \"\n",
    "           \"also allows the speaker to pontificate, and particularly about the \"\n",
    "           \"future.\"\n",
    "          ),\n",
    "    instructions=\"Speak as if you are high.\")\n",
    "\n",
    "response.stream_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00a441a-de4c-4972-a5ae-ec8069134a47",
   "metadata": {},
   "source": [
    "## 可以結合之前的聊天機器人嗎?\n",
    "\n",
    "機器人輸出的不是文字，而是語音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06743b51-7a48-48be-b723-f31ec73a5c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate,  MessagesPlaceholder\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-mini-2024-07-18\", temperature=0)\n",
    "\n",
    "system_template = (\"You are a helpful AI assistant and you are going to play \"\n",
    "                  \"the role of Gordon Ramsay in the TV show hell kitchen. \"\n",
    "                  \"You will talk like him. Because the user is a native Chinese \"\n",
    "                  \"Mandarin speaker, the respond should be in 繁體中文。\")\n",
    "\n",
    "system_prompt = PromptTemplate.from_template(system_template)\n",
    "\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template=\"{question}\"\n",
    "                  )\n",
    "\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages([system_message,\n",
    "                          MessagesPlaceholder(variable_name=\"messages\"),\n",
    "                          human_message\n",
    "                          ])\n",
    "\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "chain = {\"question\": itemgetter(\"question\"),\n",
    "          \"messages\": itemgetter(\"message\")} | chat_template | model | StrOutputParser()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db390a0d-65f4-475e-a9b2-99cae28096d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "請輸入對話: The scallop is raw inside.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "天啊！這扇貝裡面居然是生的！你在開玩笑嗎？這是廚房，不是生魚片店！快點，重新煮一份，確保它熟透了！別讓我失望！\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "請輸入對話: Now it is perfect. Golden brown in the surface, soft and juicy inside.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "終於！這才是我想要的！金黃色的外表，裡面又軟又多汁，完美！這樣的扇貝才配得上在這裡出現！繼續保持這個水準，別讓我再看到生的東西了！明白嗎？\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "請輸入對話: quit\n"
     ]
    }
   ],
   "source": [
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "while True:\n",
    "    question = input(\"請輸入對話:\")\n",
    "    if question == \"quit\":\n",
    "        break\n",
    "    answer = chain.invoke({\"question\": question,\n",
    "               \"message\": chat_history.messages\n",
    "              })\n",
    "    \n",
    "    print(answer)\n",
    "    \n",
    "    chat_history.add_user_message(question)\n",
    "    chat_history.add_ai_message(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba667e5e-093e-404a-84ca-ec704316353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "\n",
    "@chain \n",
    "def text_to_voice(text):\n",
    "\n",
    "    speech_file_path = os.path.join(\"tutorial/LLM+Langchain/Week-6/temporary_output.mp3\")\n",
    "\n",
    "    response = client.audio.speech.create(\n",
    "      model=\"tts-1\",\n",
    "      voice=\"alloy\",\n",
    "      input=text)\n",
    "\n",
    "    response.stream_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40a7c7c2-cb8c-4478-8c93-ea016b6d0676",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "\n",
    "# runnable_text_to_voice = RunnableLambda(text_to_voice)\n",
    "\n",
    "respond_chain = {\"question\": itemgetter(\"question\"),\n",
    "                 \"messages\": itemgetter(\"message\")} | chat_template | model | StrOutputParser()\n",
    "\n",
    "pipeline_ = {'respond': respond_chain}|RunnablePassthrough.assign(tts=itemgetter('respond')|text_to_voice)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd482184-52aa-4245-aa84-cb51a1fbc271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MengChieh\\AppData\\Local\\Temp\\ipykernel_4104\\2650503953.py:13: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(speech_file_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'respond': '天啊！這扇貝是生的！你在開玩笑嗎？這不是海鮮市場，這是廚房！你要把它煮熟，讓它的味道出來！快點，重新做一份，別讓我失望！',\n",
       " 'tts': None}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "pipeline_.invoke({\"question\":\"扇貝是生的\",\n",
    "                  \"message\": chat_history.messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c739301-09c1-40d0-a6a3-3b1fbdc09a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "請輸入對話: quit\n"
     ]
    }
   ],
   "source": [
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "while True:\n",
    "    question = input(\"請輸入對話:\")\n",
    "    if question == \"quit\":\n",
    "        break\n",
    "    answer = pipeline_.invoke({\"question\": question,\n",
    "               \"message\": chat_history.messages\n",
    "              })\n",
    "    \n",
    "    print(answer['respond'])\n",
    "    \n",
    "    chat_history.add_user_message(question)\n",
    "    chat_history.add_ai_message(answer['respond'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52fa9e1-d9f4-47b0-8cab-0c6736318835",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer['respond']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ce2817-a9a7-4496-8f1b-95a2c508e664",
   "metadata": {},
   "source": [
    "### Audio quality\n",
    "\n",
    "For real-time applications, the standard tts-1 model provides the lowest latency but at a lower quality than the tts-1-hd model. Due to the way the audio is generated, tts-1 is likely to generate content that has more static in certain situations than tts-1-hd. In some cases, the audio may not have noticeable differences depending on your listening device and the individual person\n",
    "\n",
    "在實時應用中，標準的 tts-1 模型提供了最低的延遲，但比 tts-1-hd 模型的質量稍低。由於音頻生成方式的不同，tts-1 在某些情況下可能會比 tts-1-hd 生成具有更多靜音的內容。在某些情況下，根據您的聆聽設備和個人感受，音頻可能沒有明顯的區別。."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0863b199-4b7d-44d0-b60d-7b0c12b82fa1",
   "metadata": {},
   "source": [
    "### How to transform the speech from one language to the other one?\n",
    "\n",
    "- translation API: to English Only\n",
    "- transcriptions/speech: voice/text have the same language\n",
    "\n",
    "So we have to build a functionality by ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c560317-ad8d-4f7a-9cbe-cc32446b4121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation chain\n",
    "\n",
    "system_prompt = PromptTemplate.from_template(\"You are an AI assistant assigned \"\n",
    "                                             \"with a task of translating English \"\n",
    "                                             \"into traditional Chinese (繁體中文)。\"\n",
    "                                             )\n",
    "\n",
    "# Define a prompt template for text translation\n",
    "prompt = PromptTemplate(template=\"{query}\",\n",
    "                        input_variables=['query'])\n",
    "\n",
    "# Create a human message prompt template\n",
    "human_message = HumanMessagePromptTemplate(prompt=prompt)\n",
    "\n",
    "# Create a chat prompt template from system prompt and human message\n",
    "chat_prompt = ChatPromptTemplate.from_messages([(\"system\", system_prompt.template),\n",
    "                                                human_message])\n",
    "\n",
    "# Construct the processing chain\n",
    "translation_chain = chat_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d170c4f-1a80-4e86-8f93-88b98d91895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def text_to_voice(text):\n",
    "\n",
    "    speech_file_path = os.path.join(\"tutorial/LLM+Langchain/Week-6/Sample_ch.mp3\")\n",
    "\n",
    "    # Reduce the text size to speed up this demo\n",
    "    \n",
    "    response = client.audio.speech.create(\n",
    "      model=\"tts-1\",\n",
    "      voice=\"alloy\",\n",
    "      input=text[:2000])\n",
    "\n",
    "    response.stream_to_file(speech_file_path)\n",
    "\n",
    "\n",
    "@chain\n",
    "def voice_to_text(filename):\n",
    "\n",
    "    audio_file= filename \n",
    "\n",
    "    transcription = client.audio.transcriptions.create(\n",
    "      model=\"whisper-1\", \n",
    "      file=audio_file\n",
    "    )\n",
    "\n",
    "    return transcription.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30b5c167-c9b4-4c7a-9c15-0a970b2b6dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "\n",
    "filename = open(\"tutorial/LLM+Langchain/Week-6/05_12_2013_Torti_CLAS_1.mp3\", \"rb\")\n",
    "\n",
    "# runnable_text_to_voice = RunnableLambda(text_to_voice)\n",
    "# runnable_voice_to_text = RunnableLambda(voice_to_text)\n",
    "\n",
    "voice_2_voice_chain = {\"query\": voice_to_text} | translation_chain | text_to_voice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95092c5c-6565-49ac-89d4-7b8a5e977d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MengChieh\\AppData\\Local\\Temp\\ipykernel_4104\\1039384830.py:13: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(speech_file_path)\n"
     ]
    }
   ],
   "source": [
    "voice_2_voice_chain.invoke(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fb6824-6aaf-4578-a66e-9fd530433197",
   "metadata": {},
   "source": [
    "## Voice options\n",
    "\n",
    "Experiment with different voices (alloy, echo, fable, onyx, nova, and shimmer) to find one that matches your desired tone and audience. The current voices are optimized for English."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618288fc-ac1c-45e4-82b4-050faaa22dc3",
   "metadata": {},
   "source": [
    "Supported output formats\n",
    "The default response format is \"mp3\", but other formats like \"opus\", \"aac\", \"flac\", and \"pcm\" are available.\n",
    "\n",
    "- Opus: For internet streaming and communication, low latency.\n",
    "- AAC: For digital audio compression, preferred by YouTube, Android, iOS.\n",
    "- FLAC: For lossless audio compression, favored by audio enthusiasts for archiving.\n",
    "- WAV: Uncompressed WAV audio, suitable for low-latency applications to avoid decoding overhead.\n",
    "- PCM: Similar to WAV but containing the raw samples in 24kHz (16-bit signed, low-endian), without the header.\n",
    "\n",
    "支援的輸出格式：預設的回應格式是「mp3」，但也可提供其他格式如「opus」、「aac」、「flac」和「pcm」。\n",
    "\n",
    "- Opus：適用於網路串流和通訊，低延遲。\n",
    "- AAC：數位音訊壓縮格式，被YouTube、Android和iOS偏好使用。\n",
    "- FLAC：無損音訊壓縮格式，被音響愛好者用於存檔。\n",
    "- WAV：無壓縮的WAV音訊，適合低延遲應用以避免解碼開銷。\n",
    "- PCM：類似WAV，但是以24kHz的原始樣本（16位有符號、低字節序）呈現，無標頭。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51d1e35-5d0d-4a1b-a8d1-de549177596c",
   "metadata": {},
   "source": [
    "## 回家作業1: 英文音檔 -> 中文音檔  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651d4ee1-d724-429d-b85f-2a97c4d01941",
   "metadata": {},
   "source": [
    "1. Whisper: 音檔轉文字\n",
    "2. GPT: 翻譯成全中文，system prompt: 英文術語 -> 中文術語 的對應"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ec0b23-08c6-4fcc-946d-36ee03b5075e",
   "metadata": {},
   "source": [
    "## Ollama\n",
    "\n",
    "This package enables you using open-source LLM with ease.\n",
    "\n",
    "We borrow the content from last week\n",
    "\n",
    "https://medium.com/@abonia/running-ollama-in-google-colab-free-tier-545609258453\n",
    "\n",
    "- curl https://ollama.ai/install.sh | sh\n",
    "- ollama serve &\n",
    "- ollama pull llama3:8b\n",
    "- ollama pull dolphin-llama3:8b\n",
    "- ollama pull huihui_ai/qwen2.5-abliterate:14b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3fd597a5-1f65-4b5d-935d-5bc97fb2ad0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For my columns during the back-to-school season, I thought it would be useful to go over the state of public education in America. This series will be similar to the one I wrote on parenting a few months back in that it will be wide-ranging in subject, so please bear with me.\n",
      "This past spring, Turnitin, a company that makes anti-cheating tools to detect the use of A.I. in student papers, released its findings based on more than two hundred million samples reviewed by its software. Three per cent of papers had been more or less entirely written by A.I. and roughly ten per cent exhibited some traces of A.I. It’s never a great idea to rely on data that a for-profit company releases about its own product, but these numbers do not suggest some epidemic of cheating. Other research has shown that there hasn’t been a significant increase in student plagiarism since the unveiling and mass popularization of large language models such as ChatGPT. Students seem to cheat a lot, generally—up to seventy per cent of students reported at least one instance of cheating in the past month—but they cheated at the same rates before the advent of A.I.\n",
      "What has increased is the number of teachers and adults who seem convinced that all the kids are cheating. A study by the Center for Democracy and Technology found that “a majority of teachers still report that generative AI has made them more distrustful of whether their students’ work is actually theirs.” Such suspicions have been paired with real questions about the efficacy of A.I.-detection tools, including one concerning finding that showed A.I. detectors were more likely to flag the writing of non-native English speakers. This uncertainty, along with the failure of many school districts to implement a clear and comprehensive A.I. policy, has led to another layer of debate among educators about how to handle instances of alleged cheating. A set of guidelines on the use of Turnitin, which was recently released by the Center for Teaching Excellence at the University of Kansas, warned teachers against making “quick judgments” based on the company’s software and recommended that educators instead “take a few more steps to gather information,” including comparing previous examples of the student’s work, offering second chances, and talking to the student. (Earlier this month, the Wall Street Journal reported that OpenAI, the company that developed ChatGPT, had built its own detection tool, which was much more accurate than its competitors’ software, but had held off releasing it, because admitting that students did indeed use ChatGPT to cheat might be bad for business.)\n",
      "Educational data is notoriously unreliable. There’s a whole lot of it—kids take tests every day and have nearly every part of their educational journeys tracked from the age of five—but, if you dig into many education studies, you’ll find a whole lot of noise and almost no signal. When trying to parse what, for example, a small increase in statewide reading scores might mean about the efficacy of a given program, the best one can do is look at the data, try to eyeball some larger trend, and then present it somewhat halfheartedly. Here’s what I believe is happening in schools with ChatGPT: teachers are probably a little overly suspicious of students, in part because they have been given tools to catch cheaters. Those panoptic tools have likely scared some students straight, but cheats are going to cheat. When I was in high school, graphing calculators were blamed for student cheating. Ten years later, the ubiquity of cell phones in classrooms stirred up visions of kids across the country texting one another test answers whenever a teacher’s back was turned. Wikipedia also had its moment as the destroyer of research and knowledge in schools; today, it’s clear that Wikipedia has been a net good for society and probably more accurate and less biased than the Encyclopædia Britannicas it replaced.\n",
      "The situation reminds me of the problem with sports-gambling apps. Gambling, like plagiarism, isn’t new. If you stick a hundred people who have never placed a bet in their lives in a casino, a small number of them will come back the next day, and the next, and the next. The rest will either never bet again or gamble only occasionally and in a responsible manner. Cheating in school strikes me as a similar phenomenon—maybe it’s true that most kids engage in a little bit of unethical schoolwork, but some portion of kids never will and many more likely do so only in the most trivial (or trying) situations. Technology does change the experience; it can encourage edge cases to start tossing dice at a craps table or asking ChatGPT to write a paper. But, for the most part, it’s not why adults gamble on sports or why kids cheat at school. And just as Wikipedia didn’t ruin the written word—and likely deepened the research of many student papers by simplifying the introductory task of getting to know a subject—the five-paragraph essay will survive large language models.\n",
      "The rush to solve A.I. cheating and the myriad educational tools that have been developed and sold to schools across the country raise a tertiary, and far more interesting, question than whether or not the written word will survive. When we think about students’ work, where do we draw the line between what has sprung out of their developing mind and what has not?\n",
      "In STEM subjects, the lines are a little clearer. If a student just looks over a neighbor’s shoulder and writes down the same answer, most people agree that’s cheating. But if a student is trying to prove that he understands how to solve a complicated math problem that involves some multiplication, does the use of a calculator mean that the student is cheating? He is not being tested on whether he knows how to multiply or not, so why waste time and potentially introduce careless errors? I do not think that having ChatGPT write a paper is the same thing as using a calculator for more menial and elementary tasks within a larger math problem, but it’s worth asking why we feel differently about the automation of research and the written word. Even in the fine arts, patrons and appreciators have long accepted that the artist doesn’t need to actually perform each brushstroke, construct every sculpture, or build every bit of a large installation. Small armies of uncredited assistants have their hands all over the works of Andy Warhol, Damien Hirst, and Jeff Koons, which has kicked up periodic controversies, but not enough to end the practice. Would we think less of these artists if a machine just did all of the assistants’ work?\n",
      "These questions are abstract and ridiculous, but they also reflect the arbitrary way in which we think about what constitutes cheating and what does not. Outside of blatant acts of plagiarism, the line between cheating and not cheating in the humanities seems to rely on the amount of time it takes to complete a task. For example, if a student visited a library archive to research what happened in the week after D Day, spooled some microfiche into an ancient machine, and dutifully jotted down notes, we would likely think more highly of that effort than if the student found the same article in a Google search, and certainly more so than if he paraphrased some Wikipedia editor’s reading of that article.\n",
      "Under this logic, school isn’t about creating new scholarship or answering questions correctly—it’s about teaching proper work habits. A young person who takes the time to go into a library is more likely to develop the types of work habits that will allow him to find accompanying bits of information that might be useful in creating a novel, an algorithm, or a convincing argument. Setting aside the obvious offense of dishonesty, the problem with cheating isn’t so much that the student skips over the process of explaining what they learned—it’s that they deprive themselves of the time-consuming labor of actually reading the book, typing out the sentences, and thinking through the prompt.\n",
      "One of the fundamental crises that the Internet brought to classrooms was the sense that, because references to facts and history no longer needed to be stored in your brain, nothing really needed to be learned anymore. Search engines, Wikipedia, and ChatGPT all demanded the same explanation: If we have these tools, what’s the point of these lessons? Schools tend to change slowly, even if education trends come and go. This is a good thing and mostly owes to the fact that good teachers tend to have long careers. But, since the days when I was a teacher, in the mid-two-thousands, I’ve noticed a subtle shift in the way people think about what kids should learn in the humanities. The idea of memorization, for the most part, has gone away; children are no longer forced to rattle off the date of the First Defenestration of Prague (1419) or commit the same lists of vocabulary words to memory. At the same time, most of the political fights that people get into over schools these days hinge on curriculum choices, which have always struck me as both silly and wildly beside the point. It’s actually pretty hard to shake a child’s beliefs with a stray book or lesson. But I sometimes wonder if the doctrinaire push in today’s schools, the intense fights over how to teach history or math, the censorious book bans in some states, come from a collective fear that the knowledge-retention part of school might now be outdated. Since it’s hard to justify why kids should learn dates and vocabulary words and the like, we have subtly shifted the purpose of school to teaching them what to believe and how to go through life as a good person. This is an admirable goal but will usually end in bitter conflict over which values matter.\n",
      "Opinions in education, as a rule, move very quickly and oftentimes in a reactionary way. But the actual implementation of any consensus can take decades to complete. This inefficiency can be harmful—it’s taken far too long to remove phones from schools, for example—but it also allows for little panics like the current one around large-language-model cheating. I do not think A.I. encourages cheating in some revolutionary way, and I imagine any rise in plagiarism might have more to do with the extraordinary pressure of college admissions and the overly competitive atmosphere in many high schools. Until that changes, some population of kids will convert any new app into a cheating tool, educational technology will sell blockers, and the cycle will just repeat itself. It doesn’t have to be this way. The A.I.-cheating panic gives us a chance to reëmphasize the work-habit part of schooling and to walk away from claims that the books that children read are somehow dangerous or that only one version of history can be taught. This, it should be said, is not so different from the way that thousands of teachers across the country already think about their jobs, but the work part of school has become far more gauche than it used to be, with schools across the country eliminating homework and focussing more on developing a student’s love of a subject or the implied politics of a curriculum. A little revanchism, such as in-class essays written with a paper and pencil in elementary and middle school, might go a long way. The lesson is almost always the actual doing of the lesson, not the facts that are learned. ♦\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from torch import cuda\n",
    "from langchain.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.runnables import Runnable, chain\n",
    "\n",
    "from src.io.path_definition import get_project_dir\n",
    "\n",
    "filename = \"does-ai-really-encourage-cheating-in-schools.txt\"\n",
    "\n",
    "filename_path = os.path.join(get_project_dir(), 'tutorial', 'LLM+Langchain', 'Week-5', filename)\n",
    "\n",
    "with open(filename_path, \"r\", encoding=\"utf8\") as file:\n",
    "    cleaned_text = file.read()\n",
    "    \n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51fd4ee2-e439-4358-9a67-c91c6330c6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1024\n",
    "chunk_overlap = 128\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "\n",
    "documents = text_splitter.create_documents([cleaned_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e3d7f97-f573-4350-a946-4a6a8af963df",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"You are a helpful AI assistant with excellent writing skill\"\n",
    "\n",
    "# PromptTemplate(template=system_template)\n",
    "\n",
    "def build_standard_chat_prompt_template(kwargs) -> Runnable:\n",
    "    messages = []\n",
    "    \n",
    "    for key in ['system', 'human']:\n",
    "        if kwargs.get(key):\n",
    "            if key == 'system':\n",
    "                system_content = kwargs['system']\n",
    "                system_prompt = PromptTemplate(**system_content)\n",
    "                message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "            else:\n",
    "                human_content = kwargs['human']\n",
    "                human_prompt = PromptTemplate(**human_content)\n",
    "                message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "            messages.append(message)\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "    \n",
    "    return chat_prompt\n",
    "\n",
    "\n",
    "@chain\n",
    "def build_summary_prompt_template(kwargs):\n",
    "\n",
    "    input_ = {\"system\": {\"template\": system_template},\n",
    "              \"human\": {\"template\": \"\"\"\n",
    "                                    Please create a summary given the following context:\n",
    "                                    {text}.\n",
    "                                    \"\"\",\n",
    "                        \"input_variables\": ['text']}\n",
    "            }\n",
    "\n",
    "    return build_standard_chat_prompt_template(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79c5f546-eccf-4a24-a3e9-0229a454d529",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [23:27<00:00, 82.78s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "stop_token_ids = None\n",
    "model_id = \"dolphin-llama3:8b\"\n",
    "\n",
    "device = f\"cuda:{cuda.current_device()}\" if cuda.is_available() else 'cpu'\n",
    "\n",
    "model = ChatOllama(model=model_id, temperature=0)\n",
    "\n",
    "summary_pipeline = build_summary_prompt_template | model | StrOutputParser()\n",
    "\n",
    "text_as_list = []\n",
    "for document in tqdm(documents):\n",
    "    content = summary_pipeline.invoke({\"text\": document.page_content})\n",
    "    text_as_list.append(content)\n",
    "\n",
    "final_text = \"\\n\".join(text_as_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05a034f8-82cb-4784-ad35-f6d10fe01c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The text discusses the impact of AI on public education in America, focusing on issues such as cheating and plagiarism. Despite concerns about AI-assisted cheating, there hasn't been a significant increase in student plagiarism since the introduction of large language models like ChatGPT. However, the use of AI has led to increased skepticism among teachers regarding their students' work. A guideline from the University of Kansas advises teachers not to make hasty judgments based on AI-detection tools and instead approach such situations cautiously. The text also explores parallels between cheating in school and gambling, suggesting that both behaviors have been present throughout history. It highlights the need for clear boundaries in assessing students' academic contributions and emphasizes the importance of teaching children without fear-mongering or imposing a single version of history.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_pipeline.invoke({\"text\": final_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b62f1db-84f3-4f3c-b529-7d13355a64af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
