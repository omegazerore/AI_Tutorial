{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bd96bd9-7ca2-4fd8-ab9a-7058e13e5264",
   "metadata": {},
   "source": [
    "# Data Analysis and Process\n",
    "\n",
    "## Student t-test\n",
    "\n",
    "Fundamental statistic application: How do you know your assumption is valid? Or how confident you are to your assumption? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cd75a5-5ded-48dc-94a7-efd2396da6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, IFrame\n",
    "\n",
    "Image(url= \"https://www.scribbr.com/wp-content/uploads/2022/06/t-table-interpretation-l.webp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5a9fae-28be-4e04-bf74-fc79638dab62",
   "metadata": {},
   "source": [
    "Example 1:\n",
    "\n",
    "https://www.statology.org/when-to-reject-null-hypothesis/\n",
    "\n",
    "A one sample t-test is used to test whether or not the mean of a population is equal to some value.\n",
    "\n",
    "For example, suppose we want to know whether or not the mean weight of a certain species of turtle is equal to 310 pounds.\n",
    "\n",
    "We go out and collect a simple random sample of 40 turtles with the following information:\n",
    "\n",
    "Sample size n = 40\n",
    "\n",
    "Sample mean weight x = 300\n",
    "\n",
    "Sample standard deviation s = 18.5\n",
    "\n",
    "We can use the following steps to perform a one sample t-test:\n",
    "\n",
    "Question:\n",
    "\n",
    "H0: μ = 310 (population mean is equal to 310 pounds)\n",
    "\n",
    "HA: μ ≠ 310 (population mean is not equal to 310 pounds)\n",
    "\n",
    "<br>\n",
    "\n",
    "單樣本 t 檢定用於測試一個母體的平均值是否等於某個特定值。\n",
    "\n",
    "例如，假設我們想知道某種海龜的平均體重是否等於 310 磅。\n",
    "\n",
    "我們隨機抽取了 40 隻海龜的簡單隨機樣本，並獲得以下信息：\n",
    "\n",
    "樣本數量 n = 40\n",
    "\n",
    "樣本平均體重 x = 300\n",
    "\n",
    "樣本標準差 s = 18.5\n",
    "\n",
    "我們可以使用以下步驟來執行單樣本 t 檢定：\n",
    "\n",
    "假設：\n",
    "\n",
    "H0: μ = 310 (母體平均值等於 310 磅)\n",
    "\n",
    "HA: μ ≠ 310 (母體平均值不等於 310 磅)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c49fc-6aac-4ecf-99d7-e3b76e179a13",
   "metadata": {},
   "source": [
    "### 1. Compute the t-value\n",
    "\n",
    "$$\n",
    "\\text{Distribution} \\sim N\\left(\\mu, \\frac{s}{\\sqrt{n}}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08e27ca-4271-4d69-8962-dd498fe5ecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = 300\n",
    "mu = 310\n",
    "s = 18.5\n",
    "n = 40\n",
    "\n",
    "z_score = (x - mu)/(s/np.sqrt(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc80b88-6959-46d8-9b94-602783ed6569",
   "metadata": {},
   "source": [
    "table: https://www.medcalc.org/manual/t-distribution-table.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a32e69-f9ea-4bec-b9be-df5bd8c0468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_of_freedom = n - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bec6fc-5639-4c4e-894a-3062257a34b1",
   "metadata": {},
   "source": [
    "Say... We want a 95% confidence interval\n",
    "\n",
    "$${t_{0.025, 39}} = 2.023$$\n",
    "\n",
    "Because $|z_score| > {t_{0.025, 39}}$ , we reject the hypothesis H0\n",
    "\n",
    "On the other hand, if $|z_score| <{t_{0.025, 39}}$, we said that we do not reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06056e83-069b-4312-a3a7-c1b823de5be7",
   "metadata": {},
   "source": [
    "### Confidence Interval\n",
    "\n",
    "Select, say, two-sides 95% confidence interval\n",
    "\n",
    "$$\\text{lower limit} = x - {t_{0.025, 39}} * \\frac{s}{\\sqrt{n}} $$\n",
    "\n",
    "$$\\text{upper limit} = x + {t_{0.025, 39}} * \\frac{s}{\\sqrt{n}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143eaa1f-37e2-463d-969e-a4924b5a5cf5",
   "metadata": {},
   "source": [
    "https://nulib.github.io/moderndive_book/ismaykimkuyper_files/figure-html/N-CIs-1.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea938d98-ec4a-4cfd-91e4-b0e775daa20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_n = s/np.sqrt(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12114d2-d4be-4e09-80ee-c2416c6e160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_limit = 300 - 2.2023 * s_n\n",
    "\n",
    "upper_limit = 300 + 2.2023 * s_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81b752d-2f85-4e49-a5c9-0021b55a0fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929fb724-477a-455b-a7d9-edbfbb049a56",
   "metadata": {},
   "source": [
    "### If we reduce the the number of samples, the uncertainty increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a5e5a-4ef0-4397-83e7-802514efe36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 300\n",
    "mu = 310\n",
    "s = 18.5\n",
    "n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbed69b-b3f1-43dc-ad21-26976f616eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score = (x - mu)/(s/np.sqrt(n))\n",
    "\n",
    "s_n = s/np.sqrt(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8467972-2806-4139-9569-1bd915c05cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 2.262\n",
    "\n",
    "s_n = 5.85\n",
    "\n",
    "upper_limit = 300 + z * s_n\n",
    "lower_limit = 300 - z * s_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bcf1f2-f0f9-4dfb-a307-e9919588b087",
   "metadata": {},
   "source": [
    "- Looking up the z-value in a table can be time-consuming and we might not always find the exact value we need. Can we automate this process with a program?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d535141-42a5-482b-90ec-c3837b36cb78",
   "metadata": {},
   "source": [
    "### scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8977ffa5-22ca-4aa0-982f-c4e5aaab0155",
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(src=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.t.html\", height=500, width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57a7a0c-2fd9-4cff-aff7-6da242a98ced",
   "metadata": {},
   "source": [
    "$$\n",
    "q = (1 - \\text{confidence interval})/2 \\quad \\text{or} \\quad q = 1 - \\frac{1 - \\text{confidence}}{2} = \\frac{1 + \\text{confidence}}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e1e0af-8554-4fb5-a006-2536be2718d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "stats.t.ppf(0.025, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282a951d-63e9-496c-88f8-7162a7b3e5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_hypothesis_fn(mean_sample, mean_hypothesis, std, sample_size, confidence):\n",
    "\n",
    "    \"\"\"\n",
    "    Performs a one-sample t-test to determine whether to reject the null hypothesis.\n",
    "\n",
    "    Parameters:\n",
    "    mean_sample (float): The mean of the sample data.\n",
    "    mean_hypothesis (float): The hypothesized population mean.\n",
    "    std (float): The standard deviation of the sample data.\n",
    "    sample_size (int): The number of samples.\n",
    "    confidence (float): The confidence level for the test (e.g., 0.95 for 95% confidence).\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - reject (bool): Whether the null hypothesis is rejected.\n",
    "        - lower_limit (float): The lower limit of the confidence interval.\n",
    "        - upper_limit (float): The upper limit of the confidence interval.\n",
    "        - z_score (float): The t-statistic calculated for the test.\n",
    "        - t (float): The critical t-value for the given confidence level and degrees of freedom.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the standard error of the mean\n",
    "    s_n = std/np.sqrt(sample_size)\n",
    "\n",
    "    # Calculate the t-statistic\n",
    "    z_scopre = (mean_sample - mean_hypothesis)/(s_n)\n",
    "\n",
    "    # Calculate the critical t-value for the given confidence level\n",
    "    q = (1+confidence)/2\n",
    "    df = sample_size - 1\n",
    "    t = stats.t.ppf(q, df)\n",
    "\n",
    "    # Determine whether to reject the null hypothesis\n",
    "    if abs(z_score) > t:\n",
    "        reject = True\n",
    "    else:\n",
    "        reject = False\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    upper_limit = mean_hypothesis + t * s_n\n",
    "    lower_limit = mean_hypothesis - t * s_n\n",
    "\n",
    "    return reject, lower_limit, upper_limit, z_score, t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7a4529-2684-4b28-bcab-06d819299fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_hypothesis_fn(mean_sample=300, mean_hypothesis=310, std=18.5, sample_size=40, confidence=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb871c83-e129-4089-be56-4773fe7a2ace",
   "metadata": {},
   "source": [
    "- How to calculate statistics such as mean and standard deviation, and determine the sample size when provided with a file?\n",
    "\n",
    "### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b4ae40-ab7a-42cb-8919-6d49d8d2f904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "temperature_df = pd.read_excel(\"Data.xlsx\", sheet_name='Temperature', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62efa45b-26bd-42f7-a554-0ee7dfef25d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95b419b-e90f-4f11-b86f-d0b6e6bfc068",
   "metadata": {},
   "source": [
    "#### mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e451be6e-0358-437d-abbe-d3791d0ebca4",
   "metadata": {},
   "source": [
    "- After executing this line, you'll obtain a Series where each element corresponds to the mean temperature of a city across all months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89f4b22-cacd-44df-8968-99da6011c6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2da0eb-a791-4c61-a3e1-d6985724cce0",
   "metadata": {},
   "source": [
    "- After executing this line, you'll obtain a Series where each element corresponds to the mean temperature of a specific month averaged across all cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea39d2c-74b8-4aef-9d77-2f181cdaa13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb1848e-6503-4f30-a448-9f98a8688baa",
   "metadata": {},
   "source": [
    "#### sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe96ea20-9bf0-4ccd-bd39-9141815f4930",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_df.mean(axis=1).sort_values(ascending=False).index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4f8803-d6e4-4cdb-ad4a-5498dbb214d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_df.mean(axis=1).sort_values(ascending=True).index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0ceabe-60cd-42d7-84c8-b926f879a3f5",
   "metadata": {},
   "source": [
    "#### std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f56bd34-e989-446f-bdc5-847ebccadaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_df.std(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4fabab-b364-42b0-af15-de981f4a3de2",
   "metadata": {},
   "source": [
    "#### count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d571a53b-9bf7-4af0-9170-e7099af77856",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = temperature_df.shape[0]\n",
    "num_cols = temperature_df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f7006a-9bc0-4987-ba0b-ee6e5a3c03a4",
   "metadata": {},
   "source": [
    "#### filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca5e06a-bff0-4cbc-9eab-eb8d9e1c243f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temperature_df.filter(like='J')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef77b9ce-c237-4a15-a14f-884d3a027e39",
   "metadata": {},
   "source": [
    "#### apply\n",
    "\n",
    "- Apply a function along an axis of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc8ed49-a74f-4b64-b4d1-45a380608d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temperature_df['Jan'].apply(lambda x: x + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df914f1c-2f41-4214-97c8-4eee5e223d85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fn(x):\n",
    "    \n",
    "    return x + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d6ddaf-7bb0-44aa-8ff8-b8e6f3929add",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temperature_df['Jan'].apply(lambda x: fn(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4dae12-8961-4ac4-b029-eb1ea3bc9aad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fn_2(x):\n",
    "    \n",
    "    return x + 10, x + 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0d534f-5fc1-43f0-9e16-21319bbf12cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temperature_df[['Jan']].apply(lambda x: fn_2(x[0]), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357bf08c-f65b-4802-b221-98352ee9f829",
   "metadata": {},
   "source": [
    "#### Merge\n",
    "\n",
    "- The merge function in Pandas is similar to SQL joins. It combines two DataFrames based on one or more keys.\n",
    "- The join is done on columns or indexes. If joining columns on columns, the DataFrame indexes will be ignored. Otherwise if joining indexes on indexes or indexes on a column or columns, the index will be passed on. When performing a cross merge, no column specifications to merge on are allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e6a545-c723-4d2c-a3ec-3f84c7ebbe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two DataFrames\n",
    "df1 = pd.DataFrame({\n",
    "    'employee_id': [1, 2, 3, 4],\n",
    "    'name': ['John', 'Anna', 'Peter', 'Linda']\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'employee_id': [3, 4, 5, 6],\n",
    "    'department': ['HR', 'Finance', 'IT', 'Operations']\n",
    "})\n",
    "\n",
    "# Merge the DataFrames on 'employee_id'\n",
    "merged_df = pd.merge(df1, df2, on='employee_id', how='inner')\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516a6c2d-11ce-4eec-8f5d-bd4bf1207801",
   "metadata": {},
   "source": [
    "#### Concatenate\n",
    "\n",
    "- The concatenate function in Pandas is used to append DataFrames along a particular axis (either rows or columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c4c007-5656-4b66-beaa-a9527791e067",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create two DataFrames\n",
    "df3 = pd.DataFrame({\n",
    "    'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "    'B': ['B0', 'B1', 'B2', 'B3']\n",
    "})\n",
    "\n",
    "df4 = pd.DataFrame({\n",
    "    'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "    'B': ['B4', 'B5', 'B6', 'B7']\n",
    "})\n",
    "\n",
    "# Concatenate DataFrames along rows\n",
    "concat_df = pd.concat([df3, df4], axis=0)\n",
    "print(concat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b8c17d-0873-4780-b891-cdb901f53ca1",
   "metadata": {},
   "source": [
    "#### Join\n",
    "\n",
    "- The join function in Pandas is used to combine two DataFrames on the index or on a key column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac26b7f-7b43-4bc1-97c5-22b18a549968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two DataFrames\n",
    "df5 = pd.DataFrame({\n",
    "    'A': ['A0', 'A1', 'A2'],\n",
    "    'B': ['B0', 'B1', 'B2']\n",
    "}, index=['K0', 'K1', 'K2'])\n",
    "\n",
    "df6 = pd.DataFrame({\n",
    "    'C': ['C0', 'C1', 'C2'],\n",
    "    'D': ['D0', 'D1', 'D2']\n",
    "}, index=['K0', 'K2', 'K3'])\n",
    "\n",
    "# Join the DataFrames\n",
    "joined_df = df5.join(df6, how='inner')\n",
    "print(joined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10453ac-9ae0-4ee3-b0e2-528649f075f0",
   "metadata": {},
   "source": [
    "#### difference between `Merge` & `Join`\n",
    "\n",
    "- merge\n",
    "    - Purpose: The merge method is designed to combine DataFrames based on one or more keys (columns) that can be specified.\n",
    "    - Usage: merge is very flexible and allows for different types of joins: inner, outer, left, and right joins.\n",
    "    - Syntax: pd.merge(left, right, on='key', how='inner')\n",
    "    - Default Join: The default join type is an inner join.\n",
    "    - Column-based: Primarily used to join on columns.\n",
    "    \n",
    "- join\n",
    "    - Purpose: The join method is mainly used to combine DataFrames based on their indices.\n",
    "    - Usage: join is convenient when you want to combine DataFrames on their index or a key column.\n",
    "    - Syntax: df1.join(df2, how='left')\n",
    "    - Default Join: The default join type is a left join.\n",
    "    - Index-based: Primarily used to join on indices but can also join on a key column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e559537f-2753-4124-ad0d-c2ea21d579ed",
   "metadata": {},
   "source": [
    "#### pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b868728e-3ac2-4780-9366-4d9353ed1863",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Date': ['2024-01-01', '2024-01-01', '2024-01-02', '2024-01-02', '2024-01-03', '2024-01-03'],\n",
    "    'City': ['New York', 'Los Angeles', 'New York', 'Los Angeles', 'New York', 'Los Angeles'],\n",
    "    'Sales': [250, 200, 300, 220, 310, 210],\n",
    "    'Expenses': [150, 180, 190, 210, 160, 200]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b47682f-6393-4f9e-99e7-1ea9dd736954",
   "metadata": {},
   "source": [
    "Let's create a pivot table to summarize the total sales and expenses by city and date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d4ea8-131d-469c-9aca-ab9c3528abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = pd.pivot_table(df, \n",
    "                             values=['Sales', 'Expenses'], \n",
    "                             index=['Date'], \n",
    "                             columns=['City'], \n",
    "                             aggfunc='sum')\n",
    "\n",
    "print(pivot_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
