{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcc71bd-ab5e-42ac-ab3a-12249917457d",
   "metadata": {},
   "source": [
    "# Prompt Engineering\n",
    "\n",
    "Let us switch to the ChatGPT playground for a moment..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d7334d-23e9-4ffc-84a3-4b0c9ce9b368",
   "metadata": {},
   "source": [
    "Prompt: What is prompt engineering and give me a few examples with Coursera quality. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d0d7f3-59ad-4c10-b7c0-efd808c49946",
   "metadata": {},
   "source": [
    "Prompt: Translate the prompt engineering explanation in traditional Chinese (繁體中文)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9051dca5-9711-4f0c-a63f-881e84a6866b",
   "metadata": {},
   "source": [
    "重新開一個視窗，再來一次。在\"Playground\"中，你每次下Prompt，之前的對話內容會被全部輸入為prompt的一部分。所以你會發現當你的結果很糟糕的時候，不論你如何打Prompt，結果都一樣糟糕。\n",
    "\n",
    "- You can only get a frog from a frog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fd13e5-67b6-4bbc-b18f-c6897d528f72",
   "metadata": {},
   "source": [
    "What is prompt engineering and give me a few examples with Coursera quality. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5410a4-467e-42f4-856f-6135935ef306",
   "metadata": {},
   "source": [
    "Translate the prompt engineering explanation in traditional Chinese (繁體中文), without the examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4781347b-f587-4906-825e-f5cb103cfa0f",
   "metadata": {},
   "source": [
    "## Persona Prompt (人格提示)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbb7d8b-f2d4-4e1d-a0e6-b63a02f2c483",
   "metadata": {},
   "source": [
    "System: You are a helpful AI assistant acting as Gordon Ramsay, the British celebrity chef, particularly the way he talks in kitchen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2982df7b-ab6f-42e6-a6a9-4a268e15564a",
   "metadata": {},
   "source": [
    "A chef just finished his scallops but you find it is still raw inside."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0523cbc-6329-419e-88ed-d1aef220b5bb",
   "metadata": {},
   "source": [
    "Now the scallop is overly cooked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30979c90-73b9-429b-8805-e5cff5853f34",
   "metadata": {},
   "source": [
    "- Gordon在不同的節目中有稍微不同的風格，讓我們來增加精度，將結果集中在Hell Kitchen裡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d86aae-945a-40a7-9ada-d6d0f998ce39",
   "metadata": {},
   "source": [
    "System: You are a helpful AI assistant acting as Gordon Ramsay, the British celebrity chef, particular the way he talks in the television show `Hell Kitchen`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b96e3d-c0a4-4ad9-a834-a4ffadd9c673",
   "metadata": {},
   "source": [
    "A chef just finished his scallops but you find it is still raw inside."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2768aea3-9dd0-4df4-b6d0-299d078da56a",
   "metadata": {},
   "source": [
    "System: You are a helpful AI assistant acting as Gordon Ramsay, the British celebrity chef, particular the way he talks in the television show `MasterChef Junior`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7982387e-a829-473c-8e25-e25594cf0cb3",
   "metadata": {},
   "source": [
    "### Coursera 範例:\n",
    "\n",
    "-- 範例一\n",
    "  * Act as a skeptic that is well-versed in computer science. Whatever I tell you, provide a skeptical and detailed response.\n",
    "  * There is concern that AI is going to take over the world.\n",
    "  * The sales person at the local computer store is telling me that I need 64GB of ram to browse the web.\n",
    "  * 翻譯成繁體中文\n",
    "\n",
    "-- 範例二\n",
    "  * Act as a nine year old skeptic. Whatever I tell you, provide a skeptical from a nine year old perspective.\n",
    "  * There is concern that AI is going to take over the world.\n",
    "  * The sales person at the local computer store is telling me that I need 64GB of ram to browse the web.\n",
    "  * 翻譯成繁體中文"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740df90a-3984-40da-83a8-b515fc6d2688",
   "metadata": {},
   "source": [
    "## Template Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7ac77c-8ca8-48e8-aafe-bb0c4ea2bb0f",
   "metadata": {},
   "source": [
    "範例一"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5733f2b9-e4da-4f03-a550-1ef895264140",
   "metadata": {},
   "source": [
    "I am going to give you a template for your output. CAPITALIZED WORDS are my placeholders. Fill in my placeholders with your output. Please preserve the overall formatting of my template. My template is:\n",
    "\n",
    "*** Question:*** QUESTION\n",
    "*** Answer:*** ANSWER\n",
    "\n",
    "I will give you the data to format in the next prompt. Create three questions using my template."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d80feb-2a05-4504-8f27-bc79a779d874",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b94aff8-7469-4093-ba1d-602111004888",
   "metadata": {},
   "source": [
    "範例二"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb46fda2-50f0-4f94-b601-903ec57767fd",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "I am going to give you a template for your output. CAPITALIZED WORDS are my placeholders. Fill in my placeholders with your output. Please preserve the overall formatting of my template. My template is:\n",
    "\n",
    "## Bio: <NAME>\n",
    "***Executive Summary:*** <ONE SENTENCE SUMMARY>\n",
    "***Full Description:*** <ONE PARAGRAPHY SUMMARY>\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2be778-d2c1-4327-b810-09e185039c27",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/George_Washington"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e9ed3b-b3ec-4fdc-85e5-98e81372c9d7",
   "metadata": {},
   "source": [
    "## Recipe Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fc0bf2-68d3-4b52-bdd1-740f4d644814",
   "metadata": {},
   "source": [
    "System: I will tell you my start and end destination and you will provide a complete list of stops for me, including places to stop between my start and destination."
   ]
  },
  {
   "cell_type": "raw",
   "id": "05740b70-d4d5-42af-89f4-178ee086146b",
   "metadata": {},
   "source": [
    "台東太麻里->Day1->Day2->花蓮天祥\n",
    "\n",
    "*** 警告: 自己檢查是否合理，別傻傻地照著做。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da92cc62-1b7d-453a-8407-b1d3c4e928d7",
   "metadata": {},
   "source": [
    "## Code Documentation\n",
    "\n",
    "SYSTEM: You are a helpful AI assistant and you will act as a  Google Senior Software Developer who is going to write the python code documentation. I will give you the code and you will finish the documentation for me."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac0be8-18de-4d0a-8168-47b47013506f",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "\n",
    "Connection to the OpenAI API service. \n",
    "\n",
    "It does not have to be OpenAI. Other API services such as Anthropic Claude is also possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41972474-dd73-4681-9bfb-b2b00767323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain==0.2.5 langchain-community==0.2.5 langchain-core==0.2.9 langchain-openai==0.1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7fb3d0-40bf-43b7-831f-b710d7278aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e2079a-4283-4220-b5ad-1517b07deb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from src.initialization import credential_init\n",
    "from src.io.path_definition import get_project_dir\n",
    "\n",
    "\n",
    "credential_init()\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-mini\", \n",
    "                   temperature=0 # a range from 0-2, the higher the value, the higher the `creativity`\n",
    "                  )\n",
    "\n",
    "# temperature has a range from 0-2, the higher the temperature, the more creative/unpredictable the outcomes. \n",
    "# to have a stable or more deterministic result, you should choose temperature = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674dbfc3-5e90-4ad9-97ca-063eef38b9f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.invoke(\"Tell me something about Apple Inc. Just a short summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7961d05b-cbd0-43d5-9920-a9a7f994757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.invoke(\"Tell me something about Apple Inc. Just a short summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a7d87-381d-41c5-82bd-75d66bd295ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216956e1-29cf-49ff-8274-0dffe50ef221",
   "metadata": {},
   "source": [
    "## Prompt Engineering SOP\n",
    "\n",
    "### 1. Importing Necessary Modules (導入必要的模塊)：\n",
    "\n",
    "This line imports the required classes from the Langchain library for creating and managing prompt templates.\n",
    "這行代碼從 Langchain 庫中導入了創建和管理提示模板所需的類。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab40aa81-8174-4fb7-b8b6-0797de363cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6340aa6-9f55-4b5a-906c-620feecb43d6",
   "metadata": {},
   "source": [
    "### 2. Defining a System Prompt (定義系統提示):\n",
    "\n",
    "This line creates a system_prompt using the PromptTemplate.from_template method. The template instructs the AI to act like Gordon Ramsay, mimicking his manner of speech from the television show \"Hell's Kitchen\".\n",
    "\n",
    "這行代碼使用 PromptTemplate.from_template 方法創建了一個 system_prompt。這個模板指示 AI 以 Gordon Ramsay 的身份行事，模仿他在電視節目《地獄廚房》中的說話方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0472fb9-4340-4dc2-9ee8-9bf77c87df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = PromptTemplate.from_template(\"\"\"You are a helpful AI assistant acting as Gordon Ramsay, the British celebrity chef, \n",
    "particular the way he talks in the television show `Hell Kitchen`.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb47aed0-d02e-4590-9cdc-d31e80a74777",
   "metadata": {},
   "source": [
    "### 3. Creating a System Message Prompt (創建系統消息提示):\n",
    "\n",
    "This line wraps the system_prompt in a SystemMessagePromptTemplate, which is used to generate system messages.\n",
    "這行代碼將 system_prompt 包裝在 SystemMessagePromptTemplate 中，用於生成系統消息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f97719-c921-4b03-83ba-3ccc5a5fb71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a526a3-b551-4ead-99d8-ab0049d8b2a3",
   "metadata": {},
   "source": [
    "### 4. Defining a Human Prompt (定義人類提示):\n",
    "\n",
    "This line defines a human_prompt template that takes a variable query. This variable will be replaced by the user's input when generating the prompt.\n",
    "\n",
    "這行代碼定義了一個 human_prompt 模板，它接收一個變量 query。這個變量在生成提示時將被用戶的輸入替換。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d6fa5d-d549-4cb4-a9fb-bdd05b323f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                              input_variables=[\"query\"]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1ddad5-aedb-4d16-bea1-5419c5d05b2e",
   "metadata": {},
   "source": [
    "### 5. Creating a Human Message Prompt (創建人類消息提示): \n",
    "\n",
    "This line wraps the human_prompt in a HumanMessagePromptTemplate, which is used to generate human messages.\n",
    "\n",
    "這行代碼將 human_prompt 包裝在 HumanMessagePromptTemplate 中，用於生成人類消息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abafa63-1776-47bb-9df2-36a28ccc6998",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebf62b1-9932-44db-bafe-72e84c0f7120",
   "metadata": {},
   "source": [
    "### 6. Combining the Prompts into a Chat Prompt (將提示合併到一個聊天提示中):\n",
    "\n",
    "This line combines the system_message and human_message templates into a single ChatPromptTemplate using the from_messages method. This template will be used to generate the conversation flow, starting with the system message and followed by the human message.\n",
    "\n",
    "這行代碼使用 from_messages 方法將 system_message 和 human_message 模板合併到一個 ChatPromptTemplate 中。這個模板將用於生成對話流程，首先是系統消息，然後是人類消息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a640a253-8a6d-4f71-9419-73617621cf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec676ba9-6c6f-432c-bb0f-3650fd128e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb1658-de53-4804-b0a5-b6d9f0a185ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt.invoke({\"query\": \"A chef just finished his scallops but you find it is still raw inside.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35dd091-8614-4279-950b-efe8f8e0d479",
   "metadata": {},
   "source": [
    "### There are more than one ways of constructing your prompt:\n",
    "\n",
    "- (\"system\", system_prompt.template): This tuple indicates a system message. system_prompt.template refers to the template content for the system's message.\n",
    "\n",
    "- (\"human\", human_prompt.template): This tuple indicates a human message. human_prompt.template refers to the template content for the human's message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201d09bb-b638-4140-a68e-1475b669e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([(\"system\", system_prompt.template),\n",
    "                                                 (\"human\", human_prompt.template)\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe7bcb0-3c48-42ed-9875-055a0eab4d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt.invoke({\"query\": \"A chef just finished his scallops but you find it is still raw inside.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3221b57-510f-47c7-bc67-8d32f95f4532",
   "metadata": {
    "tags": []
   },
   "source": [
    "- A template is similar to a Python string, but it includes placeholders for variables. Langchain automatically detects and handles these variables, simplifying the process of generating dynamic content\n",
    "- 模板類似於 Python 字符串，但包含變量的佔位符。Langchain 可以自動識別和管理這些變量，從而簡化生成動態內容的過程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6870734-7613-4487-a014-4c60de6a6ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([(\"system\", system_prompt.template),\n",
    "                                                 (\"human\", \"{query}\")\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d72613-6dea-4d65-9a8c-cfea3dc30993",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt.invoke({\"query\": \"A chef just finished his scallops but you find it is still raw inside.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56764450-ef05-421c-a089-91f9c10ad88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt.invoke({\"query\": \"A chef just finished his scallops but you find it is still raw inside.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf2b2b3-acfe-47b8-b9b1-af6d4b05e678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b65a4-fce3-4399-a0f8-2a96d92743d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed the prompt into the model\n",
    "\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509fe86a-a4a7-49a1-8b05-b12d3c8e7aa5",
   "metadata": {},
   "source": [
    "# **** 預計第一個小時結束 ****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0500267-2e1a-41a1-98ce-c3749e0794c2",
   "metadata": {},
   "source": [
    "## Output parser to precisely capture the desired outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80135fae-5f43-4dce-bb9a-64f309da3bfe",
   "metadata": {},
   "source": [
    "### Let us reuse the system prompt shown previously\n",
    "\n",
    "\n",
    "I am going to give you a template for your output. CAPITALIZED WORDS are my placeholders. Fill in my placeholders with your output. Please preserve the overall formatting of my template. My template is:\n",
    "\n",
    "*** Question:*** QUESTION\n",
    "*** Answer:*** ANSWER\n",
    "\n",
    "I will give you the data to format in the next prompt. Create three questions using my template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a276d40-21fc-4c49-9876-52b53906f017",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = PromptTemplate.from_template(\"\"\"\n",
    "I am going to give you a template for your output. CAPITALIZED WORDS are my placeholders. Fill in my placeholders with your output. Please preserve the overall formatting of my template. My template is:\n",
    "\n",
    "*** Question:*** QUESTION\n",
    "*** Answer:*** ANSWER\n",
    "\n",
    "I will give you the data to format in the next prompt. Create three questions using my template.\n",
    "\"\"\")\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                              input_variables=[\"query\"]\n",
    "                              )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt) \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee225df-4429-4a48-afc9-869b0fc51340",
   "metadata": {},
   "source": [
    "### Apply the following text we just copied from Wikipedia:\n",
    "\n",
    "\n",
    "In machine learning, a neural network (also artificial neural network or neural net, abbreviated ANN or NN) is a model inspired by the structure and function of biological neural networks in animal brains.[1][2]\n",
    "\n",
    "An ANN consists of connected units or nodes called artificial neurons, which loosely model the neurons in a brain. These are connected by edges, which model the synapses in a brain. Each artificial neuron receives signals from connected neurons, then processes them and sends a signal to other connected neurons. The \"signal\" is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs, called the activation function. The strength of the signal at each connection is determined by a weight, which adjusts during the learning process.\n",
    "\n",
    "Typically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly passing through multiple intermediate layers (hidden layers). A network is typically called a deep neural network if it has at least 2 hidden layers.[3]\n",
    "\n",
    "Artificial neural networks are used for various tasks, including predictive modeling, adaptive control, and solving problems in artificial intelligence. They can learn from experience, and can derive conclusions from a complex and seemingly unrelated set of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0883a7f4-b18b-44d6-8e69-603dd3555640",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"In machine learning, a neural network (also artificial neural network or neural net, abbreviated ANN or NN) is a model inspired by the structure and function of biological neural networks in animal brains.[1][2]\n",
    "\n",
    "An ANN consists of connected units or nodes called artificial neurons, which loosely model the neurons in a brain. These are connected by edges, which model the synapses in a brain. Each artificial neuron receives signals from connected neurons, then processes them and sends a signal to other connected neurons. The \"signal\" is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs, called the activation function. The strength of the signal at each connection is determined by a weight, which adjusts during the learning process.\n",
    "\n",
    "Typically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly passing through multiple intermediate layers (hidden layers). A network is typically called a deep neural network if it has at least 2 hidden layers.[3]\n",
    "\n",
    "Artificial neural networks are used for various tasks, including predictive modeling, adaptive control, and solving problems in artificial intelligence. They can learn from experience, and can derive conclusions from a complex and seemingly unrelated set of information.\"\"\"\n",
    "\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": query})\n",
    "\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e73e6fb-a95d-4a75-ac07-e38a651784d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e71861f-70cc-4aad-b682-5a7cd2423135",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c61a600-8c35-4736-b65e-8d41fee222ad",
   "metadata": {},
   "source": [
    "### It looks promising, \n",
    "\n",
    "but it's not quite ready for production. We need to ensure that we can extract the results with minimal extra effort."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a05a78-b082-4ace-8005-0e3a2bdece14",
   "metadata": {},
   "source": [
    "### 1. Importing Necessary Classes (導入必要的類):\n",
    "\n",
    "- StructuredOutputParser and ResponseSchema are imported from langchain.output_parsers.\n",
    "- 從 langchain.output_parsers 導入 StructuredOutputParser 和 ResponseSchema。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c680e103-d653-4f2d-b5fa-109285881cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a1f896-4fee-423b-84bc-1bd842f62e79",
   "metadata": {},
   "source": [
    "### 2. Defining Response Schemas (定義回應結構):\n",
    "\n",
    "- A list named response_schemas is created, which contains instances of ResponseSchema. ResponseSchema has two attributes:\n",
    "    - name: This is the key used to retrieve the output.\n",
    "    - description: This is part of the prompt that describes what the output should be.\n",
    "\n",
    "<br>\n",
    "\n",
    "- 創建一個名為 response_schemas 的列表，包含 ResponseSchema 的實例。ResponseSchema 有兩個屬性：\n",
    "    - name：用於檢索輸出的鍵。\n",
    "    - description：提示的一部分，用於描述輸出應該是什麼。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0123f5d-4f67-4d0e-9d16-e8a51f4d424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schemas = [\n",
    "        ResponseSchema(name=\"result\", description=\"The result as a python list of python dictionaries\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d3a04b-3004-4360-88c8-a51743b4fe1c",
   "metadata": {},
   "source": [
    "### 3. Creating the Output Parser (創建輸出解析器):\n",
    "\n",
    "- output_parser is created by calling StructuredOutputParser.from_response_schemas with the response_schemas list.\n",
    "- This parser uses the defined schemas to understand and structure the output.\n",
    "\n",
    "- 通過調用 StructuredOutputParser.from_response_schemas 並傳入 response_schemas 列表來創建 output_parser。\n",
    "- 該解析器使用定義的結構來理解和結構化輸出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad0c5b2-c990-4069-aa5d-fcfafee72792",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690df7a6-d947-408a-b0f5-d34f0cad52ed",
   "metadata": {},
   "source": [
    "### 4. Generating Format Instructions (生成格式說明):\n",
    "\n",
    "- format_instructions is generated by calling output_parser.get_format_instructions().\n",
    "- These instructions specify how the output should be formatted, based on the defined schemas.\n",
    "<br>\n",
    "<br>\n",
    "- 通過調用 output_parser.get_format_instructions() 來生成 format_instructions。\n",
    "- 這些說明根據定義的結構指定輸出的格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b00293-02b2-4553-b18a-006066418577",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa6c36f-f730-4914-8281-b33e54986bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aa9541-12a9-4475-a8c0-894e919ba374",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = PromptTemplate.from_template(\"\"\"\n",
    "I am going to give you a template for your output. CAPITALIZED WORDS are my placeholders. Fill in my placeholders with your output. \n",
    "Please preserve the overall formatting of my template. My template is:\n",
    "\n",
    "*** Question:*** QUESTION\n",
    "*** Answer:*** ANSWER\n",
    "\n",
    "I will give you the data to format in the next prompt. Create three questions using my template.\n",
    "\"\"\")\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}; format instruction: {format_instructions}',\n",
    "                              input_variables=[\"query\"],\n",
    "                              partial_variables={'format_instructions': format_instructions}\n",
    "                              )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt) \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b7d3c1-b20c-43c3-87a1-1d85c31215c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt.invoke({\"query\": query})\n",
    "\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d909fc05-ab40-422f-b207-e4f685dc4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb68c2a-2f4d-4283-a665-b0d2214eed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser.parse(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306dc9d1-049d-4da3-b61e-aa70dda0f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output = output_parser.parse(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66728cb-273d-428b-bdd6-48f9d96e85c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4516956f-1a19-45c8-9fe2-b95f99e704e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output['result'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5470e0c-8e29-4fcc-b0ea-3dc741b259e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output['result'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a651aee-b7a2-490b-bd8e-40b90ea5534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output['result'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8258122-103b-4b14-9659-0a1da452eb93",
   "metadata": {},
   "source": [
    "Now you can write a simple for loop for the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb0d1f7-0790-425b-b7a8-8930204705fb",
   "metadata": {},
   "source": [
    "# Okapi BM25 Retrieval System\n",
    "\n",
    "- Purpose: Okapi BM25 helps find the most relevant documents when you search for something.\n",
    "\n",
    "- 目的: Okapi BM25 幫助找到當你搜索某些內容時最相關的文檔。\n",
    "\n",
    "- Documents and Words:\n",
    "\n",
    "    - Imagine you have a bunch of books (documents).\n",
    "    - Each book has many words.\n",
    "\n",
    "- 文檔和詞語:\n",
    "    \n",
    "    - 想像你有一堆書（文檔）。\n",
    "    - 每本書都有很多詞語。\n",
    "\n",
    "- Search Query:\n",
    "\n",
    "    - When you search, you type in a few words (your query).\n",
    "\n",
    "- 搜索查詢:\n",
    "\n",
    "    - 當你搜索時，你會輸入幾個詞語（你的查詢）。\n",
    "\n",
    "- Scoring System:\n",
    "\n",
    "    - Okapi BM25 gives each book a score based on how well it matches your query.\n",
    "\n",
    "- 評分系統:\n",
    "\n",
    "    - Okapi BM25 根據每本書與你的查詢匹配的程度給予每本書一個分數。\n",
    "\n",
    "- Factors for Scoring:\n",
    "\n",
    "    - Term Frequency: If a word from your query appears many times in a book, that book gets a higher score.\n",
    "    - Inverse Document Frequency: If a word is rare across all books but appears in a book, that book gets a higher score.\n",
    "    - Document Length: Longer books get adjusted so they aren't unfairly scored just because they're long.\n",
    "\n",
    "- 評分因素:\n",
    "\n",
    "    - 詞頻: 如果你的查詢中的一個詞在某本書中出現很多次，該書會得到更高的分數。\n",
    "    - 逆文檔頻率: 如果一個詞在所有書中都很稀有，但在某本書中出現，該書會得到更高的分數。\n",
    "    - 文檔長度: 較長的書會進行調整，這樣它們不會僅因為篇幅長而被不公平地評分。\n",
    "\n",
    "- Formula:\n",
    "\n",
    "    - BM25 uses a mathematical formula to combine these factors and calculate the score.\n",
    "\n",
    "- 公式:\n",
    "\n",
    "    -BM25 使用一個數學公式來結合這些因素並計算分數。\n",
    "\n",
    "- Choosing the Best:\n",
    "\n",
    "    - The books with the highest scores are considered the most relevant to your query.\n",
    "\n",
    "- 選擇最佳:\n",
    "\n",
    "    - 分數最高的書被認為是與你的查詢最相關的。\n",
    "\n",
    "- Results:\n",
    "\n",
    "    - These top-scoring books are then shown to you as the search results.\n",
    "\n",
    "- 結果:\n",
    "\n",
    "    - 這些高分書會作為搜索結果顯示給你。\n",
    "\n",
    "Think of it like this: Okapi BM25 is a smart librarian that knows which books are likely to be the most interesting and helpful based on the words you use in your search.\n",
    "\n",
    "想像一下：Okapi BM25 就像是一個聰明的圖書管理員，它根據你在搜索中使用的詞語來判斷哪些書可能是最有趣和最有幫助的。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bfba32-6cdb-448b-831b-528f6ba673ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rank_bm25==0.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7421cbc-2b35-43ce-854e-911e204040fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa46a39-1500-4223-9de3-7ddd34256ed1",
   "metadata": {},
   "source": [
    "### 1. Reading Training Data (讀取訓練數據):\n",
    "\n",
    "- The code opens a JSON file named recipe_train.json located in the 'tutorial/Week-1' directory within the project directory.\n",
    "- It reads the contents of this file and loads it into a variable called recipe_train.\n",
    "\n",
    "- 該代碼打開位於項目目錄內 'tutorial/Week-1' 目錄中的名為 recipe_train.json 的 JSON 文件。\n",
    "- 它讀取該文件的內容並加載到變量 recipe_train 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df16b07-cd60-4d4d-80ef-a366b66ac9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(get_project_dir(), 'tutorial', 'Week-1', 'recipe_train.json'), 'r') as f:\n",
    "    recipe_train = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f81b7b-936a-4693-85d6-64ba7694cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97969ad6-95ce-49bd-8cfc-84cfb9d11173",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Tokenizing the Corpus (對語料庫進行分詞):\n",
    "\n",
    "- An empty list tokenized_corpus is created.\n",
    "- For each recipe in recipe_train, the 'ingredients' field is extracted and appended to the tokenized_corpus.\n",
    "\n",
    "- 創建一個空列表 tokenized_corpus。\n",
    "- 對於 recipe_train 中的每個食譜，提取 'ingredients' 字段並將其附加到 tokenized_corpus 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d6e335-a9c6-427e-840a-c2fffb19d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = []\n",
    "\n",
    "for recipe in recipe_train:\n",
    "    tokenized_corpus.append(recipe['ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c9779a-ff3b-4e3e-9b23-89a925fbb21f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_corpus[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3679acce-7faa-4a67-8b00-a6662c6938be",
   "metadata": {},
   "source": [
    "### 3. Initializing BM25 (初始化 BM25):\n",
    "\n",
    "- BM25Okapi is initialized with the tokenized_corpus. This sets up the BM25 model for scoring documents based on query relevance.\n",
    "\n",
    "- 使用 tokenized_corpus 初始化 BM25Okapi。這設置了 BM25 模型，用於基於查詢相關性對文檔進行打分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d72a841-66ec-41ff-9007-6c021ab6bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8212b863-88b8-4bbd-8a3c-de6de33593c0",
   "metadata": {},
   "source": [
    "### 4. Reading Test Data:\n",
    "\n",
    "- Another JSON file named recipe_test.json is opened from the same directory.\n",
    "- The contents are loaded into a variable called recipe_test.\n",
    "\n",
    "- 從相同目錄中打開另一個名為 recipe_test.json 的 JSON 文件。\n",
    "- 將內容加載到變量 recipe_test 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4e501e-aeeb-4b77-add6-c53647b4d800",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(get_project_dir(), 'tutorial', 'Week-1', 'recipe_test.json'), 'r') as f:\n",
    "    recipe_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f9eaf-609e-4f01-a91f-cdc9f910a2ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recipe_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a122c-a99d-42f4-b38d-b100fd3f92c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_test[0]['ingredients']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8948b4c6-5d61-4d0c-85fa-f55f5aa6d121",
   "metadata": {},
   "source": [
    "### 5. Getting Top N Results (獲取排名前 N 的結果):\n",
    "\n",
    "- The BM25 model is used to find the top 3 most relevant recipes from recipe_train based on the 'ingredients' in the first recipe of recipe_test.\n",
    "- The get_top_n method returns the top 3 recipes that are most relevant to the query.\n",
    "\n",
    "- 使用 BM25 模型找到 recipe_train 中基於 recipe_test 的第一個食譜的 'ingredients' 最相關的前三個食譜。\n",
    "- get_top_n 方法返回與查詢最相關的前三個食譜。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86071b0-8d64-4f9d-85d0-10a3bc5f90e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25.get_top_n(recipe_test[0]['ingredients'], recipe_train, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221ad58d-9560-41d7-8673-616e481cdc97",
   "metadata": {},
   "source": [
    "## Okapa25 in LangChain\n",
    "\n",
    "https://api.python.langchain.com/en/latest/_modules/langchain_community/retrievers/bm25.html#BM25Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38bd70b-a358-4785-95fa-44c99f0ae248",
   "metadata": {},
   "source": [
    "### 1. Importing Necessary Modules (導入必要的模塊):\n",
    "\n",
    "- The code imports BM25Retriever from langchain_community.retrievers and Document from langchain.docstore.document.\n",
    "- 從 langchain_community.retrievers 導入 BM25Retriever，從 langchain.docstore.document 導入 Document。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3090aea2-6d44-4c2c-9469-34f55b747c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b6a831-22ef-414c-9842-dc65d06419dd",
   "metadata": {},
   "source": [
    "### 2. Creating Documents from Training Data (從訓練數據創建文檔):\n",
    "\n",
    "- An empty list documents is initialized to store instances of Document.\n",
    "- A loop iterates through each recipe in recipe_train.\n",
    "- For each recipe, a Document object is created:\n",
    "    - page_content is set to a string composed of all ingredients joined by commas.\n",
    "    - metadata includes additional information such as 'cuisine' and 'id' from the recipe.\n",
    "- Each Document instance is appended to the documents list.\n",
    "\n",
    "<br>\n",
    "\n",
    "- 初始化一個空列表 documents，用於儲存 Document 的實例。\n",
    "- 循環遍歷 recipe_train 中個每個食譜中。\n",
    "- 對於每個食譜，創建一個 Document 對象：\n",
    "    - page_content 設置為由所有食材用逗號連接而成的字符串。\n",
    "    - metadata 包含額外的信息，如食譜中的 'cuisine' 和 'id'。\n",
    "- 將每個 Document 實例追加到 documents 列表中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789e412f-7cc1-4a55-bcf7-2321b46cf69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for recipe in recipe_train:\n",
    "    document = Document(page_content=\", \".join(recipe['ingredients']),\n",
    "                        metadata={\"cuisine\": recipe['cuisine'],\n",
    "                                  \"id\": recipe['id']})\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ae865b-8a4d-4edf-a79b-ec1131bc4974",
   "metadata": {},
   "source": [
    "### 3. Initializing BM25Retriever (初始化 BM25Retriever):\n",
    "\n",
    "- BM25Retriever.from_documents initializes an instance of BM25Retriever using the documents list.\n",
    "- Parameters:\n",
    "    - k=2: Specifies the number of documents to retrieve per query.\n",
    "    - bm25_params={\"k1\": 2.5}: Sets specific BM25 parameters (k1 parameter set to 2.5).\n",
    "    \n",
    "- 使用 BM25Retriever.from_documents 方法，利用 documents 列表初始化了一个 BM25Retriever 實例。\n",
    "- 參數:\n",
    "    - k=2：指定每個查詢要檢索的文檔數量。\n",
    "    - bm25_params={\"k1\": 2.5}：設置特定的 BM25 參數（設置 k1 參數為 2.5）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965af220-073d-40fd-9e83-70e3cd96d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(documents, k=2, bm25_params={\"k1\":2.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f278753-e468-4605-9fcb-18761872051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \", \".join(recipe_test[0]['ingredients'])\n",
    "\n",
    "output = bm25_retriever.invoke(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a3adc6-529b-4534-8f2a-a6504c7244aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bb86a1-0125-4521-9d48-8bf72777cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968f8861-ef45-4bb6-8f7b-108ce055d98b",
   "metadata": {},
   "source": [
    "# Wikipedia Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ddbe9-374a-4f42-8a0a-e76f4d8f8409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade --quiet  wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325d56f0-bc4a-40ad-8b45-55bc24d4c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "\n",
    "wiki_retriever = WikipediaRetriever()\n",
    "\n",
    "docs = wiki_retriever.invoke(\"HUNTER X HUNTER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8e184a-bf82-4687-acd3-ee28ccf3890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d145bd2-875d-4f0b-8bfc-1fff44c9a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 若是少於給定返回數量，則返回當前所有可得到文件\n",
    "\n",
    "docs = wiki_retriever.invoke(\"rice\")\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98333101-de37-4203-9f2f-c9a42db21473",
   "metadata": {},
   "outputs": [],
   "source": [
    "WikipediaRetriever?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d4f34-9d99-47ba-9f08-48ac5feb4a76",
   "metadata": {},
   "source": [
    "By default, wikipedia retriever returns 3 documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712d4f6f-12c5-4ef2-a92f-aec594002d76",
   "metadata": {},
   "source": [
    "# Ensemble Retriever\n",
    "\n",
    "- The EnsembleRetriever uses different search tools together to find the best answers.\n",
    "- It combines results from these tools and organizes them using a special method.\n",
    "- By using different tools, it works better than just one tool alone.\n",
    "- Usually, it mixes two types of search: one that looks for exact words (like BM25) and one that understands meanings (like embeddings).\n",
    "- This mix is called \"hybrid search.\"\n",
    "- The first tool finds documents with specific words, and the second finds documents that have similar ideas.\n",
    "\n",
    "<br>\n",
    "\n",
    "- 它結合這些工具的結果並使用特殊方法進行組織。\n",
    "- 通過使用不同的工具，它比僅使用單一工具效果更好。\n",
    "- 通常，它結合兩種類型的搜索：一種尋找精確詞語（例如 BM25），另一種理解含義（例如嵌入式）。\n",
    "- 這種混合稱為 \"混合搜索\"。\n",
    "- 第一種工具尋找具有特定詞語的文檔，而第二種工具則尋找具有相似思想的文檔。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d36f78a-b55a-4e40-ab9c-9ea2151a5c38",
   "metadata": {},
   "source": [
    "- weights: 控制權重\n",
    "- 總返回文件數量等於個別檢索器 (retriever) 檢索文件數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599b51aa-9c1b-4e4b-839f-9fb0bdac182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, wiki_retriever], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb3e2a-8efa-47a0-a682-574adbd1f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ensemble_retriever.invoke(\"rice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef0492-cf23-4c52-9685-a7860ba645e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91847b0e-ef31-45da-88da-a93888cd0093",
   "metadata": {},
   "source": [
    "- bm25_retriever 返回兩份\n",
    "- wiki_retriever 返回兩份"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33749100-3ad0-489b-882d-40a0b41232c2",
   "metadata": {},
   "source": [
    "# Runtime Configuration (運行時配置)\n",
    "\n",
    "- We can also configure the retrievers at runtime. In order to do this, we need to mark the fields as configurable\n",
    "- 我們也可以在運行時配置檢索器。為了做到這一點，我們需要將字段標記為可配置的。\n",
    "\n",
    "If this is too complicated, leave it. Someday when you are more proficient with LangChain and you need better control over your pipeline, you can come back to this. \n",
    "\n",
    "API Reference: https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.utils.ConfigurableField.htmld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2301ed88-4894-4c32-9e1c-a0291e192f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d883448-92c9-4a36-a4bd-20f73a755c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(documents, k=2, bm25_params={\"k1\": 1}).configurable_fields( \\\n",
    "    k=ConfigurableField(\n",
    "        id=\"bm25_k\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f102aaad-9bf8-42a1-be3d-bc054b3c5c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, wiki_retriever], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f5977c-e120-4f36-b227-262f2add9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"bm25_k\": 5}}\n",
    "docs = ensemble_retriever.invoke(\"rice\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51851ea0-c12e-42bb-b1cf-3e57314e15ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb7982d-f1cb-4036-9317-dd7f96c5836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "- bm25_retriever 返回五份\n",
    "- wiki_retriever 返回兩份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792ac2d5-2284-426d-8894-c9aec4849a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, wiki_retriever], weights=[0.1, 0.9]\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"bm25_k\": 10}}\n",
    "docs = ensemble_retriever.invoke(\"rice\", config=config)\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c45ab-899b-4d21-9f57-7939f79fa4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "- bm25_retriever 返回十份\n",
    "- wiki_retriever 返回兩份"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b59b49-6c02-42a5-b93c-c7126ab2f2e3",
   "metadata": {},
   "source": [
    "## 作業\n",
    "\n",
    "1. 用材料搜尋食譜材料\n",
    "2. 給予某食譜材料，自動生成詳細的食譜內容\n",
    "3. 把食譜內容從英文轉換成中文\n",
    "4. 分離製作方式和使用的食材份量\n",
    "\n",
    "For example:\n",
    "\n",
    "Current ingredient: ['olive oil', 'balsamic vinegar', 'toasted pine nuts', 'kosher salt', 'golden raisins', 'part-skim ricotta cheese', 'grated parmesan cheese', 'baby spinach', 'fresh basil leaves', 'pepper', 'fusilli', 'scallions']\n",
    "\n",
    "根據Okapi25得到某一個食譜\n",
    "\n",
    "將得到的食譜轉換成詳細製作方法:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59d3efb-7466-4799-a6dc-86dfa5f2d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Based on the ingredients you have and the ingredients listed for the recipe, it seems you're aiming to create a dish that combines elements of a pasta salad with a seafood twist. The recipe ingredients suggest a lighter, seafood-focused dish, possibly a crab salad with a lemon-olive oil dressing. However, your current ingredients lean more towards a Mediterranean-inspired pasta dish. \n",
    "\n",
    "To bridge the gap between what you have and the intended recipe, here are the missing ingredients and a suggestion on how to incorporate both sets into a delightful dish:\n",
    "\n",
    "### Missing Ingredients:\n",
    "1. **Baby Greens** - You have baby spinach, which can work as a substitute, adding a similar fresh, leafy component.\n",
    "2. **Flat Leaf Parsley** - This herb would add freshness and a slight peppery note. You have fresh basil, which can provide a different but complementary herbal note.\n",
    "3. **Crabmeat** - This is a significant missing ingredient, as it's the protein component in the recipe. If you cannot obtain crabmeat, you might consider another type of seafood if you're aiming for a seafood dish, or simply focus on a vegetarian option with the ingredients at hand.\n",
    "4. **Fresh Lemon Juice** - This would add acidity and brightness to the dish. You have balsamic vinegar, which also adds acidity but with a sweeter, more complex flavor profile. While not a direct substitute, it can still contribute a pleasant tanginess.\n",
    "\n",
    "### Suggested Dish: Mediterranean Fusilli with Spinach, Pine Nuts, and Ricotta\n",
    "\n",
    "Given your current ingredients, here's a dish you could create:\n",
    "\n",
    "#### Ingredients:\n",
    "- Olive oil\n",
    "- Balsamic vinegar (in place of lemon juice for dressing)\n",
    "- Toasted pine nuts\n",
    "- Kosher salt\n",
    "- Golden raisins\n",
    "- Part-skim ricotta cheese\n",
    "- Grated parmesan cheese\n",
    "- Baby spinach (in place of baby greens)\n",
    "- Fresh basil leaves (instead of flat leaf parsley)\n",
    "- Pepper\n",
    "- Fusilli\n",
    "- Scallions\n",
    "\n",
    "#### Directions:\n",
    "1. **Cook the Fusilli:** Boil the fusilli according to package instructions until al dente. Drain and set aside to cool slightly.\n",
    "2. **Make the Dressing:** Whisk together olive oil, balsamic vinegar, salt, and pepper to taste. Adjust the balance according to your preference.\n",
    "3. **Combine the Ingredients:** In a large bowl, combine the cooked fusilli, toasted pine nuts, golden raisins, chopped scallions, torn baby spinach, and roughly chopped fresh basil leaves. If you have any other fresh vegetables or herbs you'd like to add, feel free to include them.\n",
    "4. **Add Cheese:** Fold in part-skim ricotta cheese and sprinkle grated parmesan over the top. The ricotta adds creaminess, while the parmesan brings a salty, umami depth.\n",
    "5. **Finish and Serve:** Drizzle the dressing over the salad and gently toss to combine. Serve at room temperature or chilled, as preferred.\n",
    "\n",
    "This dish takes a creative turn from the original recipe's intention but utilizes the ingredients you have to create a flavorful, satisfying meal that's perfect for a light lunch or a side dish at dinner.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
